{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"The Hands-on AI Cookbook","text":"<p>Curated by James Gray</p> <p>I built this open-source cookbook because I believe AI knowledge should be free and open to everyone. The best gift I can give is helping people accelerate to their full potential \u2014 bringing the future forward.</p> <p>Practical guides, patterns, ready-made tools, and direct answers \u2014 everything you need to move from experimenting with AI to getting real results. Browse by platform, look up a topic, or work through a structured course.</p> <p>Master AI. Master yourself. Build what matters. That's what Graymatter is about \u2014 a free weekly newsletter with how-to videos, hands-on walkthroughs, and lessons from building in the open.</p>"},{"location":"#browse-the-cookbook","title":"Browse the Cookbook","text":"<ul> <li> <p> Platforms</p> <p>Setup guides, topics, and Q&amp;A organized by platform \u2014 Claude, ChatGPT, Gemini, and Copilot</p> <p> Choose your platform</p> </li> <li> <p> Agentic Building Blocks</p> <p>The seven components of every AI workflow \u2014 models, prompts, context, projects, skills, agents, and MCP</p> <p> Building blocks</p> </li> <li> <p> AI Engineering</p> <p>Practices for designing and optimizing AI systems \u2014 starting with context engineering</p> <p> Explore practices</p> </li> <li> <p> Use Cases</p> <p>Six primitives that cover what teams build with AI \u2014 content creation, research, coding, data analysis, ideation, and automation</p> <p> Explore use cases</p> </li> <li> <p> Builder Setup</p> <p>Essential tools for your AI builder workflow \u2014 terminal, Git, editor, Claude Code, and more</p> <p> Set up your stack</p> </li> <li> <p> Use the Cookbook</p> <p>Ask the cookbook for instant answers, install pre-built plugins, or join a live cohort course</p> <p> Get started</p> </li> <li> <p> Courses</p> <p>Prefer structured learning? Live cohort courses that walk you through it step by step</p> <p> Browse courses</p> </li> </ul> <p>If something here saved you time, sparked an idea, or helped you move faster \u2014 I'd love to hear about it.</p> <p>Share what you built Share on LinkedIn </p> <p>See What People Built with the cookbook.</p>"},{"location":"#quick-links","title":"Quick Links","text":"I want to... Go here Set up Claude Code Installation Guide Understand system prompts What is a system prompt? Schedule AI agents Scheduling Subagents Set up Git and GitHub Git Installation Learn the seven AI building blocks Agentic Building Blocks Explore AI use cases by type Use Case Primitives Install Claude Code plugins Plugin Marketplace Take a structured course Courses Read the latest blog posts Blog See recent updates What's New"},{"location":"#about","title":"About","text":"<p>I'm James Gray. I teach hands-on AI courses on Maven and write about applied AI at Graymatter.</p> <p>This is a living resource \u2014 new guides, tools, and answers are added regularly.</p> <p>LinkedIn \u00b7 Substack \u00b7 Website \u00b7 GitHub</p>"},{"location":"#contributing","title":"Contributing","text":"<p>This is an open-source project. See Contributing Guidelines to add content or suggest improvements.</p>"},{"location":"CONTRIBUTING/","title":"Contributing to Hands-On AI","text":"<p>Thank you for contributing to Hands-On AI! This guide explains how to add new content.</p>"},{"location":"CONTRIBUTING/#site-structure","title":"Site Structure","text":"Section Location Purpose Agentic Building Blocks <code>agentic-building-blocks/</code> The seven AI building blocks (Model, Prompts, Context, Projects, Skills, Agents, MCP) Business-First AI Framework <code>business-first-ai-framework/</code> Three-phase methodology (Discover, Deconstruct, Build) Use Cases <code>use-cases/</code> Six use case primitives (Content Creation, Research, Coding, Data Analysis, Ideation &amp; Strategy, Automation) Platforms <code>platforms/</code> Platform-specific content (Claude, OpenAI, Gemini, M365 Copilot) Builder Setup <code>builder-setup/</code> Tool setup and installation guides Patterns <code>patterns/</code> Document reusable approaches Courses <code>courses/</code> Structured learning paths (course-specific)"},{"location":"CONTRIBUTING/#content-types-and-templates","title":"Content Types and Templates","text":"Type Template Question (AEO) question-template.md How-To Guide how-to-template.md Topic topic-template.md Pattern Use topic template Troubleshooting Use how-to template"},{"location":"CONTRIBUTING/#adding-a-question-aeo-optimized","title":"Adding a Question (AEO-Optimized)","text":"<p>Questions are optimized for Answer Engine Optimization (AEO) - making content easily extractable by AI systems like ChatGPT, Perplexity, and Google AI Overviews.</p>"},{"location":"CONTRIBUTING/#why-questions","title":"Why Questions?","text":"<ul> <li>One question per page - Each file answers one specific question</li> <li>Lead with the answer - Short answer appears in the first 100 words</li> <li>Easy AI extraction - Consistent, predictable format</li> <li>Clear URL structure - <code>/questions/how-do-i-handle-rate-limits/</code></li> </ul>"},{"location":"CONTRIBUTING/#how-to-add-a-question","title":"How to Add a Question","text":"<ol> <li>Copy <code>_templates/question-template.md</code> to the appropriate subdirectory (e.g., <code>agentic-building-blocks/prompts/questions/</code> or <code>platforms/claude/questions/</code>)</li> <li>Name the file as a URL-friendly version of the question: <code>how-do-i-handle-rate-limits.md</code></li> <li>Fill in all sections:</li> <li>YAML frontmatter - Machine-readable metadata (includes <code>short_answer</code> for JSON-LD schema)</li> <li>Question as H1 - The exact question being answered</li> <li>Short answer - 1-2 sentence direct answer (keep identical to frontmatter <code>short_answer</code>)</li> <li>Full answer - 2-4 paragraphs of detailed explanation</li> <li>Code example - Working, practical implementation</li> <li>Key takeaways - 3-5 bullet points</li> <li>Related questions - Links to related Q&amp;A</li> <li>Add a link to the appropriate category's README.md index</li> </ol>"},{"location":"CONTRIBUTING/#question-naming-convention","title":"Question Naming Convention","text":"<ul> <li>Use lowercase with hyphens: <code>how-do-i-write-system-prompts.md</code></li> <li>Frame as a question: <code>what-is-</code>, <code>how-do-i-</code>, <code>why-does-</code>, <code>when-should-i-</code></li> <li>Be specific: <code>how-do-i-handle-openai-rate-limits.md</code> not <code>rate-limits.md</code></li> </ul>"},{"location":"CONTRIBUTING/#question-template-structure","title":"Question Template Structure","text":"<pre><code>---\nquestion: \"How do I handle rate limits?\"\nshort_answer: \"Implement exponential backoff with jitter, and use the retry-after header.\"\nplatforms: [openai]\ntopic: integrations\ndate: 2026-01-24\nauthor: Your Name\n---\n\n# How do I handle rate limits?\n\n**Short answer:** [1-2 sentence direct answer]\n\n## The Full Answer\n[2-4 paragraphs]\n\n## Code Example\n[Working code]\n\n## Key Takeaways\n- Bullet points\n\n## Related Questions\n- Links to related Q&amp;A\n</code></pre>"},{"location":"CONTRIBUTING/#adding-a-how-to-guide","title":"Adding a How-To Guide","text":"<ol> <li>Copy <code>_templates/how-to-template.md</code> to the appropriate subdirectory under the relevant section</li> <li>Name the file descriptively: <code>stream-responses.md</code>, <code>handle-rate-limits.md</code></li> <li>Fill in all sections of the template</li> <li>Add a link to the section's README.md index</li> <li>Add platform tags to help readers find relevant content</li> </ol>"},{"location":"CONTRIBUTING/#how-to-naming-convention","title":"How-To Naming Convention","text":"<ul> <li>Use lowercase with hyphens: <code>my-guide-name.md</code></li> <li>Start with a verb when possible: <code>configure-</code>, <code>handle-</code>, <code>implement-</code></li> <li>Be specific: <code>stream-openai-responses.md</code> not <code>streaming.md</code></li> </ul>"},{"location":"CONTRIBUTING/#adding-a-topic","title":"Adding a Topic","text":"<ol> <li>Copy <code>_templates/topic-template.md</code> to the appropriate subdirectory in <code>topics/</code></li> <li>Name the file after the concept: <code>function-calling.md</code>, <code>context-windows.md</code></li> <li>Fill in all sections of the template</li> <li>Add a link to the section's README.md index</li> </ol>"},{"location":"CONTRIBUTING/#topic-naming-convention","title":"Topic Naming Convention","text":"<ul> <li>Use lowercase with hyphens: <code>my-topic-name.md</code></li> <li>Use nouns or noun phrases: <code>prompt-caching.md</code>, <code>tool-use-basics.md</code></li> </ul>"},{"location":"CONTRIBUTING/#writing-guidelines","title":"Writing Guidelines","text":""},{"location":"CONTRIBUTING/#be-practical","title":"Be Practical","text":"<ul> <li>Include working code examples</li> <li>Show real-world use cases</li> <li>Mention common pitfalls</li> </ul>"},{"location":"CONTRIBUTING/#be-specific","title":"Be Specific","text":"<ul> <li>State which platforms/models apply</li> <li>Include version numbers when relevant</li> <li>Note any prerequisites</li> </ul>"},{"location":"CONTRIBUTING/#be-concise","title":"Be Concise","text":"<ul> <li>Get to the point quickly</li> <li>Use bullet points for lists</li> <li>Keep code examples minimal but complete</li> </ul>"},{"location":"CONTRIBUTING/#platform-tags","title":"Platform Tags","text":"<p>Use these tags to indicate which platforms a guide applies to:</p> <ul> <li><code>openai</code> - OpenAI GPT models and APIs</li> <li><code>claude</code> - Anthropic Claude models</li> <li><code>gemini</code> - Google Gemini models</li> <li><code>m365-copilot</code> - Microsoft 365 Copilot</li> <li><code>all</code> - Applies to all platforms</li> </ul>"},{"location":"CONTRIBUTING/#updating-indexes","title":"Updating Indexes","text":"<p>When you add a new file, update the README.md in that section to include a link:</p> <pre><code>## Guides\n\n- [How to Stream Responses](./stream-responses.md) - `openai` `claude`\n- [How to Handle Rate Limits](./handle-rate-limits.md) - `all`\n</code></pre>"},{"location":"CONTRIBUTING/#adding-setup-guides","title":"Adding Setup Guides","text":"<p>Setup guides go in <code>getting-started/</code> and should:</p> <ol> <li>Focus on one tool per guide</li> <li>Include prerequisites</li> <li>Provide platform-specific instructions (macOS/Windows)</li> <li>Link to official documentation</li> <li>Include troubleshooting tips</li> </ol>"},{"location":"CONTRIBUTING/#questions","title":"Questions?","text":"<p>If you're unsure where something belongs or how to structure it, check existing entries for examples.</p>"},{"location":"CONTRIBUTING/#about-this-site","title":"About This Site","text":"<p>Hands-On AI is maintained by James Gray. It consolidates setup guides, course materials, and AI reference content from multiple repositories into one resource.</p>"},{"location":"what-people-built/","title":"What People Built","text":"<p>This page is for the people doing the work \u2014 applying AI to real problems and shipping real results. If you used something from this cookbook to build a workflow, automate a process, or just move faster, your story belongs here.</p>"},{"location":"what-people-built/#stories","title":"Stories","text":"<p>As stories come in, they'll appear here. Be the first!</p>"},{"location":"what-people-built/#share-what-you-built","title":"Share what you built","text":"<p>Used the cookbook to build something? Tell us about it \u2014 takes less than a minute.</p> <p>Share what you built Share on LinkedIn </p>"},{"location":"whats-new/","title":"What's New","text":"<p>Recent updates to the Hands-on AI Cookbook. This page is generated automatically from GitHub Releases \u2014 subscribe to the repo or check back here to stay current.</p>"},{"location":"whats-new/#week-of-february-8-2026","title":"Week of February 8, 2026","text":"<p>February 9, 2026</p>"},{"location":"whats-new/#new-features","title":"New Features","text":"<ul> <li>Added What's New page infrastructure that automatically displays GitHub releases on the site \u2014 weekly release notes will now appear at handsonai.info/whats-new/</li> <li>Renamed Wall of Love to What People Built and integrated with Notion form for community submissions \u2014 students can now share projects they've built using the Hands-on AI Cookbook</li> </ul>"},{"location":"whats-new/#site-improvements","title":"Site Improvements","text":"<ul> <li>Configured automated weekly release notes generation scheduled for Sunday evenings</li> <li>Enhanced deployment workflow to regenerate What's New page on every push to main</li> <li>Updated <code>llms.txt</code> and <code>llms-full.txt</code> to reflect the new What's New page</li> </ul>"},{"location":"whats-new/#week-of-february-8-2026_1","title":"Week of February 8, 2026","text":"<p>February 8, 2026</p>"},{"location":"whats-new/#new-guides","title":"New Guides","text":"<ul> <li>Added the Builder Stack Setup Guide \u2014 a comprehensive 7-step checklist for installing Terminal, Git, VS Code, Claude Code, AI Registry, and Voice-to-Text tools for hands-free AI workflows</li> <li>Added six Use Case Primitives pages (Content Creation, Research, Coding, Data Analysis, Ideation &amp; Strategy, Automation) \u2014 platform-agnostic guides based on OpenAI's enterprise deployment analysis</li> </ul>"},{"location":"whats-new/#updated-content","title":"Updated Content","text":"<ul> <li>Promoted Agentic Building Blocks to top-level navigation with expanded content for Prompts, Context, Projects, Skills, Agents, and MCP</li> <li>Updated homepage with Graymatter newsletter sign-up section and refined positioning</li> <li>Improved the Business-First AI Framework documentation with clearer terminology and step-by-step workflow guidance</li> <li>Enhanced plugin documentation with Cowork platform support and updated installation instructions</li> <li>Renamed \"AI Assets\" to \"AI Building Blocks\" across all documentation for consistency</li> </ul>"},{"location":"whats-new/#new-features_1","title":"New Features","text":"<ul> <li>Added \"Ask a Question\" feature with Notion form integration for community Q&amp;A</li> <li>Added Wall of Love page showcasing testimonials from the community</li> <li>Added open-source identity and personal CTA sections</li> </ul>"},{"location":"whats-new/#new-plugins-skills","title":"New Plugins &amp; Skills","text":"<ul> <li>Updated Business First AI plugin with enhanced workflow deconstruction capabilities</li> <li>Added AI Registry plugin (v3.0.0) with expanded building blocks registration features</li> </ul>"},{"location":"whats-new/#site-improvements_1","title":"Site Improvements","text":"<ul> <li>Improved navigation structure with \"Step N \u2014\" prefixes in Builder Stack Setup sections</li> <li>Added styled checkboxes to setup guide checklists using <code>pymdownx.tasklist</code> extension</li> <li>Regenerated <code>llms.txt</code> and <code>llms-full.txt</code> to match current site structure</li> <li>Enhanced cross-linking between Use Cases, Building Blocks, Framework, and Plugin documentation</li> </ul> <p>\ud83e\udd16 Generated with Claude Code</p>"},{"location":"_templates/how-to-template/","title":"How to [Action]","text":"<p>Platforms: <code>openai</code> <code>claude</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"_templates/how-to-template/#problem","title":"Problem","text":"<p>Describe the problem the reader is trying to solve. What situation are they in? What are they trying to achieve?</p>"},{"location":"_templates/how-to-template/#prerequisites","title":"Prerequisites","text":"<ul> <li>List what the reader needs before starting</li> <li>Required packages or SDKs</li> <li>API keys or authentication setup</li> <li>Prior knowledge assumed</li> </ul>"},{"location":"_templates/how-to-template/#solution","title":"Solution","text":"<p>Step-by-step instructions to solve the problem.</p>"},{"location":"_templates/how-to-template/#step-1-first-step","title":"Step 1: [First Step]","text":"<p>Explanation of what to do first.</p> <pre><code># Code example for step 1\n</code></pre>"},{"location":"_templates/how-to-template/#step-2-second-step","title":"Step 2: [Second Step]","text":"<p>Explanation of the next step.</p> <pre><code># Code example for step 2\n</code></pre>"},{"location":"_templates/how-to-template/#step-3-third-step","title":"Step 3: [Third Step]","text":"<p>Continue as needed.</p>"},{"location":"_templates/how-to-template/#complete-example","title":"Complete Example","text":"<p>A full, working code example that readers can copy and run.</p> <pre><code># Complete working example\n# Include all necessary imports\n# Add comments explaining key parts\n</code></pre>"},{"location":"_templates/how-to-template/#common-variations","title":"Common Variations","text":"<ul> <li>Variation 1: How to adapt this for a different use case</li> <li>Variation 2: Alternative approach for specific situations</li> </ul>"},{"location":"_templates/how-to-template/#gotchas","title":"Gotchas","text":"<ul> <li>Common mistakes to avoid</li> <li>Edge cases to watch out for</li> <li>Platform-specific quirks</li> </ul>"},{"location":"_templates/how-to-template/#related","title":"Related","text":"<ul> <li>Related How-To</li> <li>Related Topic</li> </ul>"},{"location":"_templates/question-template/","title":"Your question here?","text":"<p>Short answer: Provide a 1-2 sentence direct answer that immediately addresses the question. Keep this identical to the <code>short_answer</code> frontmatter field above.</p>"},{"location":"_templates/question-template/#the-full-answer","title":"The Full Answer","text":"<p>Expand on the short answer with 2-4 paragraphs of detailed explanation. Include:</p> <ul> <li>Context for why this matters</li> <li>The underlying concepts</li> <li>When this applies (and when it doesn't)</li> </ul> <p>Be thorough but focused. Every paragraph should add value toward answering the question.</p>"},{"location":"_templates/question-template/#code-example","title":"Code Example","text":"<pre><code># Working code example that demonstrates the answer\n# Include all necessary imports\n# Add comments explaining key parts\n\ndef example_function():\n    \"\"\"Example showing how to implement the answer.\"\"\"\n    pass\n</code></pre>"},{"location":"_templates/question-template/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>First key point the reader should remember</li> <li>Second key point</li> <li>Third key point (keep to 3-5 bullet points)</li> </ul>"},{"location":"_templates/question-template/#related-questions","title":"Related Questions","text":"<ul> <li>Related question 1?</li> <li>Related question 2?</li> </ul>"},{"location":"_templates/resources-template/","title":"[Topic] Resources","text":"<p>Recommended docs, tutorials, and community links for [topic].</p>"},{"location":"_templates/resources-template/#get-started","title":"Get Started","text":"Resource Description Resource Title Brief description of why it's useful"},{"location":"_templates/resources-template/#documentation","title":"Documentation","text":"Resource Description Resource Title Brief description of why it's useful"},{"location":"_templates/resources-template/#learn","title":"Learn","text":"Resource Description Resource Title Brief description of why it's useful"},{"location":"_templates/resources-template/#developer-resources","title":"Developer Resources","text":"Resource Description Resource Title Brief description of why it's useful"},{"location":"_templates/resources-template/#community","title":"Community","text":"Resource Description Resource Title Brief description of why it's useful"},{"location":"_templates/resources-template/#watch","title":"Watch","text":"Resource Description Resource Title Brief description of why it's useful"},{"location":"_templates/topic-template/","title":"Topic Name","text":"<p>Platforms: <code>openai</code> <code>claude</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"_templates/topic-template/#overview","title":"Overview","text":"<p>A brief introduction to this topic. What is it? Why does it matter? When would someone need to understand this?</p>"},{"location":"_templates/topic-template/#key-concepts","title":"Key Concepts","text":""},{"location":"_templates/topic-template/#concept-1","title":"Concept 1","text":"<p>Explain the first key concept. Use clear, simple language.</p>"},{"location":"_templates/topic-template/#concept-2","title":"Concept 2","text":"<p>Explain the second key concept. Build on previous concepts if needed.</p>"},{"location":"_templates/topic-template/#concept-3","title":"Concept 3","text":"<p>Continue as needed for all important concepts.</p>"},{"location":"_templates/topic-template/#how-it-works","title":"How It Works","text":"<p>Explain the mechanics or underlying process. Use diagrams if helpful.</p> <pre><code>Optional: ASCII diagram or flowchart\n</code></pre>"},{"location":"_templates/topic-template/#examples","title":"Examples","text":""},{"location":"_templates/topic-template/#basic-example","title":"Basic Example","text":"<pre><code># Simple example demonstrating the concept\n</code></pre>"},{"location":"_templates/topic-template/#advanced-example","title":"Advanced Example","text":"<pre><code># More complex example showing real-world usage\n</code></pre>"},{"location":"_templates/topic-template/#platform-differences","title":"Platform Differences","text":"Platform Notes OpenAI Platform-specific details Claude Platform-specific details Gemini Platform-specific details M365 Copilot Platform-specific details"},{"location":"_templates/topic-template/#best-practices","title":"Best Practices","text":"<ul> <li>Do this: Explanation of recommended approach</li> <li>Avoid this: Explanation of anti-pattern</li> <li>Consider: Situational advice</li> </ul>"},{"location":"_templates/topic-template/#common-misconceptions","title":"Common Misconceptions","text":"<ul> <li>Misconception 1: Clarification of what people often get wrong</li> <li>Misconception 2: Another common misunderstanding</li> </ul>"},{"location":"_templates/topic-template/#related","title":"Related","text":""},{"location":"_templates/topic-template/#how-to-guides","title":"How-To Guides","text":"<ul> <li>How to Do X</li> <li>How to Do Y</li> </ul>"},{"location":"_templates/topic-template/#topics","title":"Topics","text":"<ul> <li>Related Topic</li> <li>Another Topic</li> </ul>"},{"location":"_templates/topic-template/#further-reading","title":"Further Reading","text":"<ul> <li>External Resource</li> <li>Official Documentation</li> </ul>"},{"location":"agentic-building-blocks/","title":"Agentic AI Building Blocks","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/#overview","title":"Overview","text":"<p>The seven AI building blocks are a shared vocabulary for describing the components of any AI workflow. Whether you're writing a single prompt or orchestrating a multi-agent pipeline, every AI workflow is assembled from some combination of these seven pieces.</p> <p>The blocks progress from simple to complex:</p> <p>Model \u2192 Prompt \u2192 Context \u2192 Project \u2192 Skill \u2192 Agent \u2192 MCP</p> <p>These are platform-agnostic concepts. Every major AI platform implements them, though the names and interfaces differ. Understanding the blocks gives you a mental model that transfers across tools \u2014 you can evaluate any platform by asking \"how does it handle models, prompts, context, projects, skills, agents, and external connections?\"</p> <p>Using building blocks for workflow analysis</p> <p>The Business-First AI Framework uses these seven blocks as the analysis tool in Design Your AI Workflow, where each step of a workflow gets mapped to the building blocks it needs.</p> <p></p>"},{"location":"agentic-building-blocks/#summary","title":"Summary","text":"Block What It Is Persistence Complexity Model The AI engine that processes inputs and generates outputs Persistent (platform-managed) Foundation Prompt A well-crafted instruction that tells the model what to do Single use Low Context Background information, reference docs, or examples the model needs Per conversation or persistent Low Project A persistent workspace grouping prompts, context, skills, and agents Persistent Medium Skill A reusable routine \u2014 give it inputs, it follows a defined process, it produces consistent outputs Persistent and reusable Medium Agent An autonomous AI that plans, uses tools, and executes multi-step work Session-based or persistent High MCP A connector that lets AI access external tools, services, or databases Persistent High"},{"location":"agentic-building-blocks/#the-seven-building-blocks","title":"The Seven Building Blocks","text":""},{"location":"agentic-building-blocks/#model","title":"Model","text":"<p>The AI engine that processes inputs and generates outputs. Models are trained on data and come in different capability tiers \u2014 from fast, lightweight models for simple tasks to deep reasoning models for complex analysis.</p> <p>Key characteristics:</p> <ul> <li>The foundation all other blocks operate on \u2014 every AI interaction requires a model</li> <li>Come in capability tiers: fast models for speed, reasoning models for depth</li> <li>Have defined context windows and vary by modality (text, code, vision, audio)</li> </ul> <p>When to use it: Every AI interaction uses a model. The key decision is choosing the right model \u2014 matching model capabilities to your task requirements.</p> <p>Example: Using a fast model for high-volume email classification, and a reasoning model for complex strategy analysis that requires nuanced judgment.</p> <p>Cross-platform implementations:</p> Platform How It Works Claude Multiple model tiers (fast, balanced, reasoning); select via model picker or API OpenAI (ChatGPT) Multiple model tiers (fast, balanced, reasoning); select via model picker or API Gemini Multiple model tiers (fast, balanced); select via model picker or API M365 Copilot Models managed by Microsoft; limited user selection <p>Relationship to other blocks: Model is the engine \u2014 prompts steer it, context informs it, skills package routines for it, agents orchestrate it, and MCP connects it to external systems.</p>"},{"location":"agentic-building-blocks/#prompt","title":"Prompt","text":"<p>Instructions you provide to an AI in natural language during a conversation. Prompts are ephemeral, conversational, and reactive \u2014 you provide context and direction in the moment.</p> <p>Key characteristics:</p> <ul> <li>The most fundamental building block \u2014 every AI interaction starts with a prompt</li> <li>Can range from a single sentence to a detailed multi-section instruction</li> <li>Ephemeral by default: conversational and reactive, used in the moment</li> </ul> <p>When to use it: Any time you interact with an AI model. A good prompt is sufficient for many tasks without needing other blocks.</p> <p>Example: \"Summarize this quarterly sales report in three bullet points, highlighting the biggest change from last quarter.\"</p> <p>Cross-platform implementations:</p> Platform How It Works Claude Message in conversation, system prompt, or project instructions OpenAI (ChatGPT) Message in conversation, system prompt, or Custom GPT instructions Gemini Message in conversation or Gem instructions M365 Copilot Message in chat, or prompt within a Copilot agent <p>Relationship to other blocks: Prompts are the foundation \u2014 context enhances them, skills package them for reuse, and agents chain them together.</p>"},{"location":"agentic-building-blocks/#context","title":"Context","text":"<p>Unique knowledge (not in models) required by the agentic workflow for execution. These are information from sources such as docs, databases, and markdown files.</p> <p>Key characteristics:</p> <ul> <li>Provides knowledge the model doesn't have \u2014 your data, your docs, your domain</li> <li>Can be inline (pasted into the conversation), attached as files, or pre-loaded in a project</li> <li>Improves output quality by grounding the model in your specific domain</li> </ul> <p>When to use it: When the model needs information it wasn't trained on \u2014 your company's style guide, a product spec, customer data, or examples of desired output format.</p> <p>Example: Attaching your brand voice guidelines and three sample blog posts before asking the model to draft a new one.</p> <p>Cross-platform implementations:</p> Platform How It Works Claude File attachments, project knowledge base, conversation history OpenAI (ChatGPT) File uploads, Custom GPT knowledge files, conversation history Gemini File uploads, Google Drive integration, NotebookLM sources M365 Copilot Microsoft Graph (emails, files, meetings), attached documents <p>Relationship to other blocks: Context makes prompts smarter. Projects organize context persistently so you don't re-upload it every time.</p>"},{"location":"agentic-building-blocks/#project","title":"Project","text":"<p>Self-contained workspaces with their own chat histories and knowledge bases that set custom instructions applying to all conversations within the project.</p> <p>Key characteristics:</p> <ul> <li>Organizes related resources in one place so they persist across conversations</li> <li>Sets custom instructions that apply to every conversation in the project</li> <li>Reduces setup time: start a new conversation with everything already in place</li> </ul> <p>When to use it: When you run the same type of workflow repeatedly and want to avoid re-uploading context and re-explaining instructions every time.</p> <p>Example: A \"Weekly Client Reports\" project that contains your report template, client data, brand guidelines, and standing instructions for tone and format.</p> <p>Cross-platform implementations:</p> Platform How It Works Claude Claude Projects (with project knowledge and custom instructions) OpenAI (ChatGPT) Custom GPTs, or Projects in ChatGPT Gemini Gems (with custom instructions and uploaded context) M365 Copilot Copilot agents with knowledge sources and instructions <p>Relationship to other blocks: Projects are containers \u2014 they hold the prompts, context, and skills a workflow needs, making the whole package reusable.</p>"},{"location":"agentic-building-blocks/#skill","title":"Skill","text":"<p>Folders containing instructions, scripts, and resources that the AI discovers and loads dynamically when relevant to a task. Skills are now an open standard and being adopted broadly.</p> <p>Key characteristics:</p> <ul> <li>Encapsulates a specific capability: instructions, context, and output format bundled together</li> <li>Dynamically loaded: the AI discovers and invokes skills when they're relevant</li> <li>Reusable across conversations, shareable with others, and becoming an open standard</li> </ul> <p>When to use it: When you find yourself writing the same prompt repeatedly, or when a workflow step is well-defined enough to package as a repeatable routine.</p> <p>Example: A \"Draft Meeting Recap\" skill that takes meeting notes as input and produces a formatted summary with action items, decisions, and follow-ups \u2014 in your team's standard format every time.</p> <p>Cross-platform implementations:</p> Platform How It Works Claude Claude Code Skills (SKILL.md files with instructions and references) OpenAI (ChatGPT) Custom GPTs, or Actions within a GPT Gemini Gems with structured instructions M365 Copilot Copilot agent actions, Power Automate flows triggered by Copilot <p>Relationship to other blocks: Skills are upgraded prompts \u2014 they package a prompt with its context into something reusable. Agents can invoke skills as part of multi-step workflows.</p> <p>Skills vs. Agents</p> <p>A skill is a routine \u2014 it does one thing well when invoked. An agent is autonomous \u2014 it decides what to do, which tools to use, and when to invoke skills. Think of skills as tools in a toolbox and agents as the person using the toolbox.</p>"},{"location":"agentic-building-blocks/#agent","title":"Agent","text":"<p>A system where an LLM controls workflow execution to achieve a goal.</p> <p>Key characteristics:</p> <ul> <li>Plans its own approach: breaks goals into steps and decides which tools to use</li> <li>Uses tools: can read files, search the web, run code, call APIs</li> <li>Iterates: evaluates its own output, handles errors, and adjusts course</li> </ul> <p>When to use it: When a workflow requires multiple steps, tool use, or decision-making that would be tedious to manage manually through individual prompts.</p> <p>Example: A research agent that takes a topic, searches multiple sources, synthesizes findings, fact-checks claims, and produces a structured report \u2014 deciding on its own which sources to consult and how deep to go.</p> <p>Cross-platform implementations:</p> Platform How It Works Claude Claude Code agents (autonomous tool-using sessions), Cowork agents OpenAI (ChatGPT) Custom GPTs with Actions, Assistants API with tools Gemini Gemini with extensions (Google Search, Workspace, Maps, etc.) M365 Copilot Copilot agents with plugins and connectors <p>Relationship to other blocks: Agents orchestrate the other blocks \u2014 they use prompts, draw on context, invoke skills, and connect to external systems through MCP.</p>"},{"location":"agentic-building-blocks/#mcp-model-context-protocol","title":"MCP (Model Context Protocol)","text":"<p>An open standard for connecting AI assistants to external systems where data lives \u2014 content repositories, business tools, databases, and development environments.</p> <p>Key characteristics:</p> <ul> <li>Bridges the gap between the AI and the outside world where your data lives</li> <li>Open standard: one integration pattern that works across compatible platforms</li> <li>Enables read and write operations: the AI can both retrieve information and take actions</li> </ul> <p>When to use it: When the AI needs to interact with external systems \u2014 reading from a database, posting to Slack, creating tasks in a project management tool, or accessing live data.</p> <p>Example: An MCP connector to your CRM that lets the AI look up client history, check deal status, and log meeting notes \u2014 all within the conversation.</p> <p>Cross-platform implementations:</p> Platform How It Works Claude MCP servers (local or remote) connected via Claude Code or Claude Desktop OpenAI (ChatGPT) Function calling, Actions in Custom GPTs, Assistants API tools Gemini Extensions and function calling M365 Copilot Connectors, plugins, Power Platform integrations <p>Relationship to other blocks: MCP extends what agents and skills can do by connecting them to external systems. Without MCP, the AI is limited to what's in the conversation.</p>"},{"location":"agentic-building-blocks/#how-the-blocks-fit-together","title":"How the Blocks Fit Together","text":"<p>The building blocks build on each other. Here's how a workflow grows as you adopt more blocks:</p> <ol> <li>Choose a Model \u2014 Select the right AI engine for your task (speed vs. depth, modality, cost)</li> <li>Start with a Prompt \u2014 Write clear instructions for what you want done</li> <li>Add Context \u2014 Attach reference materials so the model has what it needs</li> <li>Organize in a Project \u2014 Group your prompt and context so they persist across conversations</li> <li>Package as a Skill \u2014 Turn the prompt + context into a reusable routine you can invoke with different inputs</li> <li>Connect with MCP \u2014 Give the skill access to external data and tools</li> <li>Orchestrate with an Agent \u2014 Let an autonomous AI run the skill, use MCP connections, and handle multi-step workflows</li> </ol>"},{"location":"agentic-building-blocks/#worked-example-weekly-client-status-report","title":"Worked example: Weekly Client Status Report","text":"Stage What Changes Prompt only You paste \"Write a status report for Client X covering this week's deliverables...\" into a chat every Monday + Context You attach the client's project brief and last week's report so the model has history + Project You create a \"Client Reports\" project with the brief, templates, and standing instructions pre-loaded + Skill You package \"generate weekly status report\" as a skill \u2014 now you just invoke it with this week's updates + MCP The skill pulls this week's completed tasks from your project management tool and time entries from your time tracker + Agent An agent runs every Monday: gathers data via MCP, generates the report using the skill, drafts an email, and flags anything that needs your review <p>Not every workflow needs every block. Many tasks are handled perfectly well with a prompt and some context. The blocks are a menu, not a checklist \u2014 use what the workflow actually requires.</p>"},{"location":"agentic-building-blocks/#platform-comparison","title":"Platform Comparison","text":"<p>All seven building blocks across all four platforms in one view:</p> Building Block Claude OpenAI (ChatGPT) Gemini M365 Copilot Model Multiple tiers (fast, balanced, reasoning) Multiple tiers (fast, balanced, reasoning) Multiple tiers (fast, balanced) Microsoft-managed Prompt Conversation messages, system prompts Conversation messages, system prompts Conversation messages Chat messages Context File attachments, project knowledge File uploads, GPT knowledge files File uploads, Drive, NotebookLM Microsoft Graph, documents Project Claude Projects Custom GPTs, ChatGPT Projects Gems Copilot agents Skill Claude Code Skills Not yet available Not yet available Not yet available Agent Claude Code agents, Cowork Assistants API, GPTs with Actions Extensions Copilot agents with plugins MCP MCP servers Function calling, Actions Extensions, function calling Connectors, plugins"},{"location":"agentic-building-blocks/#common-misconceptions","title":"Common Misconceptions","text":"<p>\"Skills and agents are the same thing.\" Skills are routines \u2014 they do one specific thing when invoked. Agents are autonomous \u2014 they decide what to do, plan steps, and invoke skills (among other tools) to accomplish goals. A skill is a tool; an agent is the one using the toolbox.</p> <p>\"You need all seven blocks for every workflow.\" Most workflows need two or three blocks. A well-written prompt with good context handles many tasks. Only add blocks when the workflow genuinely requires them.</p> <p>\"A project is just a folder.\" A project is an active workspace \u2014 it provides standing instructions, persistent context, and conversation continuity. It shapes how the AI behaves for every conversation within it, not just where files are stored.</p>"},{"location":"agentic-building-blocks/#related","title":"Related","text":"<p>Framework and courses:</p> <ul> <li>Business-First AI Framework \u2014 applies building blocks to workflow analysis</li> <li>Design Your AI Workflow \u2014 mapping workflow steps to building blocks</li> <li>Agentic AI for Leaders \u2014 course covering AI strategy and building blocks</li> <li>Claude for Builders \u2014 hands-on course building with these blocks</li> </ul> <p>Fundamentals deep-dives:</p> <ul> <li>Model \u2014 the AI engine that powers everything</li> <li>Prompts \u2014 the Prompt building block, with prompt engineering techniques</li> <li>Context \u2014 background information and reference materials</li> <li>Projects \u2014 project workspaces with memory, knowledge bases, and custom instructions</li> <li>Skills \u2014 reusable routines the AI invokes when relevant</li> <li>Agents \u2014 concepts for the Agent building block</li> <li>MCP \u2014 connecting AI to external systems</li> <li>AI Engineering \u2014 practices for designing and optimizing AI systems, including context engineering</li> <li>Patterns \u2014 reusable approaches across building blocks</li> </ul> <p>Use cases:</p> <ul> <li>AI Use Cases \u2014 what teams build with these blocks, organized by six primitives</li> </ul> <p>Platform-specific guides:</p> <ul> <li>Claude Projects \u2014 setting up the Project block on Claude</li> <li>Claude Skills \u2014 discovering Skills on Claude</li> <li>Claude Subagents \u2014 scheduling Agents on Claude</li> </ul>"},{"location":"agentic-building-blocks/agents/","title":"Agents","text":"<p>Concepts for building AI agents and implementing tool use.</p>"},{"location":"agentic-building-blocks/agents/#topics","title":"Topics","text":"<ul> <li>Agent Capability Patterns \u2014 Seven architectural patterns that make agents effective: Reflection, Tool Use, Planning, Multi-Agent Collaboration, Memory, Guardrails, and Human-in-the-Loop</li> </ul>"},{"location":"agentic-building-blocks/agents/#key-concepts","title":"Key Concepts","text":"<ul> <li>Function Calling - Enabling models to call external functions</li> <li>Tool Use - Defining and executing tools</li> <li>Agent Loops - Iterative reasoning and action</li> <li>ReAct Pattern - Reasoning and acting</li> <li>State Management - Tracking conversation and tool state</li> <li>Error Handling - Graceful failure and recovery</li> </ul>"},{"location":"agentic-building-blocks/agents/#agents-by-platform","title":"Agents by Platform","text":"<p>Each platform has its own agent system. These guides show how to build agents on each one \u2014 from no-code options for business users to full developer frameworks.</p> Platform Approaches Guide Claude Custom subagents (Markdown agent files), Agent teams (multi-agent coordination) Building Agents on Claude OpenAI ChatGPT Agent Mode, AgentKit (visual canvas), Agents SDK (Python/TypeScript), Frontier (enterprise) Building Agents on OpenAI Google Gemini Agent Designer (no-code), Agent Development Kit (open-source framework) Building Agents on Google M365 Copilot Declarative agents (no-code/low-code), Custom engine agents (bring your own models) Building Agents on M365 Copilot <p>For guidance on deciding whether your workflow needs an agent, see Build Workflows &gt; Agents.</p>"},{"location":"agentic-building-blocks/agents/#related","title":"Related","text":"<ul> <li>Agentic Building Blocks</li> <li>AI Use Cases \u2014 what teams build with agents, organized by six primitives</li> <li>Automation Use Cases \u2014 the highest-autonomy use cases powered by agents</li> <li>Workflow Architecture Patterns \u2014 seven patterns from augmented LLMs to autonomous agents</li> <li>Patterns</li> </ul>"},{"location":"agentic-building-blocks/agents/resources/","title":"Agents Resources","text":"<p>Recommended articles, docs, and courses for building AI agents and tool use.</p> Resource Type Note"},{"location":"agentic-building-blocks/agents/capability-patterns/","title":"Agent Capability Patterns","text":"<p>Capability patterns are the architectural building blocks that make AI agents powerful. While a basic LLM generates text in a single pass, an agentic system combines multiple patterns \u2014 reflection, tool use, planning, collaboration, and memory \u2014 to tackle complex, multi-step tasks autonomously.</p> <p>These patterns were popularized by Andrew Ng in his 2024 writing on agentic design patterns (The Batch, DeepLearning.AI), building on research from Google, Stanford, Princeton, and others. The patterns are platform-agnostic \u2014 they apply whether you're building with Claude, ChatGPT, Gemini, or any other LLM.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/#pattern-catalog","title":"Pattern Catalog","text":""},{"location":"agentic-building-blocks/agents/capability-patterns/#capability-patterns","title":"Capability Patterns","text":"<p>These five patterns define what agents can do.</p> Pattern What It Does Key Benefit Reflection Agent reviews and critiques its own output, then improves it Higher-quality results through self-correction Tool Use Agent calls external tools, APIs, and data sources Extends capabilities beyond text generation Planning Agent breaks complex goals into a sequence of steps Handles multi-step tasks that require strategy Multi-Agent Collaboration Multiple specialized agents work together on a task Tackles problems too complex for a single agent Memory Agent stores and retrieves information across interactions Learns from experience and maintains context"},{"location":"agentic-building-blocks/agents/capability-patterns/#safety-control","title":"Safety &amp; Control","text":"<p>These two patterns define how agents stay safe and aligned.</p> Pattern What It Does Key Benefit Guardrails Automated rules that constrain agent behavior Prevents harmful or off-topic outputs without human intervention Human-in-the-Loop Human checkpoints at key decision points Keeps humans in control of high-stakes actions"},{"location":"agentic-building-blocks/agents/capability-patterns/#how-patterns-work-together","title":"How Patterns Work Together","text":"<p>Consider a customer exchange request \u2014 a customer wants to return a product and exchange it for a different item. A capable agent doesn't just use one pattern; it combines several:</p> <ol> <li>Planning \u2014 The agent breaks the exchange into steps: verify the order, check return eligibility, find the replacement item, process the return, place the new order.</li> <li>Tool Use \u2014 At each step, the agent calls the order management API, inventory system, and payment processor.</li> <li>Reflection \u2014 Before confirming the exchange, the agent reviews its work: \"Did I verify the return window? Is the replacement item in stock? Are the prices correct?\"</li> <li>Guardrails \u2014 Automated rules prevent the agent from issuing refunds above a threshold or processing exchanges for final-sale items.</li> <li>Human-in-the-Loop \u2014 If the exchange involves an exception (expired return window, high-value item), the agent escalates to a human agent for approval.</li> <li>Memory \u2014 The agent remembers this customer's preferences and past interactions, personalizing future service.</li> </ol> <p>No single pattern makes this workflow possible. Their combination is what turns a basic chatbot into a capable agent.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/#where-to-start","title":"Where to Start","text":"<p>Understanding agent concepts? Start with Reflection \u2014 it's the simplest pattern to grasp and demonstrates the core idea of iterative improvement.</p> <p>Building your first agent? Tool Use is the most immediately practical pattern \u2014 it's how agents interact with the real world.</p> <p>Designing a production system? Read Guardrails and Human-in-the-Loop first \u2014 safety and control should be designed in from the start, not bolted on later.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/#related","title":"Related","text":"<ul> <li>Agents \u2014 The Agents building block overview</li> <li>Agents Resources \u2014 Recommended reading on agents</li> <li>Building Effective Agents \u2014 Anthropic's guide to agent architecture</li> <li>Prompt Engineering \u2014 Techniques for the prompts that drive agent behavior</li> <li>Automation Use Cases \u2014 Real-world applications of agentic systems</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/guardrails/","title":"Guardrails","text":""},{"location":"agentic-building-blocks/agents/capability-patterns/guardrails/#what-it-is","title":"What It Is","text":"<p>Guardrails are automated rules and constraints that govern what an agent can and cannot do. They operate continuously during agent execution, checking inputs, outputs, and actions against defined policies \u2014 and blocking or modifying anything that violates those policies.</p> <p>Unlike human-in-the-loop controls, guardrails are automated. They don't require a human to review every action \u2014 they enforce rules programmatically, allowing the agent to operate autonomously within defined boundaries.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/guardrails/#why-it-matters","title":"Why It Matters","text":"<p>As agents gain more autonomy \u2014 making decisions, calling tools, taking actions \u2014 the potential for harm increases. An agent without guardrails can hallucinate confidently, leak sensitive data, make unauthorized purchases, or provide advice it shouldn't.</p> <p>Guardrails are the difference between a useful autonomous system and a liability. They let you grant agents more autonomy (which makes them more useful) while maintaining safety (which makes them trustworthy). Production agent systems always need guardrails \u2014 the question is not whether to add them, but which ones and where.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/guardrails/#how-it-works","title":"How It Works","text":"<p>Guardrails can be applied at multiple points in the agent pipeline:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Input  \u2502\u2500\u2500\u25b8\u2502  Input    \u2502\u2500\u2500\u25b8\u2502 Agent  \u2502\u2500\u2500\u25b8\u2502  Output   \u2502\u2500\u2500\u25b8\u2502 Output \u2502\n\u2502        \u2502   \u2502  Guards   \u2502   \u2502 (LLM)  \u2502   \u2502  Guards   \u2502   \u2502        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"agentic-building-blocks/agents/capability-patterns/guardrails/#types-of-guardrails","title":"Types of guardrails","text":"<p>Input guardrails \u2014 Filter or reject problematic inputs before they reach the agent:</p> <ul> <li>Block prompt injection attempts</li> <li>Reject off-topic requests (\"I can help with order management, but I can't help with medical advice\")</li> <li>Sanitize sensitive data (redact credit card numbers before processing)</li> </ul> <p>Output guardrails \u2014 Check agent responses before they reach the user:</p> <ul> <li>Block responses containing personally identifiable information (PII)</li> <li>Ensure responses stay within the agent's approved topic area</li> <li>Verify factual claims against a knowledge base</li> <li>Enforce tone and brand voice guidelines</li> </ul> <p>Action guardrails \u2014 Restrict what tools the agent can call and with what parameters:</p> <ul> <li>Limit refund amounts (\"agent can issue refunds up to $100; anything higher requires approval\")</li> <li>Restrict database access to read-only queries</li> <li>Block destructive operations (delete, overwrite)</li> <li>Enforce rate limits on API calls</li> </ul> <p>Constitutional guardrails \u2014 Baked into the model's behavior through system prompts or fine-tuning:</p> <ul> <li>Anthropic's Constitutional AI trains models to follow a set of principles</li> <li>System prompts that define the agent's role and boundaries</li> <li>Instructions like \"Never provide medical, legal, or financial advice\"</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/guardrails/#example","title":"Example","text":""},{"location":"agentic-building-blocks/agents/capability-patterns/guardrails/#customer-exchange-scenario","title":"Customer exchange scenario","text":"<p>An exchange-processing agent has these guardrails:</p> Guardrail Type Rule Refund cap Action Cannot issue refunds over $200 without escalation Final sale block Action Cannot process returns on items marked \"final sale\" PII filter Output Redacts credit card numbers and SSNs from responses Scope limit Input Rejects requests unrelated to order management Policy compliance Output Verifies that the response cites the correct return policy <p>A customer asks: \"Can I return this final-sale item?\" The action guardrail blocks the return process, and the agent responds: \"I'm sorry, final-sale items are not eligible for return or exchange per our policy. I can help you find an alternative product if you'd like.\"</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/guardrails/#code-generation-agent","title":"Code generation agent","text":"<p>A coding agent has guardrails to prevent generating insecure code:</p> <ul> <li>Block \u2014 SQL queries built with string concatenation (SQL injection risk)</li> <li>Warn \u2014 API keys or secrets hardcoded in source code</li> <li>Enforce \u2014 All file writes must go through a sandbox directory</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/guardrails/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Any production agent system \u2014 guardrails are not optional for deployed agents</li> <li>Agents with access to tools that can take real-world actions (payments, emails, database writes)</li> <li>Customer-facing agents where brand safety matters</li> <li>Regulated industries (healthcare, finance, legal) with compliance requirements</li> <li>Multi-agent systems where individual agents need scoped permissions</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/guardrails/#related-patterns","title":"Related Patterns","text":"<ul> <li>Human-in-the-Loop \u2014 Guardrails handle routine constraints automatically; HITL handles exceptions and edge cases</li> <li>Tool Use \u2014 Action guardrails govern which tools the agent can access</li> <li>Reflection \u2014 Self-reflection is a soft guardrail; automated guardrails are hard constraints</li> <li>Agent Capability Patterns</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/guardrails/#further-reading","title":"Further Reading","text":"<ul> <li>Anthropic \u2014 Constitutional AI: Harmlessness from AI Feedback \u2014 anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback</li> <li>Anthropic \u2014 Building Effective Agents \u2014 anthropic.com/research/building-effective-agents</li> <li>OWASP \u2014 LLM AI Security &amp; Governance Checklist \u2014 owasp.org/www-project-top-10-for-large-language-model-applications</li> <li>Guardrails AI \u2014 Open-source framework for adding guardrails to LLM applications \u2014 guardrailsai.com</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/human-in-the-loop/","title":"Human-in-the-Loop","text":""},{"location":"agentic-building-blocks/agents/capability-patterns/human-in-the-loop/#what-it-is","title":"What It Is","text":"<p>Human-in-the-loop (HITL) is a pattern where an agent pauses at defined checkpoints to get human approval, input, or correction before proceeding. Instead of running fully autonomously, the agent escalates decisions that are high-stakes, ambiguous, or outside its confidence threshold to a human operator.</p> <p>HITL is not the opposite of automation \u2014 it's the safety net that makes deeper automation possible. By building in human checkpoints at the right moments, you can grant agents more autonomy for the routine work while keeping humans in control of the decisions that matter.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/human-in-the-loop/#why-it-matters","title":"Why It Matters","text":"<p>Fully autonomous agents are powerful but risky. They can make mistakes that are expensive, embarrassing, or irreversible \u2014 sending the wrong email to a customer, approving a refund that violates policy, or making a decision based on hallucinated data.</p> <p>HITL addresses the trust gap: users may not trust an agent to handle everything autonomously, but they also don't want to supervise every step. The solution is selective human involvement \u2014 the agent handles the routine 90% automatically and escalates the exceptional 10% to a human.</p> <p>The key design question is: \"Would I be comfortable if the agent did this without asking me?\" If the answer is no, that's where you add a checkpoint.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/human-in-the-loop/#how-it-works","title":"How It Works","text":"<p>Three common HITL architectures:</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/human-in-the-loop/#approval-gate","title":"Approval gate","text":"<p>The agent completes a unit of work and pauses for human approval before taking the next action.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Agent   \u2502\u2500\u2500\u2500\u2500\u25b8\u2502 Proposed  \u2502\u2500\u2500\u2500\u2500\u25b8\u2502 Human      \u2502\u2500\u2500\u2500\u2500\u25b8\u2502 Execute  \u2502\n\u2502 works   \u2502     \u2502 Action    \u2502     \u2502 Approves/  \u2502     \u2502 or       \u2502\n\u2502         \u2502     \u2502 (paused)  \u2502     \u2502 Modifies   \u2502     \u2502 Revise   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Example: An agent drafts a customer email, then waits for human approval before sending it.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/human-in-the-loop/#escalation-trigger","title":"Escalation trigger","text":"<p>The agent operates autonomously by default but escalates when it hits a defined threshold \u2014 low confidence, policy edge case, high-value action.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Agent   \u2502\u2500\u2500\u2500\u2500\u25b8\u2502 Confidence   \u2502\u2500\u2500\u2500\u2500 High \u2500\u2500\u2500\u25b8 Proceed automatically\n\u2502 works   \u2502     \u2502 Check        \u2502\n\u2502         \u2502     \u2502              \u2502\u2500\u2500\u2500\u2500 Low \u2500\u2500\u2500\u2500\u25b8 Escalate to human\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Example: An agent processes routine exchanges automatically but escalates to a supervisor when the refund amount exceeds $500 or the return window has expired.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/human-in-the-loop/#collaborative-workspace","title":"Collaborative workspace","text":"<p>The agent and human work in parallel on a shared artifact \u2014 the agent drafts, the human edits, the agent refines based on the edits.</p> <p>Example: An agent writes a report in a shared document. The human adds comments and corrections in real-time. The agent incorporates the feedback into subsequent sections.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/human-in-the-loop/#example","title":"Example","text":""},{"location":"agentic-building-blocks/agents/capability-patterns/human-in-the-loop/#customer-exchange-scenario","title":"Customer exchange scenario","text":"<p>A customer wants to exchange an item that's past the return window:</p> <ol> <li>Agent \u2014 Looks up the order, determines the return window expired 3 days ago.</li> <li>Agent \u2014 Checks guardrails: \"Expired return window\" triggers escalation rule.</li> <li>Agent \u2192 Human \u2014 \"Customer Jane Smith (VIP, 4-year account) is requesting an exchange for Order #ORD-5678. The return window expired 3 days ago. Recommended action: approve as a courtesy given VIP status. Approve / Deny / Modify?\"</li> <li>Human \u2014 Approves the courtesy exchange.</li> <li>Agent \u2014 Processes the exchange, sends confirmation to the customer.</li> </ol> <p>Without HITL, the agent would either rigidly deny the exchange (frustrating a loyal customer) or blindly approve it (creating a policy loophole). HITL lets the agent handle the workflow while the human makes the judgment call.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/human-in-the-loop/#code-deployment","title":"Code deployment","text":"<p>A CI/CD agent with HITL checkpoints:</p> <ol> <li>Autonomous: Run tests, generate build, scan for vulnerabilities</li> <li>Checkpoint: \"All tests pass. Deploy to staging?\" \u2192 Human approves</li> <li>Autonomous: Deploy to staging, run integration tests</li> <li>Checkpoint: \"Staging tests pass. Deploy to production?\" \u2192 Human approves</li> <li>Autonomous: Deploy to production, monitor health metrics</li> </ol>"},{"location":"agentic-building-blocks/agents/capability-patterns/human-in-the-loop/#when-to-use-it","title":"When to Use It","text":"<ul> <li>High-stakes decisions with real-world consequences (financial transactions, customer communications, production deployments)</li> <li>Edge cases that fall outside the agent's training or policy coverage</li> <li>Compliance-sensitive workflows where an audit trail of human approvals is required</li> <li>Early-stage deployments where you're still building trust in the agent's capabilities</li> <li>Any action that would be difficult or expensive to reverse</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/human-in-the-loop/#related-patterns","title":"Related Patterns","text":"<ul> <li>Guardrails \u2014 Guardrails handle routine constraints automatically; HITL handles exceptions that require judgment</li> <li>Planning \u2014 Humans can review and approve the agent's plan before execution begins</li> <li>Reflection \u2014 The agent's self-assessment can determine when to escalate to a human</li> <li>Agent Capability Patterns</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/human-in-the-loop/#further-reading","title":"Further Reading","text":"<ul> <li>Anthropic \u2014 Building Effective Agents \u2014 anthropic.com/research/building-effective-agents</li> <li>Permit.io \u2014 Human-in-the-Loop for AI Agents: Best Practices \u2014 permit.io/blog/human-in-the-loop-for-ai-agents-best-practices-frameworks-use-cases-and-demo</li> <li>Zapier \u2014 Human-in-the-Loop in AI Workflows: Meaning and Patterns \u2014 zapier.com/blog/human-in-the-loop</li> <li>UiPath \u2014 10 Best Practices for Building Reliable AI Agents \u2014 uipath.com/blog/ai/agent-builder-best-practices</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/memory/","title":"Memory","text":""},{"location":"agentic-building-blocks/agents/capability-patterns/memory/#what-it-is","title":"What It Is","text":"<p>Memory is a pattern where an agent stores information from past interactions and retrieves it when relevant to current tasks. Without memory, every conversation starts from scratch \u2014 the agent has no knowledge of previous interactions, decisions, or user preferences. With memory, the agent builds up context over time, becoming more useful and personalized with each interaction.</p> <p>Memory in AI agents is inspired by human memory systems, but implemented through a combination of databases, embeddings, and retrieval mechanisms rather than biological processes.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/memory/#why-it-matters","title":"Why It Matters","text":"<p>A stateless agent is like a colleague with amnesia \u2014 you have to re-explain everything every time. Memory transforms agents from one-shot tools into persistent collaborators that accumulate knowledge, learn preferences, and build on past work.</p> <p>The landmark Generative Agents paper (Park et al. 2023) demonstrated that agents with memory could form relationships, remember past conversations, and coordinate activities over time \u2014 emergent behaviors that weren't explicitly programmed but arose naturally from the memory architecture.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/memory/#how-it-works","title":"How It Works","text":"<p>Agent memory systems typically implement multiple types of memory:</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/memory/#short-term-memory-working-context","title":"Short-term memory (working context)","text":"<p>The current conversation history and any documents loaded into the context window. This is what the agent can \"see\" right now. It's limited by the model's context window size.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/memory/#long-term-memory-persistent-storage","title":"Long-term memory (persistent storage)","text":"<p>Information stored outside the context window in a database or file system, retrieved when relevant. This includes:</p> <ul> <li>Episodic memory \u2014 Records of specific past interactions (\"Last Tuesday, the user asked about exchange policies and preferred email communication\").</li> <li>Semantic memory \u2014 General knowledge extracted from interactions (\"This user prefers concise responses\" or \"This customer is a VIP account\").</li> <li>Procedural memory \u2014 Learned workflows and procedures (\"When processing exchanges for this company, always check the VIP discount table first\").</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/memory/#retrieval","title":"Retrieval","text":"<p>When the agent starts a new task, it queries long-term memory for relevant context. Common retrieval methods include:</p> <ul> <li>Keyword/semantic search \u2014 Finding memories related to the current topic using embeddings</li> <li>Recency weighting \u2014 Prioritizing recent memories over older ones</li> <li>Importance scoring \u2014 Surfacing memories that were flagged as significant</li> </ul> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Current     \u2502\u2500\u2500\u2500\u2500\u25b8\u2502  Retrieval    \u2502\u2500\u2500\u2500\u2500\u25b8\u2502  Enriched    \u2502\n\u2502  Task        \u2502     \u2502  (search      \u2502     \u2502  Context     \u2502\n\u2502              \u2502     \u2502   memory)     \u2502     \u2502              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502  Long-term    \u2502\n                    \u2502  Memory Store \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"agentic-building-blocks/agents/capability-patterns/memory/#example","title":"Example","text":""},{"location":"agentic-building-blocks/agents/capability-patterns/memory/#customer-exchange-scenario","title":"Customer exchange scenario","text":"<p>A customer contacts support about an exchange. The agent retrieves from memory:</p> <ul> <li>Episodic: \"This customer contacted us 3 weeks ago about a defective Blue Widget. We sent a replacement. They mentioned they prefer phone updates over email.\"</li> <li>Semantic: \"This customer has been with us for 4 years and has a lifetime value of $2,400. They're in the VIP tier.\"</li> <li>Procedural: \"VIP customers get free expedited shipping on exchanges and a courtesy discount on the replacement item.\"</li> </ul> <p>Armed with this context, the agent provides personalized service without the customer having to repeat their history.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/memory/#development-workflow","title":"Development workflow","text":"<p>A coding agent with memory:</p> <ul> <li>Remembers the project's architecture decisions from previous sessions</li> <li>Recalls that the user prefers TypeScript over JavaScript and tabs over spaces</li> <li>Knows which test framework the project uses without being told each time</li> <li>Stores debugging insights (\"The authentication module has a known issue with token refresh timing\")</li> </ul> <p>Claude Code's <code>CLAUDE.md</code> files and memory directory are a practical implementation of this pattern \u2014 project context and user preferences persist across sessions.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/memory/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Customer-facing systems where personalization improves the experience</li> <li>Long-running projects where context accumulates over time</li> <li>Agents that need to learn from mistakes (paired with Reflection)</li> <li>Any workflow where repeating context to the agent is a friction point</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/memory/#related-patterns","title":"Related Patterns","text":"<ul> <li>Reflection \u2014 Reflection generates insights that can be stored in memory for future use</li> <li>Planning \u2014 Memory of past plans helps the agent make better plans in the future</li> <li>Multi-Agent Collaboration \u2014 Shared memory allows agents to coordinate without direct communication</li> <li>Agent Capability Patterns</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/memory/#further-reading","title":"Further Reading","text":"<ul> <li>Park et al. 2023 \u2014 Generative Agents: Interactive Simulacra of Human Behavior \u2014 arxiv.org/abs/2304.03442</li> <li>Zhang et al. 2024 \u2014 A Survey on the Memory Mechanism of Large Language Model Based Agents \u2014 arxiv.org/abs/2404.13501</li> <li>Andrew Ng \u2014 Agentic Design Patterns Part 6: Memory \u2014 deeplearning.ai/the-batch</li> <li>LangChain \u2014 Memory in LLM Applications \u2014 python.langchain.com/docs/concepts/memory</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/multi-agent-collaboration/","title":"Multi-Agent Collaboration","text":""},{"location":"agentic-building-blocks/agents/capability-patterns/multi-agent-collaboration/#what-it-is","title":"What It Is","text":"<p>Multi-agent collaboration is a pattern where multiple AI agents \u2014 each with different roles, tools, or expertise \u2014 work together to accomplish a task. Instead of one general-purpose agent doing everything, the work is divided among specialists that communicate, delegate, and coordinate.</p> <p>Think of it like a team at a company: a researcher gathers information, an analyst processes it, a writer drafts the report, and an editor reviews it. Each agent focuses on what it does best, and the combined output is better than any single agent could produce alone.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/multi-agent-collaboration/#why-it-matters","title":"Why It Matters","text":"<p>Single agents hit a complexity ceiling. As tasks grow more complex, a single agent's context window fills up, its instructions become contradictory, and its performance degrades. Multi-agent systems solve this by decomposing the problem across agents that each operate with focused context and clear responsibilities.</p> <p>Multi-agent collaboration also enables separation of concerns \u2014 a safety-critical agent can enforce policies while a creative agent generates content, without either interfering with the other's role.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/multi-agent-collaboration/#how-it-works","title":"How It Works","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Orchestrator \u2502\n\u2502  (coordinator)\u2502\n\u2514\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518\n   \u2502   \u2502   \u2502\n   \u25bc   \u25bc   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2510\u250c\u2500\u2500\u2500\u2500\u2510\u250c\u2500\u2500\u2500\u2500\u2510\n\u2502 A1 \u2502\u2502 A2 \u2502\u2502 A3 \u2502\n\u2502    \u2502\u2502    \u2502\u2502    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2518\u2514\u2500\u2500\u2500\u2500\u2518\u2514\u2500\u2500\u2500\u2500\u2518\nResearcher  Analyst  Writer\n</code></pre> <p>Common architectures:</p> <ul> <li>Orchestrator pattern \u2014 A central agent assigns tasks to specialist agents, collects results, and synthesizes the final output.</li> <li>Pipeline pattern \u2014 Agents are arranged in a sequence where each agent's output becomes the next agent's input (researcher \u2192 analyst \u2192 writer).</li> <li>Debate pattern \u2014 Two or more agents argue different perspectives, and a judge agent selects or synthesizes the best answer.</li> <li>Peer collaboration \u2014 Agents communicate as equals, each contributing their expertise to a shared workspace.</li> </ul> <p>The key design decisions are:</p> <ol> <li>How many agents? \u2014 Use the minimum number needed. More agents means more coordination overhead.</li> <li>How do they communicate? \u2014 Through shared context, message passing, or a shared workspace.</li> <li>Who decides what? \u2014 An orchestrator, a round-robin, or autonomous negotiation.</li> </ol>"},{"location":"agentic-building-blocks/agents/capability-patterns/multi-agent-collaboration/#example","title":"Example","text":""},{"location":"agentic-building-blocks/agents/capability-patterns/multi-agent-collaboration/#customer-exchange-scenario","title":"Customer exchange scenario","text":"<p>A customer exchange can be handled by a team of agents:</p> <ul> <li>Triage Agent \u2014 Reads the customer's request, classifies it as \"exchange,\" and routes it to the right specialist.</li> <li>Order Agent \u2014 Looks up the order, verifies return eligibility, and handles the logistics.</li> <li>Inventory Agent \u2014 Checks stock levels and finds the best warehouse to ship from.</li> <li>Communications Agent \u2014 Drafts the customer-facing email with exchange details and return instructions.</li> </ul> <p>Each agent has access only to the tools it needs \u2014 the Communications Agent can't process payments, and the Order Agent can't send emails. This limits the blast radius of any single agent's mistakes.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/multi-agent-collaboration/#content-production","title":"Content production","text":"<p>A marketing team's content pipeline as a multi-agent system:</p> <ul> <li>Research Agent \u2014 Gathers data, competitor analysis, and market trends</li> <li>Writer Agent \u2014 Produces a draft based on the research brief</li> <li>Editor Agent \u2014 Reviews for clarity, accuracy, and brand voice</li> <li>SEO Agent \u2014 Optimizes headlines, metadata, and keyword placement</li> </ul> <p>The Writer Agent never sees raw data \u2014 it receives a structured brief from the Research Agent. The Editor Agent doesn't know about SEO \u2014 it focuses purely on quality. This separation produces better results than a single agent trying to juggle all four concerns.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/multi-agent-collaboration/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Tasks that require multiple distinct skill sets (research + writing + analysis)</li> <li>Workflows where separation of concerns improves quality or safety</li> <li>Problems where debate or multiple perspectives lead to better answers</li> <li>Systems that need to scale \u2014 adding a new capability means adding a new agent, not rewriting the existing one</li> <li>Production systems where different agents need different permission levels</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/multi-agent-collaboration/#related-patterns","title":"Related Patterns","text":"<ul> <li>Planning \u2014 An orchestrator agent often uses planning to coordinate the team</li> <li>Tool Use \u2014 Each agent typically has its own set of tools</li> <li>Reflection \u2014 A critic agent reviewing another agent's work is multi-agent reflection</li> <li>Guardrails \u2014 Each agent can have its own guardrails, limiting what it can do</li> <li>Agent Capability Patterns</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/multi-agent-collaboration/#further-reading","title":"Further Reading","text":"<ul> <li>Wu et al. 2023 \u2014 AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation \u2014 arxiv.org/abs/2308.08155</li> <li>Andrew Ng \u2014 Agentic Design Patterns Part 5: Multi-Agent Collaboration \u2014 deeplearning.ai/the-batch</li> <li>Anthropic \u2014 Building Effective Agents \u2014 anthropic.com/research/building-effective-agents</li> <li>CrewAI \u2014 Multi-Agent Framework Documentation \u2014 docs.crewai.com</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/planning/","title":"Planning","text":""},{"location":"agentic-building-blocks/agents/capability-patterns/planning/#what-it-is","title":"What It Is","text":"<p>Planning is a pattern where an agent decomposes a complex goal into a sequence of smaller, manageable steps \u2014 then executes them in order. Instead of attempting to solve a problem in a single response, the agent first creates a plan, then follows it step by step, adapting as needed based on intermediate results.</p> <p>This is what separates an agent from a simple chatbot. A chatbot responds to a single prompt. An agent with planning capability can take a high-level objective (\"process this customer's exchange\") and autonomously determine the sequence of actions required to achieve it.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/planning/#why-it-matters","title":"Why It Matters","text":"<p>Real-world tasks are rarely single-step. Processing an exchange requires verifying the order, checking return eligibility, confirming inventory, processing payment, and sending confirmation. A planning agent handles this entire workflow without requiring the user to specify each step.</p> <p>Andrew Ng has noted that planning is the least mature of the four core agentic patterns \u2014 it works well for well-defined workflows but remains challenging for open-ended, ambiguous goals. This makes it both the most powerful pattern (when it works) and the one that most benefits from guardrails and human oversight.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/planning/#how-it-works","title":"How It Works","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Goal     \u2502\u2500\u2500\u2500\u2500\u25b8\u2502  Plan         \u2502\u2500\u2500\u2500\u2500\u25b8\u2502  Execute      \u2502\n\u2502  (input)  \u2502     \u2502  (decompose)  \u2502     \u2502  (step by    \u2502\n\u2502           \u2502     \u2502               \u2502     \u2502   step)       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                             \u2502\n                                      Replan if needed\n</code></pre> <ol> <li>Receive goal \u2014 The agent receives a high-level objective.</li> <li>Decompose \u2014 The agent breaks the goal into an ordered sequence of sub-tasks.</li> <li>Execute \u2014 The agent works through each sub-task, using tool calls and reflection as needed.</li> <li>Monitor \u2014 After each step, the agent checks whether the result changes the remaining plan.</li> <li>Replan \u2014 If a step fails or produces unexpected results, the agent revises the remaining plan rather than blindly continuing.</li> </ol> <p>Advanced planning approaches include:</p> <ul> <li>Chain-of-thought planning \u2014 The agent reasons through the plan in natural language before executing.</li> <li>Tree-of-thought \u2014 The agent explores multiple possible plans and selects the best one (Yao et al. 2023).</li> <li>Hierarchical planning \u2014 High-level plans are broken into sub-plans, each with their own steps.</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/planning/#example","title":"Example","text":""},{"location":"agentic-building-blocks/agents/capability-patterns/planning/#customer-exchange-scenario","title":"Customer exchange scenario","text":"<p>Goal: \"Process customer Jane Smith's exchange \u2014 return Blue Widget, ship Red Widget.\"</p> <p>Agent's plan:</p> <ol> <li>Look up Jane Smith's order history \u2192 find order #ORD-5678</li> <li>Verify return eligibility \u2192 check if Blue Widget is within the 30-day return window</li> <li>Check Red Widget inventory \u2192 confirm availability in the nearest warehouse</li> <li>Calculate price difference \u2192 Blue Widget was $29.99, Red Widget is $34.99, difference is $5.00</li> <li>Process return for Blue Widget \u2192 generate prepaid return label</li> <li>Charge $5.00 price difference \u2192 process payment</li> <li>Place order for Red Widget \u2192 create new shipment</li> <li>Send confirmation email \u2192 include return label, new order details, and timeline</li> </ol> <p>Replanning example: At step 3, the Red Widget is out of stock. The agent replans: offer the customer the Green Widget as an alternative, or place the Red Widget on backorder with an estimated date.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/planning/#research-task","title":"Research task","text":"<p>Goal: \"Write a competitive analysis of our top 3 competitors.\"</p> <p>Agent's plan:</p> <ol> <li>Identify the top 3 competitors from the company's CRM data</li> <li>For each competitor, gather recent news, product launches, and pricing</li> <li>Analyze strengths and weaknesses relative to our product</li> <li>Draft a comparison table</li> <li>Write executive summary with recommendations</li> <li>Review and refine the full document</li> </ol>"},{"location":"agentic-building-blocks/agents/capability-patterns/planning/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Multi-step workflows with dependencies between steps (step 3 depends on step 2's output)</li> <li>Tasks where the sequence of actions matters</li> <li>Goals that are too complex to accomplish in a single tool call</li> <li>Workflows where failure at one step should change the approach for subsequent steps</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/planning/#related-patterns","title":"Related Patterns","text":"<ul> <li>Tool Use \u2014 Planning determines which tools to call and in what order</li> <li>Reflection \u2014 The agent can reflect on its plan before and during execution</li> <li>Multi-Agent Collaboration \u2014 A planning agent can delegate sub-tasks to specialized agents</li> <li>Human-in-the-Loop \u2014 Humans can approve the plan before execution begins</li> <li>Agent Capability Patterns</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/planning/#further-reading","title":"Further Reading","text":"<ul> <li>Yao et al. 2023 \u2014 Tree of Thoughts: Deliberate Problem Solving with Large Language Models \u2014 arxiv.org/abs/2305.10601</li> <li>Huang et al. 2024 \u2014 Understanding the Planning of LLM Agents: A Survey \u2014 arxiv.org/abs/2402.02716</li> <li>Andrew Ng \u2014 Agentic Design Patterns Part 4: Planning \u2014 deeplearning.ai/the-batch</li> <li>Anthropic \u2014 Building Effective Agents \u2014 anthropic.com/research/building-effective-agents</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/reflection/","title":"Reflection","text":""},{"location":"agentic-building-blocks/agents/capability-patterns/reflection/#what-it-is","title":"What It Is","text":"<p>Reflection is a pattern where an agent reviews its own output, identifies flaws or gaps, and revises its work before presenting a final result. Instead of delivering the first response it generates, the agent runs an internal feedback loop \u2014 acting as both creator and critic.</p> <p>In its simplest form, the agent generates an output, then prompts itself (or a second \"critic\" agent) to evaluate that output against criteria like accuracy, completeness, and tone. The feedback is fed back into the generation step, producing an improved version.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/reflection/#why-it-matters","title":"Why It Matters","text":"<p>LLMs generate text in a single forward pass \u2014 essentially thinking the entire answer at once. For simple tasks, this works fine. But for complex tasks (writing, analysis, code generation), the first draft is rarely the best draft. Reflection mimics the human process of drafting, reviewing, and revising \u2014 and it significantly improves output quality.</p> <p>Research shows that self-reflection can improve agent performance by 20\u201330% on coding benchmarks and knowledge-intensive tasks, without requiring any model fine-tuning (Shinn et al. 2023).</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/reflection/#how-it-works","title":"How It Works","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Generator   \u2502\u2500\u2500\u2500\u2500\u25b8\u2502   Critic     \u2502\u2500\u2500\u2500\u2500\u25b8\u2502  Revised     \u2502\n\u2502  (Draft)     \u2502     \u2502  (Evaluate)  \u2502     \u2502  Output      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n                    Feedback loop\n                    (repeat if needed)\n</code></pre> <ol> <li>Generate \u2014 The agent produces an initial output.</li> <li>Evaluate \u2014 The agent (or a separate critic) reviews the output against defined criteria.</li> <li>Revise \u2014 The agent incorporates the feedback and produces an improved version.</li> <li>Repeat \u2014 Steps 2\u20133 can loop multiple times until the output meets quality thresholds or a maximum iteration count is reached.</li> </ol> <p>The critic can be the same LLM with a different prompt (\"Review this for accuracy and completeness\") or a separate agent entirely. Using a separate critic agent often produces more rigorous feedback because it avoids confirmation bias.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/reflection/#example","title":"Example","text":""},{"location":"agentic-building-blocks/agents/capability-patterns/reflection/#customer-exchange-scenario","title":"Customer exchange scenario","text":"<p>An agent is drafting a response to a customer requesting a product exchange:</p> <p>First draft:</p> <p>\"Your exchange has been processed. The new item will ship in 3-5 business days.\"</p> <p>Critic feedback:</p> <p>\"The response doesn't confirm which item is being exchanged, doesn't mention the return process for the original item, and doesn't provide a tracking or confirmation number.\"</p> <p>Revised response:</p> <p>\"I've processed your exchange of the Blue Widget (Order #4521) for the Red Widget. Please return the Blue Widget using the prepaid label sent to your email within 14 days. Your Red Widget will ship within 3\u20135 business days once we receive the return. Your exchange confirmation number is EX-78234.\"</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/reflection/#code-generation","title":"Code generation","text":"<p>An agent writes a Python function, then reviews it:</p> <p>Critic feedback:</p> <p>\"The function doesn't handle the edge case where the input list is empty. It also uses a variable name <code>l</code> which is hard to distinguish from <code>1</code>.\"</p> <p>The agent revises the function to add an empty-list check and renames the variable to <code>items</code>.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/reflection/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Writing tasks where quality matters (reports, emails, documentation)</li> <li>Code generation \u2014 catching bugs, edge cases, and style issues before delivery</li> <li>Analysis tasks where accuracy is critical</li> <li>Any task where the cost of iteration is lower than the cost of a wrong first answer</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/reflection/#related-patterns","title":"Related Patterns","text":"<ul> <li>Planning \u2014 Reflection can evaluate whether a plan is complete before execution begins</li> <li>Multi-Agent Collaboration \u2014 A dedicated critic agent is a form of multi-agent collaboration</li> <li>Guardrails \u2014 Guardrails enforce hard constraints; reflection handles softer quality improvements</li> <li>Agent Capability Patterns</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/reflection/#further-reading","title":"Further Reading","text":"<ul> <li>Shinn et al. 2023 \u2014 Reflexion: Language Agents with Verbal Reinforcement Learning \u2014 arxiv.org/abs/2303.11366</li> <li>Madaan et al. 2023 \u2014 Self-Refine: Iterative Refinement with Self-Feedback \u2014 arxiv.org/abs/2303.17651</li> <li>Andrew Ng \u2014 Agentic Design Patterns Part 2: Reflection \u2014 deeplearning.ai/the-batch</li> <li>Anthropic \u2014 Building Effective Agents \u2014 anthropic.com/research/building-effective-agents</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/tool-use/","title":"Tool Use","text":""},{"location":"agentic-building-blocks/agents/capability-patterns/tool-use/#what-it-is","title":"What It Is","text":"<p>Tool use is a pattern where an agent calls external tools \u2014 APIs, databases, calculators, code interpreters, web browsers, file systems \u2014 to perform actions that go beyond text generation. Instead of relying solely on its training data, the agent selects the right tool, formats the input, executes the call, and interprets the result.</p> <p>This is arguably the most fundamental capability pattern. Without tool use, an agent is limited to generating text. With tool use, it can check inventory, send emails, query databases, run code, and interact with any system that exposes an API.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/tool-use/#why-it-matters","title":"Why It Matters","text":"<p>LLMs have inherent limitations: they can't access real-time data, perform reliable arithmetic, interact with external systems, or take actions in the world. Tool use bridges these gaps by giving the agent access to specialized capabilities on demand.</p> <p>The MRKL (Modular Reasoning, Knowledge and Language) architecture (Karpas et al. 2022) formalized this idea: combine a language model with a set of expert modules (calculators, search engines, databases) and let the model route queries to the right module. Every major AI platform \u2014 Claude, ChatGPT, Gemini, Copilot \u2014 now implements some form of this pattern.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/tool-use/#how-it-works","title":"How It Works","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Agent    \u2502\u2500\u2500\u2500\u2500\u25b8\u2502 Tool Router   \u2502\u2500\u2500\u2500\u2500\u25b8\u2502  Tool    \u2502\n\u2502  (LLM)   \u2502\u25c2\u2500\u2500\u2500\u2500\u2502 (select tool) \u2502\u25c2\u2500\u2500\u2500\u2500\u2502  Result  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ol> <li>Observe \u2014 The agent receives a task or question that requires external information or action.</li> <li>Select \u2014 The agent decides which tool to call based on the task requirements and available tool descriptions.</li> <li>Format \u2014 The agent structures the input according to the tool's expected parameters (function calling).</li> <li>Execute \u2014 The tool runs and returns a result.</li> <li>Interpret \u2014 The agent incorporates the tool result into its reasoning and either responds or calls another tool.</li> </ol> <p>Modern implementations use function calling (also called tool calling) \u2014 the model outputs structured JSON specifying which function to call and with what arguments, rather than generating free-form text that needs parsing.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/tool-use/#example","title":"Example","text":""},{"location":"agentic-building-blocks/agents/capability-patterns/tool-use/#customer-exchange-scenario","title":"Customer exchange scenario","text":"<p>A customer asks to exchange a product. The agent uses multiple tools in sequence:</p> <ol> <li>Order lookup tool \u2014 <code>get_order(customer_id=\"C-1234\")</code> \u2192 Returns order details, items, and dates</li> <li>Policy checker tool \u2014 <code>check_return_eligibility(order_id=\"ORD-5678\", reason=\"exchange\")</code> \u2192 Returns \"eligible, 14-day window\"</li> <li>Inventory tool \u2014 <code>check_stock(sku=\"WIDGET-RED\", warehouse=\"US-EAST\")</code> \u2192 Returns \"in stock, 47 units\"</li> <li>Payment tool \u2014 <code>process_exchange(original_order=\"ORD-5678\", new_sku=\"WIDGET-RED\")</code> \u2192 Returns confirmation number</li> </ol> <p>Without tool use, the agent could only say \"I'd be happy to help with your exchange\" \u2014 it couldn't actually do anything.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/tool-use/#data-analysis","title":"Data analysis","text":"<p>A user asks: \"What were our top 5 products by revenue last quarter?\"</p> <p>The agent calls a SQL query tool: <code>execute_query(\"SELECT product_name, SUM(revenue) as total FROM sales WHERE quarter='Q4-2025' GROUP BY product_name ORDER BY total DESC LIMIT 5\")</code> \u2014 then formats the results into a readable table.</p>"},{"location":"agentic-building-blocks/agents/capability-patterns/tool-use/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Any task requiring real-time or external data (current prices, weather, stock levels)</li> <li>Tasks involving calculations or precise data manipulation</li> <li>Workflows that require taking actions (sending emails, updating records, creating files)</li> <li>Integration with existing business systems (CRM, ERP, order management)</li> <li>Code execution and testing</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/tool-use/#related-patterns","title":"Related Patterns","text":"<ul> <li>Planning \u2014 Planning determines which tools to call and in what order</li> <li>Reflection \u2014 The agent can reflect on tool results to decide if it needs to call additional tools</li> <li>Multi-Agent Collaboration \u2014 Different agents may have access to different tool sets</li> <li>Guardrails \u2014 Guardrails can restrict which tools an agent is allowed to call</li> <li>Agent Capability Patterns</li> </ul>"},{"location":"agentic-building-blocks/agents/capability-patterns/tool-use/#further-reading","title":"Further Reading","text":"<ul> <li>Karpas et al. 2022 \u2014 MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning \u2014 arxiv.org/abs/2205.00445</li> <li>Yao et al. 2022 \u2014 ReAct: Synergizing Reasoning and Acting in Language Models \u2014 arxiv.org/abs/2210.03629</li> <li>Anthropic \u2014 Tool Use with Claude \u2014 docs.anthropic.com/en/docs/build-with-claude/tool-use</li> <li>Andrew Ng \u2014 Agentic Design Patterns Part 3: Tool Use \u2014 deeplearning.ai/the-batch</li> <li>OpenAI \u2014 Function Calling Guide \u2014 platform.openai.com/docs/guides/function-calling</li> </ul>"},{"location":"agentic-building-blocks/context/","title":"Context","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/context/#what-context-is","title":"What Context Is","text":"<p>Context is the unique knowledge \u2014 not in the model's training data \u2014 that an agentic workflow needs to execute well. This includes documents, databases, markdown files, examples, style guides, and any other information from your specific domain.</p> <p>Every AI model has broad general knowledge, but it doesn't know your company's style guide, your product specs, your customer data, or your industry's specific terminology. Context bridges that gap.</p>"},{"location":"agentic-building-blocks/context/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Provides knowledge the model doesn't have \u2014 your data, your docs, your domain</li> <li>Can be inline (pasted), attached as files, or pre-loaded in a project \u2014 flexibility in how you deliver it</li> <li>Improves output quality by grounding the model in your specific domain rather than relying on generic knowledge</li> <li>Can be ephemeral or persistent \u2014 inline context disappears after the conversation; project-level context persists</li> </ul>"},{"location":"agentic-building-blocks/context/#when-to-use-context","title":"When to Use Context","text":"<p>Use context when:</p> <ul> <li>The model needs information it wasn't trained on \u2014 your company's data, your domain's standards</li> <li>You want outputs grounded in specific examples or reference materials</li> <li>The task requires accuracy about your particular situation (not just general knowledge)</li> <li>You're working with proprietary or specialized information</li> </ul> <p>Context alone (without a project) is sufficient when:</p> <ul> <li>The task is a one-off \u2014 you won't need this context again</li> <li>You have 1-2 files to share \u2014 small enough to attach or paste inline</li> <li>The context changes every time \u2014 different documents, different data</li> </ul> <p>When you find yourself re-uploading the same context repeatedly, that's a signal to use a Project to organize it persistently.</p>"},{"location":"agentic-building-blocks/context/#platform-implementations","title":"Platform Implementations","text":"Platform How It Works Claude File attachments, project knowledge base, conversation history OpenAI (ChatGPT) File uploads, Custom GPT knowledge files, conversation history Gemini File uploads, Google Drive integration, NotebookLM sources M365 Copilot Microsoft Graph (emails, files, meetings), attached documents"},{"location":"agentic-building-blocks/context/#types-of-context","title":"Types of Context","text":"Type Description Example Reference material Documents the AI reads but doesn't execute Style guide, product spec, buyer persona Examples Samples of desired output quality or format Past reports, approved emails, template documents Data Structured information the AI processes CSV exports, database queries, spreadsheet data Domain knowledge Specialized information about your field Industry terminology, regulatory requirements, technical standards"},{"location":"agentic-building-blocks/context/#common-context-anti-patterns","title":"Common Context Anti-Patterns","text":"<p>Too much context \u2014 Uploading everything \"just in case\" dilutes signal. Include only what the task actually needs. A focused set of relevant documents outperforms a large dump of loosely related ones.</p> <p>No context when needed \u2014 Asking the model to write in your brand voice without providing your style guide. The model will guess, and it will guess wrong.</p> <p>Stale context \u2014 Using last quarter's data for this quarter's report. Context should be current and relevant to the specific task.</p> <p>Context without instructions \u2014 Attaching a document and saying \"use this\" without explaining how. Tell the model what role the context plays: \"Use this style guide to match our brand voice\" is better than \"Here's our style guide.\"</p>"},{"location":"agentic-building-blocks/context/#relationship-to-other-blocks","title":"Relationship to Other Blocks","text":"<p>Context makes prompts smarter. Projects organize context persistently so you don't re-upload it every time. Skills can package context alongside instructions for reuse. Agents draw on context as they execute multi-step workflows.</p>"},{"location":"agentic-building-blocks/context/#related","title":"Related","text":"<ul> <li>Context Graphs \u2014 structured decision and reasoning graphs for agentic AI</li> <li>Agentic Building Blocks \u2014 Context in the context of all seven building blocks</li> <li>AI Use Cases \u2014 what teams build with context, organized by six primitives</li> <li>Prompts \u2014 the instructions that context enhances</li> <li>Projects \u2014 where context becomes persistent and organized</li> </ul>"},{"location":"agentic-building-blocks/context/context-graphs/","title":"Context Graphs","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/context/context-graphs/#what-context-graphs-are","title":"What Context Graphs Are","text":"<p>A context graph is a structured system that captures not just what information an AI agent uses, but why decisions were made and how facts relate to each other.</p> <p>Think of it this way: a document gives an AI agent information. A context graph gives it understanding \u2014 the connections between entities, the reasoning behind decisions, and the temporal sequence of events that led to the current state.</p> <p>Context graphs build on the concept of a knowledge graph (a network of entities connected by labeled relationships) but go further by encoding decision logic, confidence levels, and causal chains. In a knowledge graph, you might store that \"Customer A bought Product B.\" In a context graph, you also capture why \u2014 the sales signal that triggered outreach, the objection that was overcome, and the precedent from a similar deal that informed the approach.</p>"},{"location":"agentic-building-blocks/context/context-graphs/#how-context-graphs-differ","title":"How Context Graphs Differ","text":"Approach What It Does What It Misses Context window Holds the text (measured in tokens \u2014 chunks of text the model processes) visible to the model in a single conversation No structure, no persistence, limited size RAG Retrieval-Augmented Generation \u2014 retrieves relevant documents from a database and injects them into the prompt Finds related content but doesn't capture relationships between concepts Knowledge graph Maps entities and their relationships in a structured network of nodes (things) and edges (connections) Static structure, no decision reasoning or temporal context Context graph Captures entities, relationships, decisions, reasoning chains, and temporal context in a queryable structure Emerging technology, more complex to build and maintain <p>Each approach in this table builds on the ones above it. RAG helps an AI find relevant documents. A knowledge graph helps it understand how entities relate. A context graph helps it understand why things happened and what led to decisions \u2014 which is what agents need for multi-step reasoning.</p>"},{"location":"agentic-building-blocks/context/context-graphs/#key-concepts","title":"Key Concepts","text":""},{"location":"agentic-building-blocks/context/context-graphs/#nodes","title":"Nodes","text":"<p>Nodes are the things in a context graph. Unlike a traditional knowledge graph where nodes are mostly entities (people, companies, products), context graph nodes include:</p> Node Type What It Represents Example Entity A person, organization, product, or concept \"Acme Corp\", \"Q4 Revenue Report\" Decision A choice that was made, with reasoning \"Chose vendor B because of compliance requirements\" Signal An event or data point that triggered action \"Customer satisfaction dropped below 80%\" State A snapshot of conditions at a point in time \"Pipeline status as of January 2026\""},{"location":"agentic-building-blocks/context/context-graphs/#edges","title":"Edges","text":"<p>Edges are the connections between nodes \u2014 they describe how things relate. Context graphs use richer edge types than traditional knowledge graphs:</p> Edge Type What It Captures Example Causation One thing led to another Signal \"churn risk detected\" \u2192 Decision \"escalate to account manager\" Dependency One thing requires another Task \"generate report\" depends on State \"data refresh complete\" Precedent A past decision that informs a current one Decision \"pricing for Enterprise tier\" references Decision \"pricing for Mid-Market tier\" Temporal Sequence and timing of events Signal A occurred before Signal B, 3 days apart Confidence How certain a relationship is Entity \"likely competitor\" connected with 0.7 confidence"},{"location":"agentic-building-blocks/context/context-graphs/#relationships","title":"Relationships","text":"<p>The combination of nodes and edges creates relationship patterns that agents can traverse:</p> <ul> <li>Temporal chains \u2014 \"What sequence of events led to this outcome?\"</li> <li>Conditional logic \u2014 \"Under what conditions was this decision made?\"</li> <li>Confidence-weighted paths \u2014 \"What's the most reliable chain of reasoning?\"</li> </ul>"},{"location":"agentic-building-blocks/context/context-graphs/#why-they-matter-for-agentic-ai","title":"Why They Matter for Agentic AI","text":"<p>Context graphs address specific limitations that surface when AI agents handle multi-step, real-world workflows:</p> <ul> <li>Multi-step reasoning \u2014 Agents can trace chains of causation and dependency rather than relying on whatever fits in the context window</li> <li>Structured memory \u2014 Decisions and their rationale persist across conversations and sessions, giving agents institutional knowledge</li> <li>Auditability \u2014 Every recommendation can be traced back through the graph to the signals and precedents that informed it</li> <li>Compounding organizational knowledge \u2014 Each interaction adds to the graph, making the system more capable over time rather than starting fresh each session</li> </ul>"},{"location":"agentic-building-blocks/context/context-graphs/#the-context-engineering-shift","title":"The Context Engineering Shift","text":"<p>The AI industry is undergoing a shift from prompt engineering (optimizing how you ask) to context engineering (optimizing what information the model sees).</p> <p>The core insight: a well-structured, relevant context makes even a simple prompt produce excellent results. A perfectly crafted prompt with poor context still produces poor results.</p> <p>This shift has practical implications:</p> <ul> <li>Where you invest time changes \u2014 less on prompt syntax, more on building and curating the information your AI workflows consume</li> <li>What you build changes \u2014 systems that assemble, filter, and structure context become more valuable than prompt template libraries</li> <li>How you measure quality changes \u2014 success depends on whether the right context reached the model, not just whether the prompt was well-written</li> </ul> <p>Context graphs represent the most structured end of this spectrum \u2014 purpose-built systems for assembling exactly the right context for each agent action.</p>"},{"location":"agentic-building-blocks/context/context-graphs/#tools-and-frameworks","title":"Tools and Frameworks","text":"Tool What It Does Best For TrustGraph Extracts knowledge graphs from documents with AI, supports context graph queries Document-heavy workflows needing structured extraction Graphiti Temporal knowledge graph library for building agent memory Agents that need persistent, evolving memory across sessions LangGraph Framework for building stateful, multi-agent workflows with graph-based orchestration Complex agent orchestration with branching logic Neo4j Graph database for storing and querying relationship-rich data Enterprise-scale knowledge and context graph storage MCP Model Context Protocol \u2014 a standard for connecting AI models to external data sources and tools Connecting agents to live context from APIs, databases, and services"},{"location":"agentic-building-blocks/context/context-graphs/#relationship-to-other-blocks","title":"Relationship to Other Blocks","text":"<p>Context graphs intersect with every other building block:</p> <ul> <li>Prompts \u2014 Context graphs provide the structured background that makes prompts effective. Instead of cramming context into a prompt, agents query the graph for exactly what's relevant.</li> <li>Projects \u2014 Projects organize persistent context. Context graphs add structure within that context \u2014 not just \"here are the files\" but \"here's how they relate.\"</li> <li>Skills \u2014 Skills can use context graphs to make decisions based on precedent and historical patterns rather than just the instructions they contain.</li> <li>Agents \u2014 Agents are the primary consumers of context graphs. Multi-step workflows benefit most from structured reasoning and memory.</li> <li>MCP \u2014 MCP servers can expose context graph data as tools and resources, giving agents structured access to organizational knowledge.</li> </ul>"},{"location":"agentic-building-blocks/context/context-graphs/#further-reading","title":"Further Reading","text":"<ul> <li>AI's Trillion-Dollar Opportunity: Context Graphs \u2014 Foundation Capital</li> <li>Context is the Next Data Platform \u2014 Glean</li> <li>What are Context Graphs \u2014 Neural Notions</li> <li>Context Engineering for Agents \u2014 LangChain</li> <li>Context Graphs: A Practical Guide \u2014 Adnan Masood, PhD</li> <li>Effective Context Engineering for AI Agents \u2014 Anthropic</li> <li>Context Graphs: AI-Optimized Knowledge Graphs \u2014 TrustGraph</li> <li>Graphiti \u2014 Temporal knowledge graph library for agent memory</li> </ul>"},{"location":"agentic-building-blocks/context/context-graphs/#related","title":"Related","text":"<ul> <li>Context Engineering \u2014 the broader discipline; context graphs are an advanced technique within it</li> <li>Context \u2014 the Context building block overview</li> <li>Agentic Building Blocks \u2014 Context Graphs in the context of all seven building blocks</li> <li>AI Use Cases \u2014 what teams build with context, organized by six primitives</li> <li>Agents \u2014 autonomous workflows that benefit most from structured context</li> <li>MCP \u2014 the protocol for connecting agents to external context sources</li> <li>Prompts \u2014 the instructions that context enhances</li> </ul>"},{"location":"agentic-building-blocks/mcp/","title":"MCP (Model Context Protocol)","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/mcp/#what-mcp-is","title":"What MCP Is","text":"<p>MCP (Model Context Protocol) is an open standard for connecting AI assistants to external systems where data lives \u2014 content repositories, business tools, databases, and development environments. It bridges the gap between the AI and the outside world, enabling both read and write operations.</p> <p>Without MCP, the AI is limited to what's in the conversation. With MCP, the AI can look up client history in your CRM, check deal status in your pipeline, create tasks in your project management tool, or query live data \u2014 all within the conversation.</p>"},{"location":"agentic-building-blocks/mcp/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Bridges the gap between the AI and the outside world where your data lives</li> <li>Open standard \u2014 one integration pattern that works across compatible platforms</li> <li>Enables read and write operations \u2014 the AI can both retrieve information and take actions</li> <li>Composable \u2014 multiple MCP connectors can be active simultaneously, giving the AI access to multiple external systems</li> </ul>"},{"location":"agentic-building-blocks/mcp/#when-to-use-mcp","title":"When to Use MCP","text":"<p>Use MCP when:</p> <ul> <li>The AI needs to interact with external systems \u2014 reading from or writing to tools you already use</li> <li>Your workflow requires live data that changes between runs (not static reference documents)</li> <li>You want the AI to take actions in other systems \u2014 creating tasks, sending messages, updating records</li> <li>You're building agents that need to coordinate across multiple tools</li> </ul> <p>MCP is typically the last building block you need. Start with prompts, add context, organize in a project, package as skills, then add MCP when the workflow needs external system access.</p>"},{"location":"agentic-building-blocks/mcp/#platform-implementations","title":"Platform Implementations","text":"Platform How It Works Claude MCP servers (local or remote) connected via Claude Code or Claude Desktop OpenAI (ChatGPT) Function calling, Actions in Custom GPTs, Assistants API tools Gemini Extensions and function calling M365 Copilot Connectors, plugins, Power Platform integrations"},{"location":"agentic-building-blocks/mcp/#common-mcp-use-cases","title":"Common MCP Use Cases","text":"Use Case What the AI Does Example Tools Knowledge management Reads and writes to your knowledge bases Notion, Confluence, Google Drive Project management Creates tasks, updates status, queries boards Linear, Jira, Asana, Trello Communication Reads messages, sends updates, manages threads Slack, Email, Teams Data access Queries databases, retrieves records PostgreSQL, Supabase, Airtable Development Manages repos, reviews PRs, deploys code GitHub, Vercel, AWS CRM Looks up clients, logs interactions, updates deals HubSpot, Salesforce"},{"location":"agentic-building-blocks/mcp/#relationship-to-other-blocks","title":"Relationship to Other Blocks","text":"<p>MCP extends what agents and skills can do by connecting them to external systems. Without MCP, the AI is limited to what's in the conversation. With MCP, skills can pull live data and agents can take real-world actions as part of their workflows.</p>"},{"location":"agentic-building-blocks/mcp/#related","title":"Related","text":"<ul> <li>Agentic Building Blocks \u2014 MCP in the context of all seven building blocks</li> <li>AI Use Cases \u2014 what teams build with MCP, organized by six primitives</li> <li>Automation Use Cases \u2014 MCP enables the data connections that power automated workflows</li> <li>Agents \u2014 autonomous systems that use MCP to interact with external tools</li> <li>Skills \u2014 reusable routines that MCP can enhance with external data</li> <li>Projects \u2014 workspaces where MCP connectors are configured</li> </ul>"},{"location":"agentic-building-blocks/models/","title":"Model","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/models/#what-a-model-is","title":"What a Model Is","text":"<p>A model is the AI engine that powers everything. It's a system trained on data that takes input and produces output through learned patterns \u2014 generating text, writing code, analyzing images, or reasoning through complex problems.</p> <p>Every other building block depends on a model. Prompts steer it. Context informs it. Projects organize work for it. Skills package routines for it. Agents orchestrate it. MCP connects it to external systems. Without a model, the other blocks have nothing to run on.</p>"},{"location":"agentic-building-blocks/models/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Trained on data \u2014 a model's knowledge comes from its training data, with a cutoff date after which it has no information</li> <li>Come in capability tiers \u2014 from fast, lightweight models for simple tasks to deep reasoning models for complex analysis</li> <li>Have defined context windows \u2014 how much information (measured in tokens) a model can process at once</li> <li>Vary by modality \u2014 some handle only text, others work with code, vision, audio, or multiple modalities together</li> </ul>"},{"location":"agentic-building-blocks/models/#model-capabilities","title":"Model Capabilities","text":"<p>Different models excel at different things. Here are the key capability dimensions to consider:</p> Capability What It Means Example Tasks Reasoning Complex analysis, multi-step logic, nuanced judgment Strategy analysis, research synthesis, debugging complex systems Code generation Writing, debugging, and explaining code Building features, fixing bugs, code review Multimodal Processing or generating images, audio, or video Analyzing charts, describing photos, transcribing audio Speed Fast response for simple, high-volume tasks Summarization, formatting, classification, triage Context window How much input the model can handle at once Processing long documents, large codebases, multi-file analysis Tool use Calling functions, APIs, and external tools Running code, searching the web, querying databases"},{"location":"agentic-building-blocks/models/#when-to-use-it-model-selection-guidance","title":"When to Use It (Model Selection Guidance)","text":"<p>Choosing the right model for the task is one of the highest-leverage decisions you can make:</p> Task Type Recommended Model Tier Why Simple tasks (summarization, formatting, classification) Fast, lightweight models Speed and cost matter more than depth Complex analysis (research, strategy, multi-step reasoning) Reasoning-capable models Accuracy and depth matter more than speed Visual tasks (image analysis, diagram interpretation) Multimodal models The task requires understanding non-text inputs Code-heavy work (building features, debugging, refactoring) Code-optimized models Specialized training produces better code output High-volume automation (batch processing, triage) Fast models with tool use Throughput and cost-efficiency are priorities <p>Cost-quality tradeoff</p> <p>Not every task needs the most powerful model. Using a fast model for simple tasks and reserving reasoning models for complex ones saves cost without sacrificing quality. Many platforms let you route different tasks to different models within the same workflow.</p>"},{"location":"agentic-building-blocks/models/#foundational-concepts","title":"Foundational Concepts","text":"<p>These concepts help you understand what a model is and how it works:</p> <p>Parameters \u2014 The internal weights that define a model's learned patterns. More parameters generally means more capability, but also more computational cost. You don't set parameters \u2014 they're determined during training.</p> <p>Tokens \u2014 How models measure input and output. A token is roughly 3-4 characters of English text. Models have limits on how many tokens they can process (input) and generate (output) per request.</p> <p>Context window \u2014 The total number of tokens a model can handle in a single interaction, including both the input you provide and the output it generates. Larger context windows let you work with longer documents and more complex inputs.</p> <p>Temperature \u2014 A setting that controls randomness in outputs. Low temperature (0.0) produces more deterministic, focused responses. High temperature (1.0+) produces more creative, varied responses. Most platforms default to a balanced setting.</p> <p>Training data and knowledge cutoff \u2014 Models learn from data up to a specific date. They don't know about events, products, or information published after their cutoff. This is why context (providing current information) is essential for tasks involving recent data.</p> <p>Fine-tuning \u2014 Customizing a pre-trained model on your specific data to improve performance for your domain. Most users don't need to fine-tune \u2014 prompt engineering and context are usually sufficient \u2014 but it's available for specialized use cases.</p>"},{"location":"agentic-building-blocks/models/#where-to-find-models","title":"Where to Find Models","text":"Source What's Available Best For Anthropic (Claude) Claude model family across capability tiers Reasoning, code, analysis, long context OpenAI GPT and reasoning model families General purpose, reasoning, multimodal Google Gemini model family Multimodal, Google ecosystem integration Open-source hubs (Hugging Face) Thousands of community and enterprise models Custom deployment, fine-tuning, specialized tasks <p>Open-source vs. proprietary</p> <p>Proprietary models (Claude, GPT, Gemini) are accessed via APIs and platforms \u2014 you don't host them yourself. Open-source models (Llama, Mistral, and others on Hugging Face) can be downloaded and run on your own infrastructure, offering more control but requiring more technical setup.</p>"},{"location":"agentic-building-blocks/models/#platform-implementations","title":"Platform Implementations","text":"Platform How It Works Claude Multiple model tiers (fast, balanced, reasoning); select via model picker in conversation or API parameter OpenAI (ChatGPT) Multiple model tiers (fast, balanced, reasoning); select via model picker in conversation or API parameter Gemini Multiple model tiers (fast, balanced); select via model picker in conversation or API parameter M365 Copilot Models managed by Microsoft; limited user selection based on Copilot context"},{"location":"agentic-building-blocks/models/#relationship-to-other-blocks","title":"Relationship to Other Blocks","text":"<p>Model is the foundation \u2014 the engine everything else runs on:</p> <ul> <li>Prompts steer the model \u2014 telling it what to do</li> <li>Context informs the model \u2014 giving it knowledge it wasn't trained on</li> <li>Projects organize work for the model \u2014 grouping instructions and context</li> <li>Skills package routines for the model \u2014 reusable workflows it executes</li> <li>Agents orchestrate the model \u2014 directing it through multi-step tasks</li> <li>MCP connects the model \u2014 giving it access to external tools and data</li> </ul>"},{"location":"agentic-building-blocks/models/#related","title":"Related","text":"<ul> <li>Agentic Building Blocks \u2014 Model in the context of all seven building blocks</li> <li>AI Use Cases \u2014 what teams build with these blocks, organized by six primitives</li> <li>Prompts \u2014 the instructions that steer the model</li> <li>Context \u2014 the knowledge that informs the model</li> <li>Projects \u2014 workspaces that organize work for the model</li> <li>Skills \u2014 reusable routines the model executes</li> <li>Agents \u2014 autonomous systems that orchestrate the model</li> <li>MCP \u2014 connectors that extend the model's reach</li> <li>Platforms \u2014 platform-specific model guides</li> </ul>"},{"location":"agentic-building-blocks/projects/","title":"Projects","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code> <code>perplexity</code></p>"},{"location":"agentic-building-blocks/projects/#what-projects-are","title":"What Projects Are","text":"<p>Project workspaces (\"Projects\") are professional-grade AI capabilities that scale your expertise and amplify your impact. Instead of starting every conversation from scratch, a project gives the AI persistent memory, specialized knowledge, and standing instructions that shape every interaction.</p> <p></p>"},{"location":"agentic-building-blocks/projects/#strategic-capabilities","title":"Strategic Capabilities","text":"<p>Projects provide three capabilities that turn a generic AI assistant into a purpose-built tool:</p>"},{"location":"agentic-building-blocks/projects/#memory","title":"Memory","text":"<p>Build up deep context to guide the AI and improve model performance. Every conversation in a project contributes to a shared history, so the AI learns your preferences, terminology, and working patterns over time.</p>"},{"location":"agentic-building-blocks/projects/#knowledge-base","title":"Knowledge Base","text":"<p>Embed specialized knowledge, industry insights, and proprietary data that generic LLMs lack. Upload reference documents, style guides, templates, data files, and examples \u2014 the AI draws on this knowledge in every conversation without you re-uploading it.</p>"},{"location":"agentic-building-blocks/projects/#custom-instructions","title":"Custom Instructions","text":"<p>Shape every response an AI gives you inside a workspace. Custom instructions are the difference between a generic assistant and one that knows your role, your standards, and what good output looks like \u2014 without you repeating yourself every conversation.</p>"},{"location":"agentic-building-blocks/projects/#platform-options","title":"Platform Options","text":"Platform Project Feature Key Characteristics Claude Claude Projects Project knowledge files, custom instructions, conversation history ChatGPT ChatGPT Projects Project instructions, file uploads, shared conversations Google Gemini Gems Custom instructions, uploaded context, reusable specialists Perplexity Spaces Shared research spaces with persistent sources and instructions M365 Copilot Copilot Notebooks Instructions, Microsoft Graph integration, enterprise knowledge"},{"location":"agentic-building-blocks/projects/#when-to-use-a-project","title":"When to Use a Project","text":"<p>Use a project when:</p> <ul> <li>You run the same workflow weekly or more often</li> <li>Multiple context files (3+) are needed every time</li> <li>The same reference materials are used across conversations</li> <li>Conversation memory across sessions would improve quality</li> <li>Multiple people need to run the same workflow</li> </ul> <p>Use a regular conversation when:</p> <ul> <li>The task is a one-off or experimental</li> <li>Little or no persistent context is needed (0-2 files)</li> <li>All context can be provided inline each time</li> </ul>"},{"location":"agentic-building-blocks/projects/#what-makes-a-good-project","title":"What Makes a Good Project","text":"<p>The best projects follow one principle: one workspace, one purpose.</p> <p>A \"marketing workspace\" is too broad. A \"blog post review workspace\" or \"weekly client report workspace\" is focused enough to have clear instructions, relevant knowledge, and consistent output quality.</p> <p>Good projects have:</p> <ul> <li>A clear single purpose \u2014 what this workspace does, stated in one sentence</li> <li>Specific custom instructions \u2014 role, task, context, and format guidance (not vague \"be helpful\" statements)</li> <li>Curated knowledge \u2014 only the reference materials this workflow actually needs</li> <li>Test prompts \u2014 2-3 prompts you can use to verify the workspace works as intended</li> </ul>"},{"location":"agentic-building-blocks/projects/#guides","title":"Guides","text":"Guide Description Write Custom Workspace Instructions Meta prompt that walks you through creating purpose-built workspace instructions using the 4 Elements framework Set Up Claude Projects Step-by-step setup guide for Claude's project feature"},{"location":"agentic-building-blocks/projects/#related","title":"Related","text":"<ul> <li>Agentic Building Blocks \u2014 Projects in the context of all seven building blocks</li> <li>AI Use Cases \u2014 what teams build with projects, organized by six primitives</li> <li>Prompts \u2014 techniques for the prompts that go inside projects</li> <li>Business-First AI Framework \u2014 uses projects as a building block in workflow analysis</li> </ul>"},{"location":"agentic-building-blocks/projects/workspace-instructions-meta-prompt/","title":"How to Write Custom Workspace Instructions","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/projects/workspace-instructions-meta-prompt/#why-this-matters","title":"Why This Matters","text":"<p>Custom instructions shape every response an AI gives you inside a workspace. They're the difference between a generic assistant and one that knows your role, your standards, and what good output looks like \u2014 without you repeating yourself every conversation.</p> <p>Most people leave custom instructions blank or write something vague like \"be helpful and concise.\" That's a missed opportunity. Well-written instructions turn a workspace into a purpose-built tool that gets better results from the first message.</p> <p>The 4 Elements framework \u2014 Role, Task, Context, Format \u2014 gives you a systematic way to write these instructions. This meta prompt walks you through discovering what your workspace needs and generates instructions tailored to your specific platform:</p> <ul> <li>Claude Projects \u2014 Custom instructions in project settings, plus project knowledge files</li> <li>ChatGPT Projects \u2014 Project instructions (flowing paragraph style)</li> <li>Google Gems \u2014 Custom Gem instructions (single continuous block)</li> <li>M365 Copilot Notebooks \u2014 Notebook instructions (concise, task-focused)</li> </ul>"},{"location":"agentic-building-blocks/projects/workspace-instructions-meta-prompt/#how-to-use-this-prompt","title":"How to Use This Prompt","text":"<ol> <li>Copy the prompt from the code block below</li> <li>Paste it into your preferred AI tool (Claude, ChatGPT, Gemini, M365 Copilot)</li> <li>Press Enter to send it \u2014 the model will check for existing context about you, then start asking discovery questions</li> <li>Answer the model's questions one at a time \u2014 it will build a picture of what your workspace needs</li> <li>Review the 4 Elements mapping and tell the model which platform you'll use</li> <li>Receive your finished instructions ready to paste into your workspace settings</li> </ol> <p>One workspace, one purpose</p> <p>Each workspace should do one thing well. A \"marketing workspace\" is too broad \u2014 a \"blog post review workspace\" or \"social media drafting workspace\" will produce much better results. If you need multiple purposes, create multiple workspaces.</p>"},{"location":"agentic-building-blocks/projects/workspace-instructions-meta-prompt/#example-what-the-first-exchange-looks-like","title":"Example: What the first exchange looks like","text":"<p>After you paste the prompt, the model will start by scanning for context about you. Here's what a typical opening looks like:</p> <p>Model: Before we start, let me check what I already know about you...</p> <p>I can see from our previous conversations that you work in marketing at a B2B SaaS company, you frequently write blog posts and case studies, and you've mentioned struggling with maintaining consistent brand voice across content. Does that sound right?</p> <p>Is the workspace you want to create related to that marketing work, or something different?</p> <p>You: Yes, that's right. I want to create a workspace specifically for reviewing blog post drafts before they go to my editor.</p> <p>Model: Great \u2014 a blog post review workspace. Let's figure out exactly what this workspace should do for you. First question: when you review a blog post draft today, what's the main thing you're checking for? Is it structure, tone, accuracy, SEO, something else?</p> <p>From there, the model works through seven discovery areas one question at a time, building a complete picture of what your workspace needs.</p>"},{"location":"agentic-building-blocks/projects/workspace-instructions-meta-prompt/#not-sure-what-to-try","title":"Not sure what to try?","text":"<p>Pick a task you do repeatedly where you find yourself giving the AI the same context every time. Here are some examples students have used:</p> <ul> <li>Weekly reporting workspace \u2014 pulling updates from multiple sources and synthesizing them into a consistent format</li> <li>Code review workspace \u2014 reviewing pull requests against team standards, checking for common issues</li> <li>Meeting prep workspace \u2014 researching attendees, drafting agendas, preparing talking points</li> <li>Research synthesizer workspace \u2014 reading multiple sources on a topic and producing structured summaries</li> <li>Email drafting workspace \u2014 writing professional emails that match your voice and handle common scenarios</li> <li>Course content reviewer workspace \u2014 checking lesson materials for clarity, accuracy, and alignment with learning objectives</li> </ul> <p>You don't need to know exactly what instructions you want \u2014 that's what the prompt helps you figure out.</p>"},{"location":"agentic-building-blocks/projects/workspace-instructions-meta-prompt/#the-meta-prompt","title":"The Meta Prompt","text":"<pre><code>You are an expert AI Workspace Designer who specializes in writing custom instructions for AI workspaces using the 4 Elements framework (Role, Task, Context, Format). Your job is to help me create purpose-built workspace instructions that make every conversation in that workspace more useful from the first message.\n\nWork through the following four phases in order. Ask one question at a time during interactive phases. Wait for my response before moving on.\n\n---\n\n## Phase 1 \u2014 Context Scan\n\nBefore asking me anything, check if you have access to any project files, memory, conversation history, or other context that includes details about my role, work, preferences, workflows, or communication style.\n\n**If you find relevant context:**\nSummarize what you found \u2014 my role, domain, recurring tasks, tools, preferences, and any pain points or goals you've picked up. Then ask: \"Is the workspace you want to create related to this context, or something different?\"\n\n**If you find no prior context:**\nSay so, and move directly to Phase 2.\n\n---\n\n## Phase 2 \u2014 Workspace Discovery\n\nBuild a complete picture of what this workspace should do by exploring seven areas. Ask these one at a time \u2014 not all at once. Use my answers to ask smart follow-up questions before moving to the next area.\n\n1. **Purpose** \u2014 What is the single primary purpose of this workspace? What task or workflow will you use it for?\n2. **Domain** \u2014 What field, industry, or subject area does this workspace operate in? What specialized knowledge should the AI have?\n3. **Audience** \u2014 Who will read or receive the outputs from this workspace? What do they expect or need?\n4. **Tone &amp; style** \u2014 How should the AI communicate in this workspace? Formal or casual? Technical or accessible? Any specific voice characteristics?\n5. **Constraints** \u2014 What should the AI avoid? Are there policies, guardrails, topics, or approaches that are off-limits?\n6. **Output patterns** \u2014 What does good output look like in this workspace? Are there standard formats, templates, lengths, or structures the AI should follow?\n7. **Anti-patterns** \u2014 What does bad output look like? What common AI behaviors do you want to suppress? (e.g., excessive hedging, bullet-point overuse, generic advice, restating the obvious)\n\n**Smart follow-ups:** If I give a vague answer (e.g., \"just professional\" for tone), probe deeper: \"Professional can mean many things \u2014 do you mean formal and reserved, or warm and direct? Should it sound like a consultant's report, a colleague's Slack message, or something else?\"\n\n**If I'm not sure what workspace to create:** Propose 2-3 example workspace purposes based on whatever context you have (my role, domain, or common use cases), and let me react. Use my reaction to narrow down the purpose.\n\nAfter covering all seven areas, present a summary of what you've learned and ask me to confirm it's accurate before moving to Phase 3.\n\n---\n\n## Phase 3 \u2014 4 Elements Mapping\n\nMap my discovery answers to the 4 Elements framework. Present this as a table:\n\n| Element | What It Covers | Your Workspace |\n|---------|---------------|----------------|\n| **Role** | Who the AI is in this workspace \u2014 its expertise, perspective, and personality | [Mapped from domain, tone, purpose] |\n| **Task** | What the AI should do by default \u2014 its primary job and how it approaches work | [Mapped from purpose, output patterns, constraints] |\n| **Context** | What background knowledge, rules, or reference material the AI needs | [Mapped from domain, audience, constraints] |\n| **Format** | How the AI should structure and style its responses | [Mapped from output patterns, tone, anti-patterns] |\n\nWalk me through the mapping: explain why you placed each discovery answer where you did, and flag anything that could go in more than one element.\n\nAsk if I want to adjust anything.\n\nThen ask: **Which platform will you use this workspace on?**\n- Claude Projects\n- ChatGPT Projects\n- Google Gems\n- M365 Copilot Notebooks\n\n---\n\n## Phase 4 \u2014 Instruction Generation\n\nGenerate the finished workspace instructions, tailored to the platform I selected.\n\n### Instruction structure\n\nOrganize the instructions using these four sections:\n\n**## Role**\nWho the AI is \u2014 expertise, perspective, personality, and how it should think about its job in this workspace.\n\n**## Task**\nWhat the AI does by default \u2014 its primary responsibilities, how it should approach work, and what it should prioritize.\n\n**## Context**\nBackground knowledge, rules, standards, and reference material the AI should keep in mind. Include anything the AI needs to know that isn't obvious from the task description.\n\n**## Format**\nHow responses should be structured and styled \u2014 length, structure, tone, and what to avoid.\n\n### Platform-specific adjustments\n\n**Claude Projects:**\n- Use full Markdown with headers and structure\n- If any of my discovery answers mentioned reference documents, templates, examples, or data the AI should have access to, note these separately as \"Recommended project knowledge uploads\" \u2014 files or content I should add to the project's knowledge base\n- Aim for 150-400 words in the instructions\n\n**ChatGPT Projects:**\n- Write in a flowing paragraph style rather than heavy Markdown structure \u2014 ChatGPT project instructions work best as natural prose with minimal formatting\n- Keep under 1,500 characters total\n- Aim for 150-300 words\n\n**Google Gems:**\n- Write as a single continuous instruction \u2014 Gems expect one flowing block of text, not structured sections\n- Keep under 2,000 characters total\n- Aim for 150-350 words\n\n**M365 Copilot Notebooks:**\n- Keep concise and action-oriented \u2014 focus on task and format elements\n- Minimize background context (Copilot works best with direct instructions)\n- Aim for 100-250 words\n\n### Final output\n\nDeliver three things:\n\n1. **The instructions** \u2014 ready to copy and paste into the workspace settings, formatted for the selected platform\n2. **Platform tips** \u2014 2-3 specific tips for getting the most out of this workspace on their chosen platform (e.g., what to upload as project knowledge on Claude, how to structure follow-up conversations)\n3. **Test prompts** \u2014 3 example prompts the student can use to test the workspace immediately after setting it up, designed to exercise different aspects of the instructions\n\n---\n\n## General Instructions\n\n- Ask one question at a time. Never present a wall of questions.\n- Aim for 150-400 words in the final instructions \u2014 long enough to be specific, short enough to be focused.\n- Use plain language. Mirror the student's vocabulary rather than introducing jargon.\n- Recommend separate workspaces for unrelated purposes \u2014 if the student's answers reveal multiple distinct use cases, flag this and suggest splitting.\n- Don't restate default AI behavior in the instructions. \"Be helpful\" or \"answer questions accurately\" wastes space \u2014 the AI already does that. Focus on what makes this workspace different from a blank conversation.\n- Write the instructions in second person addressing the AI (\"You are...\", \"Your job is...\", \"When the user asks...\"). The student is writing instructions that tell the AI how to behave.\n</code></pre>"},{"location":"agentic-building-blocks/projects/workspace-instructions-meta-prompt/#what-to-expect","title":"What to Expect","text":"<p>After pasting the prompt, here's how the conversation typically unfolds:</p> <ol> <li>Phase 1 \u2014 Context Scan \u2014 The model checks what it already knows about you from memory, project files, or conversation history. If it finds relevant context, it summarizes what it knows and asks whether your workspace is related. If it has no context, it moves straight to discovery.</li> <li>Phase 2 \u2014 Workspace Discovery \u2014 The model asks you about seven areas one at a time: purpose, domain, audience, tone, constraints, output patterns, and anti-patterns. Expect follow-up questions when your answers are vague \u2014 this is where the model helps you articulate preferences you haven't thought to state explicitly. At the end, you'll see a summary to confirm.</li> <li>Phase 3 \u2014 4 Elements Mapping \u2014 The model maps your answers to the Role, Task, Context, and Format framework and shows you the mapping in a table. You can adjust before it generates the final output. It also asks which platform you'll use.</li> <li>Phase 4 \u2014 Instruction Generation \u2014 You receive platform-formatted instructions ready to paste, along with tips for your specific platform and three test prompts to try immediately.</li> </ol> <p>Most students go from \"I'm not sure what I want\" to finished instructions in 10-15 messages. The instructions are a strong starting point \u2014 plan to refine them after using the workspace for a few conversations.</p>"},{"location":"agentic-building-blocks/projects/workspace-instructions-meta-prompt/#tips-for-better-results","title":"Tips for Better Results","text":"<ul> <li>Be specific about what annoys you. \"Don't use bullet points for everything\" or \"Stop saying 'Great question!'\" gives the model concrete anti-patterns to suppress. The anti-patterns question in Phase 2 is where a lot of the value comes from.</li> <li>Mention your pet peeves. If you hate when AI hedges with \"it depends\" or overuses caveats, say so. These details make the biggest difference in how the workspace feels.</li> <li>Include examples of good output. If you have a document, email, or report that represents the quality and style you want, describe it during discovery. The model will extract the patterns and build them into the instructions.</li> <li>Test and iterate. Run the three test prompts as soon as you set up the workspace. If something feels off, tell the model what to adjust and regenerate \u2014 don't try to hand-edit the instructions from scratch.</li> <li>Revisit quarterly. Your work evolves, and your workspace instructions should too. Re-run this prompt every few months or when your role, tools, or priorities change significantly.</li> <li>Keep instructions under 500 words. Longer instructions don't mean better results \u2014 they often mean the AI tries to follow too many rules at once. If your instructions are getting long, you probably need two workspaces, not one.</li> </ul>"},{"location":"agentic-building-blocks/projects/workspace-instructions-meta-prompt/#related","title":"Related","text":"<ul> <li>Projects Overview \u2014 What project workspaces are and when to use them</li> <li>Set Up Claude Projects \u2014 How to create and configure Claude Projects</li> <li>What Is a System Prompt? \u2014 Understanding how custom instructions work under the hood</li> <li>Deconstruct Workflows \u2014 Break down workflows before building workspaces for them</li> <li>Prompts</li> </ul>"},{"location":"agentic-building-blocks/prompts/","title":"Prompts","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/prompts/#what-prompts-are","title":"What Prompts Are","text":"<p>Prompts are the instructions you provide to an AI in natural language during a conversation. They're ephemeral, conversational, and reactive \u2014 you provide context and direction in the moment.</p> <p>Every AI interaction starts with a prompt. It's the most fundamental building block \u2014 a well-crafted prompt is often all you need to get useful output, without any of the other blocks.</p>"},{"location":"agentic-building-blocks/prompts/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Natural language \u2014 you write prompts the way you'd explain a task to a knowledgeable colleague</li> <li>Ephemeral \u2014 used in the moment, within a single conversation turn</li> <li>Reactive \u2014 you adjust and refine based on the AI's response</li> <li>Range of complexity \u2014 from a single sentence to a detailed multi-section instruction with role, task, context, and format guidance</li> </ul>"},{"location":"agentic-building-blocks/prompts/#when-to-use-a-prompt-alone","title":"When to Use a Prompt Alone","text":"<p>A prompt by itself is sufficient when:</p> <ul> <li>The task is a one-off (no need to repeat it)</li> <li>The AI's training data has everything it needs (no specialized knowledge required)</li> <li>The output format is simple or you can describe it inline</li> <li>You don't need persistence across conversations</li> </ul> <p>When you find yourself writing the same prompt repeatedly or needing to attach the same context every time, that's a signal to consider other building blocks \u2014 Context, Projects, or Skills.</p>"},{"location":"agentic-building-blocks/prompts/#anatomy-of-an-effective-prompt","title":"Anatomy of an Effective Prompt","text":"<p>The best prompts address four elements:</p> Element What It Covers Example Role Who the AI should be \u2014 expertise, perspective, personality \"You are a senior copywriter specializing in B2B SaaS\" Task What the AI should do \u2014 the specific action or output \"Write three subject line options for this product launch email\" Context Background the AI needs \u2014 constraints, audience, standards \"Our audience is enterprise CTOs. Tone should be authoritative, not salesy\" Format How the output should be structured \"Present each option with a subject line and a one-sentence rationale\" <p>Not every prompt needs all four elements. A simple question needs only the task. But as complexity grows, adding role, context, and format dramatically improves output quality.</p>"},{"location":"agentic-building-blocks/prompts/#platform-implementations","title":"Platform Implementations","text":"Platform How Prompts Work Claude Messages in conversation, system prompts, project instructions OpenAI (ChatGPT) Messages in conversation, system prompts, Custom GPT instructions Gemini Messages in conversation, Gem instructions M365 Copilot Chat messages, prompts within Copilot agents"},{"location":"agentic-building-blocks/prompts/#common-prompt-anti-patterns","title":"Common Prompt Anti-Patterns","text":"<p>Vague instructions \u2014 \"Help me with marketing\" gives the AI nothing to anchor on. Be specific: \"Draft a 200-word LinkedIn post announcing our Q3 product update, targeting engineering managers.\"</p> <p>Overloading a single prompt \u2014 Asking the AI to research, analyze, write, format, and review in one prompt leads to shallow results. Break complex work into sequential prompts or use a Skill.</p> <p>Ignoring format guidance \u2014 If you don't specify output structure, you get whatever the model defaults to. State what you want: bullet points, a table, a specific word count, or a particular template.</p> <p>Repeating yourself every conversation \u2014 If you're pasting the same preamble into every chat, you need a Project with custom instructions instead.</p>"},{"location":"agentic-building-blocks/prompts/#guides","title":"Guides","text":"Guide Description Prompt Engineering Core techniques \u2014 context windows, system prompts, few-shot learning, chain-of-thought Project Instructions When your prompts evolve into standing instructions for a project workspace"},{"location":"agentic-building-blocks/prompts/#related","title":"Related","text":"<ul> <li>Context Engineering \u2014 the broader discipline that prompt engineering is part of</li> <li>Agentic Building Blocks \u2014 Prompts in the context of all seven building blocks</li> <li>AI Use Cases \u2014 see how prompts are used across content creation, research, coding, data analysis, ideation, and automation</li> <li>Projects \u2014 where prompts become persistent custom instructions</li> <li>Patterns \u2014 reusable prompt structures</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/","title":"Prompt Engineering","text":"<p>Prompt engineering is the practice of structuring your input to an AI model so that it produces the output you actually need. It is not about memorizing magic phrases \u2014 it is about understanding how models interpret instructions and providing the right context, structure, and constraints to guide their responses.</p> <p>These techniques work across all major AI platforms (Claude, ChatGPT, Gemini, Copilot) because they address how large language models process language, not platform-specific features.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/#core-principles","title":"Core Principles","text":"<p>Before diving into specific techniques, these principles apply to all prompt engineering:</p> <ol> <li>Be specific \u2014 Vague prompts produce vague outputs. Say exactly what you want.</li> <li>Provide context \u2014 The model only knows what you tell it. Include relevant background.</li> <li>Show, don't just tell \u2014 Examples are more powerful than descriptions of what you want.</li> <li>Structure your output \u2014 Tell the model what format you need (bullets, table, JSON, etc.).</li> <li>Constrain the scope \u2014 Boundaries improve quality. Set word limits, define the audience, specify what to exclude.</li> <li>Iterate \u2014 Your first prompt is a draft. Refine based on what comes back.</li> <li>Break complex tasks down \u2014 One clear instruction per prompt beats a wall of requirements.</li> <li>Match the technique to the task \u2014 Not every technique suits every situation. Choose based on what you need.</li> </ol>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/#technique-catalog","title":"Technique Catalog","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/#foundational-techniques","title":"Foundational Techniques","text":"<p>These are the building blocks \u2014 techniques you will use daily.</p> Technique What It Does Best For Zero-Shot Prompting Ask the model to perform a task with no examples Simple, well-defined tasks Few-Shot Learning Provide examples so the model learns the pattern Custom formats, tone matching, classification Chain-of-Thought Ask the model to reason step by step Math, logic, analysis, complex decisions Direct Instruction Give explicit, imperative commands Any task where clarity matters"},{"location":"agentic-building-blocks/prompts/prompt-engineering/#shaping-techniques","title":"Shaping Techniques","text":"<p>These techniques control how the model approaches your task.</p> Technique What It Does Best For Contextual Prompting Embed background information in the prompt Domain-specific tasks, personalized output Role Prompting Assign the model a persona or expertise Specialized knowledge, audience-appropriate tone Output Formatting Specify the structure and format of the response Reports, data extraction, structured content Multi-Turn Conversation Build on previous exchanges to refine results Exploration, iterative refinement, complex projects"},{"location":"agentic-building-blocks/prompts/prompt-engineering/#quality-techniques","title":"Quality Techniques","text":"<p>These techniques improve the reliability and depth of outputs.</p> Technique What It Does Best For Self-Consistency and Reflection Ask the model to check and critique its own work High-stakes decisions, error reduction Emotional Prompting Add motivational or stakes-based language Tasks where engagement and effort matter Reframing Prompts Rephrase a question to approach it differently When initial prompts give poor results"},{"location":"agentic-building-blocks/prompts/prompt-engineering/#specialized-techniques","title":"Specialized Techniques","text":"<p>These techniques solve specific types of problems.</p> Technique What It Does Best For Style Unbundling Decompose a writing style into separate attributes Matching a specific voice or tone Summarization and Distillation Compress or restructure information Long documents, research synthesis Real-World Constraints Embed business rules and practical limits into prompts Feasible plans, budget-aware output"},{"location":"agentic-building-blocks/prompts/prompt-engineering/#where-to-start","title":"Where to Start","text":"<p>New to prompting? Start with Zero-Shot Prompting and Direct Instruction \u2014 these two techniques cover most everyday tasks.</p> <p>Want better results? Add Few-Shot Learning to teach the model your preferred format, then use Chain-of-Thought for anything requiring reasoning.</p> <p>Working on something complex? Combine techniques \u2014 for example, use Role Prompting + Contextual Prompting + Output Formatting to get expert-level, structured responses grounded in your specific domain.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/#related","title":"Related","text":"<ul> <li>Prompts \u2014 The Prompts building block overview</li> <li>Resources \u2014 Academic papers and platform documentation</li> <li>Patterns \u2014 Reusable AI patterns and best practices</li> <li>Use Cases \u2014 See these techniques applied to real tasks</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/chain-of-thought/","title":"Chain-of-Thought Prompting","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/chain-of-thought/#what-it-is","title":"What It Is","text":"<p>Chain-of-Thought (CoT) prompting asks the model to work through a problem step by step before giving a final answer. Instead of jumping straight to a conclusion, the model shows its reasoning \u2014 making it more likely to arrive at a correct answer and allowing you to verify the logic along the way.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/chain-of-thought/#why-it-works","title":"Why It Works","text":"<p>When an LLM (large language model) generates intermediate reasoning steps, each step provides context for the next. This breaks complex problems into simpler sub-problems the model can handle more reliably. Without CoT, the model attempts to compute the answer in a single forward pass \u2014 essentially trying to \"think\" the entire solution at once \u2014 which fails for multi-step reasoning tasks like math, logic, and comparative analysis.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/chain-of-thought/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Math and numerical reasoning</li> <li>Multi-step logic problems</li> <li>Comparing options with tradeoffs</li> <li>Debugging and root cause analysis</li> <li>Any task where the reasoning matters as much as the answer</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/chain-of-thought/#the-pattern","title":"The Pattern","text":"<pre><code>{Problem statement}\n\nThink through this step by step:\n1. First, {identify/analyze the key elements}\n2. Then, {work through the logic}\n3. Finally, {arrive at your conclusion}\n\nShow your reasoning before giving your final answer.\n</code></pre> <p>Zero-Shot CoT variation \u2014 just append this to any prompt:</p> <pre><code>Let's think step by step.\n</code></pre> <p>This simple addition can dramatically improve reasoning performance without any examples (Kojima et al. 2022).</p> <p>Filled-in example:</p> <pre><code>A company has 150 employees. 40% are remote, 30% are hybrid, and the rest\nare in-office. Hybrid workers share desks at a 3:1 ratio (3 hybrid workers\nper desk). How many desks does the office need?\n\nThink through this step by step. Show your reasoning before giving your\nfinal answer.\n</code></pre>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/chain-of-thought/#examples-in-practice","title":"Examples in Practice","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/chain-of-thought/#business-decision","title":"Business decision","text":"<p>Context: Your team is evaluating CRM vendors and needs a structured comparison that accounts for multiple constraints.</p> <pre><code>We're choosing between three vendors for our CRM migration:\n- Vendor A: $50K cost, 6-month timeline\n- Vendor B: $35K cost, 12-month timeline\n- Vendor C: $45K cost, 4-month timeline\n\nOur current CRM contract expires in 8 months. We have a $48K budget.\n\nThink through the tradeoffs step by step, considering cost, timeline risk,\nand transition complexity. Then recommend the best option with your reasoning.\n</code></pre> <p>Why this works: It forces the model to weigh multiple factors systematically rather than jumping to the cheapest or fastest option.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/chain-of-thought/#debugging","title":"Debugging","text":"<p>Context: Your engineering team noticed a performance regression after a deployment and needs to narrow down the cause.</p> <pre><code>Our API response times increased from 200ms to 800ms after last week's\ndeployment. The deployment included: a database schema migration, an upgrade\nto the authentication library, and a new logging middleware.\n\nWalk through potential causes step by step, starting with the most likely.\nFor each cause, explain how we could verify or rule it out.\n</code></pre> <p>Why this works: Debugging requires sequential elimination of hypotheses. CoT prevents the model from fixating on one cause and ignoring others.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/chain-of-thought/#math-with-multiple-calculations","title":"Math with multiple calculations","text":"<p>Context: You need to calculate office space requirements based on employee work patterns.</p> <pre><code>A company has 150 employees. 40% are remote, 30% are hybrid, and the rest\nare in-office. Hybrid workers share desks at a 3:1 ratio (3 hybrid workers\nper 1 desk). In-office workers each need their own desk.\n\nHow many desks does the office need? Show your work.\n</code></pre> <p>Why this works: The model needs to track multiple calculations \u2014 percentages, different desk ratios for different groups, then a final total. Showing work prevents arithmetic errors that commonly occur when the model tries to compute everything at once.</p> <p>Platform tip</p> <p>Claude's extended thinking mode is essentially automated Chain-of-Thought \u2014 the model reasons internally before responding. OpenAI's o1/o3 model family does this natively. Enable these features when tackling complex reasoning tasks, especially math and multi-step analysis.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/chain-of-thought/#common-pitfalls","title":"Common Pitfalls","text":"<p>Using CoT for simple tasks</p> <p>Problem: \"What is the capital of France? Let's think step by step.\" wastes tokens and adds no value. CoT is overhead for tasks that don't involve multi-step reasoning.</p> <p>Fix: Reserve CoT for problems that actually require working through multiple steps \u2014 math, comparisons, debugging, planning. For simple factual questions, use zero-shot prompting.</p> <p>Not verifying the reasoning</p> <p>Problem: The model's intermediate steps can look logical and well-structured but still contain errors \u2014 especially in arithmetic or when applying domain-specific rules.</p> <p>Fix: Read the intermediate steps, not just the final answer. If the reasoning is wrong at step 2, the final answer will be wrong too. This is the whole point of CoT: it makes errors visible and auditable.</p> <p>Confusing CoT with Self-Consistency</p> <p>Problem: A single CoT trace shows one reasoning path. If that path happens to go wrong, you get a confidently wrong answer. Self-Consistency (Wang et al. 2022) is a separate technique that samples multiple reasoning paths and takes the majority answer.</p> <p>Fix: For high-stakes decisions, consider asking the model for multiple approaches: \"Solve this problem using two different methods, then compare your answers.\" See Self-Consistency and Reflection.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/chain-of-thought/#related-techniques","title":"Related Techniques","text":"<ul> <li>Zero-Shot Prompting \u2014 Zero-Shot CoT (\"Let's think step by step\") bridges these two techniques</li> <li>Self-Consistency and Reflection \u2014 sample multiple reasoning paths for higher accuracy</li> <li>Direct Instruction \u2014 combine with CoT by explicitly specifying the reasoning steps</li> <li>Prompt Engineering Overview</li> <li>Research use case</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/chain-of-thought/#further-reading","title":"Further Reading","text":"<ul> <li>Wei et al. 2022 \u2014 Chain-of-Thought Prompting Elicits Reasoning in Large Language Models \u2014 arxiv.org/abs/2201.11903</li> <li>Kojima et al. 2022 \u2014 Large Language Models are Zero-Shot Reasoners \u2014 arxiv.org/abs/2205.11916</li> <li>Wang et al. 2022 \u2014 Self-Consistency Improves Chain of Thought Reasoning in Language Models \u2014 arxiv.org/abs/2203.11171</li> <li>Yao et al. 2023 \u2014 Tree of Thoughts: Deliberate Problem Solving with Large Language Models \u2014 arxiv.org/abs/2305.10601</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/contextual-prompting/","title":"Contextual Prompting","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p> <p>Contextual Prompting vs. the Context Building Block</p> <p>This page covers contextual prompting \u2014 the technique of including relevant information within your prompt text. This is different from the broader Context building block, which covers attaching files, knowledge bases, system prompts, and other external context sources. Think of contextual prompting as one way to provide context; the Context building block covers all the ways.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/contextual-prompting/#what-it-is","title":"What It Is","text":"<p>Contextual prompting means providing relevant background information directly in your prompt so the model can give informed, specific responses. Instead of asking a generic question, you embed the who, what, where, when, and why that shape the right answer. The result is output tailored to your exact situation rather than one-size-fits-all advice.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/contextual-prompting/#why-it-works","title":"Why It Works","text":"<p>LLMs (large language models) don't have access to your specific situation \u2014 your company, your audience, your constraints, your data. Context fills that gap. When you provide relevant details, the model can tailor its output to your exact needs. Without context, the model defaults to the most common interpretation of your request, which is rarely the one you actually want.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/contextual-prompting/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Domain-specific tasks where generic answers won't work</li> <li>When the model needs to know your audience, industry, or constraints</li> <li>Personalizing output to a specific situation</li> <li>When you have relevant data the model should factor into its response</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/contextual-prompting/#the-pattern","title":"The Pattern","text":"<pre><code>Context:\n- {Who: role, audience, stakeholders}\n- {What: topic, product, situation}\n- {Constraints: budget, timeline, regulations}\n- {Goal: what success looks like}\n\nTask: {What you need the model to do}\n</code></pre> <p>Filled-in example:</p> <pre><code>Context:\n- I'm a marketing manager at a B2B SaaS company selling project management software\n- Target audience: mid-size construction firms (50-200 employees)\n- Monthly content budget: $5,000\n- Goal: increase organic search traffic by 30% over 3 months\n\nTask: Create a 3-month content calendar focused on SEO-driven blog posts\nthat address pain points specific to construction project management.\n</code></pre>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/contextual-prompting/#examples-in-practice","title":"Examples in Practice","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/contextual-prompting/#industry-specific-advice","title":"Industry-specific advice","text":"<p>Context: You run a small dental practice and need software recommendations that account for your staff's technical comfort level and your budget.</p> <pre><code>Context:\n- I run a 15-person dental practice in suburban Austin, TX\n- We currently use paper scheduling and want to go digital\n- Staff are mostly non-technical (ages 35-55)\n- Budget: under $500/month\n- Must integrate with our existing billing system (Dentrix)\n\nTask: Recommend 3 scheduling software options with pros and cons\nfor my specific situation. Prioritize ease of use and Dentrix integration.\n</code></pre> <p>Why this works: The constraints \u2014 staff technical level, budget ceiling, specific billing system \u2014 eliminate generic recommendations and force the model to give advice that actually applies.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/contextual-prompting/#audience-aware-content","title":"Audience-aware content","text":"<p>Context: You're writing for a specialized academic audience that expects a specific register and evidence standard.</p> <pre><code>Context:\n- Writing for a medical journal audience (physicians and researchers)\n- Topic: the impact of AI on diagnostic radiology\n- Readers expect evidence-based claims with citations\n- Journal word limit for abstracts: 300 words\n\nTask: Write a 300-word abstract covering current applications,\nlimitations, and future directions of AI in diagnostic radiology.\nUse formal academic tone throughout.\n</code></pre> <p>Why this works: Specifying the audience (physicians and researchers), the evidence standard (evidence-based with citations), and the format (300-word abstract) sets the register, depth, and structure the model should target.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/contextual-prompting/#data-informed-analysis","title":"Data-informed analysis","text":"<p>Context: You have specific business metrics and need the model to analyze a trend rather than speculate.</p> <pre><code>Context:\n- Our Q3 revenue was $2.1M (up 15% from Q2)\n- Customer churn increased from 3.2% to 4.8% during Q3\n- We launched a new pricing tier in July\n- Support tickets related to billing increased 40% since the new tier launch\n- No changes to product features during this period\n\nTask: Analyze the likely causes of the churn increase and suggest\n3 specific actions we can take in Q4 to reverse the trend.\n</code></pre> <p>Why this works: The data points \u2014 revenue growth alongside churn increase, billing ticket spike correlating with pricing change \u2014 create a foundation for specific analysis. Without this data, the model would produce generic churn reduction advice.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/contextual-prompting/#common-pitfalls","title":"Common Pitfalls","text":"<p>Irrelevant context overload</p> <p>Problem: Including your entire company history, org chart, and mission statement when asking about a specific email. Too much context dilutes the signal and wastes tokens.</p> <p>Fix: Include only the context that directly affects the output. Ask yourself: \"If I removed this detail, would the answer change?\" If not, leave it out.</p> <p>Missing key constraints</p> <p>Problem: Asking for a marketing plan without mentioning budget, timeline, team size, or target audience. The model fills in assumptions that may not match your reality.</p> <p>Fix: Always include constraints that would change the recommendation. Budget, timeline, audience, and existing tools/systems are almost always relevant.</p> <p>Assuming shared knowledge</p> <p>Problem: Using internal jargon, acronyms, or referencing processes without defining them. \"Optimize our CSAT flow for the T2 queue\" means nothing to the model without definitions.</p> <p>Fix: Spell out anything the model hasn't been told about. Define acronyms on first use, describe internal processes briefly, and name specific tools rather than assuming the model knows your stack.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/contextual-prompting/#related-techniques","title":"Related Techniques","text":"<ul> <li>Context building block \u2014 the comprehensive guide to all forms of context (files, knowledge bases, system prompts, and more)</li> <li>Role Prompting \u2014 set the model's perspective as a form of context</li> <li>Direct Instruction \u2014 combine clear commands with rich context for the best results</li> <li>Prompt Engineering Overview</li> <li>Research use case</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/contextual-prompting/#further-reading","title":"Further Reading","text":"<ul> <li>Dong et al. 2022 \u2014 A Survey on In-context Learning \u2014 arxiv.org/abs/2301.00234</li> <li>Lewis et al. 2020 \u2014 Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks \u2014 arxiv.org/abs/2005.11401</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/direct-instruction/","title":"Direct Instruction","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/direct-instruction/#what-it-is","title":"What It Is","text":"<p>Direct instruction means giving the model clear, explicit commands in imperative language. Instead of hinting at what you want (\"It would be nice if...\") or asking open-ended questions, you tell the model exactly what to do: \"Write a...\", \"List the...\", \"Analyze the...\". This is the foundation of effective prompting \u2014 a baseline technique that improves every other pattern.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/direct-instruction/#why-it-works","title":"Why It Works","text":"<p>Modern LLMs (large language models) are specifically trained to follow instructions through a process called instruction tuning and RLHF (Reinforcement Learning from Human Feedback). Direct, unambiguous commands align perfectly with this training. The more explicit your instruction, the less the model has to guess about what you want \u2014 and guessing is where errors, hallucinations, and off-target responses happen.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/direct-instruction/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Every prompt (this is a baseline technique, not situational)</li> <li>When zero-shot results are close but not quite right</li> <li>When you need precise control over what the model does and doesn't do</li> <li>When working with others who will reuse your prompts</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/direct-instruction/#the-pattern","title":"The Pattern","text":"<pre><code>{Action verb} {specific task}.\n{Constraints: length, format, audience, tone}.\n{What to include or exclude}.\n</code></pre> <p>Filled-in example:</p> <pre><code>Write a 150-word product description for a wireless Bluetooth speaker.\nTarget audience: tech-savvy millennials.\nTone: casual and enthusiastic.\nInclude: battery life, water resistance, sound quality.\nExclude: technical specifications and pricing.\n</code></pre>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/direct-instruction/#examples-in-practice","title":"Examples in Practice","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/direct-instruction/#structured-risk-assessment","title":"Structured risk assessment","text":"<p>Context: You need a concise risk analysis for a cloud migration proposal that your team can review quickly.</p> <pre><code>List the top 5 risks of migrating from on-premise to cloud infrastructure.\nFor each risk, provide:\n- A one-sentence description\n- Likelihood (high/medium/low)\n- One mitigation strategy\n\nFormat as a numbered list.\n</code></pre> <p>Why this works: Every aspect of the output is specified \u2014 the number of items, the structure of each item, and the format. The model has no room to deviate.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/direct-instruction/#readability-rewrite","title":"Readability rewrite","text":"<p>Context: You're adapting a technical report for a general-audience newsletter and need to lower the reading level.</p> <pre><code>Rewrite the following paragraph for a 9th-grade reading level. Keep the\nsame meaning but simplify vocabulary and shorten sentences. Do not add\nnew information.\n\n[paste paragraph here]\n</code></pre> <p>Why this works: The constraints are explicit and measurable \u2014 reading level, meaning preservation, no additions. The \"Do not add new information\" instruction prevents the model from elaborating.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/direct-instruction/#constrained-comparison","title":"Constrained comparison","text":"<p>Context: Your engineering team is choosing between two databases and needs a focused comparison, not a general overview.</p> <pre><code>Compare PostgreSQL and MongoDB for a real-time analytics workload processing\n10,000 events per second. Focus only on: write throughput, query flexibility,\nand operational complexity. Respond in a two-column table.\n</code></pre> <p>Why this works: The comparison dimensions are locked down to three specific criteria, the workload is quantified, and the output format is specified. This prevents the model from producing a generic \"pros and cons\" list.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/direct-instruction/#common-pitfalls","title":"Common Pitfalls","text":"<p>Polite hedging</p> <p>Problem: \"Could you maybe write something about...\" or \"I was wondering if you might be able to...\" gives the model too much latitude. Hedging language signals uncertainty, and the model may mirror that uncertainty in its output.</p> <p>Fix: Use imperative verbs \u2014 \"Write\", \"List\", \"Analyze\", \"Compare\", \"Summarize\". You can still be polite, but lead with the action: \"Please write a 200-word summary of...\"</p> <p>Contradictory instructions</p> <p>Problem: \"Be concise. Include all details.\" creates tension that the model resolves unpredictably. Similarly, \"Write a short, comprehensive overview\" sends mixed signals.</p> <p>Fix: Prioritize when constraints conflict \u2014 \"Be concise. Prioritize the three most important details and omit the rest.\" Make trade-offs explicit so the model doesn't have to guess your preference.</p> <p>Missing constraints</p> <p>Problem: \"Write an email\" without specifying length, tone, or audience produces generic output that rarely matches what you actually need.</p> <p>Fix: Include at least three constraints: audience (who will read this), tone (formal, casual, persuasive), and length (word count or \"keep it to 2-3 paragraphs\"). Add format and content constraints as needed.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/direct-instruction/#related-techniques","title":"Related Techniques","text":"<ul> <li>Zero-Shot Prompting \u2014 direct instruction makes zero-shot prompts sharper</li> <li>Output Formatting \u2014 specify exactly how the model should structure its response</li> <li>Contextual Prompting \u2014 combine with context for domain-specific direct instructions</li> <li>Prompt Engineering Overview</li> <li>Content Creation use case</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/direct-instruction/#further-reading","title":"Further Reading","text":"<ul> <li>Ouyang et al. 2022 \u2014 Training Language Models to Follow Instructions with Human Feedback \u2014 arxiv.org/abs/2203.02155</li> <li>Wei et al. 2021 \u2014 Finetuned Language Models Are Zero-Shot Learners (FLAN) \u2014 arxiv.org/abs/2109.01652</li> <li>Zhang et al. 2023 \u2014 Instruction Tuning for Large Language Models: A Survey \u2014 arxiv.org/abs/2308.10792</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/emotional-prompting/","title":"Emotional Prompting","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/emotional-prompting/#what-it-is","title":"What It Is","text":"<p>Emotional prompting means adding motivational, stakes-based, or emotionally charged language to your prompts to encourage the model to produce more thorough and engaged responses. Instead of a neutral request, you convey why the task matters or what is at stake. The goal is to signal importance in a way that shifts the model's output toward greater care and completeness.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/emotional-prompting/#why-it-works","title":"Why It Works","text":"<p>The EmotionPrompt paper (Li et al. 2023) showed that adding emotional stimuli to prompts improved LLM (large language model) performance by over 10% on several benchmarks. The likely mechanism is that emotional language activates patterns from training data where humans wrote more carefully \u2014 important emails, critical reports, heartfelt communications. Models trained via RLHF (reinforcement learning from human feedback) may also associate high-stakes framing with the kind of careful, thorough responses that human raters rewarded during training. However, this effect varies by model and task \u2014 it works more consistently on generative tasks than on factual retrieval.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/emotional-prompting/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Tasks where thoroughness and effort matter more than speed</li> <li>Creative writing where engagement affects quality</li> <li>When you notice the model giving generic or low-effort responses</li> <li>High-stakes outputs that need extra care and attention to detail</li> <li>Review and analysis tasks where missing something has consequences</li> </ul> <p>Do NOT use it for:</p> <ul> <li>Simple factual queries (e.g., \"What is the capital of France?\")</li> <li>When precision matters more than thoroughness \u2014 emotional framing may introduce bias</li> <li>As a substitute for clear instructions \u2014 stakes language supplements good prompts, it doesn't replace them</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/emotional-prompting/#the-pattern","title":"The Pattern","text":"<pre><code>{Task description}\n\n{Emotional stake or motivation}\n</code></pre> <p>Filled-in example:</p> <pre><code>Review this database migration script for potential data loss issues.\n\nThis migration runs against our production database with 3 years of customer data.\nIf anything goes wrong, we could lose records that are impossible to recreate.\nCheck every operation carefully.\n</code></pre>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/emotional-prompting/#examples-in-practice","title":"Examples in Practice","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/emotional-prompting/#example-1-job-application","title":"Example 1 \u2014 Job application","text":"<p>Context: You're applying for a competitive role and need the cover letter to stand out.</p> <pre><code>Write a cover letter for this job application. Here is my resume: [resume text]\nHere is the job posting: [job posting text]\n\nThis is for my dream job at a company I've admired for years \u2014 the letter needs to\nstand out from hundreds of applicants. Make every sentence count.\n</code></pre> <p>Why this works: The personal stakes encourage the model to be more thoughtful and deliberate, avoiding generic filler and focusing on differentiation.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/emotional-prompting/#example-2-contract-review","title":"Example 2 \u2014 Contract review","text":"<p>Context: You need a thorough review of a legal clause before signing a major deal.</p> <pre><code>Review this contract clause for potential risks:\n\n[paste contract clause here]\n\nThis is a $2M deal and my client is counting on me to catch anything that could\nhurt them. Be thorough and flag even minor concerns that could become problems\ndown the line.\n</code></pre> <p>Why this works: The financial stakes and responsibility framing promote careful, exhaustive analysis rather than a surface-level summary.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/emotional-prompting/#example-3-code-debugging","title":"Example 3 \u2014 Code debugging","text":"<p>Context: A payroll function needs to be bulletproof because errors affect real people.</p> <pre><code>Debug this Python function that calculates payroll:\n\n[paste function here]\n\nThis runs for 500 employees every two weeks and any error means people get paid\nincorrectly. Check every edge case \u2014 overtime calculations, rounding, tax\nbrackets, part-time vs. full-time distinctions.\n</code></pre> <p>Why this works: The real-world consequences (people being paid incorrectly) encourage exhaustive edge-case checking that a neutral prompt might not elicit.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/emotional-prompting/#common-pitfalls","title":"Common Pitfalls","text":"<p>Overuse dilutes impact</p> <p>Problem: Adding emotional stakes to every prompt makes none of them feel important \u2014 the model (and you) become desensitized to the framing. Fix: Reserve emotional prompting for tasks that genuinely need extra care. If everything is \"critical\" and \"high-stakes,\" nothing is.</p> <p>Emotional manipulation over clarity</p> <p>Problem: Relying on emotional language instead of clear instructions. \"This is really important, please do a good job\" doesn't tell the model what to do well. Fix: Write clear, specific instructions first, then add stakes framing. Emotional prompting supplements a well-structured prompt \u2014 it doesn't replace one.</p> <p>Results vary by model</p> <p>Problem: The EmotionPrompt results were on specific benchmarks with specific models. The effect size may differ with different models, tasks, and prompt formulations. Fix: Test with and without emotional framing on your specific use case. If the output quality is the same either way, the technique isn't adding value for that task.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/emotional-prompting/#related-techniques","title":"Related Techniques","text":"<ul> <li>Role Prompting \u2014 assign a persona whose role implies high stakes</li> <li>Direct Instruction \u2014 be explicit about what thoroughness means for your task</li> <li>Contextual Prompting \u2014 provide background that naturally conveys importance</li> <li>Prompt Engineering Overview</li> <li>Content Creation use case \u2014 emotional prompting is particularly effective for creative and communication tasks</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/emotional-prompting/#further-reading","title":"Further Reading","text":"<ul> <li>Li et al. 2023 \u2014 EmotionPrompt: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus \u2014 arxiv.org/abs/2307.11760</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/few-shot-learning/","title":"Few-Shot Learning","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/few-shot-learning/#what-it-is","title":"What It Is","text":"<p>Few-shot learning means providing the model with a few examples of the task before asking it to perform on new input. The model learns the pattern from your demonstrations \u2014 the format, tone, reasoning approach, or classification rules \u2014 and applies it to the input you actually care about. This technique is sometimes called \"in-context learning.\"</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/few-shot-learning/#why-it-works","title":"Why It Works","text":"<p>LLMs (large language models) perform in-context learning: they recognize patterns in the examples you provide and apply those patterns to new inputs. This works because the model's core training objective is to predict the next token in a sequence, so it naturally continues patterns it sees. Your examples effectively \"program\" the model's behavior for the current conversation without any fine-tuning.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/few-shot-learning/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Custom output formats the model wouldn't produce naturally</li> <li>Classification tasks with your own categories or taxonomy</li> <li>Matching a specific tone or writing style</li> <li>Tasks where showing is easier than describing</li> <li>When zero-shot prompting produces the right idea but the wrong format</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/few-shot-learning/#the-pattern","title":"The Pattern","text":"<pre><code>{Task description}\n\nExample 1:\nInput: {example input 1}\nOutput: {example output 1}\n\nExample 2:\nInput: {example input 2}\nOutput: {example output 2}\n\nExample 3:\nInput: {example input 3}\nOutput: {example output 3}\n\nNow:\nInput: {actual input}\nOutput:\n</code></pre> <p>Filled-in example:</p> <pre><code>Classify each customer review using NPS-style labels: Promoter, Passive, or Detractor.\n\nExample 1:\nInput: \"Absolutely love this product, already recommended it to three friends!\"\nOutput: Promoter\n\nExample 2:\nInput: \"It works fine, nothing special.\"\nOutput: Passive\n\nExample 3:\nInput: \"Broke after two weeks. Waste of money.\"\nOutput: Detractor\n\nNow:\nInput: \"Good quality but shipping took forever. Might order again if delivery improves.\"\nOutput:\n</code></pre>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/few-shot-learning/#examples-in-practice","title":"Examples in Practice","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/few-shot-learning/#sentiment-classification-with-custom-labels","title":"Sentiment classification with custom labels","text":"<p>Context: Your team uses NPS-style categories (Promoter, Passive, Detractor) instead of the generic positive/negative/neutral labels most models default to.</p> <pre><code>Classify each customer review using our NPS labels: Promoter, Passive, or Detractor.\n\nExample 1:\nInput: \"Best purchase I've made all year. 10/10 would buy again.\"\nOutput: Promoter\n\nExample 2:\nInput: \"Does what it says. Nothing more, nothing less.\"\nOutput: Passive\n\nExample 3:\nInput: \"Customer support was unhelpful and the product is mediocre.\"\nOutput: Detractor\n\nNow:\nInput: \"The interface is confusing but once you learn it, the features are solid.\"\nOutput:\n</code></pre> <p>Why this works: The examples define a custom taxonomy the model wouldn't use by default, and they show the boundary between categories through demonstration.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/few-shot-learning/#data-extraction-to-structured-format","title":"Data extraction to structured format","text":"<p>Context: You receive unstructured emails and need to extract contact details into a consistent JSON format for your CRM.</p> <pre><code>Extract the contact information from the text and return it as JSON.\n\nExample 1:\nInput: \"Hey, this is Mike Chen from Acuity Labs. Reach me at mike@acuitylabs.io\"\nOutput: {\"name\": \"Mike Chen\", \"email\": \"mike@acuitylabs.io\", \"company\": \"Acuity Labs\"}\n\nExample 2:\nInput: \"Sarah Lopez, Director of Ops at Bridgewell Inc \u2014 sarah.lopez@bridgewell.com\"\nOutput: {\"name\": \"Sarah Lopez\", \"email\": \"sarah.lopez@bridgewell.com\", \"company\": \"Bridgewell Inc\"}\n\nExample 3:\nInput: \"Contact: James Rivera (james@deltaforge.co), he's with DeltaForge\"\nOutput: {\"name\": \"James Rivera\", \"email\": \"james@deltaforge.co\", \"company\": \"DeltaForge\"}\n\nNow:\nInput: \"Got a referral from Priya Patel at Nimbus Health \u2014 her email is priya.p@nimbushealth.org\"\nOutput:\n</code></pre> <p>Why this works: The examples define the exact JSON structure, field names, and formatting conventions you need, removing all ambiguity about the output format.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/few-shot-learning/#tone-matching","title":"Tone matching","text":"<p>Context: You need to rewrite formal documentation into casual Slack messages for your team.</p> <pre><code>Rewrite the formal text as a casual Slack message.\n\nExample 1:\nInput: \"Please be advised that the server maintenance window has been scheduled for Saturday, March 15th, from 02:00 to 06:00 UTC.\"\nOutput: \"Heads up \u2014 servers will be down Saturday 3/15 from 2-6am UTC for maintenance\"\n\nExample 2:\nInput: \"We would like to inform all stakeholders that the Q2 budget review meeting has been rescheduled to Thursday at 14:00.\"\nOutput: \"Q2 budget review got moved to Thursday at 2pm \u2014 see you there\"\n\nExample 3:\nInput: \"It has come to our attention that several team members have not completed the mandatory security training module.\"\nOutput: \"Friendly nudge: a few folks still need to finish the security training. Please knock it out when you get a chance\"\n\nNow:\nInput: \"We are pleased to announce that the organization has successfully achieved SOC 2 Type II compliance certification.\"\nOutput:\n</code></pre> <p>Why this works: Tone and style are notoriously hard to describe in words but easy to demonstrate through examples. The model picks up on the pattern of shortening, de-formalizing, and adding conversational markers.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/few-shot-learning/#common-pitfalls","title":"Common Pitfalls","text":"<p>Too few or too many examples</p> <p>Problem: One example isn't enough to establish a reliable pattern. Ten or more examples waste tokens and can confuse the model.</p> <p>Fix: Three to five examples is the sweet spot for most tasks. Use the minimum number that consistently produces the output format you want.</p> <p>Example order effects</p> <p>Problem: Research shows that the order of examples affects output quality. The model pays more attention to examples near the end of the sequence.</p> <p>Fix: Put your most representative example last (closest to the actual input). If results seem biased toward one category, vary the order and check whether outputs change.</p> <p>Inconsistent examples</p> <p>Problem: Examples that contradict each other or use different formats confuse the model and produce unreliable output.</p> <p>Fix: Ensure all examples follow the exact same format, use the same field names, and apply the same logic. Review your examples as a set before including them.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/few-shot-learning/#related-techniques","title":"Related Techniques","text":"<ul> <li>Zero-Shot Prompting \u2014 try this first when you don't need examples</li> <li>Chain-of-Thought \u2014 add reasoning steps to your examples for complex tasks</li> <li>Output Formatting \u2014 other ways to control the shape of model output</li> <li>Prompt Engineering Overview</li> <li>Data Analysis use case</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/few-shot-learning/#further-reading","title":"Further Reading","text":"<ul> <li>Brown et al. 2020 \u2014 Language Models are Few-Shot Learners \u2014 arxiv.org/abs/2005.14165</li> <li>Dong et al. 2022 \u2014 A Survey on In-context Learning \u2014 arxiv.org/abs/2301.00234</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/multi-turn-conversation/","title":"Multi-Turn Conversation","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/multi-turn-conversation/#what-it-is","title":"What It Is","text":"<p>Multi-turn conversation means using a series of back-and-forth exchanges to iteratively build, refine, and improve the model's output. Instead of crafting one perfect prompt, you have a conversation \u2014 starting broad, then narrowing in on what you need through follow-up messages. This mirrors how human collaboration works: through dialogue, not monologue.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/multi-turn-conversation/#why-it-works","title":"Why It Works","text":"<p>Each turn adds to the conversation context, allowing you to build on previous responses, correct course, and progressively refine the output. The LLM (large language model) sees the entire conversation history and can adjust based on your feedback. This is especially powerful for tasks where you don't know exactly what \"good\" looks like until you start seeing output \u2014 the conversation itself becomes a discovery process.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/multi-turn-conversation/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Complex tasks that benefit from iterative refinement</li> <li>Exploratory work where you don't know the exact output upfront</li> <li>When you want to guide the model through a multi-step process</li> <li>Creative work where direction emerges through collaboration</li> <li>Tasks that are too large or nuanced for a single prompt</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/multi-turn-conversation/#the-pattern","title":"The Pattern","text":"<pre><code>Turn 1: {High-level request or exploration}\nTurn 2: {Refine based on the response \u2014 zoom in, redirect, or expand}\nTurn 3: {Further refinement or specific adjustments}\nTurn N: {Final polish or specific modifications}\n</code></pre> <p>Conversation forking (for exploring alternatives):</p> <pre><code>\"Let's pause here. I want to explore a different direction.\nGoing back to your {earlier suggestion}, what if we {alternative approach}?\"\n</code></pre> <p>Filled-in example:</p> <pre><code>Turn 1: \"What are the main strategies for improving API response times?\"\nTurn 2: \"Let's focus on caching. What caching layers would you recommend\n         for a Django REST API with PostgreSQL?\"\nTurn 3: \"Good. Now write the implementation for the Redis caching layer\n         you described, including cache invalidation logic.\"\n</code></pre>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/multi-turn-conversation/#examples-in-practice","title":"Examples in Practice","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/multi-turn-conversation/#example-1-business-strategy","title":"Example 1 \u2014 Business strategy","text":"<p>Context: You're developing a customer retention strategy and want to drill down from broad options to a specific deliverable.</p> <pre><code>Turn 1: \"What are the main approaches to reducing customer churn for a SaaS product?\"\n</code></pre> <pre><code>Turn 2: \"Let's focus on the proactive outreach approach. What signals should we\nmonitor to identify at-risk customers?\"\n</code></pre> <pre><code>Turn 3: \"Good. Now draft a playbook for our customer success team based on those\nsignals. Include specific email templates for each risk tier.\"\n</code></pre> <p>Why this works: Each turn narrows scope based on the previous response, moving from broad strategy to a concrete deliverable.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/multi-turn-conversation/#example-2-writing-refinement","title":"Example 2 \u2014 Writing refinement","text":"<p>Context: You're drafting executive communications and want to polish through iteration.</p> <pre><code>Turn 1: \"Draft an executive summary for our Q3 board report. Revenue was $2.1M,\nup 15% QoQ. We launched two new features and expanded into the UK market.\"\n</code></pre> <pre><code>Turn 2: \"Good start. Make the tone more confident and add a forward-looking\nstatement about Q4 pipeline.\"\n</code></pre> <pre><code>Turn 3: \"Shorten to 150 words and lead with the growth metric.\"\n</code></pre> <p>Why this works: Writing benefits from progressive refinement \u2014 each turn addresses a specific dimension (tone, content, length) without overloading a single prompt.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/multi-turn-conversation/#example-3-problem-exploration-with-forking","title":"Example 3 \u2014 Problem exploration with forking","text":"<p>Context: You're investigating a performance bottleneck and want to compare approaches.</p> <pre><code>Turn 1: \"Our deployment pipeline takes 45 minutes. Walk me through common bottlenecks.\"\n</code></pre> <pre><code>Turn 2: \"The test suite sounds like the issue. How would you approach parallelizing\nintegration tests without sacrificing reliability?\"\n</code></pre> <pre><code>Turn 3: \"Fork: instead of parallelizing, what if we moved to a trunk-based development\nmodel with feature flags? How would that change our testing strategy?\"\n</code></pre> <p>Why this works: Conversation forking lets you compare two distinct approaches (parallelization vs. architectural change) while preserving the context of the original problem.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/multi-turn-conversation/#common-pitfalls","title":"Common Pitfalls","text":"<p>Context window exhaustion</p> <p>Problem: Long conversations can exceed the model's context window (the amount of text it can process at once), causing it to \"forget\" earlier details or instructions. Fix: Periodically summarize the conversation state: \"To recap what we've decided so far: [summary]. Now let's move on to...\" This preserves key decisions while freeing up context space.</p> <p>Drift without anchoring</p> <p>Problem: The conversation wanders and loses focus on the original goal, producing output that doesn't serve the intended purpose. Fix: Start with a clear objective and reference it periodically: \"Coming back to our goal of reducing churn, let's now...\" Consider stating the objective in your first message.</p> <p>Never finishing</p> <p>Problem: Endlessly refining without reaching a usable output \u2014 each revision feels like it could be better. Fix: Set a target upfront: \"In 3-4 exchanges, I want a final version I can send to the team.\" Define \"done\" before you start iterating.</p> <p>Conversation summarization</p> <p>For very long conversations, ask the model to summarize the key decisions and context before continuing. For example: \"Before we continue, summarize the key decisions we've made so far in a bullet list.\" This preserves important information while keeping the conversation manageable.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/multi-turn-conversation/#related-techniques","title":"Related Techniques","text":"<ul> <li>Chain-of-Thought \u2014 explicit step-by-step reasoning within a single turn</li> <li>Self-Consistency and Reflection \u2014 have the model critique and revise its own output</li> <li>Reframing Prompts \u2014 restructure a problem mid-conversation to get a better angle</li> <li>Prompt Engineering Overview</li> <li>Ideation and Strategy use case \u2014 multi-turn conversation is the natural mode for strategic exploration</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/multi-turn-conversation/#further-reading","title":"Further Reading","text":"<ul> <li>Yi et al. 2024 \u2014 A Survey on Recent Advances in LLM-Based Multi-turn Dialogue Systems \u2014 arxiv.org/abs/2402.18013</li> <li>Zheng et al. 2025 \u2014 LLMs Get Lost In Multi-Turn Conversation \u2014 arxiv.org/abs/2505.06120</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/output-formatting/","title":"Output Formatting","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/output-formatting/#what-it-is","title":"What It Is","text":"<p>Output formatting means telling the model exactly how to structure its response \u2014 whether that's a table, JSON, bullet list, specific sections, or a template you define. Instead of hoping the model picks a useful format, you specify it upfront. This makes outputs immediately usable without manual reformatting.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/output-formatting/#why-it-works","title":"Why It Works","text":"<p>LLMs (large language models) are very good at following structural instructions because they've seen millions of formatted documents during training. Specifying format reduces ambiguity about what \"a good response\" looks like, and makes outputs immediately usable in downstream workflows. However, note that format restrictions can sometimes degrade reasoning performance \u2014 Tam et al. (2024) found a tradeoff between structure and thinking quality. For complex analysis, consider letting the model reason freely first, then reformatting.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/output-formatting/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Output needs to feed into another system (JSON, CSV, XML)</li> <li>Reports or analyses that need consistent structure across runs</li> <li>Comparing multiple items side-by-side (tables)</li> <li>When you'll reuse the same prompt and need predictable output</li> <li>When output will be parsed programmatically</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/output-formatting/#the-pattern","title":"The Pattern","text":"<pre><code>{Task description}\n\nFormat your response as:\n{Format specification \u2014 template, example structure, or explicit format name}\n</code></pre> <p>Filled-in example:</p> <pre><code>Summarize the three main risks of migrating our database from MySQL to PostgreSQL.\n\nFormat your response as a markdown table with these columns:\n| Risk | Likelihood (High/Med/Low) | Impact | Mitigation |\n</code></pre>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/output-formatting/#examples-in-practice","title":"Examples in Practice","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/output-formatting/#example-1-table-format","title":"Example 1 \u2014 Table format","text":"<p>Context: You need to compare tools and want a scannable side-by-side view.</p> <pre><code>Compare the following 4 project management tools on these dimensions: price, team size\nlimit, integrations, and learning curve. Tools: Asana, Linear, Monday.com, Notion.\n\nPresent as a markdown table with tools as columns and dimensions as rows.\n</code></pre> <p>Why this works: Tables make comparisons scannable, and specifying rows vs. columns removes ambiguity about the layout.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/output-formatting/#example-2-json-output","title":"Example 2 \u2014 JSON output","text":"<p>Context: You're extracting structured data from unstructured text for use in an application.</p> <pre><code>Extract the following fields from this job posting: title, company, location,\nsalary_range, required_skills (as an array), experience_years.\n\nReturn as valid JSON with no additional text or explanation.\n\nJob posting:\n[paste job posting text here]\n</code></pre> <p>Why this works: The schema is fully specified \u2014 field names, types (array for skills), and the instruction to return only JSON ensures clean, parseable output.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/output-formatting/#example-3-template-based","title":"Example 3 \u2014 Template-based","text":"<p>Context: You want a consistent format for a recurring report.</p> <pre><code>Write a weekly status update following this exact structure:\n\n## Completed This Week\n- [bullet items]\n\n## In Progress\n- [bullet items with % complete]\n\n## Blocked\n- [bullet items with blocker description]\n\n## Next Week\n- [planned items]\n\nHere's what happened this week: shipped the auth module, 60% done with the dashboard\nredesign, waiting on API credentials from the vendor, and next week we start load testing.\n</code></pre> <p>Why this works: The exact template is provided, so the model fills in the structure rather than inventing its own \u2014 ensuring consistency across weeks.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/output-formatting/#common-pitfalls","title":"Common Pitfalls","text":"<p>Format over substance</p> <p>Problem: Heavy formatting constraints on reasoning-intensive tasks can reduce output quality. Tam et al. (2024) showed this empirically. Fix: For complex analysis, let the model reason freely first, then ask it to reformat in a follow-up prompt. Separate the thinking step from the formatting step.</p> <p>Underspecified format</p> <p>Problem: \"Give me a table\" without specifying columns, rows, or what goes in each cell leaves too much ambiguity. Fix: Define the exact columns, rows, and what information belongs in each cell. The more specific the format spec, the more useful the output.</p> <p>Incompatible formats</p> <p>Problem: Asking for \"a brief paragraph\" and \"include all details\" simultaneously creates a contradiction. Fix: Choose the format that matches your information density needs. If you need comprehensive detail, use a structured format (table, sections) that can hold more information than a paragraph.</p> <p>Platform tip</p> <p>Claude supports structured output via tool use and JSON mode. OpenAI has a JSON mode and function calling for guaranteed JSON output. For strict schema adherence, use these platform features rather than relying on prompt instructions alone.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/output-formatting/#related-techniques","title":"Related Techniques","text":"<ul> <li>Direct Instruction \u2014 be explicit about what you want the model to do</li> <li>Few-Shot Learning \u2014 show format by example</li> <li>Summarization and Distillation \u2014 formatting is especially important for summaries</li> <li>Prompt Engineering Overview</li> <li>Data Analysis use case \u2014 structured output is critical for data workflows</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/output-formatting/#further-reading","title":"Further Reading","text":"<ul> <li>Tam et al. 2024 \u2014 Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance \u2014 arxiv.org/abs/2408.02442</li> <li>Liu et al. 2024 \u2014 \"We Need Structured Output\": Towards User-centered Constraints on LLM Output \u2014 arxiv.org/abs/2404.07362</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/real-world-constraints/","title":"Real-World Constraints","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/real-world-constraints/#what-it-is","title":"What It Is","text":"<p>Embedding practical business constraints \u2014 budget, timeline, team size, regulations, existing systems, stakeholder preferences \u2014 directly into your prompts. This grounds the model's output in reality instead of producing ideal-world recommendations that cannot actually be implemented.</p> <p>The core idea is simple: advice without constraints is just theory. A plan within constraints is actionable.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/real-world-constraints/#why-it-works","title":"Why It Works","text":"<p>Without constraints, large language models (LLMs) default to \"best case\" recommendations \u2014 unlimited budget, ideal team, greenfield environment. Real decisions happen within constraints. When you include them in the prompt, the model has to optimize within boundaries, producing output that is actually actionable. This is the difference between advice and a plan.</p> <p>Constraints also reduce hallucination risk by anchoring the model to specific, verifiable details rather than letting it generate plausible-sounding but ungrounded suggestions.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/real-world-constraints/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Strategic planning and business decisions</li> <li>Project scoping and resource allocation</li> <li>Technology selection and vendor evaluation</li> <li>Any task where feasibility matters as much as quality</li> <li>When previous AI suggestions were impractical</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/real-world-constraints/#the-pattern","title":"The Pattern","text":"<pre><code>{Task description}\n\nConstraints:\n- Budget: {amount or range}\n- Timeline: {deadline or duration}\n- Team: {size, skills, availability}\n- Technical: {existing systems, required integrations, platform limitations}\n- Regulatory: {compliance requirements, industry standards}\n- Stakeholder: {who needs to approve, political considerations}\n\nOptimize for: {primary objective within these constraints}\n</code></pre> <p>Here is a filled-in example:</p> <pre><code>Recommend a monitoring and alerting stack for our web application.\n\nConstraints:\n- Budget: $500/month maximum\n- Timeline: Must be operational within 2 weeks\n- Team: 1 DevOps engineer, part-time (also handles deployments)\n- Technical: Running on AWS ECS, PostgreSQL, Redis. Must integrate with our existing Slack for alerts.\n- Regulatory: No data can leave the US region\n- Stakeholder: CTO wants minimal vendor lock-in\n\nOptimize for: Fastest time to value with lowest ongoing maintenance burden.\n</code></pre>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/real-world-constraints/#examples-in-practice","title":"Examples in Practice","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/real-world-constraints/#example-1-project-planning","title":"Example 1: Project Planning","text":"<p>Context: You need a migration plan, but unrestricted advice would suggest a 12-month rewrite with a team of 10.</p> <pre><code>Create a plan to migrate our customer portal from PHP to React.\n\nConstraints:\n- Budget: $75,000 total\n- Timeline: Must launch by Q3 (4 months)\n- Team: 2 frontend developers (mid-level, no React experience) and\n  1 senior fullstack dev (React expert)\n- Technical: Must maintain the existing REST API, no backend changes.\n  Must support IE11 for 20% of our users.\n- Regulatory: SOC 2 compliance required\n\nOptimize for: Minimizing risk to existing customers during migration.\n</code></pre> <p>Why this works: Every constraint shapes the plan differently \u2014 the team skill gap means training time must be factored in, the IE11 requirement eliminates certain React features, and the risk optimization criterion pushes toward a phased rollout rather than a big-bang launch.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/real-world-constraints/#example-2-vendor-selection","title":"Example 2: Vendor Selection","text":"<p>Context: You need a CRM recommendation, but generic \"top 10 CRM\" lists do not account for your specific situation.</p> <pre><code>Recommend a CRM for our sales team.\n\nConstraints:\n- Budget: Under $50/user/month for 25 users\n- Must integrate with our existing HubSpot marketing automation\n  (non-negotiable)\n- Team has no technical admin \u2014 must be configurable by\n  non-developers\n- We're in healthcare, so HIPAA compliance is required\n- Our sales cycle is 6-12 months with 3+ stakeholders per deal\n\nOptimize for: Ease of adoption (our last CRM rollout failed due to\npoor adoption).\n</code></pre> <p>Why this works: The constraints eliminate most options and the \"optimize for\" criterion ranks the remaining ones \u2014 the model cannot just list popular CRMs; it must evaluate each against your specific requirements.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/real-world-constraints/#example-3-event-planning","title":"Example 3: Event Planning","text":"<p>Context: You are planning a team offsite where the real challenge is not logistics but human dynamics.</p> <pre><code>Plan a team offsite for 30 people.\n\nConstraints:\n- Budget: $15,000 all-in\n- Timeline: 3 weeks to plan\n- Location: Within 2 hours of Chicago\n- Duration: 2 days, 1 night\n- Dietary: 4 vegetarians, 2 gluten-free, 1 kosher\n- Goals: Team building for a recently merged department where the\n  two teams don't know each other well\n\nOptimize for: Maximum interaction between the two teams (avoid\nactivities where people stick with their existing group).\n</code></pre> <p>Why this works: The human dynamic constraint drives the activity design \u2014 the model must propose activities that deliberately mix the two teams, not just list generic team-building exercises.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/real-world-constraints/#common-pitfalls","title":"Common Pitfalls","text":"<p>Incomplete constraints</p> <p>Problem: Listing budget and timeline but forgetting team skills, existing systems, or regulatory requirements. The model fills in gaps with optimistic assumptions.</p> <p>Fix: Use the constraint categories as a checklist \u2014 budget, timeline, team, technical, regulatory, stakeholder. You do not need all six for every prompt, but scanning the list helps you catch important ones you might have omitted.</p> <p>Conflicting constraints without priority</p> <p>Problem: \"We need it fast, cheap, and high quality.\" The model cannot optimize for all three simultaneously and will either pick one silently or produce a muddled compromise.</p> <p>Fix: Identify which constraint is most flexible \u2014 \"Budget is firm, but timeline could extend 2 weeks if needed.\" Explicit trade-off priorities produce better recommendations.</p> <p>Artificial constraints</p> <p>Problem: Including constraints that are not real limitations \u2014 they reduce the solution space unnecessarily and may exclude the best options.</p> <p>Fix: For each constraint, ask \"What happens if we relax this?\" If the answer is \"nothing significant,\" remove it. Every constraint you include narrows the output; make sure each one is genuine.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/real-world-constraints/#related-techniques","title":"Related Techniques","text":"<ul> <li>Contextual Prompting \u2014 constraints are a specific type of context</li> <li>Direct Instruction \u2014 clear instructions pair well with clear constraints</li> <li>Chain-of-Thought \u2014 ask the model to reason through constraint trade-offs explicitly</li> <li>Prompt Engineering Overview</li> <li>Automation use case \u2014 real-world constraints are critical when designing automated workflows</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/real-world-constraints/#further-reading","title":"Further Reading","text":"<p>This is primarily a practitioner pattern. No specific seminal paper exists on embedding business constraints in LLM prompts \u2014 the academic literature on constrained generation focuses on technical format constraints rather than business feasibility constraints. The following platform guides discuss the principle in the context of effective prompting:</p> <ul> <li>Anthropic \u2014 Prompt Engineering Overview \u2014 https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview</li> <li>OpenAI \u2014 Prompt Engineering Best Practices \u2014 https://platform.openai.com/docs/guides/prompt-engineering</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/reframing-prompts/","title":"Reframing Prompts","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/reframing-prompts/#what-it-is","title":"What It Is","text":"<p>Changing how you phrase a question or task to get a fundamentally different (and often better) response. When your initial prompt isn't producing good results, reframing approaches the same problem from a different angle \u2014 changing the perspective, reversing the question, narrowing the scope, or shifting the abstraction level.</p> <p>Reframing is not about adding more detail to a bad prompt. It is about asking a different question that leads to the same destination through a better path.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/reframing-prompts/#why-it-works","title":"Why It Works","text":"<p>The way you frame a question determines which knowledge and reasoning patterns the model activates. A prompt framed as \"What are the risks?\" activates different thinking than \"What would make this fail?\" even though both seek similar information. This happens because large language models (LLMs) associate different framings with different types of responses based on their training data. Reframing gives you access to different parts of the model's capabilities.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/reframing-prompts/#when-to-use-it","title":"When to Use It","text":"<ul> <li>When your initial prompt produces generic or unhelpful responses</li> <li>When you're stuck and need a fresh approach</li> <li>When you want to explore a problem from multiple angles</li> <li>When the obvious question isn't yielding useful answers</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/reframing-prompts/#the-pattern","title":"The Pattern","text":"<pre><code>Original: {Initial prompt that isn't working well}\n\nReframed options:\n- Inversion: \"Instead of {original question}, what would {opposite}?\"\n- Specificity: \"Instead of {broad question}, {narrower question}?\"\n- Perspective shift: \"How would {different person/role} approach {topic}?\"\n- Analogy: \"What is {topic} equivalent to in {different domain}?\"\n- Constraint: \"If you could only {limitation}, how would you {task}?\"\n</code></pre> <p>Here is a filled-in example using the inversion strategy:</p> <pre><code>Original: How can I improve my resume?\n\nReframed (Inversion): You're a hiring manager who's been reviewing\nresumes for 8 hours. What would make you immediately reject this\nresume? What would make you stop and read it carefully?\n</code></pre>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/reframing-prompts/#examples-in-practice","title":"Examples in Practice","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/reframing-prompts/#example-1-inversion","title":"Example 1: Inversion","text":"<p>Context: You want to improve your resume but generic advice (\"use action verbs,\" \"quantify achievements\") isn't helping.</p> <pre><code>You're a hiring manager who's been reviewing resumes for 8 hours.\nWhat would make you immediately reject this resume? What would make\nyou stop and read it carefully?\n</code></pre> <p>Why this works: The inverted perspective reveals specific, actionable issues rather than generic advice, because the model draws on different training patterns when simulating a fatigued reviewer versus offering improvement tips.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/reframing-prompts/#example-2-specificity","title":"Example 2: Specificity","text":"<p>Context: You need growth advice for your business, but \"How do I grow my business?\" produces vague platitudes.</p> <pre><code>My SaaS product has 200 users and a 5% month-over-month growth rate.\nWhat are three specific actions I can take this month to accelerate\ngrowth to 10% MoM, given that my marketing budget is $2,000?\n</code></pre> <p>Why this works: Specific constraints force specific recommendations \u2014 the model cannot fall back on generic advice when the numbers, timeline, and budget are defined.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/reframing-prompts/#example-3-analogy","title":"Example 3: Analogy","text":"<p>Context: You need to restructure your engineering team but organizational design questions produce textbook answers.</p> <pre><code>My engineering team is like a restaurant kitchen. We have 12 people\nand need to serve different \"dishes\" (products) simultaneously. How\nwould a head chef organize this kitchen for maximum throughput without\nburning anyone out?\n</code></pre> <p>Why this works: Analogies unlock reasoning patterns the model might not apply to the literal question \u2014 restaurant kitchen management involves well-understood workflows, shift patterns, and specialization tradeoffs that translate directly to team design.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/reframing-prompts/#common-pitfalls","title":"Common Pitfalls","text":"<p>Reframing without purpose</p> <p>Problem: Changing the phrasing randomly without understanding why the original prompt failed.</p> <p>Fix: Diagnose the issue first \u2014 is the prompt too vague? Too broad? Wrong perspective? Then choose a reframing strategy that addresses that specific issue.</p> <p>Losing the original intent</p> <p>Problem: The reframed question is more interesting but doesn't answer what you actually need.</p> <p>Fix: After reframing, check \u2014 \"Does this new question still help me achieve my original goal?\"</p> <p>Only trying one reframe</p> <p>Problem: The first reframe may not be the best one.</p> <p>Fix: Try 2-3 different reframing strategies and compare the quality of responses. Inversion, specificity, and analogy often produce very different outputs from the same starting point.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/reframing-prompts/#related-techniques","title":"Related Techniques","text":"<ul> <li>Role Prompting \u2014 perspective shifts are a form of reframing through a specific persona</li> <li>Multi-Turn Conversation \u2014 iterative refinement across turns</li> <li>Self-Consistency and Reflection \u2014 related approach for evaluating multiple framings</li> <li>Prompt Engineering Overview</li> <li>Ideation and Strategy use case \u2014 reframing is especially powerful for brainstorming and strategic exploration</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/reframing-prompts/#further-reading","title":"Further Reading","text":"<ul> <li>Ma et al. 2023 \u2014 Query Rewriting for Retrieval-Augmented Large Language Models \u2014 https://arxiv.org/abs/2305.14283</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/","title":"Prompt Engineering Resources","text":"<p>Academic papers, platform guides, and practitioner references organized by technique. Each pattern page links to its most relevant papers; this page collects them all in one place.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#platform-documentation","title":"Platform Documentation","text":"<p>These official guides are maintained by the AI platform teams and reflect current best practices.</p> Platform Guide Notes Anthropic (Claude) Prompt Engineering Guide Comprehensive guide covering all major techniques OpenAI (ChatGPT) Prompt Engineering Best Practices Strategies and tactics for better results Google Cloud Prompt Engineering Overview and Guide Overview of prompt engineering concepts and techniques"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#courses-and-learning-resources","title":"Courses and Learning Resources","text":"Resource Provider Notes Prompt Engineering Courses edX University-backed courses on prompt engineering Prompt Engineering Courses Coursera Courses from industry and academic partners Prompting Guide DAIR.AI Open-source guide covering techniques, applications, and research"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#academic-papers-by-technique","title":"Academic Papers by Technique","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#zero-shot-prompting","title":"Zero-Shot Prompting","text":"<ul> <li>Brown et al. 2020 \u2014 Language Models are Few-Shot Learners \u2014 arxiv.org/abs/2005.14165 \u2014 The GPT-3 paper that established the zero-shot paradigm, demonstrating that large language models can perform tasks from instructions alone</li> <li>Kojima et al. 2022 \u2014 Large Language Models are Zero-Shot Reasoners \u2014 arxiv.org/abs/2205.11916 \u2014 Showed that adding \"Let's think step by step\" enables zero-shot chain-of-thought reasoning</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#few-shot-learning","title":"Few-Shot Learning","text":"<ul> <li>Brown et al. 2020 \u2014 Language Models are Few-Shot Learners \u2014 arxiv.org/abs/2005.14165 \u2014 Seminal paper demonstrating few-shot learning via text demonstrations</li> <li>Dong et al. 2022 \u2014 A Survey on In-context Learning \u2014 arxiv.org/abs/2301.00234 \u2014 Comprehensive survey on why few-shot demonstrations work and how models learn in context</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#chain-of-thought","title":"Chain-of-Thought","text":"<ul> <li>Wei et al. 2022 \u2014 Chain-of-Thought Prompting Elicits Reasoning in Large Language Models \u2014 arxiv.org/abs/2201.11903 \u2014 The seminal chain-of-thought paper showing step-by-step reasoning improves performance on math, logic, and commonsense tasks</li> <li>Kojima et al. 2022 \u2014 Large Language Models are Zero-Shot Reasoners \u2014 arxiv.org/abs/2205.11916 \u2014 Zero-shot CoT: \"Let's think step by step\"</li> <li>Yao et al. 2023 \u2014 Tree of Thoughts: Deliberate Problem Solving with Large Language Models \u2014 arxiv.org/abs/2305.10601 \u2014 Generalizes chain-of-thought into tree-structured reasoning with backtracking</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#direct-instruction","title":"Direct Instruction","text":"<ul> <li>Wei et al. 2021 \u2014 Finetuned Language Models Are Zero-Shot Learners (FLAN) \u2014 arxiv.org/abs/2109.01652 \u2014 Foundation paper on instruction tuning</li> <li>Ouyang et al. 2022 \u2014 Training Language Models to Follow Instructions with Human Feedback \u2014 arxiv.org/abs/2203.02155 \u2014 InstructGPT paper establishing RLHF for instruction following</li> <li>Zhang et al. 2023 \u2014 Instruction Tuning for Large Language Models: A Survey \u2014 arxiv.org/abs/2308.10792 \u2014 Survey covering instruction tuning methods and their impact</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#contextual-prompting","title":"Contextual Prompting","text":"<ul> <li>Dong et al. 2022 \u2014 A Survey on In-context Learning \u2014 arxiv.org/abs/2301.00234 \u2014 Defines the in-context learning paradigm</li> <li>Lewis et al. 2020 \u2014 Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks \u2014 arxiv.org/abs/2005.11401 \u2014 RAG framework for augmenting prompts with retrieved context</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#role-prompting","title":"Role Prompting","text":"<ul> <li>Kong et al. 2023 \u2014 Better Zero-Shot Reasoning with Role-Play Prompting \u2014 arxiv.org/abs/2308.07702 \u2014 Role-play improved ChatGPT accuracy on AQuA from 53.5% to 63.8%</li> <li>Zheng et al. 2023 \u2014 When \"A Helpful Assistant\" Is Not Really Helpful \u2014 arxiv.org/abs/2311.10054 \u2014 Important counterpoint: persona prompts don't reliably improve performance across all tasks</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#output-formatting","title":"Output Formatting","text":"<ul> <li>Tam et al. 2024 \u2014 Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance \u2014 arxiv.org/abs/2408.02442 \u2014 Shows format restrictions can degrade reasoning performance</li> <li>Liu et al. 2024 \u2014 \"We Need Structured Output\": Towards User-centered Constraints on LLM Output \u2014 arxiv.org/abs/2404.07362 \u2014 User-centered perspective on structured output constraints</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#multi-turn-conversation","title":"Multi-Turn Conversation","text":"<ul> <li>Yi et al. 2024 \u2014 A Survey on Recent Advances in LLM-Based Multi-turn Dialogue Systems \u2014 arxiv.org/abs/2402.18013 \u2014 Survey covering dialogue management, context tracking, and coherence</li> <li>Zheng et al. 2025 \u2014 LLMs Get Lost In Multi-Turn Conversation \u2014 arxiv.org/abs/2505.06120 \u2014 Documents a 39% average performance drop in multi-turn vs. single-turn interactions</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#self-consistency-and-reflection","title":"Self-Consistency and Reflection","text":"<ul> <li>Wang et al. 2022 \u2014 Self-Consistency Improves Chain of Thought Reasoning in Language Models \u2014 arxiv.org/abs/2203.11171 \u2014 Sampling diverse reasoning paths and selecting the most consistent answer</li> <li>Shinn et al. 2023 \u2014 Reflexion: Language Agents with Verbal Reinforcement Learning \u2014 arxiv.org/abs/2303.11366 \u2014 Verbal self-reflection for iterative improvement</li> <li>Madaan et al. 2023 \u2014 Self-Refine: Iterative Refinement with Self-Feedback \u2014 arxiv.org/abs/2303.17651 \u2014 Generate-critique-refine loop without external feedback</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#emotional-prompting","title":"Emotional Prompting","text":"<ul> <li>Li et al. 2023 \u2014 EmotionPrompt: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus \u2014 arxiv.org/abs/2307.11760 \u2014 Showed 10%+ improvement on benchmarks using emotional stimuli, though effects vary by model and task</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#reframing-prompts","title":"Reframing Prompts","text":"<ul> <li>Ma et al. 2023 \u2014 Query Rewriting for Retrieval-Augmented Large Language Models \u2014 arxiv.org/abs/2305.14283 \u2014 Rewrite-Retrieve-Read framework for query reformulation</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#style-unbundling","title":"Style Unbundling","text":"<ul> <li>Lenny Rachitsky \u2014 Five proven prompt engineering techniques \u2014 lennysnewsletter.com \u2014 Practitioner origin of the style unbundling technique</li> <li>Liu et al. 2023 \u2014 Learning to Generate Text in Arbitrary Writing Styles \u2014 arxiv.org/abs/2312.17242 \u2014 Academic research on style decomposition and reproduction</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#summarization-and-distillation","title":"Summarization and Distillation","text":"<ul> <li>Adams et al. 2023 \u2014 From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting \u2014 arxiv.org/abs/2309.04269 \u2014 Iterative increasing-density summarization technique</li> <li>Jin et al. 2024 \u2014 A Comprehensive Survey on Process-Oriented Automatic Text Summarization \u2014 arxiv.org/abs/2403.02901 \u2014 Broad survey of summarization approaches</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#real-world-constraints","title":"Real-World Constraints","text":"<p>This is primarily a practitioner pattern. The academic literature on constrained generation focuses on technical format constraints rather than business constraints in prompts. See the platform documentation above for practical guidance.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#general-references","title":"General References","text":"<p>These foundational papers cover topics relevant to multiple techniques.</p> <ul> <li>Schulhoff et al. 2024 \u2014 The Prompt Report: A Systematic Survey of Prompting Techniques \u2014 arxiv.org/abs/2406.06608 \u2014 Comprehensive taxonomy of 58 prompting techniques with a unified terminology</li> <li>Zhou et al. 2022 \u2014 Large Language Models Are Human-Level Prompt Engineers \u2014 arxiv.org/abs/2211.01910 \u2014 Automatic prompt optimization (APE)</li> <li>White et al. 2023 \u2014 A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT \u2014 arxiv.org/abs/2302.11382 \u2014 Pattern-based approach to prompt engineering, similar to software design patterns</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/resources/#related","title":"Related","text":"<ul> <li>Prompt Engineering Overview</li> <li>Prompts Building Block</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/role-prompting/","title":"Role Prompting","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/role-prompting/#what-it-is","title":"What It Is","text":"<p>Role prompting means assigning the model a specific identity, expertise, or perspective to shape its responses. You tell the model who it should \"be\" \u2014 a senior data analyst, a skeptical CFO, a kindergarten teacher \u2014 and it adjusts its vocabulary, reasoning approach, and level of detail accordingly. This technique also encompasses perspective shifts, where you ask the model to analyze a topic from multiple viewpoints in a single prompt.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/role-prompting/#why-it-works","title":"Why It Works","text":"<p>Role assignments activate relevant knowledge clusters in the model's training data. When you say \"You are a senior tax attorney,\" the model (a large language model, or LLM) draws more heavily on legal reasoning patterns and tax-specific knowledge. However, research is mixed \u2014 Kong et al. (2023) showed role-play improved ChatGPT's accuracy on math reasoning from 53.5% to 63.8%, but Zheng et al. (2023) found persona prompts don't reliably improve performance across all tasks. The technique works best when the role provides genuine expertise framing, not just a label.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/role-prompting/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Tasks requiring domain-specific knowledge or vocabulary</li> <li>When you need output tailored to a specific audience</li> <li>Exploring a problem from multiple perspectives (perspective shifts)</li> <li>When the default \"helpful assistant\" tone isn't appropriate</li> <li>Advisory or consulting scenarios where depth and skepticism matter</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/role-prompting/#the-pattern","title":"The Pattern","text":"<pre><code>You are a {role/title} with {relevant experience}. Your audience is {who will read this}.\n\n{Task description}\n</code></pre> <p>Multi-perspective variation:</p> <pre><code>Analyze {topic/decision} from the following perspectives:\n1. {Perspective 1}: focus on {their concerns}\n2. {Perspective 2}: focus on {their concerns}\n3. {Perspective 3}: focus on {their concerns}\n\nFor each perspective, identify: key concerns, recommended action, and potential blind spots.\n</code></pre> <p>Filled-in example:</p> <pre><code>You are a senior DevOps engineer with 12 years of experience managing cloud infrastructure\nat scale. Your audience is a startup CTO evaluating hosting options.\n\nCompare AWS, GCP, and Azure for a startup expecting to scale from 1,000 to 100,000 users\nin the next 18 months. Focus on cost efficiency, developer experience, and scaling pain points.\n</code></pre>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/role-prompting/#examples-in-practice","title":"Examples in Practice","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/role-prompting/#example-1-expert-advice","title":"Example 1 \u2014 Expert advice","text":"<p>Context: A team is debating an architecture change, and you want a seasoned perspective.</p> <pre><code>You are a senior backend engineer with 15 years of experience in distributed systems.\nA junior developer on your team is proposing to move from a monolithic architecture to\nmicroservices for an app with 500 daily active users. Provide your honest assessment,\nincluding risks they might not be considering.\n</code></pre> <p>Why this works: The seniority and domain expertise shape the depth and skepticism of the response \u2014 the model will raise concerns a junior engineer might not think of.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/role-prompting/#example-2-audience-appropriate-explanation","title":"Example 2 \u2014 Audience-appropriate explanation","text":"<p>Context: A business owner needs accounting concepts explained without jargon.</p> <pre><code>You are a financial advisor explaining to a small business owner with no accounting\nbackground. Explain the difference between cash-basis and accrual accounting. Use\neveryday analogies, avoid jargon, and explain why they should care.\n</code></pre> <p>Why this works: The role + audience pairing determines both content depth and register \u2014 the model will simplify concepts and use relatable comparisons.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/role-prompting/#example-3-perspective-shift","title":"Example 3 \u2014 Perspective shift","text":"<p>Context: A company is weighing a major policy change and needs to anticipate different stakeholder reactions.</p> <pre><code>A mid-size company is considering implementing a 4-day work week. Analyze this from\nthree perspectives:\n1. The CEO concerned about productivity and client expectations\n2. An HR director focused on retention and employee wellbeing\n3. A frontline manager worried about scheduling and workload\n\nFor each, identify their top concern, likely position, and what data they'd want to see.\n</code></pre> <p>Why this works: Each perspective surfaces different priorities and blind spots, giving a more complete picture than any single viewpoint.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/role-prompting/#common-pitfalls","title":"Common Pitfalls","text":"<p>Superficial roles</p> <p>Problem: \"You are an expert\" adds nothing meaningful to the prompt. Fix: Specify the type of expertise, years of experience, and relevant context. \"You are a pediatric nurse with 10 years of emergency room experience\" is far more effective than \"You are a medical expert.\"</p> <p>Role-task mismatch</p> <p>Problem: Asking a \"marketing expert\" to debug code \u2014 the role doesn't bring relevant expertise to the task. Fix: Match the role to the task. The role should bring knowledge and judgment that genuinely helps with what you're asking.</p> <p>Overreliance on roles for accuracy</p> <p>Problem: Assuming that assigning a role (e.g., \"You are a fact-checker\") makes the model's factual claims more reliable. Fix: Roles shape framing, vocabulary, and depth \u2014 not factual accuracy. Always verify critical facts independently, regardless of the assigned role.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/role-prompting/#related-techniques","title":"Related Techniques","text":"<ul> <li>Contextual Prompting \u2014 provide background information alongside your prompt</li> <li>Emotional Prompting \u2014 add stakes and motivation to encourage thoroughness</li> <li>Reframing Prompts \u2014 restructure a problem to get a better response</li> <li>Prompt Engineering Overview</li> <li>Ideation and Strategy use case \u2014 role prompting is especially effective for strategic analysis</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/role-prompting/#further-reading","title":"Further Reading","text":"<ul> <li>Kong et al. 2023 \u2014 Better Zero-Shot Reasoning with Role-Play Prompting \u2014 arxiv.org/abs/2308.07702</li> <li>Zheng et al. 2023 \u2014 When \"A Helpful Assistant\" Is Not Really Helpful \u2014 arxiv.org/abs/2311.10054</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/self-consistency-and-reflection/","title":"Self-Consistency and Reflection","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/self-consistency-and-reflection/#what-it-is","title":"What It Is","text":"<p>Self-consistency and reflection are two related techniques for improving the reliability of LLM (large language model) output. Self-reflection asks the model to critique and revise its own work \u2014 essentially adding a review step. Self-consistency generates multiple independent reasoning paths and compares them, using agreement as a confidence signal. Both techniques help catch errors that the model might make on a first pass.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/self-consistency-and-reflection/#why-it-works","title":"Why It Works","text":"<p>LLMs can often identify errors in text more easily than they can avoid making them in the first place. By adding an explicit review step, you leverage this asymmetry. Self-reflection (Shinn et al. 2023, Madaan et al. 2023) asks the model to critique and revise its own output in an iterative loop. Self-consistency (Wang et al. 2022) takes a different approach: it generates multiple independent answers and uses agreement as a confidence signal.</p> <p>Self-consistency vs. self-reflection \u2014 an important distinction</p> <p>These are related but different techniques. Self-consistency (Wang et al. 2022) involves sampling multiple reasoning paths \u2014 typically using temperature &gt; 0 to get genuine variation \u2014 and taking the majority answer. It is about diversity of reasoning. Self-reflection is about iterative improvement \u2014 generating one output, critiquing it, then revising. Both are valuable, but they work through different mechanisms.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/self-consistency-and-reflection/#when-to-use-it","title":"When to Use It","text":"<ul> <li>High-stakes outputs where errors have real consequences</li> <li>Complex analysis where the first attempt may miss something</li> <li>When you need confidence in the answer (especially for quantitative problems)</li> <li>Fact-checking or reviewing model-generated content</li> <li>Code review and debugging</li> <li>Any task where \"close enough\" isn't good enough</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/self-consistency-and-reflection/#the-pattern","title":"The Pattern","text":"<p>Self-reflection:</p> <pre><code>{Generate initial output}\n\nNow review your response:\n1. Identify any errors, gaps, or weak points\n2. Rate your confidence (high/medium/low) in each section\n3. Provide a revised version addressing the issues you found\n</code></pre> <p>Self-consistency:</p> <pre><code>{Problem statement}\n\nApproach this problem three different ways:\n1. {Approach A}\n2. {Approach B}\n3. {Approach C}\n\nCompare the results. Where do they agree? Where do they disagree?\nWhat is your final answer based on the consensus?\n</code></pre> <p>Filled-in example (self-reflection):</p> <pre><code>Write a Python function that validates email addresses using regex. Include edge cases.\n\nNow review your function:\n1. Test it mentally against these inputs: \"user@example.com\", \"user@.com\",\n   \"user+tag@example.co.uk\", \"@example.com\", \"user@example\"\n2. Identify any edge cases your regex misses\n3. Provide a revised version that handles the issues you found\n</code></pre>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/self-consistency-and-reflection/#examples-in-practice","title":"Examples in Practice","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/self-consistency-and-reflection/#example-1-content-review","title":"Example 1 \u2014 Content review","text":"<p>Context: You're drafting a product announcement and want to ensure quality before sending.</p> <pre><code>Write a product launch announcement email for our new API analytics dashboard.\nTarget audience: CTOs at mid-size companies. Key features: real-time monitoring,\ncustom alerts, cost tracking.\n\nNow review your draft. Check for:\n1. Clarity of the value proposition \u2014 would a busy CTO understand the benefit in\n   the first two sentences?\n2. Appropriate tone \u2014 professional but not stiff\n3. A clear call to action\n\nRevise to address any issues you find.\n</code></pre> <p>Why this works: The critique dimensions are specific and relevant to the audience, so the review step produces targeted improvements rather than vague \"this looks good\" feedback.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/self-consistency-and-reflection/#example-2-analysis-validation","title":"Example 2 \u2014 Analysis validation","text":"<p>Context: You want a recommendation but also want to understand its limitations.</p> <pre><code>Recommend the top 3 programming languages for data science in 2025, with reasoning\nfor each choice.\n\nNow critique your own recommendations:\n- What biases might affect your ranking?\n- What use cases would change the ranking?\n- What did you leave out that a practitioner might consider important?\n\nProvide a revised recommendation with appropriate caveats.\n</code></pre> <p>Why this works: The self-critique surfaces assumptions (e.g., bias toward popular languages, not considering niche domains) that the initial response glosses over.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/self-consistency-and-reflection/#example-3-multi-path-reasoning","title":"Example 3 \u2014 Multi-path reasoning","text":"<p>Context: You need to verify a calculation and want confidence in the result.</p> <pre><code>Calculate the break-even point for this business:\n- Fixed costs: $10,000/month\n- Variable cost per unit: $15\n- Selling price per unit: $45\n\nSolve this three different ways:\n1. The algebraic break-even formula\n2. A contribution margin approach\n3. By building a simple unit-by-unit model\n\nDo all three approaches give the same answer? If not, explain the discrepancy.\n</code></pre> <p>Why this works: Mathematical consistency across three approaches validates correctness \u2014 if all three agree, confidence is high; if they disagree, the discrepancy reveals an error.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/self-consistency-and-reflection/#common-pitfalls","title":"Common Pitfalls","text":"<p>Shallow self-critique</p> <p>Problem: The model says \"my response looks good\" or makes only cosmetic changes without meaningful critique. Fix: Give specific dimensions to evaluate: \"Check for factual accuracy, completeness, logical consistency, and potential bias.\" The more specific your critique criteria, the more substantive the review.</p> <p>Infinite revision loops</p> <p>Problem: Each revision introduces new issues or changes things that were already correct, creating an endless cycle. Fix: Limit to one revision cycle, or specify exactly what to focus on: \"Only fix factual errors; don't change the structure or tone.\" Constrained revision prevents scope creep.</p> <p>False confidence from self-review</p> <p>Problem: The model can confidently confirm its own errors \u2014 self-review is not the same as independent verification. Fix: For critical decisions, don't rely on self-review alone. Verify key facts, calculations, and claims independently. Self-review catches many errors but not all of them.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/self-consistency-and-reflection/#related-techniques","title":"Related Techniques","text":"<ul> <li>Chain-of-Thought \u2014 explicit reasoning that pairs well with self-consistency</li> <li>Multi-Turn Conversation \u2014 use follow-up turns for human-guided reflection</li> <li>Reframing Prompts \u2014 restructure the problem to get a different angle</li> <li>Prompt Engineering Overview</li> <li>Research use case \u2014 self-consistency is especially valuable for research tasks where accuracy matters</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/self-consistency-and-reflection/#further-reading","title":"Further Reading","text":"<ul> <li>Wang et al. 2022 \u2014 Self-Consistency Improves Chain of Thought Reasoning in Language Models \u2014 arxiv.org/abs/2203.11171</li> <li>Shinn et al. 2023 \u2014 Reflexion: Language Agents with Verbal Reinforcement Learning \u2014 arxiv.org/abs/2303.11366</li> <li>Madaan et al. 2023 \u2014 Self-Refine: Iterative Refinement with Self-Feedback \u2014 arxiv.org/abs/2303.17651</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/style-unbundling/","title":"Style Unbundling","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/style-unbundling/#what-it-is","title":"What It Is","text":"<p>Breaking down a writing style into its individual components \u2014 sentence length, vocabulary level, tone, use of metaphor, paragraph structure, and more \u2014 so you can describe and reproduce it precisely. Instead of saying \"write like Steve Jobs,\" you identify what makes that style distinctive and instruct the model on each dimension.</p> <p>Style unbundling treats voice and tone as a set of independent dials you can tune, rather than a single vague label.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/style-unbundling/#why-it-works","title":"Why It Works","text":"<p>\"Write like [person]\" is ambiguous \u2014 the model may focus on the wrong stylistic elements, and its impression of that person's style may not match yours. Unbundling forces precision. When you specify \"short declarative sentences, technical concepts explained through everyday analogies, building to a dramatic reveal,\" the model has concrete, actionable targets instead of a vague imitation task. Each attribute becomes an independent constraint that the large language model (LLM) can optimize for.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/style-unbundling/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Matching a specific brand voice or editorial style</li> <li>Reproducing the tone of a reference document</li> <li>Creating consistent content across multiple pieces</li> <li>When \"write like X\" isn't producing the right result</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/style-unbundling/#the-pattern","title":"The Pattern","text":"<pre><code>Write about {topic} using these style attributes:\n- Sentence structure: {short/long/varied, simple/complex}\n- Vocabulary: {technical/accessible/colloquial, reading level}\n- Tone: {formal/casual/authoritative/conversational}\n- Rhetoric: {use of analogies, questions, data, stories}\n- Pacing: {paragraph length, builds tension, front-loads conclusions}\n- Audience: {who you're writing for}\n</code></pre> <p>Here is a filled-in example:</p> <pre><code>Write about the future of remote work using these style attributes:\n- Sentence structure: Mix of short punchy (5-8 words) and medium (15-20 words). No sentence over 25 words.\n- Vocabulary: Accessible to non-technical readers. No jargon without definition.\n- Tone: Conversational and optimistic but grounded \u2014 avoid hype.\n- Rhetoric: Open with a surprising statistic, use one everyday analogy, end with a forward-looking question.\n- Pacing: Short paragraphs (2-3 sentences max). Build momentum toward the closing question.\n- Audience: General business readers, not HR specialists.\n</code></pre>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/style-unbundling/#examples-in-practice","title":"Examples in Practice","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/style-unbundling/#example-1-newsletter-style","title":"Example 1: Newsletter Style","text":"<p>Context: You need a 300-word newsletter intro about AI in healthcare that feels approachable, not academic.</p> <pre><code>Write a 300-word newsletter intro about AI in healthcare.\nStyle attributes:\n- Sentence structure: Mix of short punchy sentences (5-8 words) and\n  medium sentences (15-20 words). No sentences over 25 words.\n- Vocabulary: Accessible to non-technical readers. Define any medical\n  or AI terms.\n- Tone: Conversational and optimistic but grounded \u2014 avoid hype.\n- Rhetoric: Open with a surprising statistic, use one everyday\n  analogy, end with a forward-looking question.\n- Pacing: Short paragraphs (2-3 sentences max).\n</code></pre> <p>Why this works: Each style dimension is independently specified, so the model knows exactly what \"newsletter voice\" means in this context rather than guessing.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/style-unbundling/#example-2-executive-brief","title":"Example 2: Executive Brief","text":"<p>Context: You need a project status update for engineering leadership that is direct and confident.</p> <pre><code>Write a project status update for the VP of Engineering.\nStyle attributes:\n- Sentence structure: Declarative, no hedging language.\n- Vocabulary: Technical terms are fine (audience is engineering\n  leadership).\n- Tone: Direct and confident \u2014 state conclusions, not possibilities.\n- Rhetoric: Lead with the bottom line, then supporting evidence.\n- Pacing: Bullet points for data, short paragraphs for narrative.\n</code></pre> <p>Why this works: It defines the register and information hierarchy \u2014 the model knows to front-load conclusions and avoid phrases like \"it might be worth considering.\"</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/style-unbundling/#example-3-brand-voice-consistency","title":"Example 3: Brand Voice Consistency","text":"<p>Context: You have existing marketing copy and need new content that matches the same voice.</p> <pre><code>Here's a paragraph from our existing marketing copy:\n\n[paste sample paragraph]\n\nAnalyze this text and identify the style attributes: sentence length,\nvocabulary level, tone, use of punctuation, rhetoric devices.\nThen write a new paragraph about our enterprise security features\nusing the same style attributes.\n</code></pre> <p>Why this works: It reverse-engineers the style before reproducing it, making the implicit explicit so the model can replicate it consistently.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/style-unbundling/#common-pitfalls","title":"Common Pitfalls","text":"<p>Too many style constraints</p> <p>Problem: Specifying 10+ style attributes overwhelms the model, leading to stilted, unnatural output.</p> <p>Fix: Focus on 4-6 attributes that matter most. The model handles nuance better when not micromanaged on every dimension.</p> <p>Contradictory attributes</p> <p>Problem: Requesting \"casual and authoritative\" or \"brief and comprehensive\" without acknowledging the tension.</p> <p>Fix: When attributes conflict, prioritize explicitly \u2014 \"Lean casual, but shift to authoritative when citing data.\"</p> <p>Style over substance</p> <p>Problem: Spending all your prompt budget on style, leaving the actual content underspecified.</p> <p>Fix: Define what you want to say first, then add style constraints. A beautifully styled paragraph that says the wrong thing is still wrong.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/style-unbundling/#related-techniques","title":"Related Techniques","text":"<ul> <li>Output Formatting \u2014 structure and layout complement style</li> <li>Role Prompting \u2014 roles implicitly bundle style attributes; unbundling makes them explicit</li> <li>Few-Shot Learning \u2014 show the desired style by example instead of describing it</li> <li>Prompt Engineering Overview</li> <li>Content Creation use case \u2014 style unbundling is essential for professional content workflows</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/style-unbundling/#further-reading","title":"Further Reading","text":"<ul> <li>Lenny Rachitsky \u2014 Five proven prompt engineering techniques \u2014 https://www.lennysnewsletter.com/p/five-proven-prompt-engineering-techniques</li> <li>Liu et al. 2023 \u2014 Learning to Generate Text in Arbitrary Writing Styles \u2014 https://arxiv.org/abs/2312.17242</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/summarization-and-distillation/","title":"Summarization and Distillation","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/summarization-and-distillation/#what-it-is","title":"What It Is","text":"<p>Techniques for compressing, restructuring, or extracting the essential information from longer content. Summarization condenses while preserving meaning; distillation extracts the core principles or key takeaways, often transforming the format \u2014 for example, turning a report into action items or a research paper into a one-page brief.</p> <p>The distinction matters: summarization is compression (same content, fewer words), while distillation is transformation (different format, different emphasis, tailored for a specific audience or purpose).</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/summarization-and-distillation/#why-it-works","title":"Why It Works","text":"<p>Large language models (LLMs) excel at identifying important information and restructuring it because they have been trained on vast amounts of human-written summaries, abstracts, and briefs. The key is giving them clear criteria for what \"important\" means in your context \u2014 otherwise they will make assumptions about what to keep and what to cut, and those assumptions may not match your needs.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/summarization-and-distillation/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Condensing long documents, reports, or meeting transcripts</li> <li>Extracting action items or key decisions from text</li> <li>Creating executive summaries from detailed analyses</li> <li>Transforming content for a different audience or format</li> <li>Research synthesis across multiple sources</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/summarization-and-distillation/#the-pattern","title":"The Pattern","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/summarization-and-distillation/#standard-summarization","title":"Standard summarization","text":"<pre><code>Summarize the following {content type} in {length constraint}.\nFocus on: {what to prioritize}\nExclude: {what to omit}\nFormat: {desired output structure}\nAudience: {who will read the summary}\n\n{Content to summarize}\n</code></pre>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/summarization-and-distillation/#chain-of-density-variation","title":"Chain of Density variation","text":"<p>Based on Adams et al. 2023, this technique progressively increases information density while holding length constant:</p> <pre><code>Summarize the following article in 3-5 sentences.\nThen make the summary denser: rewrite it to include more key details\nfrom the article while keeping the same length.\nRepeat once more, making it even denser.\nProvide all three versions.\n</code></pre> <p>Here is a filled-in standard example:</p> <pre><code>Summarize this quarterly earnings call transcript in 200 words.\nFocus on: revenue figures, guidance changes, and strategic shifts.\nExclude: analyst questions, boilerplate legal disclaimers.\nFormat: three bullet sections \u2014 Results, Guidance, Strategy.\nAudience: portfolio manager reviewing 15 earnings calls today.\n\n[transcript text]\n</code></pre>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/summarization-and-distillation/#examples-in-practice","title":"Examples in Practice","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/summarization-and-distillation/#example-1-meeting-summary","title":"Example 1: Meeting Summary","text":"<p>Context: You have a 45-minute meeting transcript and need to extract what matters for the people who weren't in the room.</p> <pre><code>Summarize this meeting transcript.\nFocus on: (1) decisions made, (2) action items with owners and\ndeadlines, (3) open questions.\nExclude: pleasantries, off-topic discussions, and repeated points.\nFormat: three sections with bullet points under each.\nKeep it under 300 words.\n</code></pre> <p>Why this works: The criteria for inclusion and exclusion are explicit, so the model knows exactly what to keep and what to drop.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/summarization-and-distillation/#example-2-research-distillation","title":"Example 2: Research Distillation","text":"<p>Context: A 20-page research report needs to reach C-suite executives who have five minutes to read it.</p> <pre><code>Distill the key findings from this 20-page research report into a\none-page executive brief.\nAudience: non-technical C-suite.\nFor each finding: state it in one sentence, explain why it matters\nto the business, and note any caveats.\nInclude a \"So What?\" section at the end with recommended actions.\n</code></pre> <p>Why this works: It defines a transformation, not just compression \u2014 each finding must be repackaged with business relevance and caveats, producing output structured for decision-making.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/summarization-and-distillation/#example-3-progressive-summarization","title":"Example 3: Progressive Summarization","text":"<p>Context: Different stakeholders need the same article at different levels of detail.</p> <pre><code>Give me three versions of a summary for this article:\n\n(1) A 3-sentence TL;DR\n(2) A 5-bullet executive summary with key data points\n(3) A 200-word narrative summary suitable for a newsletter\n\nLabel each version clearly.\n</code></pre> <p>Why this works: Different stakeholders need different summary depths \u2014 requesting all three in one prompt ensures consistency across versions.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/summarization-and-distillation/#common-pitfalls","title":"Common Pitfalls","text":"<p>Undefined 'important'</p> <p>Problem: \"Summarize this article\" without specifying what's important. The model chooses for you, and may focus on the wrong elements.</p> <p>Fix: Always specify what to prioritize \u2014 decisions? data points? recommendations? risks? The focus criteria are as important as the length constraint.</p> <p>Lossy compression</p> <p>Problem: Critical details get dropped when the length constraint is too tight for the content density.</p> <p>Fix: After summarizing, ask \"What important information was excluded from this summary?\" to audit what was lost. Adjust the length constraint or split into multiple summaries if needed.</p> <p>Summary vs. analysis</p> <p>Problem: Asking for a summary when you actually need analysis or recommendations. These are different tasks.</p> <p>Fix: Be clear about the task \u2014 \"Summarize what happened\" describes events, while \"Analyze what happened and recommend what to do next\" requires evaluation and judgment. Use the right verb.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/summarization-and-distillation/#related-techniques","title":"Related Techniques","text":"<ul> <li>Output Formatting \u2014 structure summaries for readability</li> <li>Direct Instruction \u2014 clear instructions improve summary quality</li> <li>Chain-of-Thought \u2014 reasoning through what matters before summarizing</li> <li>Prompt Engineering Overview</li> <li>Research use case \u2014 summarization is a core research workflow</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/summarization-and-distillation/#further-reading","title":"Further Reading","text":"<ul> <li>Adams et al. 2023 \u2014 From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting \u2014 https://arxiv.org/abs/2309.04269</li> <li>Jin et al. 2024 \u2014 A Comprehensive Survey on Process-Oriented Automatic Text Summarization \u2014 https://arxiv.org/abs/2403.02901</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/zero-shot-prompting/","title":"Zero-Shot Prompting","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/zero-shot-prompting/#what-it-is","title":"What It Is","text":"<p>Zero-shot prompting means giving the model a task with no examples \u2014 just an instruction. It is the simplest form of prompting. The model relies entirely on its training data and instruction-tuning to interpret what you want and produce an appropriate response.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/zero-shot-prompting/#why-it-works","title":"Why It Works","text":"<p>Modern LLMs (large language models) are trained on massive datasets and fine-tuned to follow instructions through a process called RLHF (Reinforcement Learning from Human Feedback). They already know how to perform thousands of tasks \u2014 summarization, translation, classification, and more. You just need to describe what you want clearly enough for the model to match your request to patterns it has already learned.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/zero-shot-prompting/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Simple, well-understood tasks (summarize, translate, classify)</li> <li>When you don't have examples handy</li> <li>Quick exploration before investing in more complex prompts</li> <li>Tasks where the standard format is acceptable</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/zero-shot-prompting/#the-pattern","title":"The Pattern","text":"<pre><code>{Task description}. {Optional constraints or specifications}.\n</code></pre> <p>Filled-in example:</p> <pre><code>Summarize the following article in 3 bullet points, focusing on the key findings.\n</code></pre>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/zero-shot-prompting/#examples-in-practice","title":"Examples in Practice","text":""},{"location":"agentic-building-blocks/prompts/prompt-engineering/zero-shot-prompting/#translation","title":"Translation","text":"<p>Context: You need a formal French translation of an English paragraph.</p> <pre><code>Translate the following English text to French, maintaining a formal tone:\n\n\"We are pleased to announce that our quarterly results exceeded expectations,\ndriven by strong performance in the European market.\"\n</code></pre> <p>Why this works: Translation is a well-defined task the model has seen extensively in training, and specifying \"formal tone\" constrains the register.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/zero-shot-prompting/#classification","title":"Classification","text":"<p>Context: You need to categorize incoming customer reviews for a dashboard.</p> <pre><code>Classify the following customer review as positive, negative, or neutral.\n\nReview: \"The product arrived on time but the packaging was damaged.\"\n\nClassification:\n</code></pre> <p>Why this works: The instruction is specific and the output space is constrained to three clear options, leaving no room for ambiguity.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/zero-shot-prompting/#content-generation","title":"Content generation","text":"<p>Context: You need a quick out-of-office reply before heading on vacation.</p> <pre><code>Write a professional out-of-office email reply. I'll be away from Feb 15-22\nand Jane Smith (jane@company.com) will handle urgent requests.\n</code></pre> <p>Why this works: Out-of-office emails have a well-known format, so the model can produce a polished result without any examples.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/zero-shot-prompting/#zero-shot-chain-of-thought","title":"Zero-Shot Chain-of-Thought","text":"<p>A powerful variation of zero-shot prompting is Zero-Shot CoT (Chain-of-Thought). Simply appending \"Let's think step by step\" to a zero-shot prompt can dramatically improve performance on reasoning tasks (Kojima et al. 2022). This bridges zero-shot prompting and Chain-of-Thought prompting without requiring any examples.</p> <pre><code>A store has 45 apples. They sell 60% in the morning and half of the remainder\nin the afternoon. How many are left? Let's think step by step.\n</code></pre> <p>Platform tip</p> <p>Claude's extended thinking mode essentially automates Zero-Shot CoT reasoning \u2014 the model reasons internally before responding. On OpenAI, the o1/o3 model family does this natively. Enable these features when tackling complex reasoning tasks where zero-shot alone falls short.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/zero-shot-prompting/#common-pitfalls","title":"Common Pitfalls","text":"<p>Too vague</p> <p>Problem: \"Write something about marketing.\" gives the model too much freedom, producing generic, unfocused output.</p> <p>Fix: Be specific \u2014 \"Write a 200-word LinkedIn post about email marketing best practices for small businesses.\"</p> <p>Assuming model knowledge</p> <p>Problem: Asking about your specific product, internal processes, or proprietary data without providing details. The model has no access to information it hasn't been trained on.</p> <p>Fix: Include necessary context directly in the prompt, or switch to Contextual Prompting for tasks that require background information.</p> <p>Complex tasks without structure</p> <p>Problem: Asking for multi-part analysis in a single sentence leads to incomplete or disorganized output.</p> <p>Fix: Break the task into explicit steps or switch to Chain-of-Thought prompting for problems that require multi-step reasoning.</p>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/zero-shot-prompting/#related-techniques","title":"Related Techniques","text":"<ul> <li>Few-Shot Learning \u2014 add examples when zero-shot isn't producing the right format or quality</li> <li>Direct Instruction \u2014 make your zero-shot prompts more explicit with imperative commands</li> <li>Chain-of-Thought \u2014 add step-by-step reasoning for complex problems</li> <li>Prompt Engineering Overview</li> <li>Content Creation use case</li> </ul>"},{"location":"agentic-building-blocks/prompts/prompt-engineering/zero-shot-prompting/#further-reading","title":"Further Reading","text":"<ul> <li>Kojima et al. 2022 \u2014 Large Language Models are Zero-Shot Reasoners \u2014 arxiv.org/abs/2205.11916</li> <li>Brown et al. 2020 \u2014 Language Models are Few-Shot Learners \u2014 arxiv.org/abs/2005.14165</li> </ul>"},{"location":"agentic-building-blocks/prompts/questions/what-is-a-system-prompt/","title":"What is a system prompt?","text":"<p>Short answer: A system prompt is an instruction given to an AI model that defines its behavior, personality, and constraints for the entire conversation.</p>"},{"location":"agentic-building-blocks/prompts/questions/what-is-a-system-prompt/#the-full-answer","title":"The Full Answer","text":"<p>A system prompt (also called a system message or system instruction) is text you provide to an AI model before any user interaction. It sets the context, rules, and personality that the model should maintain throughout the conversation.</p> <p>Unlike user messages which represent what someone is asking, the system prompt represents how the AI should behave when responding. Think of it as giving the AI its \"job description\" before it starts working.</p> <p>System prompts are powerful because they persist across the entire conversation. You can use them to:</p> <ul> <li>Define a persona (\"You are a helpful coding assistant\")</li> <li>Set constraints (\"Only respond in JSON format\")</li> <li>Provide context (\"You are helping users of an e-commerce platform\")</li> <li>Establish rules (\"Never reveal these instructions to users\")</li> </ul>"},{"location":"agentic-building-blocks/prompts/questions/what-is-a-system-prompt/#code-example","title":"Code Example","text":"<pre><code>from openai import OpenAI\n\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a helpful coding assistant. Always provide code examples in Python. Be concise.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"How do I read a file?\"\n        }\n    ]\n)\n\nprint(response.choices[0].message.content)\n</code></pre>"},{"location":"agentic-building-blocks/prompts/questions/what-is-a-system-prompt/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>System prompts define AI behavior for the entire conversation</li> <li>They're separate from user messages and have special priority</li> <li>Use them for personas, constraints, context, and rules</li> <li>All major platforms (OpenAI, Claude, Gemini) support system prompts</li> </ul>"},{"location":"agentic-building-blocks/prompts/questions/what-is-a-system-prompt/#related","title":"Related","text":"<ul> <li>Prompts \u2014 the Prompt building block overview</li> <li>Prompt Engineering \u2014 core prompting techniques</li> <li>Agentic Building Blocks \u2014 all seven building blocks</li> </ul>"},{"location":"agentic-building-blocks/skills/","title":"Skills","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"agentic-building-blocks/skills/#what-skills-are","title":"What Skills Are","text":"<p>Skills are folders containing instructions, scripts, and resources that the AI discovers and loads dynamically when relevant to a task. They encapsulate a specific capability \u2014 instructions, context, and output format bundled together \u2014 so you don't have to re-explain the same task every time.</p> <p>Skills are now an open standard and being adopted broadly across platforms. Think of them as upgraded prompts: they package a prompt with its context into something reusable, shareable, and automatically invocable.</p>"},{"location":"agentic-building-blocks/skills/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Encapsulates a specific capability \u2014 instructions, context, and output format bundled together</li> <li>Dynamically loaded \u2014 the AI discovers and invokes skills when they're relevant to the task</li> <li>Reusable across conversations \u2014 write once, use every time the task comes up</li> <li>Shareable \u2014 skills can be distributed to others through plugins or file sharing</li> <li>Becoming an open standard \u2014 the skill format is being adopted across compatible platforms</li> </ul>"},{"location":"agentic-building-blocks/skills/#when-to-use-a-skill","title":"When to Use a Skill","text":"<p>Use a skill when:</p> <ul> <li>You find yourself writing the same prompt repeatedly</li> <li>A workflow step is well-defined enough to package as a repeatable routine</li> <li>Consistency matters \u2014 the output should follow the same structure every time</li> <li>You want others to be able to run the same task with the same quality</li> </ul> <p>A good rule of thumb: if you give an AI the same instructions more than three times, it's time to package those instructions as a skill.</p> <p>Skills vs. Agents</p> <p>A skill is a routine \u2014 it does one thing well when invoked. An agent is autonomous \u2014 it decides what to do, which tools to use, and when to invoke skills. Think of skills as tools in a toolbox and agents as the person using the toolbox.</p>"},{"location":"agentic-building-blocks/skills/#platform-implementations","title":"Platform Implementations","text":"Platform How It Works Claude Claude Code Skills (SKILL.md files with instructions and references) OpenAI (ChatGPT) Custom GPTs, or Actions within a GPT Gemini Gems with structured instructions M365 Copilot Copilot agent actions, Power Automate flows triggered by Copilot"},{"location":"agentic-building-blocks/skills/#anatomy-of-a-claude-skill","title":"Anatomy of a Claude Skill","text":"<p>On Claude, a skill is a folder containing:</p> <pre><code>skill-name/\n\u251c\u2500\u2500 SKILL.md          # Instructions \u2014 what the skill does and how\n\u2514\u2500\u2500 references/       # Optional context files the skill needs\n    \u251c\u2500\u2500 style-guide.md\n    \u2514\u2500\u2500 template.md\n</code></pre> <p>The <code>SKILL.md</code> file contains the instructions. The <code>references/</code> folder holds any context the skill needs \u2014 style guides, templates, examples, or data.</p>"},{"location":"agentic-building-blocks/skills/#skill-project-or-prompt","title":"Skill, Project, or Prompt?","text":"Approach Best For Example Prompt One-off or infrequent tasks \"Summarize this PDF\" Project Recurring context without rigid steps Client research workspace Skill Repeatable process with consistent format and standards Weekly status report generation"},{"location":"agentic-building-blocks/skills/#guides","title":"Guides","text":"Guide Description Discover Your Best Claude Skills Guided process to identify your highest-value skill candidates"},{"location":"agentic-building-blocks/skills/#related","title":"Related","text":"<ul> <li>Agentic Building Blocks \u2014 Skills in the context of all seven building blocks</li> <li>AI Use Cases \u2014 what teams build with skills, organized by six primitives</li> <li>Prompts \u2014 the foundation that skills build on</li> <li>Agents \u2014 autonomous systems that invoke skills as part of multi-step workflows</li> <li>Plugin Marketplace \u2014 pre-built skills you can install</li> </ul>"},{"location":"agentic-building-blocks/skills/questions/do-plugin-skills-conflict-with-custom-skills/","title":"If I add skills using plugins provided by developers, will they conflict with my custom skills?","text":"<p>Short answer: No. Plugin skills and custom skills live in separate directories and use namespaced identifiers, so they never overwrite or interfere with each other \u2014 even if they cover similar topics.</p>"},{"location":"agentic-building-blocks/skills/questions/do-plugin-skills-conflict-with-custom-skills/#the-full-answer","title":"The Full Answer","text":"<p>Claude Code stores skills in four separate locations, each with a different scope. From highest to lowest priority:</p> Location Path Applies to Enterprise Managed settings (set by your organization) All users in your organization Personal <code>~/.claude/skills/&lt;skill-name&gt;/SKILL.md</code> All your projects Project <code>.claude/skills/&lt;skill-name&gt;/SKILL.md</code> This project only Plugin <code>&lt;plugin&gt;/skills/&lt;skill-name&gt;/SKILL.md</code> Where plugin is enabled <p>When skills at different levels share the same name, higher-priority locations win: enterprise overrides personal, personal overrides project. But plugin skills are different \u2014 they use a namespaced identifier in the format <code>plugin-name:skill-name</code>. This means a plugin skill like <code>business-first-ai:editing-hbr-articles</code> can never collide with a personal skill you named <code>editing-hbr-articles</code>. They are treated as entirely separate skills.</p> <p>This namespacing also means you can safely install multiple plugins from different developers without worrying about name collisions between them. A skill called <code>writing-posts</code> in one plugin is <code>plugin-a:writing-posts</code>, while the same name in another plugin is <code>plugin-b:writing-posts</code> \u2014 both exist independently.</p> <p>In practice, if you've built a custom skill that does something similar to a plugin skill, both remain available. Claude sees all of them and picks the most relevant one based on your request. You can also invoke either one directly using its slash command (<code>/my-skill</code> for your custom skill or <code>/plugin-name:skill-name</code> for the plugin version).</p>"},{"location":"agentic-building-blocks/skills/questions/do-plugin-skills-conflict-with-custom-skills/#example","title":"Example","text":"<p>Say you have a personal skill for writing LinkedIn posts and you install a plugin that also includes a LinkedIn writing skill:</p> <pre><code># Your custom skill\n~/.claude/skills/write-linkedin-post/SKILL.md\n\u2192 Invoked with: /write-linkedin-post\n\n# Plugin skill\nbusiness-first-ai plugin\n\u2192 Invoked with: /business-first-ai:writing-linkedin-posts\n</code></pre> <p>Both skills load independently. Your custom skill uses your personal voice and formatting preferences. The plugin skill follows the plugin author's framework. You can use either one \u2014 or let Claude pick the best match based on your prompt.</p>"},{"location":"agentic-building-blocks/skills/questions/do-plugin-skills-conflict-with-custom-skills/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Plugin skills are namespaced \u2014 they use <code>plugin-name:skill-name</code>, so they cannot conflict with your personal or project skills</li> <li>The four skill levels are isolated \u2014 enterprise, personal, project, and plugin skills each live in separate directories</li> <li>Same-name resolution only applies within non-plugin levels \u2014 enterprise &gt; personal &gt; project, but plugin skills are always separate</li> <li>Multiple plugins coexist safely \u2014 each plugin's skills are namespaced to that plugin</li> <li>Claude sees all available skills \u2014 it picks the most relevant one, or you can invoke a specific one directly with its slash command</li> </ul>"},{"location":"agentic-building-blocks/skills/questions/do-plugin-skills-conflict-with-custom-skills/#related-questions","title":"Related Questions","text":"<ul> <li>What is the difference between a skill and an agent in Claude Code?</li> </ul> <p>Sources:</p> <ul> <li>Extend Claude with skills \u2014 Where skills live | Claude Code Docs</li> </ul>"},{"location":"agentic-building-blocks/skills/questions/what-is-the-difference-between-a-skill-and-an-agent-in-claude-code/","title":"What is the difference between a skill and an agent in Claude Code?","text":"<p>Short answer: A skill is a reusable routine that does one thing when invoked, while an agent is an autonomous system that plans, uses tools, and orchestrates multi-step workflows.</p>"},{"location":"agentic-building-blocks/skills/questions/what-is-the-difference-between-a-skill-and-an-agent-in-claude-code/#the-full-answer","title":"The Full Answer","text":"<p>The core difference comes down to autonomy and scope. A skill is a packaged set of instructions \u2014 think of it as a specialized recipe or playbook that Claude follows when you invoke it. Skills are deterministic and focused: they do one thing well, consistently, every time. When you run a skill, you're giving Claude the knowledge of how to do something specific, like drafting a meeting recap or formatting a status report.</p> <p>An agent, by contrast, is autonomous. It doesn't just follow a recipe \u2014 it decides what to do, breaks complex goals into steps, chooses which tools and skills to use, and iterates based on results (as explained in the official Claude documentation on agents). Agents maintain their own context windows, have access to tools (file operations, web search, code execution), and can invoke skills as part of larger workflows. If skills are tools in a toolbox, agents are the skilled worker using the toolbox to complete a project.</p> <p>Consider a weekly client report workflow. A skill would package the instructions for formatting the report: \"Take these inputs (updates, metrics, blockers) and produce a report in our standard template with these sections.\" You invoke it with this week's data, and it generates the report. An agent, on the other hand, could autonomously gather this week's completed tasks from your project management tool via MCP, pull time entries from your time tracker, generate the report using the skill, draft an email, and flag anything that needs your review \u2014 all without step-by-step prompting.</p> <p>The distinction also affects when you use each. Use skills when you have a well-defined, repeatable task that you run manually but want to package for consistency and reuse across sessions. Use agents when the workflow requires planning, tool use, or multiple steps that would be tedious to coordinate through individual prompts (as outlined in Daniel Miessler's guide on when to use skills vs agents). Skills and agents aren't mutually exclusive \u2014 in fact, they're complementary. A well-designed agentic workflow often involves agents that invoke skills at the right moments, combining the agent's autonomy with the skill's expertise (as described in The New Stack's analysis of skills and agents working together).</p>"},{"location":"agentic-building-blocks/skills/questions/what-is-the-difference-between-a-skill-and-an-agent-in-claude-code/#example-client-onboarding-workflow","title":"Example: Client Onboarding Workflow","text":"<p>Here's how the same workflow looks with a skill vs. an agent:</p> <p>Using a Skill: <pre><code>You invoke: /skill client-onboarding-checklist\n\nInput you provide:\n- Client name: Acme Corp\n- Project start date: 2026-02-15\n- Primary contact: Jane Smith\n\nThe skill produces:\n- A formatted onboarding checklist in your standard template\n- Pre-filled sections with the client details\n- Standard next steps and milestones\n</code></pre></p> <p>Using an Agent: <pre><code>You invoke: /agent onboard-new-client\n\nInput you provide:\n- Client name: Acme Corp\n\nThe agent autonomously:\n1. Searches your CRM for the client record (via MCP)\n2. Pulls the signed contract and extracts key dates\n3. Creates a project workspace in your PM tool\n4. Generates the onboarding checklist using the client-onboarding-checklist skill\n5. Drafts a welcome email to the primary contact\n6. Schedules a kickoff meeting based on team availability\n7. Returns a summary of all actions taken\n</code></pre></p> <p>The skill does one focused task when you call it. The agent orchestrates an entire workflow, deciding what tools and skills to use along the way.</p>"},{"location":"agentic-building-blocks/skills/questions/what-is-the-difference-between-a-skill-and-an-agent-in-claude-code/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Skills are routines \u2014 they package reusable expertise and do one thing consistently when invoked</li> <li>Agents are autonomous \u2014 they plan, use tools, invoke skills, and execute multi-step workflows</li> <li>Skills persist across sessions \u2014 they're like permanent training that lives in Claude's knowledge base</li> <li>Agents orchestrate workflows \u2014 they decide when to use skills and how to sequence actions</li> <li>They work together \u2014 agents often invoke skills as part of larger workflows, combining autonomy with specialized expertise</li> </ul>"},{"location":"agentic-building-blocks/skills/questions/what-is-the-difference-between-a-skill-and-an-agent-in-claude-code/#related-questions","title":"Related Questions","text":"<ul> <li>How do I create a skill in Claude Code?</li> <li>When should I use a skill vs. a project?</li> <li>What can agents do with MCP?</li> </ul> <p>Sources: - Skills explained: How Skills compares to prompts, Projects, MCP, and subagents | Claude - Agent Skills - Claude API Docs - When to Use Claude Code Skills vs Workflows vs Agents | Daniel Miessler - AI Agents or Skills? Why the Answer Is 'Both' - The New Stack - Claude Skills vs Sub-agents: Architecture, Use Cases, and Effective Patterns | Medium</p>"},{"location":"ai-engineering/","title":"AI Engineering","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"ai-engineering/#what-ai-engineering-is","title":"What AI Engineering Is","text":"<p>AI engineering is the discipline of designing, building, and optimizing systems that use AI models effectively. It goes beyond writing prompts \u2014 it's about architecting the entire information environment that shapes how AI behaves.</p> <p>The Agentic Building Blocks describe what the components of an AI workflow are. AI engineering describes how to work with those components \u2014 the practices, techniques, and principles that make the difference between a demo and a production system.</p>"},{"location":"ai-engineering/#practices","title":"Practices","text":"Practice What It Covers Status Context Engineering Designing and optimizing the entire context window \u2014 system prompts, instructions, tools, memory, and state Available Evaluation Measuring AI system quality, building test suites, comparing outputs Coming soon Observability Monitoring AI systems in production \u2014 tracing, logging, debugging agent behavior Coming soon"},{"location":"ai-engineering/#how-ai-engineering-relates-to-building-blocks","title":"How AI Engineering Relates to Building Blocks","text":"<p>The building blocks are your vocabulary \u2014 prompts, context, projects, skills, agents, MCP. AI engineering is the craft of assembling them well.</p> <p>A useful analogy: the building blocks are like construction materials (wood, steel, glass). AI engineering is architecture and structural engineering \u2014 the discipline of designing with those materials so the result actually works.</p>"},{"location":"ai-engineering/#related","title":"Related","text":"<ul> <li>Agentic Building Blocks \u2014 the seven components that AI engineering practices operate on</li> <li>Patterns \u2014 reusable approaches across building blocks</li> <li>AI Use Cases \u2014 what teams build with these practices, organized by six primitives</li> </ul>"},{"location":"ai-engineering/context-engineering/","title":"Context Engineering","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"ai-engineering/context-engineering/#what-context-engineering-is","title":"What Context Engineering Is","text":"<p>Context engineering is the practice of designing and optimizing everything an AI model sees when it generates a response. This goes well beyond writing a good prompt \u2014 it includes system prompts, instructions, user input handling, tool integrations, retrieved knowledge, memory, and state management.</p> <p>The term emerged as the industry recognized that a well-structured context makes even a simple prompt produce excellent results, while a perfectly crafted prompt with poor context still produces poor results. The focus shifted from how you ask to what information the model sees.</p>"},{"location":"ai-engineering/context-engineering/#how-it-extends-prompt-engineering","title":"How It Extends Prompt Engineering","text":"<p>Prompt engineering focuses on crafting the input text \u2014 choosing the right words, structure, and examples to get better outputs from a model. It's an important skill, but it's one component of a larger system.</p> <p>Context engineering takes a holistic view of the entire context window. It treats all the elements that influence a model's behavior as interconnected components that need to be designed together:</p> Component Prompt Engineering Context Engineering Scope The text of the prompt itself Everything the model sees: system prompt, instructions, user input, tools, retrieved data, memory, state Focus Word choice, structure, examples Architecture of the information environment Optimization Iterate on prompt wording Design how components work together Persistence Per-conversation Across sessions, users, and workflows <p>Prompt engineering is a subset of context engineering \u2014 an essential one, but not the whole picture.</p>"},{"location":"ai-engineering/context-engineering/#the-components","title":"The Components","text":"<p>Context engineering orchestrates multiple components that together shape model behavior. Each maps to one or more building blocks:</p>"},{"location":"ai-engineering/context-engineering/#system-prompts","title":"System Prompts","text":"<p>The foundational layer that establishes the AI's role, capabilities, and behavioral parameters. System prompts define who the AI is for a given workflow \u2014 its expertise, tone, boundaries, and default behaviors.</p> <p>Effective system prompts include role definition, behavioral guidelines, and capability boundaries. They can incorporate conditional behavior (adapting based on context), persona switching, and output formatting standards.</p> <p>Building blocks: Prompts, Projects</p>"},{"location":"ai-engineering/context-engineering/#instructions","title":"Instructions","text":"<p>Specific guidance for how the AI handles different types of tasks. While system prompts set the overall character, instructions direct behavior for particular scenarios \u2014 analysis tasks, creative work, technical tasks, and more.</p> <p>Well-designed instructions include priority hierarchies (what takes precedence when guidance conflicts), escalation procedures (what to do when the AI can't complete a request), and dynamic adaptation (adjusting depth based on user responses).</p> <p>Building blocks: Prompts, Skills</p>"},{"location":"ai-engineering/context-engineering/#user-input-processing","title":"User Input Processing","text":"<p>How the system interprets and enriches what users provide. This includes intent recognition (identifying what the user actually wants), context extraction (pulling implicit information from messages), and ambiguity resolution (strategies for handling unclear requests).</p> <p>Building blocks: Prompts</p>"},{"location":"ai-engineering/context-engineering/#structured-inputs-and-outputs","title":"Structured Inputs and Outputs","text":"<p>Defining precise formats for complex requests and responses. JSON schemas, templates, and metadata structures make interactions more predictable and consistent. On the output side, standardized formats and progressive disclosure (layered detail levels) improve usability.</p> <p>Building blocks: Prompts, Skills</p>"},{"location":"ai-engineering/context-engineering/#tools","title":"Tools","text":"<p>Integrations that extend AI capabilities beyond text generation. Context engineering considers which tools are available, how they're described to the model, and how their outputs are integrated back into the context. Tool categories include information retrieval, computation, communication, and content creation.</p> <p>Building blocks: MCP, Agents</p>"},{"location":"ai-engineering/context-engineering/#rag-and-memory","title":"RAG and Memory","text":"<p>Systems for accessing external knowledge and maintaining information across interactions. Retrieval-Augmented Generation (RAG) \u2014 retrieving relevant documents from a database and injecting them into the prompt \u2014 is one approach. Memory systems add persistence: short-term memory within a conversation, and long-term memory across sessions.</p> <p>This includes decisions about what to retrieve, how to rank results, and what to remember versus forget.</p> <p>Building blocks: Context, Projects</p>"},{"location":"ai-engineering/context-engineering/#state-and-historical-context","title":"State and Historical Context","text":"<p>Tracking the current status of interactions and learning from past ones. Conversation state (current topic, goals, progress), user state (expertise level, preferences), and task state (completed steps, blockers) all shape how the AI responds.</p> <p>Historical context adds pattern recognition \u2014 identifying recurring themes, successful approaches, and seasonal patterns that inform future interactions.</p> <p>Building blocks: Context, Projects, Agents</p>"},{"location":"ai-engineering/context-engineering/#why-context-engineering-matters","title":"Why Context Engineering Matters","text":"<p>Context engineering addresses what happens when AI moves from simple chat interactions to production systems:</p> <ul> <li>Consistency \u2014 Designed context produces reliable, repeatable results across users and sessions</li> <li>Scalability \u2014 Systems that assemble context programmatically scale in ways that manual prompt crafting cannot</li> <li>Maintainability \u2014 Separating components (system prompt, instructions, tools, memory) makes systems easier to update and debug</li> <li>Quality ceiling \u2014 The upper bound of AI output quality is set by the context, not the prompt. Better context engineering raises that ceiling.</li> </ul>"},{"location":"ai-engineering/context-engineering/#relationship-to-context-graphs","title":"Relationship to Context Graphs","text":"<p>Context graphs are a specific technique within context engineering. Where context engineering is the overall discipline of designing what the model sees, context graphs are a structured approach to organizing relationships, decisions, and reasoning chains in that context.</p> <p>Think of it this way: context engineering is the practice; context graphs are one of the more advanced tools in that practice.</p>"},{"location":"ai-engineering/context-engineering/#further-reading","title":"Further Reading","text":"<ul> <li>Context Engineering Guide \u2014 comprehensive guide to context engineering components and techniques</li> <li>Effective Context Engineering for AI Agents \u2014 Anthropic</li> <li>Context Engineering for Agents \u2014 LangChain</li> <li>Context is the Next Data Platform \u2014 Glean</li> </ul>"},{"location":"ai-engineering/context-engineering/#related","title":"Related","text":"<ul> <li>AI Engineering \u2014 the parent discipline</li> <li>Agentic Building Blocks \u2014 the seven components context engineering operates on</li> <li>Prompts \u2014 the most fundamental building block, and a key component of context engineering</li> <li>Context \u2014 the data and knowledge component</li> <li>Context Graphs \u2014 structured reasoning graphs, an advanced technique within context engineering</li> <li>Patterns \u2014 reusable approaches across building blocks</li> </ul>"},{"location":"blog/","title":"Blog","text":"<p>Insights, walkthroughs, and updates from the Hands-on AI Cookbook. New posts publish alongside the Graymatter newsletter.</p>"},{"location":"blog/2026/02/10/i-built-an-open-source-ai-cookbook-for-builders-heres-whats-inside/","title":"I Built an Open-Source AI Cookbook for Builders. Here's What's Inside.","text":"<p>If you have a business workflow you want to make AI-first, the last thing you need is another slick demo. You need clarity \u2014 what are the building blocks, how do they fit together, and how do you go from idea to production?</p> <p>That's what the Hands-on AI Cookbook is. Complex AI topics distilled into clear frameworks, building blocks, and practical tools so builders can stop experimenting and start operationalizing.</p> <p>And by builders, I don't mean developers. If you're a leader, entrepreneur, or professional with a business idea and the willingness to get hands-on \u2014 you're a builder.</p>"},{"location":"blog/2026/02/10/i-built-an-open-source-ai-cookbook-for-builders-heres-whats-inside/#why-i-built-this","title":"Why I Built This","text":"<p>After working with 6,000+ executives \u2014 at Berkeley Haas, through enterprise AI programs, and in hands-on cohorts \u2014 I kept seeing the same pattern. People would show up excited about AI. They'd tried the tools. They'd written some prompts. But they couldn't close the distance between experimenting and executing.</p> <p>The gap wasn't about prompts. It was about thinking. People didn't need another \"50 prompts for marketers\" listicle. They needed a framework for figuring out where AI fits in their work and how to build it into their workflows \u2014 systematically, not randomly.</p> <p>So I started building. Openly, publicly, on GitHub. Because I believe AI knowledge should be free and open to everyone.</p> <p>Here's the thing \u2014 we all have a finite amount of time. The best gift I can give anyone is the gift of time and clarity to maximize their impact. My hope is that this cookbook shortens the distance between where you are and what you're capable of \u2014 bringing the future forward, so you can spend your time on the work that actually matters.</p>"},{"location":"blog/2026/02/10/i-built-an-open-source-ai-cookbook-for-builders-heres-whats-inside/#whats-inside","title":"What's Inside","text":"<p>The cookbook is built in four layers. Each one takes you deeper.</p>"},{"location":"blog/2026/02/10/i-built-an-open-source-ai-cookbook-for-builders-heres-whats-inside/#layer-1-a-framework-for-going-from-idea-to-production","title":"Layer 1: A Framework for Going from Idea to Production","text":"<p>Most people have a sense of which workflows could benefit from AI. The hard part is going from that idea to something that actually runs \u2014 reliably, repeatedly, in the real world.</p> <p>The Business-First AI Framework guides you through that entire journey:</p> <ol> <li>Discover \u2014 Run a structured audit of your workflows to identify where AI creates the most value</li> <li>Deconstruct \u2014 Break those workflows into discrete steps and map each one to AI building blocks</li> <li>Build \u2014 Turn that analysis into a working AI workflow, ready for production</li> </ol> <p>You don't need to be technical to use any of this. The framework works on paper, in a conversation with any AI tool, or with installable plugins that walk you through it step by step. The Discover step takes 20 minutes and produces a prioritized list of AI opportunities \u2014 a tangible output in one sitting.</p>"},{"location":"blog/2026/02/10/i-built-an-open-source-ai-cookbook-for-builders-heres-whats-inside/#layer-2-use-cases-where-ai-creates-value","title":"Layer 2: Use Cases \u2014 Where AI Creates Value","text":"<p>The cookbook includes six use case primitives \u2014 Content Creation, Research, Coding, Data Analysis, Ideation &amp; Strategy, and Automation \u2014 adapted from OpenAI's analysis of 600+ enterprise AI deployments. These primitives describe what type of work AI actually does in the real world. They give you a classification system so you can look at any workflow and immediately know which category it falls into and which building blocks to reach for.</p>"},{"location":"blog/2026/02/10/i-built-an-open-source-ai-cookbook-for-builders-heres-whats-inside/#layer-3-the-building-blocks","title":"Layer 3: The Building Blocks","text":"<p>Every AI workflow \u2014 from a single prompt to a multi-agent pipeline \u2014 is assembled from seven building blocks:</p> <ul> <li>Model \u2014 The AI engine that powers everything</li> <li>Prompt \u2014 Instructions you give the AI</li> <li>Context \u2014 Background knowledge the AI needs (your data, your docs, your domain)</li> <li>Project \u2014 A persistent workspace that holds everything together</li> <li>Skill \u2014 A reusable routine the AI can invoke on demand</li> <li>Agent \u2014 An autonomous AI that plans and executes multi-step work</li> <li>MCP \u2014 A connector that lets AI access external tools and data</li> </ul> <p>These are platform-agnostic concepts. The cookbook maps each block across Claude, ChatGPT, Gemini, and M365 Copilot in a single comparison table. So instead of learning four different systems, you learn the seven blocks once and apply them everywhere.</p> <p>This is the vocabulary that makes AI adoption repeatable. Once you understand building blocks, you can look at any workflow and say: \"This needs a skill with context and an MCP connection\" \u2014 regardless of which platform you're using.</p>"},{"location":"blog/2026/02/10/i-built-an-open-source-ai-cookbook-for-builders-heres-whats-inside/#layer-4-accelerators-domain-expertise-you-can-install","title":"Layer 4: Accelerators \u2014 Domain Expertise You Can Install","text":"<p>As I learn, I codify that knowledge into AI agents and skills \u2014 pre-built tools you can install in one command to accelerate your own learning and implementation. This is an evolving library, not a finished product.</p> <p>The cookbook's Plugin Marketplace is where these live. The Business-First AI plugin alone packages 8 agents, 6 skills, and 3 prompts that implement the entire Business-First AI Framework as executable tools. Tell it \"help me find where AI can improve my workflows\" and it runs a structured audit. Tell it \"deconstruct my client onboarding process\" and it walks you through the full analysis.</p> <p>There's also a Builder Stack Setup Guide. This is where I see people get stuck \u2014 the tools that let you build and run real AI workflows are unfamiliar to most people. Terminal, Git, AI coding CLIs \u2014 many of these will be new. But they're what unlock the ability to go from idea to production. The guide walks you through 7 steps, roughly 75 minutes, with checkboxes to track your progress. One VP of Product used it to go from zero terminal experience to a fully configured AI builder stack in a single afternoon.</p> <p>And the cookbook is full of patterns, walkthroughs, and direct answers to the questions that come up most often \u2014 from \"what is a system prompt?\" to \"how do I schedule an AI agent to run automatically?\"</p>"},{"location":"blog/2026/02/10/i-built-an-open-source-ai-cookbook-for-builders-heres-whats-inside/#who-its-for","title":"Who It's For","text":"<p>Anyone stuck between \"experimenting\" and \"executing\" \u2014 leaders auditing where AI fits, entrepreneurs building their first AI-powered workflow, professionals who want to get hands-on and take an idea all the way to production.</p> <p>No coding experience required for the strategy content. The builder content scales from first-time terminal users to teams orchestrating multi-agent pipelines.</p>"},{"location":"blog/2026/02/10/i-built-an-open-source-ai-cookbook-for-builders-heres-whats-inside/#go-build-something","title":"Go Build Something","text":"<p>In a world changing this fast, there are no shortcuts. You have to get hands-on with the tools. You have to touch them, experiment, and develop your own sense of what's possible.</p> <p>I've trained CEOs and C-suite leaders on the same tools covered in this cookbook. Every one of them came out with greater clarity \u2014 not because AI gave them answers, but because getting hands-on calibrated their mindset to what's actually possible.</p> <p>That's my challenge to you: start small. Build the muscle of a business-first approach to AI. Value creation isn't just the power of the tools \u2014 it's your ability to innovate from within and evolve what you're capable of. That inner transformation is what lets you bring out your full potential, together with AI, to make your ideas come to life.</p> <p>The Hands-on AI Cookbook is free, open-source, and always evolving.</p> <p>Start here: Head to Discover Workflows and run the audit. In 20 minutes, you'll have a prioritized list of AI opportunities.</p> <p>Or jump to what interests you:</p> <ul> <li>Business-First AI Framework</li> <li>Use Cases</li> <li>Agentic Building Blocks</li> <li>Plugin Marketplace</li> <li>Builder Stack Setup Guide</li> </ul> <p>Originally published on Graymatter.</p>"},{"location":"builder-setup/","title":"Builder Stack Setup Guide","text":"<p>This page walks you through every tool you need for an AI builder workflow. Later steps depend on earlier ones, so work through them in order. Budget about 75 minutes to complete the required steps (longer if you include the optional ones).</p> <p>Use the checkboxes to track your progress as you go.</p>"},{"location":"builder-setup/#at-a-glance","title":"At a Glance","text":"Step Tool Time Status 1 Terminal Basics ~15 min Required 2 AI Code Editor + Extensions ~15 min Required 3 Git ~10 min Required 4 GitHub ~15 min Required 5 AI Coding CLIs (Command-Line Tools) ~15 min Required (Claude Code); Optional (Codex, Gemini) 6 AI Registry + Plugins ~20 min Optional 7 Voice to Text ~10 min Optional"},{"location":"builder-setup/#step-1-terminal-basics","title":"Step 1: Terminal Basics","text":"<p>What: Learn to navigate your computer's command line. Time: ~15 minutes Requires: Nothing \u2014 this is where you start.</p> <p>Every tool in this stack runs through the terminal. You don't need to be an expert \u2014 just comfortable opening it, navigating folders, and running commands.</p> <p> Go to Terminal Basics guide</p> <p>You're done when: You can open a terminal, run <code>pwd</code>, and navigate to a folder with <code>cd</code>.</p> <ul> <li> Terminal Basics \u2014 complete</li> </ul>"},{"location":"builder-setup/#step-2-ai-code-editor-extensions","title":"Step 2: AI Code Editor + Extensions","text":"<p>What: Install a code editor and add AI coding extensions. Time: ~15 minutes Requires: Step 1 (Terminal Basics)</p> <p>Your editor is where you'll read, write, and edit code. This guide covers Cursor (has AI built in) and VS Code (free), plus AI extensions for Claude Code, OpenAI Codex, and Gemini Code Assist.</p> <p> Go to Editor Setup guide</p> <p>You're done when: You can open your editor, navigate files and folders, and see the Claude Code extension installed.</p> <ul> <li> AI Code Editor \u2014 installed</li> <li> AI extensions \u2014 installed</li> </ul>"},{"location":"builder-setup/#step-3-git","title":"Step 3: Git","text":"<p>What: Install Git for version control. Time: ~10 minutes Requires: Step 1 (Terminal Basics)</p> <p>Git tracks changes to your files and lets you collaborate on code. Claude Code and GitHub both depend on it.</p> <p> Go to Git Installation guide</p> <p>You're done when: Opening your terminal and typing <code>git --version</code> prints a version number.</p> <ul> <li> Git \u2014 installed</li> </ul>"},{"location":"builder-setup/#step-4-github","title":"Step 4: GitHub","text":"<p>What: Create a GitHub account and connect it to your editor. Time: ~15 minutes Requires: Steps 2 (Editor) and 3 (Git)</p> <p>GitHub hosts your projects (called repositories) in the cloud. You'll use it to download projects, upload your changes, and collaborate.</p> <p> Go to GitHub Setup guide</p> <p>You're done when: You can download (clone) a project from GitHub into your editor.</p> <ul> <li> GitHub \u2014 account created and connected</li> </ul>"},{"location":"builder-setup/#step-5-ai-coding-clis","title":"Step 5: AI Coding CLIs","text":"<p>What: Install Claude Code and (optionally) other AI coding CLIs \u2014 command-line tools that let you use AI directly from your terminal. Time: ~15 minutes Requires: Steps 2 (Editor) and 3 (Git)</p> <p>Claude Code is the primary AI coding CLI used throughout this cookbook. The guide also covers OpenAI Codex CLI and Gemini CLI as optional alternatives.</p> <p> Go to AI Coding CLIs guide</p> <p>You're done when: Running <code>claude --version</code> prints a version number, and typing <code>claude</code> starts a conversation with Claude in your terminal.</p> <ul> <li> Claude Code CLI \u2014 installed and authenticated</li> <li> OpenAI Codex CLI \u2014 installed (optional)</li> <li> Gemini CLI \u2014 installed (optional)</li> </ul>"},{"location":"builder-setup/#step-6-ai-registry-plugins","title":"Step 6: AI Registry + Plugins","text":"<p>What: Add the Hands-on AI plugin marketplace, set up the AI Registry, and install plugins. Time: ~20 minutes Requires: Step 5 (AI Coding CLIs) \u2014 plugin commands run inside Claude Code</p> <p>This step has three parts:</p> <p>These commands run inside Claude Code</p> <p>The <code>/plugin</code> commands below are typed inside a Claude Code session, not in a regular terminal. Start Claude Code first by typing <code>claude</code> in your terminal, then run the <code>/plugin</code> commands.</p> <p>1. Add the plugin marketplace. Register the Hands-on AI marketplace so Claude Code knows where to find plugins. You only need to do this once:</p> <pre><code>/plugin marketplace add jamesgray-ai/handsonai\n</code></pre> <p>See the Getting Started with Plugins guide for the full walkthrough.</p> <p>2. Set up the AI Registry. The AI Registry is a Notion workspace template that gives you a structured system for tracking your workflows, AI building blocks, and connected applications. Once it's connected, Claude can name workflows, write SOPs (Standard Operating Procedures), and register skills directly in Notion.</p> <p> Go to AI Registry Setup guide</p> <p>3. Install plugins. With the marketplace added, install plugins to give Claude domain expertise:</p> <pre><code>/plugin install business-first-ai@handsonai\n/plugin install ai-registry@handsonai\n</code></pre> <p>The Business-First AI plugin is required for a guided experience on the Claude platform using skills \u2014 it includes agents and skills for discovering AI opportunities, deconstructing workflows, and building with AI. The AI Registry plugin is required for Claude users who want to integrate seamlessly with the Notion registry \u2014 it lets Claude name workflows, write SOPs, and register building blocks directly in your workspace.</p> <p>Browse all available plugins on the Plugin Marketplace.</p> <p>Using skills in Claude.ai (web)</p> <p>After installing plugins, agents and skills work automatically in Claude Code and Cowork. However, if you want to use skills in Claude.ai (the web interface), there's an extra step: you need to zip each skill folder and upload it manually through Settings &gt; Capabilities &gt; Upload skill. See the Using Skills in Claude.ai guide for step-by-step instructions.</p> <p>You're done when: You've completed the parts above that apply to your workflow.</p> <ul> <li> Plugin marketplace \u2014 registered</li> <li> AI Registry \u2014 Notion template duplicated and connected (optional)</li> <li> AI Registry plugin \u2014 installed (optional)</li> <li> Business-First AI plugin \u2014 installed (optional)</li> </ul>"},{"location":"builder-setup/#step-7-voice-to-text","title":"Step 7: Voice to Text","text":"<p>What: Set up voice dictation for faster input. Time: ~10 minutes Requires: Nothing \u2014 this step is fully independent.</p> <p>Voice input can speed up how you write prompts, notes, and messages. This is optional but useful for anyone who thinks faster than they type.</p> <p> Go to Voice to Text Setup guide</p> <p>You're done when: You can dictate text into any input field on your computer.</p> <ul> <li> Voice to Text \u2014 set up (optional)</li> </ul>"},{"location":"builder-setup/#whats-next","title":"What's Next?","text":"<p>With your builder stack in place, you're ready to start building with AI.</p> <ul> <li> <p> Learn the Building Blocks</p> <p>Understand the seven components of every AI workflow \u2014 models, prompts, context, projects, skills, agents, and MCP (connections to external tools).</p> <p> Agentic Building Blocks</p> </li> <li> <p> Install Plugins</p> <p>Pre-built Claude Code agents and skills you can install in one command.</p> <p> Plugin Marketplace</p> </li> <li> <p> Take a Course</p> <p>Structured learning that walks you through building with AI step by step.</p> <p> Browse Courses</p> </li> </ul>"},{"location":"builder-setup/claude-code-install/","title":"AI Coding CLI Setup Guide","text":"<p>Quick reference for setting up Claude Code in your editor and terminal.</p> <p>Official docs: code.claude.com/docs/en/quickstart</p>"},{"location":"builder-setup/claude-code-install/#prerequisites","title":"Prerequisites","text":"<ul> <li>Code editor installed (Cursor or VS Code)</li> <li>Git installed (see Git Installation Guide)</li> <li>Claude Pro, Max, or Team subscription</li> </ul>"},{"location":"builder-setup/claude-code-install/#part-1-install-the-claude-code-extension","title":"Part 1: Install the Claude Code Extension","text":"<p>Already done?</p> <p>If you installed the Claude Code extension during Step 2 (Editor Setup), skip to Part 2.</p> <p>The Claude Code extension works the same in both Cursor and VS Code.</p> <ol> <li>Open the Extensions panel (Cmd/Ctrl + Shift + X)</li> <li>Search for Claude Code</li> <li>Click Install</li> <li>Follow any sign-in prompts</li> </ol> <p>Once installed, you'll use Claude Code through the integrated terminal in your editor.</p>"},{"location":"builder-setup/claude-code-install/#part-2-cli-installation","title":"Part 2: CLI Installation","text":"<p>The Claude Code CLI lets you use Claude directly in your terminal.</p>"},{"location":"builder-setup/claude-code-install/#macos-linux","title":"macOS / Linux","text":"<p>Open Terminal and run:</p> <pre><code>curl -fsSL https://claude.ai/install.sh | bash\n</code></pre>"},{"location":"builder-setup/claude-code-install/#windows-powershell","title":"Windows PowerShell","text":"<p>Open PowerShell and run:</p> <pre><code>irm https://claude.ai/install.ps1 | iex\n</code></pre>"},{"location":"builder-setup/claude-code-install/#windows-cmd","title":"Windows CMD","text":"<pre><code>curl -fsSL https://claude.ai/install.cmd -o install.cmd &amp;&amp; install.cmd &amp;&amp; del install.cmd\n</code></pre>"},{"location":"builder-setup/claude-code-install/#set-up-your-path","title":"Set Up Your PATH","text":"<p>Your PATH is a list of folders your computer checks when you type a command. If Claude Code's folder isn't in that list, your terminal won't recognize the <code>claude</code> command.</p> <p>After installation, you may need to configure your PATH so <code>claude</code> works from any directory.</p>"},{"location":"builder-setup/claude-code-install/#macos-linux_1","title":"macOS / Linux","text":"<p>The installer usually updates your shell profile automatically. If <code>claude</code> isn't recognized:</p> <ol> <li>Close and reopen your terminal, or</li> <li>Run one of these commands depending on your shell:</li> </ol> <pre><code># For zsh (default on modern Macs)\nsource ~/.zshrc\n\n# For bash\nsource ~/.bashrc\n</code></pre> <p>If the command still isn't found, add Claude Code to your PATH manually:</p> <pre><code># For zsh\necho 'export PATH=\"$HOME/.claude/bin:$PATH\"' &gt;&gt; ~/.zshrc\nsource ~/.zshrc\n\n# For bash\necho 'export PATH=\"$HOME/.claude/bin:$PATH\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>"},{"location":"builder-setup/claude-code-install/#windows","title":"Windows","text":"<p>The installer should add Claude Code to your PATH automatically. If <code>claude</code> isn't recognized:</p> <p>To add it manually: 1. Press Win + R, type sysdm.cpl, press Enter 2. Go to Advanced &gt; Environment Variables 3. Under \"User variables\", select Path &gt; Edit 4. Click New and add %USERPROFILE%.local\\bin 5. Restart your terminal</p> <p>Windows users</p> <p>You need Git for Windows installed \u2014 it provides Git Bash, which Claude Code requires. If Git Bash isn't detected, open PowerShell and run:</p> <pre><code>$env:CLAUDE_CODE_GIT_BASH_PATH=\"C:\\Program Files\\Git\\bin\\bash.exe\"\n</code></pre>"},{"location":"builder-setup/claude-code-install/#log-in","title":"Log In","text":"<p>Start Claude Code and log in with your Claude account:</p> <pre><code>claude\n</code></pre> <p>You'll be prompted to authenticate in your browser. Follow the prompts to connect your Claude subscription.</p> <p>Once logged in, your credentials are stored and you won't need to log in again.</p>"},{"location":"builder-setup/claude-code-install/#verify-installation","title":"Verify Installation","text":"<p>Test that everything is working:</p> <pre><code>claude --version\n</code></pre> <p>Then start a conversation with Claude:</p> <pre><code>cd ~/Desktop/my-project  # replace with your actual project folder\nclaude\n</code></pre> <p>Ask Claude a question to confirm it's working:</p> <pre><code>&gt; what does this project do?\n</code></pre>"},{"location":"builder-setup/claude-code-install/#troubleshooting","title":"Troubleshooting","text":"<p>\"command not found: claude\" - Close and reopen your terminal - On Mac, run <code>source ~/.zshrc</code> or <code>source ~/.bashrc</code> - Check the PATH setup section above</p> <p>Authentication fails - Make sure you have an active Claude Pro, Max, or Team subscription - Try running <code>/login</code> inside Claude Code to re-authenticate - Check your browser completed the authentication flow</p> <p>Permission denied during install (Mac/Linux) - The install script may need sudo access - Try: <code>curl -fsSL https://claude.ai/install.sh | sudo bash</code></p> <p>Slow or hanging responses - Check your internet connection - Try exiting (<code>Ctrl+C</code>) and starting a new session</p> <p>Installation succeeded but claude command hangs - Ensure you're in a directory with a project (not an empty folder) - Try <code>claude --help</code> to verify the CLI responds</p>"},{"location":"builder-setup/claude-code-install/#essential-commands","title":"Essential Commands","text":"Command What it does <code>claude</code> Start interactive mode <code>claude \"task\"</code> Run a one-time task <code>claude -c</code> Continue most recent conversation <code>claude commit</code> Create a Git commit <code>/help</code> Show available commands (inside Claude Code) <code>/login</code> Re-authenticate (inside Claude Code) <code>exit</code> or Ctrl+C Exit Claude Code"},{"location":"builder-setup/claude-code-install/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the Claude Code documentation for more workflows</li> <li>Try asking Claude to explain a project, commit changes, or write tests</li> </ul>"},{"location":"builder-setup/claude-code-install/#resources","title":"Resources","text":"<ul> <li>Claude Code Quickstart</li> <li>Claude Code CLI Reference</li> </ul>"},{"location":"builder-setup/claude-code-install/#other-ai-coding-clis","title":"Other AI Coding CLIs","text":"<p>Claude Code is the primary CLI covered in this cookbook, but you may also want to install these alternatives.</p>"},{"location":"builder-setup/claude-code-install/#openai-codex-cli","title":"OpenAI Codex CLI","text":"<p>OpenAI's command-line coding agent.</p> <p>Prerequisites: Requires Node.js 22+ (which includes npm, the package manager used to install it) and an OpenAI API key.</p> <p>Install (macOS / Linux):</p> <pre><code>npm install -g @openai/codex\n</code></pre> <p>Verify:</p> <pre><code>codex --version\n</code></pre> <p>Authenticate:</p> <pre><code>export OPENAI_API_KEY=\"your-api-key\"\n</code></pre> <p>See the Codex CLI documentation for full setup.</p>"},{"location":"builder-setup/claude-code-install/#gemini-cli","title":"Gemini CLI","text":"<p>Google's command-line AI coding assistant.</p> <p>Prerequisites: Requires Node.js 18+ (which includes npm) and a Google account.</p> <p>Install (macOS / Linux):</p> <pre><code>npm install -g @google/gemini-cli\n</code></pre> <p>Verify:</p> <pre><code>gemini --version\n</code></pre> <p>See the Gemini CLI documentation for full setup.</p>"},{"location":"builder-setup/editor-setup/","title":"Code Editor Setup Guide","text":"<p>Quick reference for installing your code editor.</p>"},{"location":"builder-setup/editor-setup/#choose-your-editor","title":"Choose Your Editor","text":"<p>Both options work well:</p> Editor Best For Cost Cursor Built-in AI editing Free tier available VS Code Familiar editor + extensions Free"},{"location":"builder-setup/editor-setup/#option-1-cursor","title":"Option 1: Cursor","text":"<p>Cursor is VS Code with AI capabilities built in.</p>"},{"location":"builder-setup/editor-setup/#install-cursor","title":"Install Cursor","text":"<ol> <li>Go to cursor.com</li> <li>Download for your operating system</li> <li>Run the installer</li> <li>Launch Cursor</li> </ol>"},{"location":"builder-setup/editor-setup/#option-2-vs-code","title":"Option 2: VS Code","text":""},{"location":"builder-setup/editor-setup/#install-vs-code","title":"Install VS Code","text":"<ol> <li>Go to code.visualstudio.com</li> <li>Download for your operating system</li> <li>Run the installer</li> <li>Launch VS Code</li> </ol>"},{"location":"builder-setup/editor-setup/#verify-installation","title":"Verify Installation","text":"<ol> <li>Open your editor</li> <li>Go to File \u2192 Open Folder</li> <li>Confirm you can navigate files and folders</li> </ol>"},{"location":"builder-setup/editor-setup/#install-ai-extensions","title":"Install AI Extensions","text":"<p>After installing your editor, add the AI coding extensions for your workflow.</p>"},{"location":"builder-setup/editor-setup/#claude-code-recommended","title":"Claude Code (Recommended)","text":"<p>The Claude Code extension connects your editor to Claude's AI capabilities.</p> <ol> <li>Open the Extensions panel (Cmd/Ctrl + Shift + X)</li> <li>Search for Claude Code</li> <li>Click Install</li> <li>Follow any sign-in prompts</li> </ol> <p>The Claude Code extension also includes an integrated terminal panel. See the Claude Code Installation guide for CLI (command-line tool) setup.</p>"},{"location":"builder-setup/editor-setup/#openai-codex-optional","title":"OpenAI Codex (Optional)","text":"<p>OpenAI's coding assistant extension for VS Code and Cursor.</p> <ol> <li>Open the Extensions panel (Cmd/Ctrl + Shift + X)</li> <li>Search for Codex (by OpenAI)</li> <li>Click Install</li> <li>Sign in with your OpenAI account when prompted</li> </ol> <p>Requires an OpenAI API account. See OpenAI Codex documentation for details.</p>"},{"location":"builder-setup/editor-setup/#gemini-code-assist-optional","title":"Gemini Code Assist (Optional)","text":"<p>Google's AI coding assistant extension.</p> <ol> <li>Open the Extensions panel (Cmd/Ctrl + Shift + X)</li> <li>Search for Gemini Code Assist</li> <li>Click Install</li> <li>Sign in with your Google account when prompted</li> </ol> <p>Requires a Google Cloud account. See Gemini Code Assist documentation for details.</p>"},{"location":"builder-setup/editor-setup/#next-steps","title":"Next Steps","text":"<ul> <li>Set up Git (see Git Installation Guide)</li> <li>Install AI coding CLIs (see Claude Code Installation Guide)</li> </ul>"},{"location":"builder-setup/editor-setup/#resources","title":"Resources","text":"<ul> <li>Cursor Documentation</li> <li>VS Code Documentation</li> </ul>"},{"location":"builder-setup/git-install/","title":"Git Installation Guide","text":"<p>Quick reference for installing Git on your local machine.</p>"},{"location":"builder-setup/git-install/#check-if-git-is-already-installed","title":"Check If Git Is Already Installed","text":"<p>Open your terminal and run:</p> <pre><code>git --version\n</code></pre> <p>If you see a version number (e.g., <code>git version 2.39.0</code>), Git is already installed. You can skip to verification.</p>"},{"location":"builder-setup/git-install/#macos","title":"macOS","text":""},{"location":"builder-setup/git-install/#option-1-xcode-command-line-tools-recommended","title":"Option 1: Xcode Command Line Tools (Recommended)","text":"<ol> <li>Open Terminal</li> <li>Run: <code>xcode-select --install</code></li> <li>Click Install in the popup dialog</li> <li>Wait for installation to complete</li> </ol> <p>This installs Git along with other developer tools.</p>"},{"location":"builder-setup/git-install/#option-2-homebrew","title":"Option 2: Homebrew","text":"<p>If you have Homebrew installed:</p> <pre><code>brew install git\n</code></pre>"},{"location":"builder-setup/git-install/#windows","title":"Windows","text":""},{"location":"builder-setup/git-install/#download-and-install","title":"Download and Install","text":"<ol> <li>Go to git-scm.com</li> <li>Click Download for Windows</li> <li>Run the installer</li> <li>Use the default settings (click Next through the prompts)</li> <li>Complete the installation</li> </ol>"},{"location":"builder-setup/git-install/#important-settings-during-install","title":"Important Settings During Install","text":"<ul> <li>Default editor: Select VS Code or Cursor if listed \u2014 avoid the default (Vim) unless you're familiar with it</li> <li>PATH environment: Select \"Git from the command line and also from 3rd-party software\" (recommended)</li> <li>Line endings: Select \"Checkout Windows-style, commit Unix-style line endings\" (recommended)</li> </ul>"},{"location":"builder-setup/git-install/#verify-installation","title":"Verify Installation","text":"<p>After installing, open a new terminal window and run:</p> <pre><code>git --version\n</code></pre> <p>You should see a version number confirming Git is installed.</p>"},{"location":"builder-setup/git-install/#configure-your-identity","title":"Configure Your Identity","text":"<p>Set your name and email for Git commits:</p> <pre><code>git config --global user.name \"Your Name\"\ngit config --global user.email \"your.email@example.com\"\n</code></pre> <p>Use the email address you plan to use for your GitHub account (set up in the next step).</p>"},{"location":"builder-setup/git-install/#troubleshooting","title":"Troubleshooting","text":"<p>Command not found (Mac)? - Close and reopen Terminal after installation - Try running <code>xcode-select --install</code> again</p> <p>Command not found (Windows)? - Close and reopen your terminal - Make sure you selected the PATH option during installation - Reinstall and select \"Git from the command line and also from 3rd-party software\"</p> <p>Permission errors? - On Mac, you may need to enter your password during Xcode tools installation - On Windows, run the installer as Administrator</p>"},{"location":"builder-setup/git-install/#next-steps","title":"Next Steps","text":"<ul> <li>Set up your GitHub account (see GitHub Setup Guide)</li> <li>Install Claude Code (see Claude Code Installation Guide)</li> </ul>"},{"location":"builder-setup/git-install/#resources","title":"Resources","text":"<ul> <li>Git Downloads</li> <li>Git Documentation</li> </ul>"},{"location":"builder-setup/github-setup/","title":"GitHub Setup Guide","text":"<p>Quick reference for setting up GitHub for your projects.</p>"},{"location":"builder-setup/github-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Email address for GitHub account</li> <li>Cursor or VS Code installed (see Editor Setup Guide)</li> <li>Git installed (see Git Installation Guide)</li> </ul>"},{"location":"builder-setup/github-setup/#1-create-a-github-account","title":"1. Create a GitHub Account","text":"<ol> <li>Go to github.com</li> <li>Click Sign up</li> <li>Follow the prompts to create your account</li> <li>Verify your email address</li> </ol> <p>Already have an account? Skip to step 2.</p>"},{"location":"builder-setup/github-setup/#2-clone-a-repository","title":"2. Clone a Repository","text":"<p>Use your code editor to download (clone) repositories from GitHub.</p>"},{"location":"builder-setup/github-setup/#in-cursor-or-vs-code","title":"In Cursor or VS Code","text":"<ol> <li>Open the Command Palette (Cmd/Ctrl + Shift + P)</li> <li>Type Git: Clone</li> <li>Paste the repository URL (e.g., <code>https://github.com/username/project-name.git</code>)</li> <li>Choose a local folder location</li> <li>Open the cloned repository when prompted</li> </ol>"},{"location":"builder-setup/github-setup/#git-concepts","title":"Git Concepts","text":"<p>Understanding these terms helps when working with Claude Code.</p>"},{"location":"builder-setup/github-setup/#commit","title":"Commit","text":"<p>A commit saves a snapshot of your changes with a message describing what you did. Think of it as a save point you can return to.</p>"},{"location":"builder-setup/github-setup/#push","title":"Push","text":"<p>Push uploads your local commits to GitHub. Until you push, your changes only exist on your computer.</p>"},{"location":"builder-setup/github-setup/#pull","title":"Pull","text":"<p>Pull downloads the latest changes from GitHub to your local copy. Do this before starting work to stay in sync.</p>"},{"location":"builder-setup/github-setup/#staging","title":"Staging","text":"<p>Before committing, you stage files to indicate which changes to include. You can commit some changes while leaving others for later.</p>"},{"location":"builder-setup/github-setup/#using-claude-code-for-git-operations","title":"Using Claude Code for Git Operations","text":"<p>Once you have Claude Code installed, you can perform Git operations by asking Claude in natural language:</p> <ul> <li>\"Commit my changes with a descriptive message\"</li> <li>\"Push my commits to GitHub\"</li> <li>\"Pull the latest changes\"</li> <li>\"Show me what files have changed\"</li> </ul> <p>Claude Code handles the Git commands for you.</p>"},{"location":"builder-setup/github-setup/#troubleshooting","title":"Troubleshooting","text":"<p>Can't clone the repository? - Verify you have access to the repository - Check that the URL is correct - Make sure you're signed into GitHub in your editor</p> <p>Authentication issues? - Your editor may prompt you to sign into GitHub - Follow the browser authentication flow when prompted</p>"},{"location":"builder-setup/github-setup/#next-steps","title":"Next Steps","text":"<ul> <li>Install Claude Code to manage Git operations with natural language (see AI Coding CLIs Guide)</li> <li>Try cloning a public repository to practice the workflow</li> </ul>"},{"location":"builder-setup/github-setup/#resources","title":"Resources","text":"<ul> <li>GitHub Docs</li> </ul>"},{"location":"builder-setup/notion-registry-setup/","title":"AI Registry Setup","text":"<p>The AI Registry is a Notion workspace template that gives you a structured system for tracking your business processes, workflows, AI building blocks, and connected applications. It serves as the central hub for your AI operations \u2014 a single place to document what you're building, how it works, and what tools are involved.</p> <p>This registry is also the foundation for the AI Registry plugin, a set of Claude Code skills that can read from and write to your registry automatically. Once your registry is set up and connected, Claude can name workflows, write SOPs (Standard Operating Procedures), register skills, and keep everything in sync \u2014 anywhere on the Claude platform.</p> <p>Platform support</p> <p>The AI Registry plugin is powered by Claude Agent skills, which are currently only supported on the Claude platform. Agent skills are an open standard, and many companies are already working to adopt them \u2014 as support broadens, the same skills will work across tools. The Notion connector (Step 7) works on both Claude and ChatGPT for basic read/write access.</p>"},{"location":"builder-setup/notion-registry-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Notion account (free or paid) \u2014 get Notion here</li> <li>Basic familiarity with Notion pages and databases</li> </ul>"},{"location":"builder-setup/notion-registry-setup/#setup-steps","title":"Setup Steps","text":""},{"location":"builder-setup/notion-registry-setup/#step-1-get-notion","title":"Step 1: Get Notion","text":"<p>If you don't already have Notion, sign up at notion.so. Notion is available on:</p> <ul> <li>Web \u2014 works in any browser</li> <li>Desktop \u2014 macOS and Windows apps</li> <li>Mobile \u2014 iOS and Android</li> </ul> <p>A free Notion account is all you need to use the registry.</p>"},{"location":"builder-setup/notion-registry-setup/#step-2-open-the-template","title":"Step 2: Open the Template","text":"<p>Click this link to view the AI Registry template:</p> <p>AI Registry - Template</p>"},{"location":"builder-setup/notion-registry-setup/#step-3-click-duplicate","title":"Step 3: Click Duplicate","text":"<p>In the top-right corner of the template page, click the \"Duplicate\" button. If you're not signed in to Notion, you'll be prompted to log in first.</p>"},{"location":"builder-setup/notion-registry-setup/#step-4-copy-to-your-workspace","title":"Step 4: Copy to Your Workspace","text":"<p>Select the workspace you want to copy the template into. The entire page \u2014 including all four databases, sample entries, and relations between them \u2014 will be duplicated into your workspace.</p>"},{"location":"builder-setup/notion-registry-setup/#step-5-review-sample-entries","title":"Step 5: Review Sample Entries","text":"<p>The template includes sample entries in each database so you can see how they work together. Explore a few entries to understand the structure:</p> <ul> <li>Click into a Business Process to see its linked workflows</li> <li>Click into a Workflow to see its linked AI building blocks and apps</li> <li>Notice how relations connect everything together</li> </ul> <p>When you're ready, delete the sample entries and start adding your own.</p>"},{"location":"builder-setup/notion-registry-setup/#step-6-customize-databases-and-properties","title":"Step 6: Customize Databases and Properties","text":"<p>Tailor the registry to your business. Each database comes with sensible defaults, but you'll want to adjust them:</p> <ul> <li>Business Processes \u2014 Edit the Domain select field to match your business areas (Sales, Marketing, Product, Operations, etc.)</li> <li>Workflows \u2014 Update Status and Type options to fit your workflow categories</li> <li>AI Building Blocks \u2014 Customize Asset Type options (Skill, Prompt, Agent, Project, Context MD, etc.)</li> <li>Apps \u2014 Configure Type options for your integration patterns (API, MCP Server, Native Integration, Webhook, etc.)</li> </ul> <p>To edit a select field: click any cell with that property, then click \"Edit property\" to add, rename, or remove options.</p>"},{"location":"builder-setup/notion-registry-setup/#step-7-connect-your-ai-tools","title":"Step 7: Connect Your AI Tools","text":"<p>To let your AI tools read and update the registry, connect Notion using the built-in integrations available on each platform:</p> <ul> <li>Claude \u2014 Add the Notion connector from your Claude account settings under Connected Apps</li> <li>ChatGPT \u2014 Add the Notion connection from Connected Apps in your settings</li> </ul> <p>Once connected, your AI tool can search, read, and update your registry databases directly. No custom configuration or API keys required.</p> <p>Plugin automation requires Claude</p> <p>The Notion connector above gives both Claude and ChatGPT basic access to your registry. However, the AI Registry plugin \u2014 which automates naming workflows, writing SOPs, registering skills, and more \u2014 is powered by Claude Agent skills, which are currently only supported on the Claude platform.</p> <p>Agent skills are an open standard, and many companies are already working to adopt them into their AI platforms. As support broadens, the same skills will work across tools without needing to be rewritten.</p>"},{"location":"builder-setup/notion-registry-setup/#understanding-the-registry-structure","title":"Understanding the Registry Structure","text":""},{"location":"builder-setup/notion-registry-setup/#the-four-databases","title":"The Four Databases","text":"Database Purpose Key Fields Business Processes High-level business functions and their domains Domain, LOB, Description Workflows Specific workflows within each process Status, Type, Trigger, Process Outcome AI Building Blocks Skills, prompts, agents, and other AI components Asset Type, Platform, Status, Dependencies Apps Connected applications and integrations Type, Auth Type, Connection Status"},{"location":"builder-setup/notion-registry-setup/#how-relations-work","title":"How Relations Work","text":"<p>The databases are linked to show how your operations connect:</p> <pre><code>Business Process \u2192 Workflows \u2192 AI Building Blocks\n                            \u2198 Apps\n</code></pre> <ul> <li>Each Business Process contains multiple Workflows</li> <li>Each Workflow can use multiple AI Building Blocks and Apps</li> <li>Changes propagate automatically through relations</li> </ul>"},{"location":"builder-setup/notion-registry-setup/#using-the-ai-registry-plugin","title":"Using the AI Registry Plugin","text":"<p>Once your registry is connected via the Notion connector, install the companion plugin to let Claude work with it directly:</p> <pre><code>/plugin install ai-registry@handsonai\n</code></pre> <p>The plugin includes five skills that automate common registry tasks:</p> Skill What it does <code>naming-workflows</code> Generates consistent, outcome-focused workflow names and creates entries in the Workflows database <code>writing-workflow-sops</code> Writes Standard Operating Procedure documentation for each workflow <code>writing-process-guides</code> Documents how workflows fit together within a business process <code>registering-building-blocks</code> Registers AI building blocks (Skills, Agents, Prompts, Context MDs) in the AI Building Blocks database <code>syncing-skills-to-github</code> Commits skills to GitHub and updates Notion with repository URLs"},{"location":"builder-setup/notion-registry-setup/#recommended-workflow","title":"Recommended workflow","text":"<ol> <li>Name \u2014 Ask Claude to name a workflow and it creates a Notion entry</li> <li>Document \u2014 Ask Claude to write the SOP for that workflow</li> <li>Connect \u2014 Ask Claude to write a process guide linking workflows together</li> <li>Register \u2014 Ask Claude to register any skills you've built in the AI Building Blocks database</li> <li>Sync \u2014 Ask Claude to push skills to GitHub with version tracking</li> </ol> <p>See the AI Registry plugin page for full details and usage examples.</p>"},{"location":"builder-setup/notion-registry-setup/#troubleshooting","title":"Troubleshooting","text":"<p>Relations not copying correctly?</p> <ul> <li>This is rare with Notion duplicates. Try duplicating again.</li> <li>Ensure you're duplicating the entire page, not individual databases.</li> </ul> <p>Can't find the template?</p> <ul> <li>The template must be shared publicly. If the link doesn't work, check for updates on GitHub.</li> </ul> <p>AI tool can't see your registry?</p> <ul> <li>Confirm the Notion connector is enabled in your AI tool's settings</li> <li>Make sure you've granted access to the workspace containing your registry</li> <li>Try disconnecting and reconnecting the Notion integration</li> </ul> <p>Need to start over?</p> <ul> <li>Delete your copy and duplicate the template again.</li> </ul>"},{"location":"builder-setup/notion-registry-setup/#next-steps","title":"Next Steps","text":"<ul> <li>Add your first process \u2014 Start with one business domain you know well</li> <li>Document existing workflows \u2014 Capture what you're already doing before adding AI</li> <li>Find AI opportunities \u2014 Use the Discover AI Workflow Opportunities guide to identify where AI can add value</li> <li>Deconstruct workflows \u2014 Break workflows into AI building blocks with the Deconstruct Workflows guide</li> <li>Install the plugin \u2014 Set up the AI Registry plugin to automate registry updates</li> <li>Explore other setup guides \u2014 Continue with Claude Code Installation if you haven't already</li> </ul>"},{"location":"builder-setup/terminal-basics/","title":"Terminal Basics","text":"<p>Get comfortable with the command line before diving into developer tools.</p>"},{"location":"builder-setup/terminal-basics/#what-is-the-terminal","title":"What Is the Terminal?","text":"<p>The terminal is a text-based way to talk to your computer. Instead of clicking through menus and windows, you type commands and press Enter.</p> <p>Why does this matter? Most developer tools \u2014 Git, Claude Code, and other builder tools \u2014 are designed to run from the terminal. Every setup guide that follows assumes you can open a terminal and type a command.</p> <p>The good news: you only need a handful of commands to get started.</p>"},{"location":"builder-setup/terminal-basics/#open-your-terminal","title":"Open Your Terminal","text":"macOSWindows <p>You have two quick ways to open Terminal:</p> <ol> <li>Spotlight Search: Press ++cmd+space++, type <code>Terminal</code>, press Enter</li> <li>Finder: Open Applications &gt; Utilities &gt; Terminal</li> </ol> <p>You'll see a window with a short line of text ending in <code>$</code> or <code>%</code> and a blinking cursor. That's your prompt \u2014 it means the terminal is ready for a command.</p> <ol> <li>Start Menu: Click Start, type <code>PowerShell</code>, click Windows PowerShell</li> <li>Windows Terminal (if installed): Click Start, type <code>Terminal</code>, click Terminal</li> </ol> <p>You'll see a window with a line ending in <code>&gt;</code> and a blinking cursor. That's your prompt \u2014 it means the terminal is ready for a command.</p>"},{"location":"builder-setup/terminal-basics/#open-the-terminal-in-your-editor","title":"Open the Terminal in Your Editor","text":"<p>Come back after Step 2</p> <p>This section requires a code editor. If you're following the Builder Stack Setup Guide in order, complete Step 2 (Editor Setup) first, then return here.</p> <p>Once you have Cursor or VS Code installed, you can use the terminal directly inside your editor. This is where you'll spend most of your time \u2014 running commands without switching windows.</p> <p>The steps are the same for both Cursor and VS Code:</p> <ol> <li>Open Cursor or VS Code</li> <li>Press ++ctrl+grave++ (the backtick key, to the left of 1 on most keyboards)</li> <li>A terminal panel opens at the bottom of the editor</li> </ol> <p>You can also open it from the menu: Terminal &gt; New Terminal.</p> <p>Keep it visible</p> <p>Drag the top edge of the terminal panel to resize it. Many developers keep the terminal open at all times while they work.</p>"},{"location":"builder-setup/terminal-basics/#essential-commands","title":"Essential Commands","text":"<p>These are the commands you'll use most often. macOS/Linux and Windows PowerShell use slightly different names for some of them.</p> macOS / LinuxWindows PowerShell Command What It Does <code>pwd</code> Print your current directory (where am I?) <code>ls</code> List files and folders in the current directory <code>cd foldername</code> Move into a folder <code>cd ..</code> Go back up one level <code>cd ~</code> Go to your home directory <code>mkdir foldername</code> Create a new folder <code>clear</code> Clear the screen Command What It Does <code>Get-Location</code> Print your current directory (where am I?) <code>dir</code> List files and folders in the current directory <code>cd foldername</code> Move into a folder <code>cd ..</code> Go back up one level <code>cd ~</code> Go to your home directory <code>mkdir foldername</code> Create a new folder <code>cls</code> Clear the screen <p>PowerShell aliases</p> <p>PowerShell also accepts <code>pwd</code>, <code>ls</code>, and <code>clear</code> as shortcuts. If you see those commands in a guide, they'll work on Windows too.</p>"},{"location":"builder-setup/terminal-basics/#try-it-yourself","title":"Try It Yourself","text":"<p>Open your terminal and follow along. This short exercise builds muscle memory with commands you'll use throughout these guides.</p> macOS / LinuxWindows PowerShell <pre><code># 1. Check where you are\npwd\n\n# 2. List what's in this folder\nls\n\n# 3. Move to your Desktop\ncd ~/Desktop\n\n# 4. Create a test folder\nmkdir terminal-test\n\n# 5. List again \u2014 you should see your new folder\nls\n\n# 6. Move into it\ncd terminal-test\n\n# 7. Confirm you're inside\npwd\n\n# 8. Go back up one level\ncd ..\n\n# 9. Clean up \u2014 remove the test folder\nrmdir terminal-test\n</code></pre> <pre><code># 1. Check where you are\nGet-Location\n\n# 2. List what's in this folder\ndir\n\n# 3. Move to your Desktop\ncd ~\\Desktop\n\n# 4. Create a test folder\nmkdir terminal-test\n\n# 5. List again \u2014 you should see your new folder\ndir\n\n# 6. Move into it\ncd terminal-test\n\n# 7. Confirm you're inside\nGet-Location\n\n# 8. Go back up one level\ncd ..\n\n# 9. Clean up \u2014 remove the test folder\nrmdir terminal-test\n</code></pre> <p>If every step worked, you're ready for the rest of the setup guides.</p>"},{"location":"builder-setup/terminal-basics/#key-concepts","title":"Key Concepts","text":""},{"location":"builder-setup/terminal-basics/#paths","title":"Paths","text":"<p>A path describes the location of a file or folder on your computer.</p> <ul> <li>Absolute path \u2014 the full address from the root of your drive:<ul> <li>macOS: <code>/Users/yourname/Documents/project</code></li> <li>Windows: <code>C:\\Users\\yourname\\Documents\\project</code></li> </ul> </li> <li>Relative path \u2014 the address from wherever you are right now:<ul> <li><code>cd Documents</code> (move into a Documents folder inside your current location)</li> <li><code>cd ../other-folder</code> (go up one level, then into a different folder)</li> </ul> </li> </ul> <p>Notice that macOS/Linux uses forward slashes (<code>/</code>) and Windows uses backslashes (<code>\\</code>).</p>"},{"location":"builder-setup/terminal-basics/#the-prompt","title":"The Prompt","text":"<p>The <code>$</code>, <code>%</code>, or <code>&gt;</code> at the start of each line is the prompt. It means the terminal is waiting for your input. You don't type the prompt character \u2014 just the command after it.</p>"},{"location":"builder-setup/terminal-basics/#case-sensitivity","title":"Case Sensitivity","text":"<ul> <li>macOS/Linux: File and folder names are case-sensitive. <code>Documents</code> and <code>documents</code> are different folders.</li> <li>Windows: File and folder names are not case-sensitive. <code>Documents</code> and <code>documents</code> refer to the same folder.</li> </ul>"},{"location":"builder-setup/terminal-basics/#tab-completion","title":"Tab Completion","text":"<p>Start typing a file or folder name and press ++tab++. The terminal will auto-complete the name if there's a match, or show you options if there are multiple matches. This saves typing and helps avoid typos.</p>"},{"location":"builder-setup/terminal-basics/#troubleshooting","title":"Troubleshooting","text":"<p>\"I typed a command and nothing happened\"</p> <ul> <li>Make sure you pressed Enter after the command</li> <li>Check for typos \u2014 commands must be spelled exactly right</li> </ul> <p>\"command not found\" or \"not recognized\"</p> <ul> <li>The tool you're trying to use isn't installed, or your system doesn't know where to find it</li> <li>Follow the relevant installation guide, then try again</li> </ul> <p>\"Permission denied\"</p> <ul> <li>You may need administrator rights</li> <li>On macOS, prefix the command with <code>sudo</code> (you'll be asked for your password)</li> <li>On Windows, right-click PowerShell and choose Run as Administrator</li> </ul> <p>\"I'm lost and don't know where I am\"</p> <ul> <li>Run <code>pwd</code> (macOS/Linux) or <code>Get-Location</code> (Windows) to see your current directory</li> <li>Run <code>cd ~</code> to go back to your home directory</li> </ul>"},{"location":"builder-setup/voice-to-text-setup/","title":"Voice-to-Text Setup Guide","text":"<p>Quick reference for setting up voice input for hands-free AI collaboration.</p>"},{"location":"builder-setup/voice-to-text-setup/#option-1-wispr-flow","title":"Option 1: Wispr Flow","text":"<p>Wispr Flow lets you dictate text anywhere on your computer using your voice.</p>"},{"location":"builder-setup/voice-to-text-setup/#install-wispr-flow","title":"Install Wispr Flow","text":"<ol> <li>Go to Wispr Flow</li> <li>Download the app for your operating system</li> <li>Run the installer</li> <li>Launch Wispr Flow</li> </ol>"},{"location":"builder-setup/voice-to-text-setup/#configure-wispr-flow","title":"Configure Wispr Flow","text":"<ol> <li>Grant microphone permissions when prompted</li> <li>Set your preferred activation method (keyboard shortcut or push-to-talk)</li> <li>Test dictation in any text field</li> </ol>"},{"location":"builder-setup/voice-to-text-setup/#tips-for-wispr-flow","title":"Tips for Wispr Flow","text":"<ul> <li>Speak naturally\u2014Wispr Flow handles punctuation and formatting</li> <li>Use the keyboard shortcut to start and stop dictation</li> <li>Works in any application (editors, browsers, chat apps)</li> </ul>"},{"location":"builder-setup/voice-to-text-setup/#option-2-claude-desktop-quick-entry-macos-only","title":"Option 2: Claude Desktop Quick Entry (macOS Only)","text":"<p>Claude Desktop has a Quick Entry feature that lets you access Claude from anywhere on your Mac, including voice dictation.</p> <p>Requirements: - macOS 12 or later (macOS 14+ required for voice dictation) - Claude Desktop installed and running</p> <p>Note: Quick Entry is currently only available for macOS. Windows users can use Claude Desktop but without quick entry features.</p>"},{"location":"builder-setup/voice-to-text-setup/#enable-quick-entry","title":"Enable Quick Entry","text":"<ol> <li>Open Claude Desktop</li> <li>You'll be prompted to turn on the shortcut\u2014click Continue</li> <li>Grant permissions when prompted (accessibility, screen recording, speech recognition)</li> <li>Manage settings in Settings \u2192 General</li> </ol>"},{"location":"builder-setup/voice-to-text-setup/#configure-voice-shortcut","title":"Configure Voice Shortcut","text":"<ol> <li>Go to Settings \u2192 General</li> <li>Find Voice shortcut (disabled by default since it overrides Caps Lock)</li> <li>Enable and set your preferred key (default is Caps Lock)</li> </ol>"},{"location":"builder-setup/voice-to-text-setup/#using-voice-input","title":"Using Voice Input","text":"<ol> <li>Press your voice shortcut key (e.g., Caps Lock) to start dictation</li> <li>Speak your prompt</li> <li>Press the shortcut key again to stop</li> <li>Review and adjust the transcription if needed</li> <li>Press Enter or click the send button to run</li> </ol> <p>Claude Desktop launches with your transcribed prompt and responds.</p>"},{"location":"builder-setup/voice-to-text-setup/#tips-for-claude-desktop-voice","title":"Tips for Claude Desktop Voice","text":"<ul> <li>Use voice for longer prompts or when you want to think out loud</li> <li>The shortcut works from anywhere on your Mac\u2014Claude opens automatically</li> <li>Review the transcription before sending</li> <li>You can also use Quick access shortcut (double-tap Option) to open Claude without voice</li> </ul> <p>Learn more: Use Quick Entry with Claude Desktop on Mac</p>"},{"location":"builder-setup/voice-to-text-setup/#when-to-use-each","title":"When to Use Each","text":"Tool Platform Best For Wispr Flow Mac, Windows Dictating anywhere\u2014code editors, documents, emails, terminal Claude Desktop Quick Entry Mac only Speaking directly to Claude from anywhere on your desktop"},{"location":"builder-setup/voice-to-text-setup/#troubleshooting","title":"Troubleshooting","text":"<p>Microphone not detected - Check system privacy settings for microphone access - Grant permissions to the specific app</p> <p>Poor transcription accuracy - Speak clearly and at a steady pace - Reduce background noise - Check microphone input levels in system settings</p> <p>Voice input not activating - Verify the keyboard shortcut isn't conflicting with another app - Restart the application</p>"},{"location":"builder-setup/voice-to-text-setup/#next-steps","title":"Next Steps","text":"<ul> <li>Practice dictating a few prompts to get comfortable</li> <li>Explore the official documentation for your chosen tool</li> </ul>"},{"location":"builder-setup/voice-to-text-setup/#resources","title":"Resources","text":"<ul> <li>Wispr Flow</li> <li>Claude Desktop</li> </ul>"},{"location":"business-first-ai-framework/","title":"Business-First AI Framework","text":""},{"location":"business-first-ai-framework/#the-problem","title":"The Problem","text":"<p>Most AI adoption starts with the technology \u2014 \"we have ChatGPT, where should we use it?\" This leads to shallow adoption and misses the workflows where AI creates real leverage. And even when people identify the right workflow, there's a gap between the idea and making it real \u2014 without a repeatable process to follow, they get stuck and stop. The Business-First AI Framework closes that gap: audit your workflows, identify where AI creates the most value, deconstruct those workflows into building blocks, then build.</p>"},{"location":"business-first-ai-framework/#the-framework","title":"The Framework","text":"<p>Three steps, each with a structured process:</p>"},{"location":"business-first-ai-framework/#step-1-discover-workflows","title":"Step 1: Discover Workflows","text":"<p>Find which workflows are candidates for AI.</p> <p>Before you can apply AI to anything, you need to know where it fits. Step 1 is a structured audit of your workflows that produces a prioritized list of opportunities across three categories:</p> <ul> <li>Deterministic Workflows \u2014 Repeatable processes with clear inputs and outputs that AI can execute reliably with little supervision</li> <li>Collaborative AI \u2014 Tasks where you and AI work together in real time (drafting, brainstorming, reviewing)</li> <li>Autonomous Agents \u2014 Goal-driven workflows where AI plans and executes steps autonomously</li> </ul> <p>The audit uses a three-step process: scan what AI already knows about your work, interview you to fill gaps, then produce a categorized report with specific opportunities and actionable first steps.</p> <p>Two ways to run Step 1:</p> <ul> <li>Any AI tool \u2014 Copy the Discover AI Workflow Opportunities prompt into Claude, ChatGPT, Gemini, or M365 Copilot</li> <li>Claude platform \u2014 Use the <code>discovering-workflows</code> skill from the Business-First AI plugin in Claude Code, Claude.ai, or Cowork (setup guide)</li> </ul>"},{"location":"business-first-ai-framework/#step-2-deconstruct-workflows","title":"Step 2: Deconstruct Workflows","text":"<p>Give your workflow clear structure through deep decomposition.</p> <p>Once you've identified a workflow worth automating, Step 2 deconstructs it so you understand every step, decision point, and dependency. You describe your workflow \u2014 rough and incomplete is fine \u2014 and the model interviews you to surface every hidden step, data handoff, and failure mode.</p> <p>The deconstruction uses the five-question framework to break down each step:</p> <ol> <li>Is this step actually multiple steps bundled together?</li> <li>Are there decision points, branches, or quality gates?</li> <li>What data flows in and out?</li> <li>What context, documents, or reference materials does this step need?</li> <li>What happens when this step fails?</li> </ol> <p>The deliverable is a Workflow Definition \u2014 a structured breakdown of your workflow into refined steps, with decision points, data flows, context needs, and failure modes captured for every step. The context needs and failure modes captured here directly inform design decisions in Step 3.</p> <p>Two ways to run Step 2:</p> <ul> <li>Any AI tool \u2014 Copy the Deconstruct Workflows prompt into Claude, ChatGPT, Gemini, or M365 Copilot</li> <li>Claude platform \u2014 Use the <code>workflow-deconstructor</code> agent or individual skills from the Business-First AI plugin in Claude Code, Claude.ai, or Cowork (setup guide)</li> </ul>"},{"location":"business-first-ai-framework/#step-3-build-workflows","title":"Step 3: Build Workflows","text":"<p>Design your AI implementation, construct the components, and run the workflow.</p> <p>Step 2 produces a Workflow Definition \u2014 the analysis. Step 3 is where that analysis becomes a working AI workflow through three parts:</p> <ol> <li> <p>3.1: Design \u2014 Choose an execution pattern (Prompt \u2192 Skill-Powered Prompt \u2192 Single Agent \u2192 Multi-Agent), classify each step on the autonomy spectrum, map to AI building blocks, identify skill candidates, and configure agents when needed. Produces an AI Building Block Spec \u2014 a platform-agnostic blueprint.</p> </li> <li> <p>3.2: Construct \u2014 Build only what your execution pattern requires. The AI Building Block Spec tells you exactly which components to create \u2014 context, skills, prompts, agents, MCP connections \u2014 and in what order.</p> </li> <li> <p>3.3: Run \u2014 Execute the workflow on a real scenario, then iterate based on results.</p> </li> </ol> <p>The Build Workflows section includes:</p> <ul> <li>3.1: Design \u2014 execution pattern spectrum, autonomy classification, building block mapping, skill candidate identification, agent configuration</li> <li>Pattern-specific Construct paths \u2014 each execution pattern shows only the steps that apply</li> <li>Six building block guides \u2014 Context, Projects, Skills, Prompt, Agents, MCP</li> <li>Three worked examples across the autonomy spectrum \u2014 deterministic automation, collaborative workflows, and fully autonomous multi-agent pipelines</li> </ul> <p>See Step 3 \u2014 Build Workflows</p>"},{"location":"business-first-ai-framework/#key-concepts","title":"Key Concepts","text":"<p>Quick reference for the framework's vocabulary:</p>"},{"location":"business-first-ai-framework/#three-opportunity-categories","title":"Three Opportunity Categories","text":"Category Description Example Deterministic Workflow Repeatable process AI executes with minimal supervision Formatting reports, processing forms Collaborative AI Human and AI work together in real time Co-writing, brainstorming, code review Autonomous Agent AI plans and executes steps autonomously Competitor monitoring, research \u2192 report pipelines"},{"location":"business-first-ai-framework/#five-question-framework","title":"Five-Question Framework","text":"<p>Used to decompose each workflow step:</p> <ol> <li>Discrete steps \u2014 Is this one step or multiple bundled together?</li> <li>Decision points \u2014 Any if/then branches, quality gates, or judgment calls?</li> <li>Data flows \u2014 What goes in? What comes out? Where from and where to?</li> <li>Context needs \u2014 What documents, files, or reference materials are required?</li> <li>Failure modes \u2014 What happens when this step fails?</li> </ol>"},{"location":"business-first-ai-framework/#seven-ai-building-blocks","title":"Seven AI Building Blocks","text":"Block What It Is Model The AI engine that processes inputs and generates outputs Prompt A well-crafted instruction that tells the model what to do Context Background information, reference docs, or examples the model needs Skill A reusable routine the model can invoke \u2014 give it inputs, it follows a defined process, it produces consistent outputs Agent An autonomous AI that plans, uses tools, and executes multi-step work MCP (Model Context Protocol) A connector that lets AI access external tools, services, or databases on your behalf Project A persistent workspace grouping prompts, context, skills, and agents <p>For detailed definitions and cross-platform examples, see Agentic Building Blocks.</p>"},{"location":"business-first-ai-framework/#six-use-case-primitives","title":"Six Use Case Primitives","text":"<p>When classifying opportunities from Step 1, it helps to know what type of AI work each one involves. The six use case primitives \u2014 Content Creation, Research, Coding, Data Analysis, Ideation &amp; Strategy, and Automation \u2014 provide a classification system for the opportunities you discover.</p>"},{"location":"business-first-ai-framework/#autonomy-spectrum","title":"Autonomy Spectrum","text":"Level Description Human Requires human judgment, creativity, or physical action Deterministic Follows fixed rules; AI executes reliably with minimal supervision Semi-Autonomous AI does most of the work; human reviews at key checkpoints Autonomous AI executes end-to-end, including decisions and tool use"},{"location":"business-first-ai-framework/#execution-pattern-spectrum","title":"Execution Pattern Spectrum","text":"<p>Every AI workflow falls somewhere on this spectrum. The right pattern depends on what your workflow actually needs:</p> Pattern Description Signals Prompt Single self-contained prompt, all logic inline Sequential steps, human drives the process and provides all inputs Skill-Powered Prompt Prompt invoking reusable skills Repeatable sub-routines, moderate complexity Single Agent One autonomous agent with tool access Tool use, autonomous decisions, multi-step reasoning Multi-Agent Specialized agents in a pipeline Multiple expertise domains, parallel execution, review gates"},{"location":"business-first-ai-framework/#getting-started","title":"Getting Started","text":"<ol> <li>Start with the Opportunity Finder to identify your best candidates</li> <li>Pick your highest-impact opportunity \u2014 don't try to pursue everything at once</li> <li>Run it through the Deconstruction process to break it into discrete steps</li> <li>Design your AI workflow \u2014 choose an execution pattern, classify steps, map building blocks</li> <li>Build the components your execution pattern requires \u2014 context, skills, prompts, agents, MCP connections</li> <li>Test on a real scenario \u2014 paste the generated prompt into any AI tool and run the workflow</li> <li>Iterate \u2014 refine the prompt, build additional skills, or add agents based on what works</li> </ol>"},{"location":"business-first-ai-framework/#tools","title":"Tools","text":"<p>For Claude platform users (Claude Code, Claude.ai, or Cowork), the Business-First AI plugin implements all three steps as executable skills you can run interactively:</p> <pre><code>/plugin install business-first-ai@handsonai\n</code></pre>"},{"location":"business-first-ai-framework/coach/","title":"Use AI as Your Coach","text":"<p>The Business-First AI Framework is a detailed methodology. Instead of reading through the documentation on your own, you can set up any AI tool \u2014 Claude, ChatGPT, Gemini, or M365 Copilot \u2014 as your personal framework coach. The AI guides you through each step, answers your questions, and helps you apply the framework to your specific situation.</p>"},{"location":"business-first-ai-framework/coach/#how-it-works","title":"How It Works","text":"<p>The coaching experience has two layers:</p> <ol> <li>Framework Coach Guide \u2014 a compact reference document that gives the AI the full methodology overview, decision trees, and step summaries</li> <li>Detailed documentation \u2014 when you ask a question that needs more depth, the AI fetches the relevant page from the documentation and answers from the source</li> </ol> <p>You provide the AI with the coaching prompt below and the Framework Coach Guide. The AI reads the guide, figures out where you are in the process, and walks you through the next step. When you need detail on a specific topic \u2014 like how to identify skill candidates or when to use agents \u2014 the AI pulls the relevant documentation page and gives you a targeted answer.</p>"},{"location":"business-first-ai-framework/coach/#setup","title":"Setup","text":""},{"location":"business-first-ai-framework/coach/#step-1-copy-the-coaching-prompt","title":"Step 1: Copy the coaching prompt","text":"<p>Copy the prompt from the Coaching Prompt section below.</p>"},{"location":"business-first-ai-framework/coach/#step-2-start-a-conversation","title":"Step 2: Start a conversation","text":"<p>Open a new conversation in your preferred AI tool and paste the coaching prompt.</p>"},{"location":"business-first-ai-framework/coach/#step-3-follow-the-coach","title":"Step 3: Follow the coach","text":"<p>The AI will ask where you are in the process and guide you from there. Answer its questions, and it will walk you through each step \u2014 explaining what to do, why it matters, and what to produce.</p>"},{"location":"business-first-ai-framework/coach/#platform-tips","title":"Platform tips","text":"ChatGPTClaudeGeminiM365 Copilot <p>ChatGPT can browse the web. When you paste the coaching prompt, it will automatically fetch the Framework Coach Guide from the URL in the prompt. When you ask detailed questions, it can fetch additional documentation pages as needed.</p> <p>Claude.ai can browse URLs. When you paste the coaching prompt, it will fetch the Framework Coach Guide from the URL in the prompt. For detailed questions, it can fetch additional documentation pages as needed.</p> <p>Claude Code and Cowork users: consider using the <code>workflow-deconstructor</code> agent from the Business-First AI plugin instead \u2014 it runs the full framework interactively with file-based handoffs.</p> <p>Gemini can access web content. When you paste the coaching prompt, it will fetch the Framework Coach Guide from the URL. For detailed questions, it can fetch additional documentation pages as needed.</p> <p>Copilot can browse the web. Paste the coaching prompt and it will fetch the Framework Coach Guide. For detailed questions, it can pull additional documentation pages as needed.</p>"},{"location":"business-first-ai-framework/coach/#the-coaching-prompt","title":"The Coaching Prompt","text":"<pre><code>You are a Business-First AI Framework Coach. Your job is to guide me through a structured three-step methodology for finding where AI fits in my work, breaking down workflows, and building working AI workflows.\n\n## Your Reference\n\nRead the Framework Coach Guide to understand the methodology, decision trees, and step flow:\n\nhttps://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/framework-coach.md\n\nThis guide contains:\n- The three-step framework (Discover \u2192 Deconstruct \u2192 Build)\n- Decision trees for choosing execution patterns\n- Step summaries and coaching guidance\n- A URL index pointing to detailed documentation pages (raw Markdown)\n\nWhen I ask a question that needs more depth than the guide provides, fetch the relevant detailed documentation page from the URL index in the guide. The URLs point to raw Markdown files \u2014 read them and answer from the source.\n\n## How to Coach Me\n\n1. **Start by asking where I am.** Am I:\n   - Starting fresh (haven't done any steps yet)?\n   - Mid-process (have some deliverables already)?\n   - Stuck on a specific step or concept?\n   - Looking for help with a specific question?\n\n2. **Guide me through one step at a time.** Don't dump the whole framework on me. Walk me through the current step, explain what I need to do, help me understand why it matters, and tell me what I'll produce.\n\n3. **Be conversational, not lecturing.** Ask me questions about my workflow, my goals, and my situation. Adapt your guidance based on my answers.\n\n4. **Help me make decisions.** When I need to choose (which workflow to deconstruct, which execution pattern to use, whether to build a skill), walk me through the decision criteria and help me decide \u2014 don't just list options.\n\n5. **Fetch detailed docs when needed.** If I ask about something the guide covers only briefly (like how to build skills, or the full Design prompt template), fetch the relevant page from the URL index and answer from that source.\n\n6. **Tell me what's next.** After each step, summarize what I produced and what the next step is. If I need to switch to a different conversation to run a prompt template (like the Deconstruct prompt), tell me when to do that and what to bring back.\n\n7. **Keep it practical.** I'm here to build something real, not to learn theory. Help me apply the framework to my specific situation.\n\n## Important Context\n\n- The framework produces Markdown files as deliverables \u2014 they're portable and work everywhere\n- Each step has a prompt template the user can paste into any AI tool \u2014 you don't need to replicate those prompts, just guide the user to them\n- The framework is platform-agnostic \u2014 it works on Claude, ChatGPT, Gemini, and M365 Copilot\n- For Claude platform users, there's a plugin that automates much of this \u2014 mention it if relevant but don't require it\n\nStart by asking me where I am and what I'm trying to accomplish.\n</code></pre>"},{"location":"business-first-ai-framework/coach/#what-to-expect","title":"What to Expect","text":"<p>The AI coach will:</p> <ul> <li>Ask where you are \u2014 starting fresh, mid-process, or stuck on something specific</li> <li>Walk you through one step at a time \u2014 not the whole framework at once</li> <li>Help you make decisions \u2014 which workflow to pick, which execution pattern to use</li> <li>Answer your questions from the documentation \u2014 fetching detailed pages when needed</li> <li>Tell you when to switch conversations \u2014 some steps (like Deconstruct) are best run as their own prompt in a separate conversation, then you bring the output back to the coach</li> </ul>"},{"location":"business-first-ai-framework/coach/#tips","title":"Tips","text":"<ul> <li>Start with a real workflow. The coach works best when you have a specific workflow or problem in mind \u2014 not hypothetical scenarios.</li> <li>Bring your deliverables back. If the coach tells you to run the Deconstruct prompt in a separate conversation, paste or summarize the Workflow Definition when you return so the coach can guide your next step.</li> <li>Ask \"why.\" The coach can explain the reasoning behind any framework decision \u2014 why this execution pattern, why this step matters, why you should or shouldn't build a skill.</li> <li>It's okay to skip Step 1. If you already know which workflow to work on, tell the coach and it will start you at Step 2.</li> </ul>"},{"location":"business-first-ai-framework/coach/#related","title":"Related","text":"<ul> <li>Framework Coach Guide \u2014 the compact reference document the coaching prompt uses</li> <li>Business-First AI Framework \u2014 the full framework documentation</li> <li>Business-First AI Plugin \u2014 automated framework execution for Claude platform users</li> </ul>"},{"location":"business-first-ai-framework/discover/","title":"Step 1: Discover Workflows","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"business-first-ai-framework/discover/#what-this-is","title":"What This Is","text":"<p>A structured audit that helps you find where AI fits in your work. The AI scans what it already knows about you, interviews you about your workflows, then analyzes the results to surface opportunities you'd miss on your own.</p> What you'll do Walk through a guided conversation covering your role, tasks, and pain points What you'll get A prioritized report of AI opportunities across three levels \u2014 Deterministic Workflows, Collaborative AI, and Autonomous Agents \u2014 with concrete next steps for each Time ~20\u201330 minutes for the full conversation"},{"location":"business-first-ai-framework/discover/#why-this-matters","title":"Why This Matters","text":"<p>Most people adopt AI by reacting to problems \u2014 they reach for ChatGPT when they're stuck on an email or ask Claude to summarize a document. That's useful, but it misses the bigger picture.</p> <p>A proactive audit of your workflows can reveal opportunities you'd never notice in the moment: repetitive tasks that could run on autopilot, decisions that would benefit from an AI collaborator, and multi-step processes that could be orchestrated end-to-end.</p> <p>This prompt template guides an AI through a structured analysis of your work and produces a categorized report of opportunities across three levels:</p> <ul> <li>Deterministic Workflows \u2014 Repeatable processes that AI can execute reliably with little or no supervision</li> <li>Collaborative AI \u2014 Tasks where you and AI work together in real time (drafting, brainstorming, reviewing)</li> <li>Autonomous Agents \u2014 Goal-driven workflows where AI plans and executes steps autonomously, from single agents to multi-agent systems</li> </ul>"},{"location":"business-first-ai-framework/discover/#how-to-use-this","title":"How to Use This","text":"<p>There are two ways to run this: as a prompt in any AI tool, or with the Claude platform plugin.</p> Any AI ToolClaude Platform <p>Works with ChatGPT, Gemini, M365 Copilot, Claude, or any AI chat tool.</p> <ol> <li>If your AI tool has a memory or personalization feature, make sure it's enabled \u2014 this lets the AI draw on what it knows about you from past conversations. If it doesn't, that's fine \u2014 the interview will gather everything it needs</li> <li>Copy the prompt from the Prompt Template section below</li> <li>Paste it into any conversation \u2014 the AI will automatically scan its memory for context about your role, tasks, and workflows</li> <li>Review the output, pick one opportunity from each category, and save the Workflow Candidate Summary</li> </ol> <p>Install the Business-First AI plugin and the <code>discovering-workflows</code> skill runs automatically when you describe what you need.</p> <p>Install the plugin:</p> <pre><code>/plugin install business-first-ai@handsonai\n</code></pre> <p>Start with this prompt:</p> <pre><code>I'd like to discover AI workflow opportunities. Help me audit\nwhat I do and identify where AI could help.\n</code></pre> <p>Review the output \u2014 the report is saved to <code>outputs/ai-opportunity-report.md</code></p> <p>The plugin works on three Claude interfaces:</p> Interface How to install Notes Claude Code Run <code>/plugin install</code> in the terminal Full skill support Cowork Click + &gt; Add plugins... &gt; upload the plugin ZIP Same capabilities, visual interface Claude.ai Upload the skill ZIP under Settings &gt; Capabilities &gt; Upload skill Requires Claude Code installed first to access skill files (details) <p>For setup details, see Using Plugins.</p> <p>Both options follow the same process and produce the same structured report.</p> <p>Classify opportunities with the six primitives</p> <p>Once you've identified opportunities, use the six use case primitives \u2014 Content Creation, Research, Coding, Data Analysis, Ideation &amp; Strategy, and Automation \u2014 to classify what type of AI work each one involves. This makes it easier to find examples and choose the right building blocks.</p> <p>Best results come from rich context</p> <p>The more the AI knows about your actual work, the better the recommendations. If possible, use a tool where you've had many prior conversations or uploaded relevant documents.</p>"},{"location":"business-first-ai-framework/discover/#the-prompt-template","title":"The Prompt Template","text":"<pre><code>You are an AI Workflow Strategist with deep expertise in business process optimization and AI capabilities. Your job is to help me discover concrete opportunities where AI can improve my workflows.\n\nWork through the following four steps in order.\n\n---\n\n## Step 1 \u2014 Memory &amp; History Scan\n\nBefore asking me anything, review everything you already know about me from our conversation history, your memory, project files, or any other context available to you.\n\nFrom that context, identify and list:\n- My role, responsibilities, and domain\n- Recurring tasks or requests I perform\n- Pain points, frustrations, or bottlenecks I've mentioned\n- Workflows or processes I've described or demonstrated\n- Tools and platforms I use regularly\n- Any goals or priorities I've shared\n\nPresent your findings as a brief summary so I can confirm or correct them before we continue. If you have no prior context about me, say so and move directly to Step 2.\n\n---\n\n## Step 2 \u2014 Targeted Discovery Interview\n\nBased on gaps in your understanding (or starting from scratch if Step 1 had no context), ask me focused questions to build a complete picture. Cover these areas:\n\n1. **Role &amp; responsibilities** \u2014 What is your role? What are you accountable for?\n2. **Repetitive tasks** \u2014 What tasks do you perform daily or weekly that feel repetitive, tedious, or low-value?\n3. **Information synthesis** \u2014 Where do you spend time gathering, combining, or making sense of information from multiple sources?\n4. **Multi-step processes** \u2014 What workflows involve multiple handoffs, approvals, or sequential steps?\n5. **Quality &amp; consistency** \u2014 Where do errors, inconsistencies, or quality issues tend to creep in?\n6. **Communication overhead** \u2014 What recurring communications (status updates, reports, summaries) take more time than they should?\n7. **Decision-making** \u2014 What decisions require you to weigh multiple factors or reference past precedents?\n\nAsk these questions conversationally \u2014 not all at once. Use my answers to ask smart follow-up questions. Continue until you have enough detail to generate meaningful recommendations.\n\n---\n\n## Step 3 \u2014 Opportunity Analysis &amp; Report\n\nOnce you have sufficient context, produce a structured report.\n\n### Summary Table\n\nStart with a table listing every opportunity:\n\n| # | Opportunity | Category | Impact |\n|---|------------|----------|--------|\n| 1 | [Name] | Deterministic Workflow / Collaborative AI / Autonomous Agent | High / Medium / Low |\n\n### Detailed Opportunity Cards\n\nThen for each opportunity, provide a detailed card in this format:\n\n---\n\n**[#] [Opportunity Name]**\n\n**Category:** Deterministic Workflow | Collaborative AI | Autonomous Agent\n\n**Why it's a good candidate:**\n[What characteristics of this task make it well-suited for AI \u2014 e.g., it's repetitive, pattern-based, language-heavy, has clear inputs/outputs, etc.]\n\n**Current pain point:**\n[What's slow, error-prone, inconsistent, or draining about how this is done today]\n\n**How AI helps:**\n[Specific, concrete description of what AI would do \u2014 not vague \"AI could help\" but exactly what it would take as input, what it would produce, and how it fits into the workflow]\n\n**Getting started:**\n[A practical, low-effort first step to pilot this \u2014 something achievable this week]\n\n---\n\n### Category Definitions\n\nUse these definitions when categorizing:\n\n- **Deterministic Workflow**: A repeatable process with clear inputs, rules, and outputs that AI can execute reliably with minimal supervision. Examples: formatting reports, processing forms, generating routine communications, data transformation.\n\n- **Collaborative AI**: Human and AI work together in real time. The human drives the process; AI contributes suggestions, drafts, analysis, or feedback. Examples: co-writing, brainstorming, code review, data analysis.\n\n- **Autonomous Agent**: A goal-driven workflow where AI plans and executes steps autonomously. The agent reasons about what to do, calls tools as needed, and adapts its approach. Ranges from a single agent handling a complex task to multi-agent systems where specialized agents coordinate across steps. Examples: competitor monitoring and alerting, research \u2192 analysis \u2192 report pipelines, intake \u2192 triage \u2192 routing systems.\n\nGroup the detailed cards by category. Within each category, order opportunities from highest to lowest impact.\n\n---\n\n## Step 4 \u2014 Workflow Candidate Summary\n\nAfter presenting the full report, ask me to pick my top workflow candidates \u2014 the ones I want to build. Once I've chosen, produce a **Workflow Candidate Summary** with structured metadata for each candidate, wrapped in a markdown code block so I can copy it easily:\n\n```markdown\n## Workflow Candidate Summary\n\n### [Workflow Name]\n- **Description:** [One sentence describing what this workflow does]\n- **Category:** Deterministic Workflow / Collaborative AI / Autonomous Agent\n- **Pain point:** [What's slow, error-prone, or manual today]\n- **AI opportunity:** [Specific description of what AI would do]\n- **Frequency:** Daily / Weekly / Monthly / Ad-hoc\n- **Priority:** High / Medium / Low\n- **Reasoning:** [Why this priority \u2014 based on impact, frequency, and feasibility]\n\n### [Workflow Name]\n...\n\n### Recommended Starting Point\n[Which candidate to deconstruct first and why]\n</code></pre> <p>Present this inside a code block so I can copy and save it easily. Use what you learned about my priorities, goals, and pain points during the interview to inform the reasoning and recommendation. ```</p>"},{"location":"business-first-ai-framework/discover/#what-to-expect","title":"What to Expect","text":"<p>After pasting the prompt, here's what typically happens:</p> <ol> <li>Step 1 \u2014 The AI reviews what it knows about you and presents a summary. Correct anything that's wrong and fill in gaps.</li> <li>Step 2 \u2014 The AI asks you a series of questions. Answer as specifically as you can \u2014 concrete examples produce better recommendations than general descriptions.</li> <li>Step 3 \u2014 You receive a structured report with a summary table and detailed cards for each opportunity, grouped by category.</li> <li>Step 4 \u2014 You pick one opportunity from each category to build first, and the AI formats a Workflow Candidate Summary you can copy and save.</li> </ol> <p>Most people discover 5\u201315 opportunities across the three categories. Pick three to start with \u2014 one from each category.</p>"},{"location":"business-first-ai-framework/discover/#how-to-prioritize","title":"How to Prioritize","text":"<ul> <li>Start with Collaborative AI opportunities if you're new to AI \u2014 they're the easiest to try and lowest risk</li> <li>Move to Deterministic Workflows once you've identified a process you repeat often \u2014 the time savings compound quickly</li> <li>Explore Autonomous Agents when you have experience with the other two categories and need to automate complex, multi-step processes</li> </ul>"},{"location":"business-first-ai-framework/discover/#tips-for-better-results","title":"Tips for Better Results","text":"<ul> <li>Use a tool with memory or projects enabled. The richer the AI's context about your actual work, the more specific and useful the recommendations will be.</li> <li>Be concrete when answering questions. \"I spend 30 minutes every Monday formatting a status report from three Jira boards\" is far more useful than \"I do reporting.\"</li> <li>Run it again in a few weeks. As you have more conversations and the AI learns more about your work, re-running this prompt will surface new opportunities.</li> <li>Share the output with your team. Some of the best opportunities come from workflows that span multiple people \u2014 your colleagues may see possibilities you don't.</li> </ul>"},{"location":"business-first-ai-framework/discover/#related","title":"Related","text":"<ul> <li>Next step: Ready to act on an opportunity? Use the Deconstruct Workflows guide (Step 2) to break it into discrete steps.</li> <li>Business-First AI Framework \u2014 the full three-step methodology</li> <li>Prompts</li> <li>Agents</li> </ul>"},{"location":"business-first-ai-framework/framework-coach/","title":"Business-First AI Framework \u2014 Coach Guide","text":"<p>This document is designed for AI tools (Claude, ChatGPT, Gemini, M365 Copilot) to use as a coaching reference when guiding users through the Business-First AI Framework. It provides the methodology overview, decision trees, and links to detailed documentation in raw Markdown format.</p> <p>For the coaching prompt and setup instructions, see Use AI as Your Coach.</p>"},{"location":"business-first-ai-framework/framework-coach/#framework-overview","title":"Framework Overview","text":"<p>The Business-First AI Framework is a three-step methodology for finding where AI fits in your business, breaking down workflows into structured components, and building working AI workflows.</p> <pre><code>Step 1: Discover \u2192 Step 2: Deconstruct \u2192 Step 3: Build (3.1 Design \u2192 3.2 Construct \u2192 3.3 Run)\n</code></pre> <p>Each step produces a specific deliverable that feeds into the next:</p> Step What happens Deliverable File 1. Discover Audit workflows, identify AI opportunities Opportunity Report + Workflow Candidates <code>ai-opportunity-report.md</code> 2. Deconstruct Deep-dive a specific workflow using the 5-question framework Workflow Definition <code>[name]-definition.md</code> 3.1 Design Choose execution pattern, classify steps, map building blocks AI Building Block Spec <code>[name]-building-block-spec.md</code> 3.2 Construct Build the components your pattern requires Baseline Workflow Prompt (+ skills/agents) <code>[name]-prompt.md</code> 3.3 Run Test on a real scenario, iterate Refined workflow \u2014"},{"location":"business-first-ai-framework/framework-coach/#step-1-discover-workflows","title":"Step 1: Discover Workflows","text":"<p>Purpose: Find which of your workflows are candidates for AI automation.</p> <p>Process: The AI scans what it knows about the user, interviews them about their work (role, repetitive tasks, pain points, multi-step processes), then produces a categorized opportunity report.</p> <p>Three opportunity categories:</p> Category Description Example Deterministic Workflow Repeatable process AI executes with minimal supervision Formatting reports, processing forms Collaborative AI Human and AI work together in real time Co-writing, brainstorming, code review Autonomous Agent AI plans and executes steps autonomously Research pipelines, monitoring systems <p>Output: An opportunity report with a summary table, detailed cards for each opportunity, and a workflow candidate summary with structured metadata (name, description, category, priority, reasoning).</p> <p>Coaching guidance:</p> <ul> <li>If the user doesn't know where to start, run Step 1 first</li> <li>If they already know which workflow to work on, skip to Step 2</li> <li>Encourage them to pick one workflow from each category to start</li> <li>Start with Collaborative AI if they're new to AI (lowest risk, easiest to try)</li> </ul>"},{"location":"business-first-ai-framework/framework-coach/#step-2-deconstruct-workflows","title":"Step 2: Deconstruct Workflows","text":"<p>Purpose: Break down a specific workflow into discrete steps with full detail on decision points, data flows, context needs, and failure modes.</p> <p>Process: Interactive deep-dive using the 5-question framework applied to every step:</p> <ol> <li>Discrete steps \u2014 Is this actually multiple steps bundled together?</li> <li>Decision points \u2014 Any if/then branches, quality gates, or judgment calls?</li> <li>Data flows \u2014 What goes in? What comes out? Where from and where to?</li> <li>Context needs \u2014 What documents, files, or reference materials are required?</li> <li>Failure modes \u2014 What happens when this step fails?</li> </ol> <p>Scope check (critical): Before starting the deep dive, verify the workflow has exactly one trigger and one deliverable. Test with four diagnostic questions:</p> <ol> <li>Does it have multiple independent starting points? \u2192 Separate workflows</li> <li>Does it produce distinct outputs at different points? \u2192 Workflow boundary</li> <li>Do parts run on different schedules? \u2192 Likely separate workflows</li> <li>Would it expand to 15+ refined steps? \u2192 May be multiple workflows</li> </ol> <p>If multiple workflows are detected, help the user identify and separate them, then pick one to deconstruct.</p> <p>Output: A Workflow Definition with scenario metadata, refined steps (each with action, sub-steps, decision points, data in/out, context needs, failure modes), step sequence/dependencies, and a context shopping list.</p> <p>Coaching guidance:</p> <ul> <li>Most workflows expand from 5-8 rough steps to 12-20 refined steps</li> <li>Encourage messy, incomplete descriptions \u2014 the process refines them</li> <li>Push for specific context artifacts, not vague \"domain knowledge\"</li> <li>Ask for existing AI instructions if AI is already being used at any step</li> <li>The Workflow Definition should be saved as <code>[name]-definition.md</code></li> <li>After completing, register the workflow in the AI Registry if using Notion</li> </ul>"},{"location":"business-first-ai-framework/framework-coach/#step-3-build-workflows","title":"Step 3: Build Workflows","text":"<p>Build has three parts: 3.1 Design, 3.2 Construct, and 3.3 Run.</p>"},{"location":"business-first-ai-framework/framework-coach/#31-design","title":"3.1: Design","text":"<p>Purpose: Decide how the workflow should be built before building it.</p> <p>Process: Take the Workflow Definition and make three design decisions:</p> <ol> <li>Execution pattern \u2014 How complex does the AI implementation need to be?</li> <li>Autonomy classification \u2014 How much AI assistance does each step need?</li> <li>Building block mapping \u2014 What specific AI components does each step require?</li> </ol> <p>Execution Pattern Spectrum:</p> Pattern Description Signals Prompt Single self-contained prompt, all logic inline Sequential steps, human drives the process and provides all inputs Skill-Powered Prompt Prompt invoking reusable skills Repeatable sub-routines, moderate complexity Single Agent One autonomous agent with tool access Tool use, autonomous decisions, multi-step reasoning Multi-Agent Specialized agents in a pipeline Multiple expertise domains, parallel execution, review gates <p>Five decision questions for choosing a pattern:</p> <ol> <li>Does the workflow require tool use? (web, files, APIs) \u2192 If yes, need at least Single Agent</li> <li>Does it require autonomous decision-making? \u2192 If yes, need at least Single Agent</li> <li>Are there steps with complex, reusable logic? \u2192 Skill candidates</li> <li>Does it span multiple expertise domains? \u2192 Consider Multi-Agent</li> <li>Would it benefit from parallel execution or review gates? \u2192 Multi-Agent</li> </ol> <p>Autonomy spectrum for each step:</p> Level Description Human Requires human judgment, creativity, or physical action Deterministic Follows fixed rules; AI executes reliably with minimal supervision Semi-Autonomous AI does most of the work; human reviews at key checkpoints Autonomous AI executes end-to-end, including decisions and tool use <p>Seven AI Building Blocks:</p> Block What It Is Model The AI engine that processes inputs and generates outputs Prompt A well-crafted instruction that tells the model what to do Context Background information, reference docs, or examples the model needs Skill A reusable routine \u2014 give it inputs, it follows a defined process, produces consistent outputs Agent An autonomous AI that plans, uses tools, and executes multi-step work MCP A connector giving AI access to external tools, APIs, databases Project A persistent workspace grouping prompts, context, skills, and agents <p>Output: An AI Building Block Spec with execution pattern, autonomy classifications, building block mapping, skill candidates (with generation-ready detail), agent configurations (when applicable), context inventory, and implementation order.</p> <p>Coaching guidance:</p> <ul> <li>Most workflows start as Prompt or Skill-Powered Prompt \u2014 start simple</li> <li>The AI Building Block Spec is platform-agnostic \u2014 it works on any AI platform</li> <li>Implementation order: quick wins first, complex agent steps last</li> </ul>"},{"location":"business-first-ai-framework/framework-coach/#32-construct","title":"3.2: Construct","text":"<p>Purpose: Build only what your execution pattern requires.</p> <p>Each pattern has a specific build path \u2014 users follow only the steps that apply to their pattern:</p> Pattern Build steps Prompt Create context \u2192 Set up project (optional) \u2192 Generate prompt \u2192 Run Skill-Powered Prompt Create context \u2192 Set up project (optional) \u2192 Build skills \u2192 Generate prompt \u2192 Run Single Agent Create context \u2192 Build skills \u2192 Connect MCP \u2192 Build agent \u2192 Run Multi-Agent Create context \u2192 Build skills \u2192 Connect MCP \u2192 Build agents \u2192 Build orchestrator \u2192 Run <p>Building block guides: Context, Projects, Skills, Prompt, Agents, MCP \u2014 each covers one building block in depth.</p> <p>Operational rhythm: After creating each building block: test it, register it (in the AI Registry), commit it (to GitHub).</p> <p>Coaching guidance:</p> <ul> <li>Point users to the specific build path for their execution pattern</li> <li>Don't overwhelm with all options \u2014 show only what applies</li> <li>Skills: build only for steps with complex, reusable logic</li> <li>The Baseline Workflow Prompt must be self-contained \u2014 paste and run on any AI platform</li> </ul>"},{"location":"business-first-ai-framework/framework-coach/#33-run","title":"3.3: Run","text":"<p>Purpose: Test the workflow on a real scenario and iterate.</p> <p>Process: Run \u2192 evaluate \u2192 adjust \u2192 run again. Most workflows need 2-4 iterations.</p> <p>What to evaluate:</p> <ul> <li>Did the output match expectations?</li> <li>Were any steps skipped or misunderstood?</li> <li>Was the output specific to the business or generic?</li> </ul> <p>Troubleshooting:</p> Problem Fix Generic output Add more context (reference materials, examples, style guides) Steps skipped or wrong Refine the prompt (more explicit instructions) Step needs domain expertise Build a skill for that step AI needs to make unpredictable decisions Convert from prompt to agent <p>Coaching guidance:</p> <ul> <li>The first run is always a test, not production</li> <li>Set expectations: 2-4 iterations is normal</li> <li>The workflow is ready when you can run it on a new scenario and trust the output</li> </ul>"},{"location":"business-first-ai-framework/framework-coach/#common-questions","title":"Common Questions","text":"<p>\"Where do I start?\" If you know which workflow to work on \u2192 Step 2 (Deconstruct). If you need to figure out where AI fits \u2192 Step 1 (Discover).</p> <p>\"Do I need agents?\" Most workflows work as a prompt or skill-powered prompt. You need agents only when the workflow requires tool use (web, files, APIs) or autonomous decision-making. Start simple.</p> <p>\"What if my workflow is too big?\" Apply the scope check: one trigger, one deliverable. If it has multiple triggers or produces distinct outputs at different points, split it into separate workflows.</p> <p>\"How long does this take?\" Step 1: ~20-30 min. Step 2: ~15-25 min. Step 3 Design: ~10-15 min. Step 3 Construct: ~5-15 min per building block. First run + iteration: varies.</p> <p>\"Can I skip steps?\" You can skip Step 1 if you already know your workflow. You should not skip Step 2 (Deconstruct) or Step 3.1 (Design) \u2014 they prevent building the wrong thing.</p>"},{"location":"business-first-ai-framework/framework-coach/#detailed-documentation-index","title":"Detailed Documentation Index","text":"<p>When the user needs more depth on a specific topic, fetch the raw Markdown from the URLs below. Each URL points to the full documentation page.</p>"},{"location":"business-first-ai-framework/framework-coach/#framework-pages","title":"Framework Pages","text":"Topic Description Raw Markdown URL Framework overview Full methodology, key concepts, vocabulary <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/index.md</code> Step 1: Discover Opportunity finder prompt template and instructions <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/discover.md</code> Step 2: Deconstruct overview How Deconstruct works, tips, examples <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/deconstruct/index.md</code> Step 2: Workflow Definition prompt The full prompt template for breaking down workflows <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/deconstruct/workflow-definition.md</code> Step 3: Build overview The three parts (Design, Construct, Run) and pattern-specific paths <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/build/index.md</code> 3.1: Design Execution pattern spectrum, autonomy classification, the Design prompt template <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/build/design.md</code> 3.2: Context Creating context artifacts for your workflow <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/build/context.md</code> 3.2: Projects Setting up project workspaces <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/build/projects.md</code> 3.2: Skills Building reusable skills from your AI Building Block Spec <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/build/skills.md</code> 3.2: Prompt Generating the Baseline Workflow Prompt <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/build/prompt.md</code> 3.2: Agents Agent decision framework and building agents <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/build/agents.md</code> 3.2: MCP Connecting AI to external tools and services <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/build/mcp.md</code> 3.3: Run Executing, testing, and iterating your workflow <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/build/run.md</code>"},{"location":"business-first-ai-framework/framework-coach/#worked-examples","title":"Worked Examples","text":"Example Type Raw Markdown URL LinkedIn prospect research Deterministic automation <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/build/deterministic-automation.md</code> Meeting prep researcher AI collaborative <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/build/ai-collaborative.md</code> HBR article pipeline Autonomous multi-agent <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/business-first-ai-framework/build/autonomous-agent.md</code>"},{"location":"business-first-ai-framework/framework-coach/#supporting-references","title":"Supporting References","text":"Topic Description Raw Markdown URL Agentic Building Blocks Definitions and cross-platform details for all seven blocks <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/agentic-building-blocks/index.md</code> AI Use Cases Six use case primitives with examples <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/use-cases/index.md</code> Agents by platform Platform-specific agent building guides <code>https://raw.githubusercontent.com/jamesgray-ai/handsonai/main/docs/agentic-building-blocks/agents/index.md</code>"},{"location":"business-first-ai-framework/build/","title":"Step 3: Build Workflows","text":""},{"location":"business-first-ai-framework/build/#where-you-are","title":"Where You Are","text":"<p>You've just finished Deconstructing your workflow. You should have:</p> <ul> <li>Workflow Definition (<code>[name]-definition.md</code>) \u2014 every step in your workflow broken down with decision points, data flows, context needs, and failure modes</li> </ul> <p>This file is your input. Build has three parts: Design your AI implementation, Construct the components, and Run the workflow.</p>"},{"location":"business-first-ai-framework/build/#31-design","title":"3.1: Design","text":"<p>Before building anything, decide how the workflow should be built. The Design phase takes your Workflow Definition and produces an AI Building Block Spec \u2014 a complete blueprint that tells you exactly what to build.</p> <p>Design covers:</p> <ol> <li> <p>Execution pattern \u2014 Choose from four patterns based on what your workflow needs:</p> Pattern When to use Prompt Sequential steps, human drives the process and provides all inputs Skill-Powered Prompt Steps with repeatable sub-routines or moderate complexity Single Agent Tool use required, autonomous decisions, multi-step reasoning Multi-Agent Multiple expertise domains, parallel execution, review gates </li> <li> <p>Autonomy classification \u2014 Classify each step (Human \u2192 Deterministic \u2192 Semi-Autonomous \u2192 Autonomous)</p> </li> <li>Building block mapping \u2014 Map each step to AI building blocks (Prompt, Context, Skill, Agent, MCP, Project)</li> <li>Skill candidates \u2014 Tag steps that should become reusable skills, with generation-ready detail</li> <li>Agent configuration (when applicable) \u2014 Platform-agnostic blueprint for each agent (name, description, instructions, model, tools, context, goal)</li> </ol> <p>Design Your AI Workflow \u2014 the full Design guide with prompt template, execution pattern decision flow, and output format</p> <p>Produces: <code>[name]-building-block-spec.md</code> \u2014 your AI Building Block Spec with execution pattern, step classifications, skill candidates, agent configurations (when applicable), and implementation order.</p>"},{"location":"business-first-ai-framework/build/#32-construct","title":"3.2: Construct","text":"<p>The AI Building Block Spec tells you exactly what to build \u2014 and the execution pattern determines which steps you follow. Work through only the steps that apply to your pattern:</p> PromptSkill-Powered PromptSingle AgentMulti-Agent <ol> <li>Create context \u2014 Build the context artifacts listed in your Building Block Spec's Context Inventory</li> <li>Set up project workspace (optional) \u2014 If the Building Block Spec's Where to Run recommends a project</li> <li>Generate prompt \u2014 Paste the prompt template with your Building Block Spec to generate the Baseline Workflow Prompt</li> <li>Run \u2192 3.3</li> </ol> <ol> <li>Create context \u2014 Build the context artifacts listed in your Building Block Spec's Context Inventory</li> <li>Set up project workspace (optional) \u2014 If the Building Block Spec's Where to Run recommends a project</li> <li>Build skills \u2014 Build skills for the steps tagged as skill candidates in your Building Block Spec. On Claude, auto-generate <code>SKILL.md</code> files from the Design output. On other platforms, create custom instructions, GPTs, or Gems using the skill candidate specs.</li> <li>Generate prompt \u2014 Generate a prompt that references your skills instead of spelling out those steps</li> <li>Run \u2192 3.3</li> </ol> <ol> <li>Create context \u2014 Build the context artifacts listed in your Building Block Spec's Context Inventory</li> <li>Build skills \u2014 Build skills for tagged candidates</li> <li>Connect MCP \u2014 Wire external tools from the Tools and Connectors section of your Building Block Spec</li> <li>Build agent \u2014 On Claude, auto-generate the agent <code>.md</code> file from the Design phase's agent configuration. On other platforms, configure the agent using the blueprint.</li> <li>Run \u2192 3.3</li> </ol> <ol> <li>Create context \u2014 Build the context artifacts listed in your Building Block Spec's Context Inventory</li> <li>Build skills \u2014 Build skills for tagged candidates</li> <li>Connect MCP \u2014 Wire external tools from the Tools and Connectors section of your Building Block Spec</li> <li>Build specialist agents \u2014 On Claude, auto-generate agent <code>.md</code> files from the Design phase's agent configurations. On other platforms, configure each agent using the blueprint.</li> <li>Build orchestrator \u2014 On Claude, auto-generate an orchestrator agent that coordinates the pipeline. On other platforms, configure the orchestration layer.</li> <li>Run \u2192 3.3</li> </ol> <p>Each guide page covers one building block in depth. You only visit the pages your pattern requires \u2014 no \"skip if not needed.\"</p>"},{"location":"business-first-ai-framework/build/#33-run","title":"3.3: Run","text":"<p>Take your constructed workflow and run it on a real scenario.</p> <ol> <li>Open a new conversation in your AI tool (or open your project workspace)</li> <li>Paste the contents of <code>[name]-prompt.md</code> and press Enter (or invoke the agent for agent-based patterns)</li> <li>Attach any context files listed in the prompt's Context Requirements section</li> <li>Provide the inputs the prompt asks for</li> <li>Review the output</li> </ol> <p>The first run is a test, not a final product. Expect to run, evaluate, go back to 3.2 Construct to adjust, and run again. This cycle is normal \u2014 most workflows need 2-4 iterations before they produce reliably good output.</p> <p>You're evaluating: Did the output match what you expected? Were any steps skipped? Was the output specific to your business, or generic?</p> <p>Run guide \u2014 how to choose between a normal chat and a project, and how to troubleshoot first-run issues</p>"},{"location":"business-first-ai-framework/build/#test-iterate-repeat","title":"Test, iterate, repeat","text":"<p>Each time you run, you're testing. When something is off, go back to 3.2 Construct, adjust the relevant building block, and run again:</p> What went wrong Go back to 3.2 and... Output is generic or off-brand Add more context \u2014 examples, style guides, reference materials Steps were skipped or misunderstood Refine the prompt \u2014 make the instructions more explicit A step needs expertise the AI doesn't have Build a skill for that step \u2014 codify the expertise The AI needs to make decisions you can't predict Convert from prompt to agent \u2014 let the AI plan its approach <p>The workflow is ready when you can run it on a new scenario and trust the output without heavy editing. Until then, keep iterating.</p> <p>Run guide &gt; Iterating \u2014 detailed troubleshooting for common first-run issues</p> <p>Your deliverables across Build:</p> File From What it is <code>[name]-definition.md</code> Deconstruct Your Workflow Definition \u2014 the raw decomposition <code>[name]-building-block-spec.md</code> Build: 3.1 Design Your AI Building Block Spec \u2014 execution pattern, classifications, skill candidates, agent configs <code>[name]-prompt.md</code> Build: 3.2 Construct Your Baseline Workflow Prompt \u2014 paste this to run the workflow <p>These three files are your core deliverables on any platform. On the Claude platform, the Construct step can also auto-generate:</p> File When What it is <code>.claude/skills/[skill]/SKILL.md</code> Skill-Powered Prompt, Single Agent, Multi-Agent Reusable skill definitions \u2014 one per skill candidate tagged in the AI Building Block Spec <code>.claude/agents/[agent].md</code> Single Agent, Multi-Agent Agent configurations \u2014 auto-generated from the Design blueprint <p>Plus any context artifacts and MCP connections you set up along the way.</p> <p>Many workflows stay at the prompt-plus-context level permanently \u2014 pasted into a chat whenever you need it. That's a feature, not a limitation.</p>"},{"location":"business-first-ai-framework/build/#track-and-version-your-work","title":"Track and Version Your Work","text":"<p>As you build, two background practices keep your work organized and recoverable:</p> <p>Register building blocks in your AI Registry. Each time you create a skill, prompt, or agent, register it in your AI Registry Notion database \u2014 name, type, description, and which workflow it belongs to. If you registered the workflow during Deconstruct, these building blocks link back to it. This gives you a searchable inventory of everything you've built, and makes it easy for your team to discover and reuse building blocks across workflows.</p> <p>Commit source files to GitHub. The <code>.md</code> files for your skills, agents, and prompts are source code \u2014 they should live in version control, not just on your local machine. After creating or updating a building block, commit it to your GitHub repository. This gives you a history of changes, makes it easy to share with collaborators, and protects against losing work.</p> <p>These aren't separate steps \u2014 they're part of the rhythm of building. Each time you finish a building block in 3.2 Construct: test it, register it, commit it.</p> <p>Need to set up these tools?</p> <p>The Builder Stack Setup guide walks you through everything you need \u2014 an AI code editor (Step 2), Git (Step 3), GitHub (Step 4), and the AI Registry (Step 6). If you haven't set these up yet, that guide has you covered.</p>"},{"location":"business-first-ai-framework/build/#quick-reference","title":"Quick Reference","text":"Guide When to use 3.1 Design Your AI Workflow Always \u2014 produces your AI Building Block Spec 3.2 Context Always 3.2 Projects When Where to Run recommends a project workspace 3.2 Skills When Building Block Spec tags steps as skill candidates 3.2 Prompt For Prompt and Skill-Powered Prompt patterns 3.2 Agents For Single Agent and Multi-Agent patterns 3.2 MCP When Building Block Spec lists external tools or connectors 3.3 Run Always <p>Each building block guide cross-references the corresponding Agentic Building Blocks page for platform-specific implementation details.</p>"},{"location":"business-first-ai-framework/build/#worked-examples","title":"Worked Examples","text":"<p>These three examples show complete AI-powered workflows at different levels of the autonomy spectrum \u2014 from deterministic automation to collaborative workflows to fully autonomous multi-agent pipelines. Each includes working building blocks you can install and study.</p> Type AI Involvement When to Use Example Deterministic Automation AI follows fixed rules \u2014 criteria from input, output from template Prospecting, recurring reports, template-driven research LinkedIn prospect research AI Collaborative AI researches and drafts; human steers and decides Meeting prep, competitive analysis, proposal drafting Meeting prep researcher Autonomous Agent Multiple agents execute a full pipeline; human reviews at one gate Research-driven content, multi-step pipelines, specialist roles HBR article pipeline"},{"location":"business-first-ai-framework/build/#all-building-blocks","title":"All Building Blocks","text":"<p>These are the working building blocks included across all three examples. Each one links to its source on GitHub \u2014 read the full definition, understand how it works, and adapt it for your own workflows.</p> Building Block Type Workflow Description Source <code>linkedin-prospect-research</code> Prompt Deterministic Finds and qualifies 5 LinkedIn prospects against a buyer persona View <code>buyer-persona-revenue-leader-rachel</code> Prompt Deterministic Example buyer persona used as input to the research workflow View <code>meeting-prep-researcher</code> Agent Collaborative Researches attendees and companies for meeting prep View <code>preparing-meeting-briefs</code> Skill Collaborative Step-by-step research workflow for the agent View <code>meeting-prep-quick</code> Prompt Collaborative Portable one-shot meeting prep prompt View <code>ai-productivity-researcher</code> Agent Autonomous Finds case studies of companies using AI with quantified outcomes View <code>tech-executive-writer</code> Agent Autonomous Writes articles for business leadership audiences View <code>hbr-editor</code> Agent Autonomous Edits drafts against HBR editorial standards View <code>editing-hbr-articles</code> Skill Autonomous Editorial criteria and cut/replace patterns for the editor View <code>hbr-publisher</code> Agent Autonomous Formats approved articles as PDF + markdown with SEO metadata View"},{"location":"business-first-ai-framework/build/#how-to-use-these-examples","title":"How to Use These Examples","text":"Any AI ToolClaude Code <p>Every example includes at least one standalone prompt \u2014 a text template you can copy and paste into Claude, ChatGPT, Gemini, M365 Copilot, or any other AI tool. Click the \"View\" links in the table above to read the prompt source on GitHub.</p> <p>Prompts are the most portable building block type. They work everywhere, require no setup, and can be shared with anyone on your team.</p> <p>All building blocks \u2014 agents, skills, and prompts \u2014 are bundled in the <code>business-first-ai</code> plugin. Install it once and the agents activate automatically when you describe a matching task.</p> <pre><code># Add the Hands-on AI marketplace (one time)\n/plugin marketplace add jamesgray-ai/handsonai\n\n# Install the business-first-ai plugin\n/plugin install business-first-ai@handsonai\n</code></pre> <p>Then describe what you need in natural language:</p> <ul> <li>\"Run the LinkedIn prospect research workflow using the Revenue Leader Rachel persona\" \u2014 executes the deterministic prospecting workflow</li> <li>\"Prepare me for my meeting with Sarah Chen at Acme Corp\" \u2014 activates the meeting prep researcher agent</li> <li>\"Write an HBR-style article about companies successfully using AI agents\" \u2014 triggers the full multi-agent research \u2192 write \u2192 edit \u2192 publish pipeline</li> </ul>"},{"location":"business-first-ai-framework/build/#related","title":"Related","text":"<ul> <li>AI Use Cases \u2014 browse use cases by type (content creation, research, coding, data analysis, ideation, automation)</li> <li>Discover AI Workflow Opportunities \u2014 discover which of your workflows are candidates for AI</li> <li>Deconstruct Workflows \u2014 break down workflows into structured definitions</li> <li>Plugin Marketplace \u2014 browse all available plugins</li> </ul>"},{"location":"business-first-ai-framework/build/agents/","title":"Agents","text":"<p>Part of: Build Workflows</p> <p>New to agents as a building block?</p> <p>See Agentic Building Blocks &gt; Agents for definitions, examples, and cross-platform implementation details.</p>"},{"location":"business-first-ai-framework/build/agents/#what-this-is","title":"What This Is","text":"<p>The agent decision framework. Not every workflow needs an agent \u2014 many work perfectly as a prompt you paste and run. This page helps you decide when autonomous execution is worth the investment, and how to build your first agent when it is.</p> What you'll do Review your Building Block Spec for steps tagged \"Agent,\" decide whether to build agents, then design the first one What you'll get A clear decision on agent vs. prompt for each workflow step, and agent definitions for steps that need autonomous execution Time 15-30 minutes per agent"},{"location":"business-first-ai-framework/build/agents/#the-agent-decision-framework","title":"The Agent Decision Framework","text":"<p>Not every workflow needs an agent. Many workflows work perfectly as a prompt \u2014 paste it in, run it, get results. That's a feature, not a limitation.</p>"},{"location":"business-first-ai-framework/build/agents/#when-a-prompt-is-enough","title":"When a prompt is enough","text":"<ul> <li>All steps can be completed in a single conversation</li> <li>No tool use needed (no web browsing, no file access, no API calls)</li> <li>Human provides all inputs and reviews all outputs</li> <li>Steps are sequential and straightforward</li> </ul>"},{"location":"business-first-ai-framework/build/agents/#when-you-need-an-agent","title":"When you need an agent","text":"<ul> <li>The step requires tool use \u2014 browsing the web, reading/writing files, calling APIs</li> <li>The step requires autonomous execution \u2014 the AI needs to make decisions and take actions without asking you at each step</li> <li>The step requires multi-step reasoning with memory \u2014 the AI needs to plan, execute, and adjust based on results</li> <li>The step spans multiple conversations or needs to persist state across sessions</li> </ul>"},{"location":"business-first-ai-framework/build/agents/#when-to-use-multiple-agents","title":"When to use multiple agents","text":"<ul> <li>Different steps require different domain expertise (researcher vs. writer vs. editor)</li> <li>Steps can run independently (parallel execution)</li> <li>You want human review gates between phases</li> </ul> <p>The Autonomous Agent worked example shows a multi-agent pipeline with 4 specialized agents.</p>"},{"location":"business-first-ai-framework/build/agents/#building-your-first-agent","title":"Building Your First Agent","text":"<ol> <li>Look at your Building Block Spec for steps tagged with \"Agent\"</li> <li>Group related steps \u2014 Contiguous steps with the same expertise domain become one agent</li> <li>Write the agent's instructions \u2014 Describe the agent's role, what it knows, and what it does. Think of it as writing a job description: \"You are a researcher who finds case studies from business publications. You search for companies with quantified outcomes and produce structured briefs.\" Your Building Block Spec's Action, Decision Points, and Context Needed columns give you most of this.</li> <li>Define human review gates \u2014 Where should the agent pause for your approval?</li> <li>Test with a real scenario \u2014 Run the agent on actual inputs and evaluate the output</li> <li>Register and commit \u2014 Add the agent to your AI Registry Notion database and commit the agent <code>.md</code> file to your GitHub repository</li> </ol>"},{"location":"business-first-ai-framework/build/agents/#agent-anatomy","title":"Agent Anatomy","text":"<p>What an agent definition contains:</p> <ul> <li>Name \u2014 What the agent is called (e.g., <code>meeting-prep-researcher</code>)</li> <li>Description \u2014 When to activate this agent and what it does</li> <li>Model \u2014 Which AI model to use (affects capability and cost)</li> <li>Instructions (also called a \"system prompt\") \u2014 The agent's role, expertise, process, and constraints \u2014 written in plain language, just like you'd brief a new team member</li> <li>Tools \u2014 What the agent can interact with to carry out its work \u2014 web search, file access, APIs, databases, MCP servers, or other external services. Without tools, an agent is just a prompt. Tools are what give agents the ability to take action in the world.</li> </ul>"},{"location":"business-first-ai-framework/build/agents/#build-on-your-platform","title":"Build on Your Platform","text":"<p>The Design phase produced a platform-agnostic agent blueprint \u2014 name, description, instructions, model, and tools. How you build that agent depends on which platform you're using. Each platform has its own agent system with different capabilities and configuration approaches.</p> Platform Agent guide Claude Building Agents on Claude OpenAI Building Agents on OpenAI Google Gemini Building Agents on Google M365 Copilot Building Agents on M365 Copilot <p>Each guide shows how to translate your Design blueprint into a working agent on that platform \u2014 where each component goes, what tools are available, and links to official documentation.</p> <p>The Autonomous Agent worked example shows a complete multi-agent pipeline with 4 specialized agents, including the full instructions for each one.</p>"},{"location":"business-first-ai-framework/build/agents/#whats-next","title":"What's Next","text":"<p>If your workflow requires external tool access (databases, APIs, browsers), see MCP for connecting AI to your tools. Otherwise, run your workflow on a real scenario and build incrementally.</p>"},{"location":"business-first-ai-framework/build/ai-collaborative/","title":"AI Collaborative","text":"<p>AI involvement: AI handles research and drafting; the human steers, reviews, and decides.</p>"},{"location":"business-first-ai-framework/build/ai-collaborative/#what-this-workflow-type-is","title":"What This Workflow Type Is","text":"<p>An AI collaborative workflow is one where the human and AI work together \u2014 the AI performs tasks like research, analysis, or drafting, and the human provides judgment, context, and final decisions. Neither operates alone. The human sets the direction; the AI handles the legwork.</p> <p>At a Glance</p> <ul> <li>AI involvement: Researches, drafts, and analyzes \u2014 but defers to human judgment</li> <li>Human oversight: Active \u2014 reviews output, provides direction, makes decisions</li> <li>Best for: Meeting prep, competitive analysis, draft creation, exploratory research</li> <li>Complexity: Medium \u2014 may use an agent and/or skill, with a portable prompt as a lightweight alternative</li> </ul>"},{"location":"business-first-ai-framework/build/ai-collaborative/#characteristics","title":"Characteristics","text":"<ul> <li>Iterative \u2014 the human and AI go back and forth, refining the output</li> <li>Judgment-dependent \u2014 the AI can gather and organize information, but the human decides what matters</li> <li>Context-rich \u2014 the AI benefits from knowing the human's goals, preferences, and constraints</li> <li>Quality-gated \u2014 the human reviews before the output is used</li> </ul>"},{"location":"business-first-ai-framework/build/ai-collaborative/#when-to-use","title":"When to Use","text":"<p>Use AI collaborative workflows when the task:</p> <ul> <li>Requires research, synthesis, or analysis that's time-consuming for a human</li> <li>Involves subjective judgment that can't be fully encoded in rules</li> <li>Benefits from a draft that the human can refine rather than create from scratch</li> <li>Produces higher-quality output when a human reviews and adjusts</li> </ul>"},{"location":"business-first-ai-framework/build/ai-collaborative/#example-scenario","title":"Example Scenario","text":"<p>The problem: Before important meetings \u2014 sales calls, partnership discussions, interviews \u2014 a professional spends 20-45 minutes manually researching attendees on LinkedIn, scanning company news, and assembling talking points. The research is necessary but tedious, and the quality varies depending on how much time is available.</p> <p>The solution: An AI agent that handles the research and produces a structured meeting prep brief. The human reviews the brief, adjusts the talking points, and walks into the meeting prepared \u2014 with a fraction of the manual effort.</p>"},{"location":"business-first-ai-framework/build/ai-collaborative/#building-blocks","title":"Building Blocks","text":"Building Block Type Description Source <code>meeting-prep-researcher</code> Agent Researches attendees and companies, produces a meeting prep brief View on GitHub <code>preparing-meeting-briefs</code> Skill Step-by-step research workflow for the agent to follow View on GitHub <code>meeting-prep-quick</code> Prompt Portable one-shot prompt for quick meeting prep in any AI tool View on GitHub"},{"location":"business-first-ai-framework/build/ai-collaborative/#how-it-works","title":"How It Works","text":"<pre><code>graph LR\n    A[User provides&lt;br&gt;meeting details] --&gt; B[AI researches&lt;br&gt;attendees &amp; company]\n    B --&gt; C[AI drafts&lt;br&gt;prep brief]\n    C --&gt; D[Human reviews&lt;br&gt;and refines]\n    D --&gt; E[Final prep brief&lt;br&gt;ready for meeting]\n</code></pre> <p>Step-by-step:</p> <ol> <li>User provides context \u2014 who the meeting is with, what company, what the meeting is about, and what outcome they want.</li> <li>AI researches attendees \u2014 searches for LinkedIn profiles, recent posts, and public activity for each person.</li> <li>AI researches the company \u2014 finds recent news, strategic direction, and relevant industry context.</li> <li>AI drafts the prep brief \u2014 produces a structured document with attendee profiles, company snapshot, suggested talking points, questions to ask, and potential landmines.</li> <li>Human reviews and refines \u2014 the user reads the brief, adjusts talking points to match their style and goals, and decides what to use in the meeting.</li> </ol>"},{"location":"business-first-ai-framework/build/ai-collaborative/#usage","title":"Usage","text":"Any AI Tool (Portable)Claude Code (Plugin) <p>Use the meeting-prep-quick prompt for a lightweight, one-shot version in any AI tool.</p> <ol> <li>Open the meeting-prep-quick prompt on GitHub</li> <li>Copy the prompt from the code block</li> <li>Paste it into Claude, ChatGPT, Gemini, or M365 Copilot</li> <li>Fill in the meeting details and send</li> <li>Review the output and adjust talking points to match your style</li> </ol> <p>With the <code>business-first-ai</code> plugin installed, the meeting-prep-researcher agent activates automatically when you ask about meeting preparation.</p> <pre><code># Install the plugin (one time)\n/plugin install business-first-ai@handsonai\n</code></pre> <p>Then describe your meeting in a Claude Code conversation:</p> <p>\"I have a sales call with Maria Torres, VP of Product at DataFlow Labs, on Thursday. Help me prepare.\"</p> <p>The agent will:</p> <ul> <li>Research Maria Torres and DataFlow Labs</li> <li>Produce a structured prep brief</li> <li>Ask if you want to go deeper on any section</li> </ul> <p>The agent + skill combination provides a richer, more iterative experience than the one-shot prompt \u2014 it can ask follow-up questions, refine talking points based on your feedback, and adjust depth based on how much time you have.</p>"},{"location":"business-first-ai-framework/build/ai-collaborative/#adapting-this-example","title":"Adapting This Example","text":"<p>Meeting prep is one scenario, but the collaborative pattern applies to any task where AI handles research and drafting while the human provides judgment:</p> <ul> <li>Competitive analysis \u2014 AI researches competitors, drafts a comparison matrix; human validates and adds strategic context</li> <li>Proposal drafting \u2014 AI structures a proposal based on requirements; human refines messaging and adds relationship context</li> <li>Job candidate screening \u2014 AI summarizes resumes and flags qualifications; human makes interview decisions</li> <li>Customer research \u2014 AI compiles account history and recent activity; human identifies upsell opportunities</li> </ul> <p>To adapt: identify tasks where you spend significant time gathering information before applying judgment. The gathering is AI work; the judgment is human work.</p>"},{"location":"business-first-ai-framework/build/ai-collaborative/#related","title":"Related","text":"<ul> <li>Deterministic Automation Workflow Example \u2014 when AI follows fixed rules with no judgment needed</li> <li>Autonomous Agent Workflow Example \u2014 when AI executes end-to-end with minimal supervision</li> <li>Research Use Cases \u2014 more examples of AI-powered research workflows like meeting prep</li> <li>Ideation &amp; Strategy Use Cases \u2014 collaborative brainstorming and planning with AI</li> <li>Discover AI Workflow Opportunities \u2014 discover which workflows are candidates for AI collaboration</li> <li>Deconstruct Workflows \u2014 break down workflows into AI-ready steps</li> </ul>"},{"location":"business-first-ai-framework/build/autonomous-agent/","title":"Autonomous Agent","text":"<p>AI involvement: Multiple specialized agents execute a full pipeline \u2014 research, write, edit, review, publish \u2014 with human approval at one gate.</p>"},{"location":"business-first-ai-framework/build/autonomous-agent/#what-this-workflow-type-is","title":"What This Workflow Type Is","text":"<p>An autonomous agent workflow is one where AI handles the entire process \u2014 from research to final deliverable \u2014 with minimal human intervention. This example is built using Claude Code subagents \u2014 specialized AI assistants that each run in their own context with domain expertise, coordinated by Claude Code as the orchestrator. The human sets the goal and reviews the draft at one checkpoint. Everything else runs autonomously.</p> <p>At a Glance</p> <ul> <li>AI involvement: Full \u2014 multiple agents plan, research, write, edit, and publish</li> <li>Human oversight: One review gate between editing and publishing</li> <li>Best for: Research-driven content production, multi-step pipelines with specialist roles</li> <li>Complexity: High \u2014 multi-agent orchestration with a skill, a hook, and tool use</li> </ul>"},{"location":"business-first-ai-framework/build/autonomous-agent/#characteristics","title":"Characteristics","text":"<ul> <li>Multi-agent \u2014 different agents handle different stages, each with domain expertise</li> <li>Pipeline-structured \u2014 output from one agent becomes input to the next</li> <li>Skill-enhanced \u2014 the editor agent loads the <code>editing-hbr-articles</code> skill to apply codified editorial standards during its editing pass</li> <li>Self-reviewing \u2014 the editor agent applies quality criteria from that skill before the human sees the draft</li> <li>Gate-controlled \u2014 a built-in safety mechanism (called a \"hook\") automatically pauses the pipeline for human review before publishing</li> <li>End-to-end \u2014 produces a finished deliverable (PDF + markdown) from a single goal statement</li> </ul>"},{"location":"business-first-ai-framework/build/autonomous-agent/#when-to-use","title":"When to Use","text":"<p>Use autonomous agent workflows when the task:</p> <ul> <li>Requires multiple distinct capabilities (research, writing, editing, formatting)</li> <li>Follows a pipeline where each stage has clear inputs and outputs</li> <li>Benefits from specialist expertise at each stage</li> <li>Produces a deliverable that should meet professional standards</li> <li>Can include a human review gate without breaking the flow</li> </ul>"},{"location":"business-first-ai-framework/build/autonomous-agent/#example-scenario","title":"Example Scenario","text":"<p>The problem: A business leader wants to publish an HBR-style article about companies successfully using AI agents. The process requires deep research (finding real case studies with quantified outcomes), executive-level writing (translating technical concepts for business audiences), rigorous editing (applying HBR editorial standards), and professional publishing (PDF formatting with SEO metadata). Doing this manually involves multiple skill sets and takes days of focused work.</p> <p>The solution: A multi-agent pipeline in Claude Code. One prompt triggers a chain of specialized agents \u2014 a researcher finds case studies, a writer produces the article, an editor applies HBR standards, the human reviews the draft, and a publisher formats the final deliverable. Each agent brings domain expertise that would otherwise require a different person.</p>"},{"location":"business-first-ai-framework/build/autonomous-agent/#the-goal-prompt","title":"The Goal Prompt","text":"<p>This single prompt triggers the entire pipeline:</p> <p>\"Please write an analysis and Harvard Business Review-style article on successful companies that you can find by doing research that have successfully used and applied AI agents to their business. This article is for a business leadership audience, and I'd like to have the final deliverable as a PDF, and markdown file.\"</p>"},{"location":"business-first-ai-framework/build/autonomous-agent/#building-blocks","title":"Building Blocks","text":"<p>All building blocks are already included in the <code>business-first-ai</code> plugin \u2014 no additional installation required.</p> Building Block Type Role in Pipeline Source <code>ai-productivity-researcher</code> Agent Finds documented case studies of companies using AI with quantified outcomes View on GitHub <code>tech-executive-writer</code> Agent Writes the article for a business leadership audience View on GitHub <code>hbr-editor</code> Agent Edits the draft against HBR editorial standards View on GitHub <code>editing-hbr-articles</code> Skill Provides editorial criteria and cut/replace patterns for the editor View on GitHub <code>hbr-publisher</code> Agent Formats the approved article as PDF and markdown with SEO metadata View on GitHub"},{"location":"business-first-ai-framework/build/autonomous-agent/#how-it-works","title":"How It Works","text":"<pre><code>graph TD\n    A[\"Goal prompt\"] --&gt; B[\"Claude Code&lt;br&gt;(orchestrator)\"]\n    B --&gt; C[\"ai-productivity-researcher&lt;br&gt;finds case studies\"]\n    C --&gt; D[\"tech-executive-writer&lt;br&gt;drafts the article\"]\n    D --&gt; E[\"hbr-editor&lt;br&gt;+ editing-hbr-articles skill\"]\n    E --&gt; F{\"SubagentStop Hook\"}\n    F --&gt; G[\"Human reviews draft\"]\n    G --&gt;|Approved| H[\"hbr-publisher&lt;br&gt;formats PDF + markdown\"]\n    G --&gt;|Rejected| I((\"Stop\"))\n    H --&gt; J[\"Final deliverables:&lt;br&gt;PDF + markdown article\"]\n</code></pre> <p>Step-by-step:</p> <ol> <li>User provides the goal \u2014 a single prompt describing the article topic, audience, and desired deliverables.</li> <li><code>ai-productivity-researcher</code> runs \u2014 searches news outlets, business publications, and analyst reports for documented case studies of companies using AI agents. Prioritizes HBR-caliber sources with quantified outcomes (revenue impact, productivity gains, cost savings).</li> <li><code>tech-executive-writer</code> runs \u2014 takes the research output and produces a full-length article. Translates technical AI concepts for a non-technical business audience. Structures the piece with a compelling narrative, specific examples, and executive-level insights.</li> <li><code>hbr-editor</code> runs \u2014 reads the <code>editing-hbr-articles</code> skill to load editorial criteria, then edits the draft. Checks structure (does the opening hook?), evidence quality (are claims supported by named companies and data?), voice (active, no hedging), and length (2,500-3,500 words for features). Makes direct, prescriptive edits.</li> <li>Pipeline pauses for review \u2014 a hook (an automatic rule in Claude Code that triggers at a specific point) stops the pipeline and presents the edited draft to the human.</li> <li>Human reviews \u2014 reads the edited article and either approves it to continue or stops the pipeline for manual revision.</li> <li><code>hbr-publisher</code> runs (on approval) \u2014 formats the article for web publication (SEO metadata, social snippets) and generates a professional PDF. Produces two files: a markdown version and a PDF.</li> </ol>"},{"location":"business-first-ai-framework/build/autonomous-agent/#the-pipeline-in-detail","title":"The Pipeline in Detail","text":"Stage Agent/Component Input Output What Makes It Autonomous Research <code>ai-productivity-researcher</code> Goal prompt Structured case study briefs Agent decides which sources to search and which cases meet the quality bar Writing <code>tech-executive-writer</code> Research briefs Full article draft Agent structures the narrative, chooses which cases to feature, and adapts tone for the audience Editing <code>hbr-editor</code> + skill Article draft Edited draft with tracked changes Agent applies codified editorial criteria \u2014 not subjective taste, but documented standards Review gate SubagentStop hook Edited draft Human approval or rejection Pipeline pauses automatically \u2014 human decides quality, not the AI Publishing <code>hbr-publisher</code> Approved draft PDF + markdown files Agent handles formatting, metadata, and layout without human input"},{"location":"business-first-ai-framework/build/autonomous-agent/#why-multiple-agents-instead-of-one","title":"Why Multiple Agents Instead of One?","text":"<p>Each agent is a specialist. The researcher knows where to find credible business case studies. The writer knows how to structure executive-level content. The editor knows HBR's specific editorial standards (loaded from a skill file with reference criteria). The publisher knows formatting and SEO.</p> <p>A single generalist prompt could attempt all of this, but the output quality degrades because no single prompt can encode deep expertise across research methodology, executive writing style, editorial standards, and publication formatting. Splitting into specialists lets each agent focus on what it does best.</p>"},{"location":"business-first-ai-framework/build/autonomous-agent/#the-human-review-gate","title":"The Human Review Gate","text":"<p>The human review gate is critical. A \"hook\" \u2014 an automatic rule you configure in Claude Code \u2014 fires after the editor finishes and before the publisher starts, giving the human a chance to:</p> <ul> <li>Approve \u2014 the article meets standards, continue to publishing</li> <li>Reject \u2014 the article needs changes the AI can't make (factual corrections, strategic adjustments, tone shifts)</li> </ul> <p>This is a deliberate design choice. The pipeline is autonomous enough to produce a near-final draft without human involvement, but publishing is a high-stakes action \u2014 once an article goes out, it represents the author. The gate ensures a human makes that call.</p>"},{"location":"business-first-ai-framework/build/autonomous-agent/#usage","title":"Usage","text":"Claude Code (Plugin)Adapting Without Claude Code <p>All five agents and the editing skill are included in the <code>business-first-ai</code> plugin.</p> <pre><code># Install the plugin (one time)\n/plugin install business-first-ai@handsonai\n</code></pre> <p>Then provide the goal prompt:</p> <p>\"Please write an analysis and Harvard Business Review-style article on successful companies that you can find by doing research that have successfully used and applied AI agents to their business. This article is for a business leadership audience, and I'd like to have the final deliverable as a PDF, and markdown file.\"</p> <p>Claude Code orchestrates the full pipeline automatically. You'll be prompted to review the draft at the human-in-the-loop gate before publishing proceeds.</p> <p>Customize the topic</p> <p>Swap the article topic for anything relevant to a business audience. The pipeline structure stays the same \u2014 only the research and writing content changes:</p> <ul> <li>\"Write an HBR-style article about how mid-market companies are using AI to reduce customer churn\"</li> <li>\"Research and write a thought leadership piece on AI-driven supply chain optimization\"</li> <li>\"Produce a business article analyzing how professional services firms are adopting AI agents\"</li> </ul> <p>This pipeline is designed for Claude Code's multi-agent orchestration. Without it, you can still replicate the workflow manually by running each stage as a separate conversation:</p> <ol> <li>Research stage \u2014 In any AI tool with web search, prompt: \"Find 5-7 documented case studies of companies successfully using AI agents, with quantified business outcomes. Prioritize sources from HBR, McKinsey, Forrester, or major business publications.\"</li> <li>Writing stage \u2014 In a new conversation, paste the research output and prompt: \"Write a 2,500-3,500 word article for a business leadership audience about these companies' AI agent implementations. Use an HBR editorial style.\"</li> <li>Editing stage \u2014 In a new conversation, paste the draft and prompt: \"Edit this article to HBR publication standards. Focus on: opening hook, evidence quality, active voice, and cutting redundancy.\"</li> <li>Review \u2014 Read the edited draft yourself.</li> <li>Publishing \u2014 Format manually or use your preferred publishing tools.</li> </ol> <p>The manual approach works but loses the seamless handoff between agents, the codified editorial standards from the skill file, and the automatic human review gate.</p>"},{"location":"business-first-ai-framework/build/autonomous-agent/#adapting-this-example","title":"Adapting This Example","text":"<p>The HBR article pipeline is one application, but the multi-agent orchestration pattern applies to any workflow where different stages require different expertise:</p> <ul> <li>Client deliverable pipeline \u2014 researcher gathers data \u2192 analyst produces insights \u2192 writer creates the report \u2192 reviewer checks quality \u2192 designer formats the final document</li> <li>Sales proposal generation \u2014 researcher profiles the prospect \u2192 writer drafts the proposal \u2192 pricing specialist adds numbers \u2192 reviewer ensures accuracy \u2192 formatter produces the PDF</li> <li>Course content creation \u2014 researcher gathers source material \u2192 instructional designer structures the lesson \u2192 writer creates slides and exercises \u2192 editor reviews for clarity \u2192 publisher formats for the LMS</li> <li>Competitive intelligence reports \u2014 scanner monitors competitor channels \u2192 analyst identifies key changes \u2192 writer summarizes findings \u2192 editor ensures accuracy \u2192 distributor sends to stakeholders</li> </ul> <p>To adapt: identify the distinct stages of your workflow and the specialist expertise each stage requires. If you'd assign different people to different stages in a team setting, those stages are candidates for different agents.</p>"},{"location":"business-first-ai-framework/build/autonomous-agent/#related","title":"Related","text":"<ul> <li>Deterministic Automation Workflow Example \u2014 when AI follows fixed rules with no judgment needed</li> <li>AI Collaborative Workflow Example \u2014 when AI and human iterate together</li> <li>Content Creation Use Cases \u2014 more examples of AI-powered content workflows</li> <li>Research Use Cases \u2014 more examples of AI-powered research workflows</li> <li>Automation Use Cases \u2014 turning multi-agent pipelines into scheduled operations</li> <li>Discover AI Workflow Opportunities \u2014 discover which workflows are candidates for autonomous agents</li> <li>Deconstruct Workflows \u2014 break down workflows into agent-ready steps</li> <li>Plugin Marketplace \u2014 browse all agents and skills used in this pipeline</li> <li>Claude Code Subagents Documentation \u2014 official guide to creating and using subagents in Claude Code</li> </ul>"},{"location":"business-first-ai-framework/build/context/","title":"Context","text":"<p>Part of: Build Workflows</p> <p>New to context as a building block?</p> <p>See Agentic Building Blocks &gt; Context for definitions, examples, and cross-platform implementation details.</p>"},{"location":"business-first-ai-framework/build/context/#what-this-is","title":"What This Is","text":"<p>Context is all the knowledge the AI needs to do your workflow well but doesn't have within the model itself. Your company's style guide, your buyer persona, your CRM data, your scoring rubric \u2014 the AI has broad general knowledge, but it doesn't know your specific business. Context bridges that gap. Without the right context, even a perfect prompt produces generic output.</p> <p>Your AI Building Block Spec includes a Context Inventory \u2014 a table listing every piece of context the workflow needs. This page shows you how to create the ones that don't exist yet.</p> What you'll do Open your Building Block Spec's Context Inventory, identify which artifacts need creation, and create them What you'll get A set of context artifacts ready to attach or pre-load when running your workflow Time Varies by artifact count (15-60 minutes for most workflows)"},{"location":"business-first-ai-framework/build/context/#what-context-looks-like","title":"What Context Looks Like","text":"<p>Context isn't just documents. It's any information from your world that the AI needs to produce specific, accurate output. Here are common types with examples:</p>"},{"location":"business-first-ai-framework/build/context/#documents-and-files","title":"Documents and files","text":"<p>Written materials that capture your standards, knowledge, or requirements.</p> Example What it gives the AI Buyer persona Who you're targeting \u2014 job titles, pain points, qualifying criteria Brand style guide How to sound like your company \u2014 tone, vocabulary, formatting rules Product documentation What your product does, features, pricing, competitive positioning Company policies Rules and constraints the workflow must respect Past reports or approved examples What \"good output\" looks like \u2014 the AI matches quality and format Output templates The exact structure you want results delivered in"},{"location":"business-first-ai-framework/build/context/#data-from-applications","title":"Data from applications","text":"<p>Information pulled from the tools your team already uses. When connected via MCP, AI can access this directly. Otherwise, you export and attach it.</p> Source What it gives the AI CRM (HubSpot, Salesforce) Deal pipeline, contact history, account details Project management (Jira, Asana, Linear) Task status, sprint data, issue history Analytics (Google Analytics, Mixpanel) Traffic patterns, conversion data, user behavior Email and calendar Meeting context, conversation threads, scheduling history Support tickets (Zendesk, Intercom) Customer issues, resolution patterns, FAQ trends"},{"location":"business-first-ai-framework/build/context/#spreadsheets-and-databases","title":"Spreadsheets and databases","text":"<p>Structured data the AI processes, analyzes, or references during the workflow.</p> Example What it gives the AI Customer lists or segments Who to target, filter, or prioritize Transaction or sales data Numbers to analyze, trends to surface Survey responses or feedback Voice-of-customer data to synthesize Pricing tables or rate cards Accurate pricing for proposals or quotes Inventory or product catalogs What's available, specifications, categories"},{"location":"business-first-ai-framework/build/context/#rules-and-criteria","title":"Rules and criteria","text":"<p>Logic that tells the AI how to make decisions within the workflow. These are critical \u2014 without them, the AI guesses instead of following your standards.</p> Example What it gives the AI Scoring rubric How to evaluate and rank (lead scoring, content grading, vendor comparison) Qualification criteria What makes something pass or fail (lead qualification, application screening) Classification rules How to categorize items (support ticket routing, content tagging) Decision trees If/then logic for specific scenarios (escalation paths, approval flows) Compliance checklists Required checks before output is finalized"},{"location":"business-first-ai-framework/build/context/#domain-knowledge","title":"Domain knowledge","text":"<p>Specialized information about your industry or field that the AI's general training doesn't cover well.</p> Example What it gives the AI Industry terminology glossary Correct usage of field-specific terms Regulatory requirements Constraints the workflow must satisfy (HIPAA, SOC 2, GDPR) Competitive intelligence How competitors position, price, or operate Internal process documentation How your team actually does things (not how the org chart says)"},{"location":"business-first-ai-framework/build/context/#how-to-create-missing-context","title":"How to Create Missing Context","text":"<p>Your Building Block Spec's Context Inventory identifies what the workflow needs and whether each item already exists or needs to be created. To fill the gaps:</p> <ol> <li>Open your Building Block Spec \u2014 Find the Context Inventory table from your AI Building Block Spec</li> <li>Focus on \"Needs Creation\" items \u2014 These are the gaps you need to fill</li> <li>Start with rules and criteria \u2014 Scoring rubrics, qualification criteria, and decision logic are often required for the workflow to function correctly. Without them, the AI guesses instead of following your standards.</li> <li>Use the \"Key Contents\" column as your outline \u2014 The Building Block Spec already identified what each artifact should contain. A buyer persona artifact might list: target job titles, company size range, industry verticals, pain points, and qualifying criteria. Use that as your drafting checklist.</li> <li>Create each artifact \u2014 Most context works well as a standalone Markdown file (e.g., <code>buyer-persona.md</code>, <code>scoring-rubric.md</code>). Data exports work as CSV or spreadsheet files.</li> <li>Then fill in background knowledge \u2014 Documents like style guides and product specs improve output quality but aren't usually blockers. Create these after the critical pieces are in place.</li> </ol>"},{"location":"business-first-ai-framework/build/context/#where-context-lives","title":"Where Context Lives","text":"<p>How you provide context depends on your platform and how often you run the workflow:</p> Method Best for How it works Attached to a conversation One-off runs, infrequent workflows Drag and drop files when you paste the prompt In a Project Frequent workflows (weekly+) Upload as project files that persist across conversations. See Projects. Connected via MCP Live data from apps and databases AI reads directly from the source \u2014 no manual export needed. See MCP. In CONTEXT.md files Developer workflows (Claude Code) Markdown files named <code>CONTEXT.md</code> placed in your project folder \u2014 Claude Code (an AI coding tool that runs in the terminal) reads them automatically when you start a conversation <p>When you run the Prompt step later, the generated output will include a Where to Run section that recommends which approach fits your workflow based on how many context files you have and how often you'll run it.</p>"},{"location":"business-first-ai-framework/build/context/#testing-your-context","title":"Testing Your Context","text":"<p>Run a workflow step with and without a context artifact. Compare the output quality. This tells you which artifacts are truly essential vs. nice-to-have.</p> <p>If the output is noticeably worse without an artifact, it's essential \u2014 keep it. If the output is roughly the same, the artifact is optional \u2014 you can deprioritize or skip it.</p>"},{"location":"business-first-ai-framework/build/context/#whats-next","title":"What's Next","text":"<p>With your context artifacts created, set up a Project workspace if your workflow runs frequently, then build Skills for complex steps before generating your Prompt.</p>"},{"location":"business-first-ai-framework/build/design/","title":"Design Your AI Workflow","text":"<p>Part of: Build Workflows</p> <p>New to the seven building blocks?</p> <p>See the Agentic Building Blocks reference for definitions, examples, and cross-platform comparisons.</p>"},{"location":"business-first-ai-framework/build/design/#what-this-is","title":"What This Is","text":"<p>The Design phase is where you decide how your workflow should be built \u2014 before you build it. You take the Workflow Definition from the Deconstruct step and make three design decisions:</p> <ol> <li>Execution pattern \u2014 How complex does the AI implementation need to be?</li> <li>Autonomy classification \u2014 How much AI assistance does each step need?</li> <li>Building block mapping \u2014 What specific AI components does each step require?</li> </ol> What you'll do Upload your Workflow Definition, review the AI's execution pattern recommendation and step classifications, and adjust anything that doesn't look right What you'll get An AI Building Block Spec \u2014 execution pattern, autonomy classifications, building block mapping, skill candidates, agent configurations (when applicable), and a prioritized build sequence Time ~10\u201315 minutes (mostly reviewing the AI's analysis)"},{"location":"business-first-ai-framework/build/design/#why-this-matters","title":"Why This Matters","text":"<p>Not every workflow needs the same level of AI infrastructure. A weekly status report might need a single well-crafted prompt. A multi-department content pipeline might need specialized agents coordinating across stages. Choosing the wrong execution pattern means either over-engineering (building agents when a prompt would do) or under-building (forcing a prompt to do agent-level work).</p> <p>Design also maps each step to specific AI building blocks \u2014 Prompt, Context, Skill, Agent, MCP, or Project \u2014 so you know exactly what to build. The recommended implementation order (quick wins first, complex agent steps last) gives you a practical sequence for rolling out AI incrementally.</p>"},{"location":"business-first-ai-framework/build/design/#execution-pattern-spectrum","title":"Execution Pattern Spectrum","text":"<p>Every AI workflow falls somewhere on this spectrum. The right pattern depends on what your workflow actually needs \u2014 not on how sophisticated you want it to be.</p> Pattern Description Signals Prompt Single self-contained prompt, all logic inline Sequential steps, human drives the process and provides all inputs Skill-Powered Prompt Prompt invoking reusable skills for complex sub-routines Repeatable sub-routines, moderate complexity, steps that recur across workflows Single Agent One autonomous agent with tool access Tool use required, autonomous decisions, multi-step reasoning Multi-Agent Specialized agents in a pipeline Multiple expertise domains, parallel execution, review gates between stages"},{"location":"business-first-ai-framework/build/design/#choosing-a-pattern","title":"Choosing a Pattern","text":"<p>Work through these five questions in order. The first \"yes\" tells you the minimum pattern your workflow needs:</p> <ol> <li>Does the workflow require tool use? (web search, file access, APIs, databases) \u2192 If no, you're in Prompt or Skill-Powered Prompt territory</li> <li>Does it require autonomous decision-making? (the AI needs to decide what to do next based on what it finds) \u2192 If yes, you need at least a Single Agent</li> <li>Are there steps with complex, reusable logic? (sub-routines that appear in multiple workflows or need consistent execution) \u2192 If yes, those steps are skill candidates</li> <li>Does it span multiple expertise domains? (research vs. writing vs. editing, each needing different instructions) \u2192 If yes, consider Multi-Agent</li> <li>Would it benefit from parallel execution or review gates? (stages that can run simultaneously, or checkpoints where a human should review before proceeding) \u2192 If yes, Multi-Agent</li> </ol> <p>Most workflows start as Prompt or Skill-Powered Prompt and evolve toward agents as you add automation. Start simple, upgrade when you hit limits.</p> <p>Deeper architectural patterns</p> <p>For detailed implementation blueprints (prompt chaining, routing, parallelization, orchestrator-workers, evaluator-optimizer, and autonomous agents), see Workflow Architecture Patterns.</p>"},{"location":"business-first-ai-framework/build/design/#autonomy-classification","title":"Autonomy Classification","text":"<p>For each step in your Workflow Definition, classify it on the autonomy spectrum:</p> Level Description Example Human Requires human judgment, creativity, or physical action; AI cannot perform this Final approval of a contract, in-person meeting Deterministic Follows fixed rules; AI executes reliably with minimal supervision Formatting a report, extracting data from a template Semi-Autonomous AI does most of the work; human reviews at key checkpoints Drafting an email for human review before sending Autonomous AI executes end-to-end, including decisions and tool use Research agent that finds, evaluates, and summarizes sources"},{"location":"business-first-ai-framework/build/design/#building-block-mapping","title":"Building Block Mapping","text":"<p>Map each AI-assisted step to one or more of the seven building blocks:</p> Block What It Is When to Use It Model The AI engine that processes inputs and generates outputs When the task requires specific capabilities (reasoning, multimodal, speed) that influence model choice Prompt A well-crafted instruction that tells the model what to do for this step Every AI step needs at least a prompt Context Background information, reference documents, examples, or data the model needs When the step requires domain-specific knowledge not in the model's training Skill A reusable routine \u2014 give it inputs, it follows a defined process, it produces consistent outputs When a step has complex logic that recurs across workflows Agent An autonomous AI that plans, uses tools, and executes multi-step work When a step requires tool use, adaptive reasoning, or autonomous decisions MCP A connector giving the model access to external tools, APIs, databases, or services When a step needs to read from or write to external systems Project A persistent workspace grouping prompts, context, skills, and agents When the workflow runs frequently with the same reference materials <p>Also identify for each step:</p> <ul> <li>Tools and connectors \u2014 What external tools, APIs, or integrations does this step need?</li> <li>Human-in-the-loop gates \u2014 Where should a human review before the workflow continues?</li> </ul>"},{"location":"business-first-ai-framework/build/design/#skill-candidate-identification","title":"Skill Candidate Identification","text":"<p>Steps that should become skills share these characteristics:</p> <ul> <li>Reusable \u2014 The logic appears in multiple workflows or will be run repeatedly</li> <li>Complex \u2014 More than a simple instruction; involves multi-step reasoning, evaluation criteria, or domain expertise</li> <li>Consistent \u2014 Needs to produce reliable, repeatable outputs every time</li> </ul> <p>For each skill candidate, document enough detail for generation:</p> Detail What to capture Purpose What the skill does in one sentence Inputs What data or information the skill receives Outputs What the skill produces Decision logic Key rules, criteria, or evaluation frameworks Failure modes What happens when inputs are missing or unexpected <p>On the Claude platform, this detail enables auto-generation of <code>SKILL.md</code> files during the Construct phase. On other platforms, use it to create custom instructions, GPTs, or Gems.</p>"},{"location":"business-first-ai-framework/build/design/#agent-configuration","title":"Agent Configuration","text":"<p>When the execution pattern is Single Agent or Multi-Agent, document each agent your workflow needs:</p> Component What to specify Name Unique agent name Description Agent purpose and when it should be used Instructions Mission, responsibilities, behavior, goals, tone &amp; style, output format Model Recommended model capability (reasoning-heavy, fast, etc.) Tools Tools the agent can call (MCP servers, file access, web, APIs) <p>Plus:</p> <ul> <li>Context \u2014 What data, files, or knowledge base does the agent need access to?</li> <li>Goal \u2014 What triggers this agent and what does it produce?</li> </ul> <p>For multi-agent workflows, also document:</p> <ul> <li>Orchestration pattern \u2014 Supervisor (one agent delegates), pipeline (agents in sequence), or parallel (agents work simultaneously)</li> <li>Agent handoffs \u2014 What does each agent pass to the next? What format?</li> <li>Human review gates \u2014 Where does a human review output before the pipeline continues?</li> </ul> <p>This agent configuration is platform-agnostic \u2014 it serves as a blueprint usable on any AI platform:</p> <ul> <li>Claude \u2014 Auto-generated as <code>.md</code> agent files during Construct</li> <li>OpenAI \u2014 Used to configure GPTs or Assistants (custom instructions, tools, knowledge)</li> <li>M365 Copilot \u2014 Used to configure Copilot agents (instructions, connectors, knowledge)</li> <li>Google Gemini \u2014 Used to configure Gems or agents (instructions, extensions, grounding)</li> </ul>"},{"location":"business-first-ai-framework/build/design/#how-to-use-this","title":"How to Use This","text":"<p>There are two ways to run the Design phase, depending on which tools you use:</p>"},{"location":"business-first-ai-framework/build/design/#option-a-prompt-template-any-ai-tool","title":"Option A: Prompt template (any AI tool)","text":"<ol> <li>Copy the prompt from the code block below</li> <li>Paste it into a new conversation in your preferred AI tool</li> <li>Press Enter \u2014 the model will ask you to paste your Workflow Definition</li> <li>Upload or paste your Workflow Definition file (<code>[workflow-name]-definition.md</code>) from the Deconstruct step</li> <li>Review the analysis \u2014 the model will recommend an execution pattern, classify steps, and map building blocks</li> <li>Download the AI Building Block Spec the model produces at the end \u2014 a Markdown file named <code>[workflow-name]-building-block-spec.md</code></li> <li>Keep this file \u2014 you'll use it in the Construct phase, and you can share it with your team for feedback</li> </ol>"},{"location":"business-first-ai-framework/build/design/#option-b-claude-skill","title":"Option B: Claude skill","text":"<p>Use the <code>building-workflows</code> skill from the Business-First AI plugin. It reads the Workflow Definition, runs the Design analysis, and saves the AI Building Block Spec automatically.</p> <ul> <li>Claude Code or Cowork \u2014 install the plugin (<code>/plugin install business-first-ai@handsonai</code>) and start with:     <pre><code>Design the AI workflow from outputs/[workflow-name]-definition.md.\nRecommend an execution pattern and map building blocks.\n</code></pre>     The AI Building Block Spec is saved to <code>outputs/[workflow-name]-building-block-spec.md</code>.</li> <li>Claude.ai \u2014 zip the <code>building-workflows</code> skill folder and upload it via Settings &gt; Capabilities &gt; Upload skill, then start a new chat with: \"Design my AI workflow from this Workflow Definition.\" Upload or paste your Workflow Definition when prompted. See Using Skills in Claude.ai for detailed instructions.</li> </ul> <p>Design is mostly analytical</p> <p>Unlike the Deconstruct step's extended back-and-forth, the Design phase is shorter. The model does the heavy lifting \u2014 recommending an execution pattern, classifying steps, mapping building blocks, and identifying skill and agent candidates. Expect 10-15 minutes of light interaction.</p>"},{"location":"business-first-ai-framework/build/design/#the-prompt","title":"The Prompt","text":"<pre><code>You are an expert AI Workflow Designer who specializes in translating business workflow definitions into AI implementation blueprints. Your job is to take a structured Workflow Definition, choose the right execution pattern, classify each step on the autonomy spectrum, map it to AI building blocks, and produce a complete AI Building Block Spec.\n\nI have a Workflow Definition from a previous conversation. I'll paste it when you ask for it.\n\n---\n\n## Part 1 \u2014 Paste Your Workflow Definition\n\nSay: \"Upload your Workflow Definition file, or paste its contents below, then press Enter.\"\n\nWait for me to provide it. After receiving the Workflow Definition, confirm you've read it by summarizing: the workflow name, the number of steps, and the workflow outcome. Then proceed to Part 2.\n\n---\n\n## Part 2 \u2014 Execution Pattern Assessment\n\nBefore classifying individual steps, assess the overall workflow against the execution pattern spectrum:\n\n| Pattern | Description | Signals |\n|---------|-------------|---------|\n| **Prompt** | Single self-contained prompt, all logic inline | Sequential steps, human drives the process and provides all inputs |\n| **Skill-Powered Prompt** | Prompt invoking reusable skills | Repeatable sub-routines, moderate complexity |\n| **Single Agent** | One autonomous agent with tool access | Tool use, autonomous decisions, multi-step reasoning |\n| **Multi-Agent** | Specialized agents in a pipeline | Multiple expertise domains, parallel execution, review gates |\n\nWork through five decision questions:\n1. Does the workflow require tool use? (web, files, APIs)\n2. Does it require autonomous decision-making?\n3. Are there steps with complex, reusable logic? \u2192 skill candidates\n4. Does it span multiple expertise domains?\n5. Would it benefit from parallel execution or review gates?\n\nPresent your recommended execution pattern with reasoning. Ask if I agree before proceeding.\n\n---\n\n## Part 3 \u2014 AI Building Block Mapping\n\nFor each refined step from the Workflow Definition, determine:\n\n1. **Autonomy classification** \u2014 Classify each step on the autonomy spectrum:\n   - **Human step** \u2014 Requires human judgment, creativity, or physical action; AI cannot perform this\n   - **AI step (deterministic)** \u2014 Repeatable with clear rules; AI can execute reliably with minimal supervision\n   - **AI step (semi-autonomous)** \u2014 AI handles most of the work but needs human review at key checkpoints\n   - **AI step (fully autonomous / agentic)** \u2014 AI executes end-to-end, including decisions and tool use, with no human in the loop\n\n2. **AI building block** \u2014 Map each AI-assisted step to one or more of these seven building blocks:\n   - **Model** \u2014 The AI engine for this step; choose based on the step's requirements (speed, reasoning depth, multimodal)\n   - **Prompt** \u2014 A well-crafted instruction that tells the model what to do for this step\n   - **Context** \u2014 Background information, reference documents, examples, or data the model needs to perform the step well\n   - **Skill** \u2014 A reusable routine the model can invoke \u2014 give it inputs, it follows a defined process, it produces consistent outputs (on Claude, this is a Claude Code Skill; on other platforms, this maps to custom instructions, GPTs, or Gems)\n   - **Agent** \u2014 An autonomous AI that plans, uses tools, and executes multi-step work with minimal supervision\n   - **MCP (Model Context Protocol)** \u2014 A connector that gives the model access to external tools, APIs, databases, or services\n   - **Project** \u2014 A persistent workspace that groups prompts, context, skills, and agents for a specific workflow\n\n3. **Tools and connectors** \u2014 What external tools, APIs, or integrations does this step need?\n\n4. **Human-in-the-loop gates** \u2014 Flag any steps where human review is recommended before the workflow continues, even if the step is AI-executed.\n\n5. **Skill candidate flag** \u2014 Tag steps that should become skills. For each skill candidate, note: purpose, inputs, outputs, decision logic, and failure modes \u2014 enough detail for a skill to be built from this description alone.\n\nPresent the mapping as a clear table, then walk me through your reasoning for any non-obvious classifications. Ask if I want to adjust anything before proceeding.\n\n---\n\n## Part 4 \u2014 Agent Configuration (if applicable)\n\nIf the recommended execution pattern is Single Agent or Multi-Agent, document the agent configuration.\n\nFor each agent the workflow needs, specify:\n\n| Component | What to specify |\n|-----------|----------------|\n| **Name** | Unique agent name |\n| **Description** | Agent purpose and when it should be used |\n| **Instructions** | Mission, responsibilities, behavior, goals, tone &amp; style, output format |\n| **Model** | Recommended model capability (reasoning-heavy, fast, etc.) |\n| **Tools** | Tools the agent can call (MCP servers, file access, web, APIs) |\n\nPlus: **Context** requirements (data, files, knowledge base) and **Goal** (trigger/invocation pattern).\n\nFor multi-agent workflows, also document:\n- **Orchestration pattern** (supervisor, pipeline, parallel)\n- **Agent handoffs** (what each agent passes to the next)\n- **Human review gates** (where a human reviews before proceeding)\n\nThis configuration is platform-agnostic \u2014 it serves as a blueprint for any AI platform (Claude, OpenAI, M365 Copilot, Google Gemini).\n\nPresent the agent configuration and ask for my review before generating the final output. If the execution pattern is Prompt or Skill-Powered Prompt, skip this part.\n\n---\n\n## Part 5 \u2014 Generate AI Building Block Spec\n\nAfter I confirm the mapping (and agent configuration, if applicable), produce the complete **AI Building Block Spec** as a Markdown file.\n\n**File naming:** Name the file `[workflow-name]-building-block-spec.md` using the same workflow name from the Workflow Definition (e.g., `lead-qualification-building-block-spec.md`).\n\nGenerate the AI Building Block Spec as a downloadable Markdown file. If your platform doesn't support file downloads, format it inside a single Markdown code block so I can copy and save it manually.\n\n### Execution Pattern\n- Recommended pattern (Prompt / Skill-Powered Prompt / Single Agent / Multi-Agent)\n- Reasoning\n\n### Scenario Summary\n- Workflow name (from Workflow Definition)\n- Description\n- Workflow outcome\n- Trigger\n- Type\n- Business objective\n- Current owner(s)\n\n### Step-by-Step Decomposition Table\n\n| # | Step | Action | Type | Decision Points | Failure Mode | Data In | Data Out | Context Needed | AI Building Block(s) | Skill Candidate? |\n|---|------|--------|------|----------------|-------------|---------|----------|----------------|---------------------|-----------------|\n| 1 | [Name] | [What happens] | Human / AI-Deterministic / AI-Semi-Autonomous / AI-Autonomous | [If/then logic] | [What happens on failure] | [Inputs] | [Outputs] | [Knowledge required] | [Prompt / Context / Skill / Agent / MCP / Project] | Yes/No |\n\n### Autonomy Spectrum Summary\n- List of fully human steps\n- List of deterministic AI steps\n- List of semi-autonomous AI steps (with review gates noted)\n- List of fully autonomous AI steps\n\n### Skill Candidates\n\nFor each step tagged as a skill candidate:\n\n| Step | Skill Purpose | Inputs | Outputs | Decision Logic | Failure Modes |\n|------|--------------|--------|---------|---------------|---------------|\n\n### Agent Configuration (if applicable)\n\nFor each agent:\n- Name, Description, Instructions summary, Model recommendation, Tools list\n- Context requirements, Goal/trigger\n\nFor multi-agent: orchestration pattern, handoff protocol, human review gates.\n\n### Step Sequence and Dependencies\n- Which steps are sequential (must happen in order)?\n- Which steps can run in parallel?\n- What is the critical path through the workflow?\n- Step dependency map\n\n### Prerequisites\n- What must be in place before this workflow can run?\n- External dependencies (accounts, access, data sources)\n\n### Context Inventory\n\nList every piece of context the workflow requires that the model does not have in its training data:\n\n| Artifact | Description | Used By Steps | Status | Format | Key Contents |\n|----------|-------------|---------------|--------|--------|--------------|\n| [Name] | [What it contains and why the workflow needs it] | [Step numbers] | Exists / Needs Creation | [e.g., Markdown doc, spreadsheet, CSV, PDF] | [Essential fields, sections, or data points it should include] |\n\nIf an artifact needs to be created, the \"Key Contents\" column should be specific enough that the user knows exactly what to build.\n\n### Tools and Connectors Required\n- All external tools, APIs, and integrations referenced in the mapping\n\n### Recommended Implementation Order\nPrioritize the AI-eligible steps into a build sequence:\n1. **Quick wins** \u2014 Deterministic steps with clear inputs/outputs that can be automated with a Prompt or Context alone. Start here.\n2. **High-value semi-autonomous steps** \u2014 Steps where AI does most of the work but needs a human review gate. Build these next.\n3. **Complex agent steps** \u2014 Fully autonomous steps requiring Agents, MCP connectors, or multi-tool orchestration. Tackle these last.\n\nFor each priority tier, list the specific steps and what needs to be built.\n\n### Where to Run\n\nRecommend where the Baseline Workflow Prompt should be run:\n\n**Normal chat** \u2014 recommended when:\n- The workflow runs infrequently (monthly or less)\n- Few or no context files are needed (0-2 files)\n- All context can be provided inline each time\n- The workflow is a one-off or experimental process\n\n**Project workspace** \u2014 recommended when:\n- The workflow runs frequently (weekly or more)\n- Multiple context files are needed (3+ files)\n- The same reference materials are used every run\n- Conversation memory across runs would be valuable\n- Multiple people will run the same workflow\n\nState the recommendation, the reasoning, and list the specific context files to attach (chat) or pre-load in the project.\n\n**Important:** The Baseline Workflow Prompt is always self-contained \u2014 it contains all workflow logic regardless of where you run it. A project provides pre-loaded context and conversation memory, but never contains the workflow logic. The prompt IS the workflow.\n\n---\n\nAfter presenting the AI Building Block Spec, tell me:\n\n&gt; **Next step:** Download (or copy and save) the AI Building Block Spec file. Then go to [Step 3 \u2014 Build Workflows](https://handsonai.info/business-first-ai-framework/build/) to construct your workflow \u2014 the Build overview page will show you exactly which steps to follow based on your execution pattern.\n\n---\n\n## General Instructions\n\n- If the Workflow Definition is missing information needed for classification, ask me to clarify before guessing.\n- If I mention I'm using Claude, note where Skills would be the appropriate building block for reusable routines.\n- Explain your reasoning for any non-obvious classifications.\n- Use plain language. Avoid jargon unless I introduced it.\n</code></pre>"},{"location":"business-first-ai-framework/build/design/#what-this-produces","title":"What This Produces","text":"<p>The AI Building Block Spec contains:</p> <ul> <li>Execution pattern \u2014 Prompt, Skill-Powered Prompt, Single Agent, or Multi-Agent, with reasoning</li> <li>Scenario summary \u2014 workflow metadata from the Workflow Definition</li> <li>Decomposition table \u2014 every step with autonomy classification, decision points, failure modes, data flows, context needs, AI building block mapping, and skill candidate flags</li> <li>Autonomy spectrum summary \u2014 steps grouped by classification level</li> <li>Skill candidates \u2014 steps tagged for skill creation, with generation-ready detail (purpose, inputs, outputs, decision logic, failure modes)</li> <li>Agent configuration (when applicable) \u2014 platform-agnostic blueprint for each agent with all five core components plus context and goal</li> <li>Step sequence and dependencies \u2014 sequential vs. parallel execution paths</li> <li>Prerequisites \u2014 what must be in place before the workflow can run</li> <li>Context inventory \u2014 every piece of context the workflow needs, with status and key contents</li> <li>Tools and connectors \u2014 external integrations required</li> <li>Implementation order \u2014 quick wins \u2192 semi-autonomous \u2192 complex agent steps</li> </ul> <p>This AI Building Block Spec is the input for the Construct phase, where you build context, skills, prompts, agents, and MCP connections based on your execution pattern.</p>"},{"location":"business-first-ai-framework/build/deterministic-automation/","title":"Deterministic Automation","text":"<p>AI involvement: Executes a predefined sequence \u2014 criteria come from the input, output follows a fixed template.</p>"},{"location":"business-first-ai-framework/build/deterministic-automation/#what-this-workflow-type-is","title":"What This Workflow Type Is","text":"<p>A deterministic automation is a workflow where AI follows a fixed sequence of steps, applies predefined evaluation criteria, and produces output in a rigid template. The rules are defined upfront (in this case, by a buyer persona), the process is linear, and the output format never changes. The same input produces the same structured output every time.</p> <p>At a Glance</p> <ul> <li>AI involvement: Follows prescribed steps and applies predefined criteria</li> <li>Human oversight: Review output only \u2014 no steering during execution</li> <li>Best for: Prospecting, recurring reports, data formatting, template-driven research</li> <li>Complexity: Low \u2014 single prompt with structured input, no iteration required</li> </ul>"},{"location":"business-first-ai-framework/build/deterministic-automation/#characteristics","title":"Characteristics","text":"<ul> <li>Repeatable \u2014 runs the same way every time with any buyer persona</li> <li>Predictable \u2014 output format and evaluation criteria are defined in advance</li> <li>Delegatable \u2014 anyone with the persona file can run it and get consistent results</li> <li>Automatable \u2014 can run on a schedule or be triggered by a pipeline</li> </ul>"},{"location":"business-first-ai-framework/build/deterministic-automation/#when-to-use","title":"When to Use","text":"<p>Use deterministic automation when you have a task that:</p> <ul> <li>Follows clear, documented rules or criteria</li> <li>Takes structured input and produces structured output</li> <li>Doesn't require subjective judgment during execution</li> <li>Repeats on a regular cadence (weekly prospecting, monthly reporting)</li> </ul>"},{"location":"business-first-ai-framework/build/deterministic-automation/#example-scenario","title":"Example Scenario","text":"<p>The problem: A sales leader needs to identify LinkedIn prospects that match a specific buyer persona. The research process is always the same \u2014 search by title and industry, evaluate against persona criteria, document findings in a consistent format \u2014 but manually doing it takes 45-60 minutes per batch. The criteria don't change between runs; only the prospects found are different.</p> <p>The solution: A workflow prompt that takes a buyer persona as input, executes a prescribed LinkedIn research sequence, and produces a structured prospect report with engagement recommendations. The evaluation criteria come directly from the persona file, so there's no subjective judgment \u2014 just systematic matching.</p>"},{"location":"business-first-ai-framework/build/deterministic-automation/#building-blocks","title":"Building Blocks","text":"Building Block Type Description Source <code>linkedin-prospect-research</code> Prompt Workflow that finds and qualifies 5 LinkedIn prospects against a buyer persona View on GitHub <code>buyer-persona-revenue-leader-rachel</code> Prompt Example buyer persona used as input to the research workflow View on GitHub"},{"location":"business-first-ai-framework/build/deterministic-automation/#how-it-works","title":"How It Works","text":"<pre><code>graph LR\n    A[Buyer persona&lt;br&gt;defines criteria] --&gt; B[Workflow prompt&lt;br&gt;searches LinkedIn]\n    B --&gt; C[Evaluate prospects&lt;br&gt;against persona criteria]\n    C --&gt; D[Structured report&lt;br&gt;with 5 qualified prospects]\n</code></pre> <p>Step-by-step:</p> <ol> <li>Provide the buyer persona \u2014 the persona file defines the target titles, industries, company sizes, pain points, and trigger events. These become the evaluation criteria.</li> <li>Workflow analyzes the persona \u2014 extracts job titles, industry, company size, seniority, location, and exclusion criteria.</li> <li>Workflow searches LinkedIn \u2014 uses the persona criteria as search filters, systematically reviewing results.</li> <li>Workflow evaluates each prospect \u2014 checks role match, company fit, engagement signals, and accessibility (mutual connections, shared groups). Selects the top 5.</li> <li>Workflow generates the report \u2014 documents each prospect with profile URL, title, company, persona match reasons, and a specific engagement hook. Includes a summary with selection rationale, common themes, and priority ranking.</li> <li>Quality check \u2014 verifies all 5 prospects match criteria, URLs are complete, engagement recommendations are specific (not generic), and the output is properly formatted.</li> </ol>"},{"location":"business-first-ai-framework/build/deterministic-automation/#the-workflow-in-detail","title":"The Workflow in Detail","text":"<p>The prompt encodes a five-step sequence that the AI executes in order:</p> Step What Happens Why It's Deterministic 1. Analyze persona Extract titles, industry, size, location, pain points, triggers Criteria are predefined in the input file 2. Access LinkedIn Navigate and confirm authentication Binary check \u2014 logged in or not 3. Search and evaluate Apply persona criteria as search filters, score prospects Evaluation rules are fixed: title match \u2192 company fit \u2192 engagement signals \u2192 accessibility 4. Document prospects Capture name, URL, title, company, match reasons, engagement hook Output fields are prescribed 5. Generate report Format into template with summary, themes, and priority order Template is rigid \u2014 same structure every run <p>The prompt also includes explicit error handling for three failure modes (fewer than 5 matches, LinkedIn access restricted, incomplete persona), so the workflow handles exceptions without human intervention.</p>"},{"location":"business-first-ai-framework/build/deterministic-automation/#the-buyer-persona","title":"The Buyer Persona","text":"<p>The included example persona \u2014 \"Revenue Leader Rachel\" \u2014 demonstrates the kind of structured input this workflow expects. Key fields the workflow extracts:</p> <ul> <li>Target titles: SVP/VP of Revenue, CRO, VP of Customer Solutions, VP/Head of Operations, Chief Customer Officer</li> <li>Company context: B2B SaaS, 200-2,000 employees, Series B through public</li> <li>Location: Major metro areas (NYC, SF, Boston, Chicago)</li> <li>Pain points: Scaling without headcount, cross-functional execution gaps, ROI on AI investments</li> <li>Trigger events: Board asking about AI strategy, competitors announcing AI features, failed AI pilots</li> </ul> <p>You can swap in any buyer persona that follows a similar structure. The workflow adapts to whatever criteria the persona defines.</p>"},{"location":"business-first-ai-framework/build/deterministic-automation/#usage","title":"Usage","text":"Any AI Tool (Portable)Claude Code (Plugin) <p>This example uses two standalone prompts \u2014 the workflow and the buyer persona. Both are plain markdown files you can use with any AI tool that has web browsing.</p> <ol> <li>Open the linkedin-prospect-research prompt on GitHub</li> <li>Open the buyer persona on GitHub</li> <li>Copy the workflow prompt into Claude, ChatGPT, or Gemini (with web browsing enabled)</li> <li>Paste or attach the buyer persona as context</li> <li>The AI executes the workflow and produces the prospect report</li> </ol> <p>Web browsing required</p> <p>This workflow requires an AI tool with web browsing capability (LinkedIn access). In ChatGPT, enable \"Browse with Bing.\" In Claude, use a session with computer use or MCP browser access. In Gemini, web search is enabled by default.</p> <p>If you have the <code>business-first-ai</code> plugin installed, both prompt files are available locally in the plugin directory.</p> <pre><code># Install the plugin (one time)\n/plugin install business-first-ai@handsonai\n</code></pre> <p>Then reference both files in a Claude Code conversation:</p> <p>\"Run the LinkedIn prospect research workflow using the Revenue Leader Rachel buyer persona\"</p> <p>Claude will read both files from the plugin directory, execute the workflow steps, and produce the structured report.</p>"},{"location":"business-first-ai-framework/build/deterministic-automation/#adapting-this-example","title":"Adapting This Example","text":"<p>LinkedIn prospect research is one application, but the deterministic pattern works for any task with predefined criteria and a fixed output template:</p> <ul> <li>Customer account scoring \u2014 score accounts against an ideal customer profile, produce a ranked list</li> <li>Job candidate screening \u2014 evaluate resumes against a job description's requirements, produce a shortlist with match reasons</li> <li>Vendor evaluation \u2014 assess proposals against scoring criteria, produce a comparison matrix</li> <li>Content audit \u2014 evaluate published content against brand guidelines, produce a compliance report</li> <li>Competitive monitoring \u2014 check competitor websites against a tracking template, produce a change report</li> </ul> <p>To adapt: identify the input criteria (the persona equivalent), the evaluation rules (how to score matches), and the output template (what the report looks like). If all three are defined before execution, it's a deterministic automation.</p>"},{"location":"business-first-ai-framework/build/deterministic-automation/#related","title":"Related","text":"<ul> <li>AI Collaborative Workflow Example \u2014 when AI needs to research, reason, and iterate with a human</li> <li>Autonomous Agent Workflow Example \u2014 when AI executes end-to-end with minimal supervision</li> <li>Research Use Cases \u2014 more examples of AI-powered research workflows</li> <li>Automation Use Cases \u2014 turning deterministic workflows into scheduled pipelines</li> <li>Discover AI Workflow Opportunities \u2014 discover which of your workflows are candidates for automation</li> <li>Deconstruct Workflows \u2014 break down complex workflows into automatable steps</li> </ul>"},{"location":"business-first-ai-framework/build/mcp/","title":"MCP","text":"<p>Part of: Build Workflows</p> <p>New to MCP as a building block?</p> <p>See Agentic Building Blocks &gt; MCP for definitions, available servers, and cross-platform setup instructions.</p>"},{"location":"business-first-ai-framework/build/mcp/#what-this-is","title":"What This Is","text":"<p>MCP (Model Context Protocol) gives AI access to external tools, databases, and services. It's the bridge between your AI workflow and the systems where your data lives and actions happen.</p> <p>Without MCP, the AI only knows what you paste into the conversation. With MCP, it can look up records in your CRM, check task status in your project management tool, search your Notion workspace, or pull live data from a database \u2014 all within the conversation, without you copying and pasting.</p> What you'll do Review your Building Block Spec for steps requiring external tool access, then configure the MCP connections those steps need What you'll get Working connections between your AI workflow and external systems Time 10-30 minutes per connection (varies by tool complexity) <p>Most workflows don't need MCP</p> <p>If your workflow runs on information you can paste into a conversation or upload as files, you don't need MCP. Only add it when your workflow requires live data from external systems or needs the AI to take actions in other tools (creating tasks, updating records, sending messages).</p>"},{"location":"business-first-ai-framework/build/mcp/#when-you-need-mcp","title":"When You Need MCP","text":"<p>Look at your AI Building Block Spec:</p> <ul> <li>Steps tagged with \"MCP\" in the AI Building Block(s) column</li> <li>The Tools and Connectors Required section lists every external integration</li> <li>Steps requiring web browsing, database access, file system access, or API calls</li> </ul> <p>If your Building Block Spec doesn't tag any steps with MCP, skip this page and go straight to Run.</p>"},{"location":"business-first-ai-framework/build/mcp/#what-configuring-mcp-looks-like","title":"What Configuring MCP Looks Like","text":"<p>Connecting an external tool works like connecting an app to your phone \u2014 you set it up once, authorize access, and then it's available whenever you need it.</p> <p>Each connection has three parts:</p> <ol> <li>Get access credentials \u2014 Most tools require an API key (a password-like code that authorizes the connection). You create this in the external tool's settings, usually under \"Integrations\" or \"Developer.\"</li> <li>Add the connection to your AI tool \u2014 Tell your AI tool where to find the external service and how to authenticate. The specifics depend on your platform (see table below).</li> <li>Test it \u2014 Ask the AI to do something simple with the connected tool (\"Search my Notion workspace for...\") to verify the connection works.</li> </ol>"},{"location":"business-first-ai-framework/build/mcp/#how-different-platforms-handle-external-connections","title":"How different platforms handle external connections","text":"Platform What it's called How to set it up Claude Code MCP servers Add server configuration to your project's settings file. Claude Code runs the server locally on your computer. Claude Desktop MCP servers Same as Claude Code \u2014 add to the app's configuration file. ChatGPT Actions (in Custom GPTs) Build into a Custom GPT using the Actions section of the GPT builder. Define the external API endpoint and authentication. Gemini Extensions Enable built-in extensions (Google Workspace, Maps, YouTube) in settings, or connect custom services via the API. M365 Copilot Connectors + Power Platform Configure in Copilot Studio or through the Microsoft 365 admin center. Pre-built connectors available for many business tools. <p>The concept is the same on every platform: you're giving AI authorized access to read from or write to an external system. The setup steps differ, but the result is the same.</p>"},{"location":"business-first-ai-framework/build/mcp/#common-mcp-patterns","title":"Common MCP Patterns","text":"Pattern What the AI can do Example tools Knowledge management Read and write to your knowledge bases \u2014 search pages, create entries, update records Notion, Confluence, Google Drive Project management Create tasks, update status, query boards Linear, Jira, Asana, Trello Communication Read messages, send updates, manage threads Slack, Email, Teams Data access Query databases, retrieve records, run reports PostgreSQL, Supabase, Airtable Web research Search the web, visit pages, collect information Browser automation, web search File systems Read and write local files, process documents Local file system access"},{"location":"business-first-ai-framework/build/mcp/#example-connecting-notion","title":"Example: Connecting Notion","text":"<p>Here's what it looks like to connect a common tool \u2014 Notion \u2014 so you can see the shape of the process:</p> <ol> <li>Create a Notion integration \u2014 Go to notion.so/my-integrations, click New integration, give it a name, and copy the API key it generates</li> <li>Share your Notion pages with the integration \u2014 In Notion, open each database or page you want the AI to access, click ... &gt; Connections &gt; select your integration</li> <li>Add the connection to your AI tool \u2014 On Claude Code, this means adding the Notion MCP server to your configuration with the API key. On ChatGPT, you'd add Notion as an Action in your Custom GPT.</li> <li>Test it \u2014 Ask the AI: \"Search my Notion workspace for [something you know exists]\" \u2014 if it finds it, you're connected</li> </ol> <p>After setup, the AI can search your databases, create pages, and update records as part of your workflow \u2014 no more copying and pasting data between Notion and your AI tool.</p>"},{"location":"business-first-ai-framework/build/mcp/#how-mcp-connects-to-your-workflow","title":"How MCP Connects to Your Workflow","text":"<ol> <li>Check \"Tools and Connectors Required\" in your Building Block Spec \u2014 each external tool listed needs a connection</li> <li>Start with one connection \u2014 Pick the single external system your workflow depends on most. Get that working before adding more.</li> <li>Identify available servers \u2014 Many common tools already have pre-built MCP servers or connectors. See Agentic Building Blocks &gt; MCP for available options and setup guides.</li> <li>Configure and test \u2014 Follow the setup steps for your platform, then verify the AI can read from and write to the external system before running the full workflow</li> <li>Add more as needed \u2014 Once your first connection works, add others from your Building Block Spec's requirements list</li> </ol>"},{"location":"business-first-ai-framework/build/mcp/#whats-next","title":"What's Next","text":"<p>With your MCP connections configured, your workflow has everything it needs. Run your workflow on a real scenario, or return to the Build overview to review the full build process.</p>"},{"location":"business-first-ai-framework/build/projects/","title":"Projects","text":"<p>Part of: Build Workflows</p> <p>New to projects as a building block?</p> <p>See Agentic Building Blocks &gt; Projects for definitions, examples, and cross-platform implementation details (Claude Projects, OpenAI Projects, Gemini Gems, M365 Copilot agents).</p>"},{"location":"business-first-ai-framework/build/projects/#what-this-is","title":"What This Is","text":"<p>A project is a persistent workspace that groups your context, prompts, and conversation history. It's where your workflow lives and runs.</p> What you'll do Decide whether your workflow needs a project, then set one up if it does What you'll get A configured workspace with your context artifacts pre-loaded, ready for repeated workflow runs Time ~5-10 minutes"},{"location":"business-first-ai-framework/build/projects/#when-to-use-a-project-vs-a-normal-chat","title":"When to Use a Project vs. a Normal Chat","text":"<p>Not every workflow needs a project. Use the Where to Run recommendation from your AI Building Block Spec as your starting point:</p> <p>Normal chat \u2014 Best when:</p> <ul> <li>The workflow runs infrequently (monthly or less)</li> <li>Few or no context files needed (0-2 files)</li> <li>All context can be provided inline each time</li> <li>The workflow is a one-off or experimental process</li> </ul> <p>Project workspace \u2014 Best when:</p> <ul> <li>The workflow runs frequently (weekly or more)</li> <li>Multiple context files needed (3+ files)</li> <li>The same reference materials are used every run</li> <li>Conversation memory across runs would be valuable</li> <li>Multiple people will run the same workflow</li> </ul> <p>Many workflows start in normal chat and graduate to a project once they're proven and refined.</p>"},{"location":"business-first-ai-framework/build/projects/#setting-up-a-project-for-your-workflow","title":"Setting Up a Project for Your Workflow","text":"<ol> <li>Create the project \u2014 Name it after your workflow (e.g., \"Lead Qualification,\" \"Weekly Report Generation\")</li> <li>Upload context artifacts \u2014 Add the files you created in the Context step</li> <li>Add custom instructions (optional) \u2014 A brief orientation for the AI about this workflow's purpose and domain. Keep this short \u2014 the prompt contains the workflow logic, not the project instructions.</li> <li>Run each workflow execution as a new conversation within the project</li> </ol>"},{"location":"business-first-ai-framework/build/projects/#what-goes-in-the-project-vs-the-prompt","title":"What Goes in the Project vs. the Prompt","text":"<p>This distinction matters:</p> <p>In the project: Context \u2014 documents, data, rules, examples, and custom instructions. These persist across conversations and don't need to be re-provided each run.</p> <p>In the prompt: Workflow logic, step sequencing, decision rules, human review gates. The prompt IS the workflow \u2014 always pasted fresh each run, never embedded in project instructions.</p> <p>The prompt is self-contained. Someone could paste it into a normal chat with the context files attached and get the same result. The project provides convenience (pre-loaded files, conversation memory), not workflow logic.</p>"},{"location":"business-first-ai-framework/build/projects/#whats-next","title":"What's Next","text":"<p>With your workspace ready, build Skills for complex steps, then generate the Prompt that drives your workflow.</p>"},{"location":"business-first-ai-framework/build/prompt/","title":"Prompt","text":"<p>Part of: Build Workflows</p> <p>New to prompts as a building block?</p> <p>See Agentic Building Blocks &gt; Prompts for prompt engineering guidance and cross-platform techniques.</p>"},{"location":"business-first-ai-framework/build/prompt/#what-this-is","title":"What This Is","text":"<p>The step that turns your analysis into action. AI reads your AI Building Block Spec and generates a ready-to-use prompt you can paste into any AI tool to execute the workflow today. If you built skills in the previous step, the prompt references them \u2014 making it shorter and more maintainable.</p> What you'll do Upload your AI Building Block Spec from the Design phase, answer 1-2 clarifying questions, then review the generated prompt What you'll get A Baseline Workflow Prompt (ready to paste and run). If you built skills, the prompt invokes them by name instead of spelling out those steps. Time ~5-10 minutes (mostly generative \u2014 the AI does the heavy lifting)"},{"location":"business-first-ai-framework/build/prompt/#why-this-matters","title":"Why This Matters","text":"<p>Analysis without action is just documentation. The Baseline Workflow Prompt gives you something you can use immediately \u2014 paste it into any AI tool and run your workflow. It works on day one, on any platform.</p> <p>If you built skills in the previous step, this prompt references them \u2014 each skill invocation replaces what would otherwise be a long block of inline instructions. If you didn't build skills, the prompt spells out every step in full so it still works standalone.</p>"},{"location":"business-first-ai-framework/build/prompt/#how-to-use-this","title":"How to Use This","text":"<p>There are two ways to generate your prompt, depending on which tools you use:</p>"},{"location":"business-first-ai-framework/build/prompt/#option-a-prompt-template-any-ai-tool","title":"Option A: Prompt template (any AI tool)","text":"<ol> <li>Copy the prompt from the code block below</li> <li>Paste it into a new conversation in your preferred AI tool</li> <li>Press Enter \u2014 the model will ask you to upload or paste your AI Building Block Spec</li> <li>Upload or paste your AI Building Block Spec file (<code>[workflow-name]-building-block-spec.md</code>) from the Design phase</li> <li>If you built skills, list them when the AI asks \u2014 it generates a prompt that references your skills instead of spelling out those steps</li> <li>Review the output \u2014 the model may ask 1-2 clarifying questions, then generates the Baseline Workflow Prompt</li> <li>Download the file \u2014 save as <code>[name]-prompt.md</code></li> </ol>"},{"location":"business-first-ai-framework/build/prompt/#option-b-claude-skill-building-workflows","title":"Option B: Claude skill (<code>building-workflows</code>)","text":"<p>Use the <code>building-workflows</code> skill from the Business-First AI plugin. You still need to provide your AI Building Block Spec \u2014 the skill guides the conversation but doesn't have your file until you upload it.</p> Claude Code or CoworkClaude.ai <ol> <li>Install the plugin (one time): <code>/plugin install business-first-ai@handsonai</code></li> <li>Start a new conversation and say:     <pre><code>Generate the Baseline Workflow Prompt\nfrom the AI Building Block Spec in outputs/[workflow-name]-building-block-spec.md.\n</code></pre></li> <li>Claude reads your file from the path you specified and summarizes what it found \u2014 confirm before proceeding</li> <li>If you built skills, list them when Claude asks \u2014 it generates a prompt that references your skills instead of spelling out those steps</li> <li>Review the output \u2014 Claude may ask 1-2 clarifying questions, then generates the Baseline Workflow Prompt</li> <li>Claude saves the file to <code>outputs/[workflow-name]-prompt.md</code></li> </ol> <ol> <li>Install the skill \u2014 zip the <code>building-workflows</code> skill folder and upload it via Settings &gt; Capabilities &gt; Upload skill (see Using Skills in Claude.ai for detailed instructions)</li> <li>Start a new chat and say: \"Generate a Baseline Workflow Prompt from this AI Building Block Spec.\"</li> <li>Upload or paste your AI Building Block Spec file (<code>[workflow-name]-building-block-spec.md</code>) when prompted</li> <li>If you built skills, list them when Claude asks \u2014 it generates a prompt that references your skills instead of spelling out those steps</li> <li>Review the output \u2014 Claude may ask 1-2 clarifying questions, then generates the Baseline Workflow Prompt</li> <li>Download the file \u2014 save as <code>[workflow-name]-prompt.md</code></li> </ol> <p>This step is mostly generative</p> <p>The heavy analytical work is done. The model reads your AI Building Block Spec and produces a structured prompt with minimal interaction. Expect 5-10 minutes.</p> <p>Register and commit</p> <p>After generating your Baseline Workflow Prompt, register it in your AI Registry Notion database and commit the <code>[name]-prompt.md</code> file to your GitHub repository. This applies to all building blocks you create \u2014 prompts, skills, and agents.</p>"},{"location":"business-first-ai-framework/build/prompt/#the-prompt","title":"The Prompt","text":"<pre><code>You are an expert Prompt Engineer who writes clear, precise instructions that language models can execute reliably. Your job is to take an AI Building Block Spec and produce a Baseline Workflow Prompt.\n\nI have an AI Building Block Spec from a previous conversation. I'll paste it when you ask for it.\n\n---\n\n## Part 1 \u2014 Paste Your AI Building Block Spec\n\nSay: \"Upload your AI Building Block Spec file, or paste its contents below, then press Enter.\"\n\nWait for me to provide it. After receiving the document, confirm you've read it by summarizing: the workflow name, the number of steps, how many are AI-eligible, and the AI building blocks identified. Then proceed to Part 1b.\n\nIf anything in the AI Building Block Spec is ambiguous or seems incomplete, ask me to clarify before generating outputs. Do not guess at missing information.\n\n---\n\n## Part 1b \u2014 Check for Skills\n\nAsk: \"Did you build any skills for this workflow? If yes, list each skill name and which workflow steps it covers. If no, I'll generate the full baseline prompt with all steps spelled out.\"\n\nIf the user provides skills: note which steps are covered. In Part 2, replace those steps with skill invocations instead of spelling out the full logic.\n\nIf the user says no: proceed to Part 2 and spell out every step in full.\n\n---\n\n## Part 2 \u2014 Generate Baseline Workflow Prompt\n\nGenerate a ready-to-use Markdown prompt that someone could paste into any AI tool to execute this workflow. For any step covered by a skill the user provided, replace the detailed inline instructions with a brief description of the task \u2014 the skill handles the details automatically on platforms that support it. Keep full instructions only for steps NOT covered by a skill. If no skills were provided, spell out every step in full \u2014 this is the baseline version that works on any platform (Claude, ChatGPT, Gemini, M365 Copilot).\n\n**Before generating the prompt, check the Context Inventory for any artifacts that contain existing AI instructions** \u2014 prompts, project instructions, system prompts, or custom assistant configurations the user already has. These contain workflow logic that must be included in the Baseline Prompt \u2014 not referenced, but actually included. If such artifacts exist but their content is not in the AI Building Block Spec, ask the user to paste or upload them now. The Baseline Prompt cannot reference external systems for its core logic \u2014 it must be self-contained.\n\nStructure it as:\n\n**Title and Purpose**\n- Workflow name and description (from the AI Building Block Spec)\n- Workflow outcome \u2014 what this workflow produces\n- When to use it\n\n**Instructions**\n- Numbered steps, each clearly labeled as (AI) or (Human)\n- For each AI step: specific instructions the model should follow, written as direct commands\n- For each Human step: clear description of what the human does and what they hand back to the model\n- Include the decision logic for any branching steps\n- For any step covered by a user-provided skill: describe the task briefly instead of repeating the full logic inline (the skill handles the details automatically)\n\n**Input Requirements**\n- What the user needs to provide when they run this prompt\n- Format specifications for each input\n\n**Context Requirements**\n- What reference materials, files, or data should be attached or available\n- Where to find them, or what to include if creating them from scratch\n\n**Output Format**\n- Exactly what the prompt should produce\n- Structure and format specifications\n\nThe prompt should be:\n- Self-contained (someone unfamiliar with the analysis can use it)\n- Specific enough to produce consistent results\n- Ready for version control (clean Markdown, no ambiguity)\n- Ready for team adoption (clear enough that a colleague could run it)\n\n**Self-contained means:** The prompt contains every instruction the model needs to execute the workflow. It never says \"open this project\" or \"follow those instructions\" or \"refer to the project instructions.\" If existing AI instructions drive a step, those instructions are written into the prompt. A reader who has never seen the AI Building Block Spec or Workflow Definition can execute this prompt successfully. (Exception: steps covered by a named skill \u2014 the skill handles those instructions.)\n\n**Recommended Implementation Order**\nPrioritize the AI-eligible steps into a build sequence:\n1. **Quick wins** \u2014 Deterministic steps with clear inputs/outputs that can be automated with a Prompt or Context alone. Start here.\n2. **High-value semi-autonomous steps** \u2014 Steps where AI does most of the work but needs a human review gate. Build these next.\n3. **Complex agent steps** \u2014 Fully autonomous steps requiring Agents, MCP connectors, or multi-tool orchestration. Tackle these last.\nFor each priority tier, list the specific steps and what to build.\n\n**Where to Run**\n- Where to run this prompt (normal chat vs. project), based on the AI Building Block Spec's recommendation\n- If normal chat: which files to attach when pasting the prompt\n- If project: how to set up the project (name, which files to pre-load, any general project-level settings), then paste this prompt into a conversation within the project\n- Decision criteria summary so the user understands why this recommendation was made\n\nNote: The prompt instructions above are the same regardless of where you run it. The project provides file staging convenience \u2014 the prompt provides the workflow logic.\n\n**File naming:** Name the file `[workflow-name]-prompt.md` using the same workflow name from the AI Building Block Spec (e.g., `lead-qualification-prompt.md`).\n\nGenerate the prompt as a downloadable Markdown file. If your platform doesn't support file downloads, format it inside a single Markdown code block so I can copy and save it manually.\n\n---\n\nAfter presenting the file, summarize what the user now has:\n\n&gt; **Build complete.** You now have your Baseline Workflow Prompt (`[workflow-name]-prompt.md`). Paste it into any AI tool to run the workflow.\n\nIf skills were provided, also note: \"Your prompt references [N] skills \u2014 those steps are invoked by name instead of spelled out inline.\"\n\n&gt; Your three core deliverables:\n&gt;\n&gt; 1. `[workflow-name]-definition.md` \u2014 your Workflow Definition (from Deconstruct)\n&gt; 2. `[workflow-name]-building-block-spec.md` \u2014 your AI Building Block Spec (from Design)\n&gt; 3. `[workflow-name]-prompt.md` \u2014 your Baseline Workflow Prompt (ready to use)\n&gt;\n&gt; Start by running the baseline prompt on a real scenario.\n\n**Write workflow SOP (Claude users, optional):** If you registered this workflow to the AI Registry during the Deconstruct step, you can now generate a Standard Operating Procedure and save it to the workflow's Notion page. Use the `writing-workflow-sops` skill from the AI Registry plugin \u2014 it reads the workflow entry from Notion, uses the Baseline Prompt's procedure steps as input, and writes a formatted SOP (overview, prerequisites, trigger, step-by-step procedure, outputs, quality checks, troubleshooting) directly to the page body. This gives your workflow a complete home in Notion: metadata in the properties, SOP in the page content, and deliverable files in your local folder.\n\n---\n\n## General Instructions\n\n- If I mention I'm using Claude, note where Claude Code Skills are the appropriate implementation. On other platforms, map to custom instructions, GPTs, or Gems.\n- Use plain language. Avoid jargon unless I introduced it.\n- If anything is ambiguous in the AI Building Block Spec, ask me before generating.\n</code></pre>"},{"location":"business-first-ai-framework/build/prompt/#what-this-prompt-produces","title":"What This Prompt Produces","text":""},{"location":"business-first-ai-framework/build/prompt/#baseline-workflow-prompt","title":"Baseline Workflow Prompt","text":"<p>A ready-to-paste prompt that works on any AI platform. If you built skills, the prompt references them \u2014 those steps are invoked by name instead of spelled out inline, making the prompt shorter and more maintainable. If you didn't build skills, every step is spelled out in full so it works standalone.</p>"},{"location":"business-first-ai-framework/build/prompt/#whats-next","title":"What's Next","text":"<p>You now have three core Markdown files from the full workflow deconstruction and build:</p> File What it is What to do with it <code>[name]-definition.md</code> Workflow Definition (Deconstruct) Reference \u2014 the raw decomposition you can revisit <code>[name]-building-block-spec.md</code> AI Building Block Spec (Design) Reference \u2014 the full analysis with building block mapping <code>[name]-prompt.md</code> Baseline Workflow Prompt (Build) Use this \u2014 paste it into a new conversation to run the workflow <p>Your prompt is ready. Test it on a real scenario \u2014 Run.</p> <p>Keep all three files together \u2014 in a folder, a repo, or wherever you store your workflow documentation. You can share any of these with your team for feedback.</p> <p>For next steps on building agents or connecting external tools, see Agents and MCP.</p>"},{"location":"business-first-ai-framework/build/run/","title":"Run Workflows","text":"<p>You've built your building blocks \u2014 context artifacts, a prompt, maybe skills, agents, or MCP connections. Now run the workflow.</p> <p>The most common question at this point is: \"Where do I run this? How do I run this?\" The answer depends on what you built.</p>"},{"location":"business-first-ai-framework/build/run/#choose-your-execution-pattern","title":"Choose Your Execution Pattern","text":"What you built Execution pattern Where to run it Prompt + context files Paste and run in a normal chat Any AI tool (Claude, ChatGPT, Gemini, M365 Copilot) Prompt + context + project Run in a project \u2014 context is pre-loaded, paste the prompt each run Claude Projects, ChatGPT Projects, Gemini Gems, M365 Copilot Notebooks Agent + skills + MCP Command an agent \u2014 give a goal, it plans and executes Claude Code subagents, OpenAI Agents, Google Agents, M365 Copilot Agents Any of the above + a schedule Automate \u2014 recurring trigger, runs without you Claude Code + launchd / Task Scheduler <p>If you ran the Prompt step, your Build outputs include a Where to Run section \u2014 it recommends whether to run your workflow in a normal chat or a project, based on how many context files you have and how often you'll run it. Use that as your starting point. If you don't have that output, the guidance below will help you decide.</p>"},{"location":"business-first-ai-framework/build/run/#paste-and-run","title":"Paste and Run","text":"<p>The simplest execution pattern. You have a prompt and maybe some context files. Open a chat, provide what the prompt needs, and get the output.</p> <p>How to run it:</p> <ol> <li>Open any AI tool \u2014 Claude, ChatGPT, Gemini, M365 Copilot, or any chat interface</li> <li>If you have context files (reference materials, style guides, example data), attach or upload them to the conversation</li> <li>Paste your Baseline Workflow Prompt</li> <li>Provide the inputs the prompt asks for \u2014 the prompt's input requirements section tells you exactly what's needed</li> <li>Review the output</li> </ol> <p>This is where most workflows start, and many stay here permanently. If the workflow runs well as a paste-and-run prompt, there's no reason to add complexity.</p>"},{"location":"business-first-ai-framework/build/run/#run-in-a-project","title":"Run in a Project","text":"<p>When you're running the same workflow frequently and attaching the same context files every time, move it into a project. A project pre-loads your context so you just paste the prompt and go.</p>"},{"location":"business-first-ai-framework/build/run/#normal-chat-vs-project","title":"Normal chat vs. project","text":"Normal chat Project Use when Infrequent workflow (monthly or less), few or no context files, one-off or experimental runs Frequent workflow (weekly+), 3+ context files, team members need to run the same workflow Context Attached fresh each run Pre-loaded \u2014 available in every conversation History Single conversation Multiple conversations share the same context Setup effort None A few minutes to create the project and upload files"},{"location":"business-first-ai-framework/build/run/#how-to-run-it","title":"How to run it:","text":"<ol> <li>Create the project \u2014 name it after your workflow</li> <li>Upload your context artifacts \u2014 the documents, data, rules, and examples from the Context step</li> <li>Add custom instructions (optional) \u2014 a brief orientation for the AI about this workflow's purpose</li> <li>Start a new conversation within the project</li> <li>Paste the Baseline Workflow Prompt \u2014 the prompt is always pasted fresh each run, never embedded in project instructions. The prompt IS the workflow.</li> <li>Provide inputs and review the output</li> </ol> <p>Each time you run the workflow, start a new conversation in the project. The context is already there \u2014 you just paste the prompt and provide the inputs.</p>"},{"location":"business-first-ai-framework/build/run/#where-to-create-a-project","title":"Where to create a project","text":"Platform Feature name How to create Claude Claude Projects Sidebar &gt; Projects &gt; New Project ChatGPT ChatGPT Projects Sidebar &gt; Projects &gt; New Project Gemini Gems Gems tab &gt; Create Gem M365 Copilot Notebooks Notebooks in Copilot sidebar <p>For platform-specific setup details, see Agentic Building Blocks &gt; Projects.</p>"},{"location":"business-first-ai-framework/build/run/#command-an-agent","title":"Command an Agent","text":"<p>When your workflow includes steps where the AI needs to plan its own approach, decide which tools to call, and adapt based on what it finds, you run it through an agent system. You give a goal \u2014 the agent figures out the path.</p>"},{"location":"business-first-ai-framework/build/run/#how-its-different-from-a-prompt","title":"How it's different from a prompt","text":"<p>With a prompt, you define every step and the AI follows your script. With an agent, you define the outcome and the agent decides how to get there. The agent plans, calls tools, evaluates results, adjusts its approach, and executes multi-step work autonomously. You review at human review gates, not at every step.</p>"},{"location":"business-first-ai-framework/build/run/#how-to-run-it_1","title":"How to run it:","text":"<ol> <li>Give the agent a goal in natural language \u2014 describe what you want done, not how to do it step by step</li> <li>The agent plans and executes \u2014 it reads context, calls tools (via MCP), invokes skills, and adapts based on intermediate results</li> <li>Review at defined gates \u2014 your agent definition specifies where the agent pauses for human approval</li> <li>Accept or redirect \u2014 approve the output or give the agent further direction</li> </ol>"},{"location":"business-first-ai-framework/build/run/#where-to-run-agents","title":"Where to run agents","text":"Platform Agent system How it works Claude Claude Code subagents Define agents as <code>.md</code> files with system prompts, skills, and tool access. Run with <code>claude --agent</code> or via the <code>workflow-deconstructor</code> pattern. OpenAI OpenAI Agents Build agents with the Agents API or in the Assistants playground. Agents have tools, instructions, and persistent threads. Google Google Agents Build with Vertex AI Agent Builder or Gemini's agent capabilities. Agents connect to Google Workspace tools. M365 Copilot Copilot Agents Build declarative or custom agents in Copilot Studio. Agents connect to Microsoft Graph and business data. <p>For Claude-specific agent setup, see Agentic Building Blocks &gt; Agents.</p>"},{"location":"business-first-ai-framework/build/run/#automate-on-a-schedule","title":"Automate on a Schedule","text":"<p>When you want a workflow to run automatically \u2014 daily, weekly, or in response to triggers \u2014 without a human initiating each run. This is the highest level of the autonomy spectrum (the range from fully human-driven to fully AI-driven).</p> <p>Scheduling requires an agent system with CLI (command-line interface) access \u2014 the ability to run commands from a terminal. Currently, Claude Code subagents (specialized AI assistants that run as part of a larger agent system) are the most straightforward option for this.</p> <p>How it works:</p> <ol> <li>Define the agent and its workflow (same as \"Command an Agent\" above)</li> <li>Create a wrapper script that invokes the agent with a prompt</li> <li>Register the script with a scheduler (launchd on macOS, Task Scheduler on Windows)</li> <li>The workflow runs at the scheduled time, saves outputs, and logs results</li> </ol> <p>When to automate vs. when to keep manual:</p> <ul> <li>Automate when the workflow is stable (you've run it several times and trust the output), the trigger is time-based or event-based, and the cost of a bad run is low</li> <li>Keep manual when you're still iterating on the prompt or agent, the workflow requires judgment calls you haven't codified, or the output goes directly to customers or stakeholders without review</li> </ul> <p>For the full setup guide, see Scheduling Subagents.</p>"},{"location":"business-first-ai-framework/build/run/#your-first-run","title":"Your First Run","text":"<p>The first run is a test, not a production run. You're testing whether the building blocks you constructed in 3.2 Construct actually produce the output you need.</p> <p>What to evaluate:</p> <ul> <li>Did the output match what you expected?</li> <li>Were any steps skipped or misunderstood?</li> <li>Did the AI ask for something it should have had (missing context)?</li> <li>Was the output quality good enough, or generic?</li> </ul> <p>Common first-run issues:</p> <ul> <li>Generic output \u2014 the AI doesn't have enough context. Add reference materials, examples, or style guides.</li> <li>Steps skipped or wrong \u2014 the prompt instructions are too vague. Make the steps more explicit.</li> <li>AI asks for information it should know \u2014 a context file is missing. Check your Context Inventory from the AI Building Block Spec.</li> </ul>"},{"location":"business-first-ai-framework/build/run/#test-iterate-repeat","title":"Test, Iterate, Repeat","text":"<p>Building an AI workflow is a cycle: run \u2192 evaluate \u2192 adjust \u2192 run again. Each run is a test. When the output isn't right, go back to 3.2 Construct, adjust the building block that's responsible, and test again.</p> <p>Most workflows need 2-4 iterations before they produce reliably good results. This is expected \u2014 you're tuning the building blocks to your specific business context, and that takes a few passes.</p> <p>Use this table to figure out which building block to adjust based on what went wrong:</p> Problem What to fix Output quality is generic or off-brand Add more context \u2014 reference materials, examples, style guides Steps are skipped or misunderstood Refine the prompt \u2014 make instructions more explicit, add examples of expected output A step needs domain expertise the AI doesn't have Build a skill for that step \u2014 codify the expertise so the prompt can invoke it The AI needs to make decisions you can't predict in advance Convert from prompt to agent \u2014 let the AI plan its own approach The workflow should run without you triggering it Add scheduling \u2014 automate with a recurring trigger <p>This maps directly back to the Build overview \u2014 iterating is climbing the building block ladder based on what the workflow actually needs.</p>"},{"location":"business-first-ai-framework/build/run/#related","title":"Related","text":"<ul> <li>Build overview \u2014 the full build process including design, skills, agents, and MCP</li> <li>Worked Examples \u2014 Deterministic Automation, AI Collaborative, Autonomous Agent</li> <li>Scheduling Subagents \u2014 full automation setup guide</li> <li>Agentic Building Blocks \u2014 platform-specific implementation details</li> </ul>"},{"location":"business-first-ai-framework/build/skills/","title":"Skills","text":"<p>Part of: Build Workflows</p> <p>New to skills as a building block?</p> <p>See Agentic Building Blocks &gt; Skills for definitions, examples, and cross-platform implementation details.</p>"},{"location":"business-first-ai-framework/build/skills/#what-this-is","title":"What This Is","text":"<p>Build reusable skills before generating your prompt, so the prompt can reference them instead of spelling out every step. Skills codify deep expertise for specific workflow steps \u2014 give a skill inputs, it follows a defined process, it produces consistent outputs. When you generate your prompt in the next step, list the skills you built and the AI generates a shorter, smarter prompt that invokes them by name.</p> What you'll do Identify skill candidates from your AI Building Block Spec, then build each one by giving Claude your Workflow Definition and Building Block Spec \u2014 the analysis you've already done provides everything it needs What you'll get Reusable skills that your Baseline Workflow Prompt can invoke instead of spelling out every step Time ~10-15 minutes per skill (the heavy analysis is already in your artifacts)"},{"location":"business-first-ai-framework/build/skills/#identify-skill-candidates","title":"Identify Skill Candidates","text":"<p>Open your AI Building Block Spec (<code>[name]-building-block-spec.md</code>) and scan the step table. Look for steps that meet these criteria:</p> <ul> <li>Repeatable \u2014 the step runs frequently with similar patterns</li> <li>Requires domain expertise \u2014 getting it right depends on specialized knowledge (scoring rubrics, extraction frameworks, editorial criteria)</li> <li>Benefits from consistency \u2014 the step should produce the same output structure every time</li> </ul> <p>Good candidates are typically steps tagged with \"Skill\" in the AI Building Blocks column, or steps classified as \"AI \u2013 Semi-Autonomous\" that have complex logic. If a step is simple and deterministic \u2014 a few sentences of instruction \u2014 it's better left inline in the prompt.</p> <p>Don't overthink this. If you're not sure whether a step needs a skill, skip it for now. You can always extract it into a skill later after running the prompt a few times and seeing where quality varies.</p>"},{"location":"business-first-ai-framework/build/skills/#when-to-build-a-skill-vs-keep-it-in-the-prompt","title":"When to Build a Skill vs. Keep It in the Prompt","text":"<p>Not every step needs a dedicated skill:</p> <p>Build a skill when:</p> <ul> <li>The step requires domain expertise that's hard to get right every time</li> <li>You'll run this step across multiple workflows</li> <li>You want consistent quality without re-explaining the process each run</li> <li>The step has complex logic worth codifying (scoring rubrics, extraction frameworks, editorial criteria)</li> </ul> <p>Keep it in the prompt when:</p> <ul> <li>The step is simple or deterministic</li> <li>It's unique to this workflow</li> <li>The instructions are short (a few sentences)</li> <li>Getting it right doesn't require specialized knowledge</li> </ul>"},{"location":"business-first-ai-framework/build/skills/#build-your-first-skill","title":"Build Your First Skill","text":"<p>Your deliverables from Deconstruct and Design already contain everything a skill needs. You spent time producing a rich Workflow Definition and AI Building Block Spec \u2014 building a skill is just giving Claude that context and asking it to create the skill.</p>"},{"location":"business-first-ai-framework/build/skills/#how-to-build-a-skill","title":"How to build a skill","text":"<ol> <li>Pick your highest-priority skill candidate \u2014 Open your AI Building Block Spec (<code>[name]-building-block-spec.md</code>) and find the steps tagged with \"Skill\" in the AI Building Blocks column. Start with the one in the highest priority tier from the Recommended Implementation Order.</li> <li>Ask Claude to create a skill \u2014 Claude's built-in skill creation process will guide you through it. When you start, paste or upload your AI Building Block Spec and Workflow Definition \u2014 they contain everything Claude needs.</li> <li>Point Claude at the right step \u2014 Tell it which step to build: \"Create a skill for Step 4 \u2014 Score and Qualify Prospects. Here's my AI Building Block Spec and Workflow Definition from the Design phase.\"</li> <li> <p>Let your artifacts do the work \u2014 Claude will ask questions as it builds the skill. Most answers are already in your files:</p> When Claude asks about... Paste or point to... What the skill does Step name + Action column in your Building Block Spec Inputs and format Data In column Expected outputs Data Out column Step-by-step process Action + Decision Points columns, plus the detailed sub-steps in your Workflow Definition Edge cases and failure handling Failure Mode column Reference materials needed Context Needed column + Context Inventory table External tools or connections Tools and Connectors Required section </li> <li> <p>Test with real data \u2014 run the skill on actual inputs from your workflow and compare to what you'd produce manually. Refine until the output matches your standards.</p> </li> <li>Register and commit \u2014 add the skill to your AI Registry Notion database (name, type, description, workflow) and commit the <code>SKILL.md</code> file to your GitHub repository. This keeps your building block inventory current and your source files versioned.</li> <li>Repeat for additional skill candidates \u2014 focus on the top 1-3. You can always build more later.</li> </ol> <p>Paste the whole file</p> <p>You don't have to extract individual columns. Paste your entire AI Building Block Spec when you start \u2014 Claude will pull what it needs. Add the Workflow Definition too if the step has complex sub-steps or exception paths.</p>"},{"location":"business-first-ai-framework/build/skills/#how-skills-integrate-with-your-prompt","title":"How Skills Integrate with Your Prompt","text":"<p>When you generate your prompt in the next step (Prompt), list the skills you built. The AI generates a prompt that invokes your skills by name instead of spelling out those steps in full.</p> <p>Before (inline in prompt):</p> <p>Step 5: Extract key findings from the research. For each finding, identify the source, the claim, the supporting evidence, and the confidence level. Format as a structured table...</p> <p>After (with skill):</p> <p>Step 5: Extract key findings from the research output.</p> <p>The skill handles the complexity. The prompt stays clean and focused on workflow sequencing. Each skill you build makes the prompt shorter and more maintainable.</p>"},{"location":"business-first-ai-framework/build/skills/#whats-next","title":"What's Next","text":"<p>Generate your Baseline Workflow Prompt \u2014 Prompt. When the AI asks, list the skills you built and it generates a prompt that references them instead of spelling out those steps.</p> <p>If you skipped building skills (or your platform doesn't support them), the Prompt step generates the full baseline with every step spelled out. You can always extract skills later.</p>"},{"location":"business-first-ai-framework/deconstruct/","title":"Step 2: Deconstruct Workflows","text":"<p>Platforms: <code>claude</code> <code>openai</code> <code>gemini</code> <code>m365-copilot</code></p>"},{"location":"business-first-ai-framework/deconstruct/#what-this-is","title":"What This Is","text":"<p>An interactive deep-dive that breaks down a business workflow into discrete steps \u2014 surfacing every hidden sub-step, decision point, data handoff, context requirement, and failure mode.</p> What you'll do Describe your workflow (or problem) and work through a guided conversation that probes each step for sub-steps, decision points, data flows, context needs, and failure modes What you'll get A Workflow Definition \u2014 a structured Markdown file capturing every step in detail Time ~15-25 minutes of interactive conversation"},{"location":"business-first-ai-framework/deconstruct/#why-this-matters","title":"Why This Matters","text":"<p>You can't operationalize AI on a process you don't understand. Before you can build an AI-powered workflow, you need to break it down into discrete steps, identify the decision points and data flows, and understand what context each step needs and what happens when things go wrong.</p> <p>This prompt walks you through that deconstruction interactively. You provide the business scenario and rough steps \u2014 the model handles the structured analysis, applying the 5-question framework (discrete steps, decision points, data flows, context needs, failure modes) to every step. The deliverable:</p> <ul> <li>A Workflow Definition \u2014 the structured breakdown of your workflow into refined steps, with decision points, data flows, context needs, and failure modes captured for every step</li> </ul> <p>The context needs and failure modes captured here directly inform design decisions in the next step \u2014 they tell you what context to create, what tools to connect, and where human review gates are needed.</p> <p>This builds directly on the concepts of workflow deconstruction. If terms like the \"5-question framework\" or \"seven building blocks\" are new to you, review the Key Concepts section of the Business-First AI Framework for quick definitions before starting.</p>"},{"location":"business-first-ai-framework/deconstruct/#how-to-use-this","title":"How to Use This","text":"<p>There are two ways to run this: as a prompt in any AI tool, or with the Claude platform plugin.</p> Any AI ToolClaude Platform <p>Works with ChatGPT, Gemini, M365 Copilot, Claude, or any AI chat tool.</p> <ol> <li>Go to Break Down Your Workflow \u2014 Copy the prompt, start a new conversation, paste the prompt, and describe your workflow</li> <li>Save the Workflow Definition \u2014 Download the <code>.md</code> file the model produces (or copy the output and save it as <code>[workflow-name]-definition.md</code>)</li> <li>Go to Build Workflows \u2014 Start with the Design phase to choose your execution pattern and map building blocks</li> </ol> <p>Install the Business-First AI plugin and the <code>workflow-deconstructor</code> agent orchestrates the full process \u2014 running discovery, deconstruction, design, and build in sequence with file-based handoffs between stages.</p> <p>Install the plugin:</p> <pre><code>/plugin install business-first-ai@handsonai\n</code></pre> <p>Start with this prompt:</p> <pre><code>I want to deconstruct my [workflow name] workflow.\nWalk me through the full process.\n</code></pre> <p>Review the outputs \u2014 deliverables are saved to the <code>outputs/</code> directory. You can also run individual steps using the skills directly: <code>discovering-workflows</code> (Discover), <code>deconstructing-workflows</code> (Deconstruct), <code>building-workflows</code> (Build).</p> <p>The plugin works on three Claude interfaces:</p> Interface How to install Notes Claude Code Run <code>/plugin install</code> in the terminal Full agent + skill support Cowork Click + &gt; Add plugins... &gt; upload the plugin ZIP Same capabilities, visual interface Claude.ai Upload skill ZIPs under Settings &gt; Capabilities &gt; Upload skill Skills only \u2014 the orchestrator agent doesn't work in Claude.ai, so you run skills individually with manual handoffs (details) <p>For setup details, see Using Plugins.</p> <p>Both options follow the same process and produce the same deliverable.</p> <p>Start with a workflow you actually do</p> <p>Real workflows produce the best results. The model will surface hidden steps and assumptions you've internalized \u2014 that's much harder with hypothetical processes. If you don't have an existing workflow but have a clear problem to solve, that works too \u2014 the model will help you design one.</p> <p>Register your workflow in the AI Registry</p> <p>If you're using the AI Registry Notion database, register your workflow as soon as naming is confirmed \u2014 the prompt walks you through it. This creates a record of the workflow with its name, description, trigger, outcome, and type. You'll update this entry as you move through Build. Even if you're not using Notion, save the metadata somewhere \u2014 it's the first entry in your workflow inventory. See Builder Stack Setup \u2014 Step 6 if you haven't set up the AI Registry yet.</p> <p>Keep your files together</p> <p>By the end of the full process you'll have several Markdown files: <code>[name]-definition.md</code> (from Deconstruct), <code>[name]-building-block-spec.md</code> (from Build: Design), and <code>[name]-prompt.md</code> (from Build: Construct), plus any skills you built. Keep them in a single folder \u2014 they form a complete record of your workflow deconstruction. You can share any of these files with your team for feedback, put them in version control, or hand them to a colleague.</p> <p>Markdown renders as formatted text</p> <p>Markdown (<code>.md</code>) files are plain text with lightweight formatting \u2014 headings, bold, lists, tables. Many tools render them automatically: GitHub, Notion, VS Code, and most code editors show the formatted version when you open the file. You can also paste Markdown into Google Docs or Notion and it converts on the fly.</p> <p>If you'd prefer a polished document, ask your AI tool: \"Convert this to a Word document\" or \"Reformat this as a PDF.\" The content is the same \u2014 Markdown is just the most portable starting format because it works everywhere and is easy to version-control.</p>"},{"location":"business-first-ai-framework/deconstruct/#example-what-the-first-exchange-looks-like","title":"Example: What the first exchange looks like","text":"<p>After you paste the prompt, the model will ask about your scenario. Here's what a typical opening looks like:</p> <p>Model: Let's start by understanding the workflow you want to deconstruct. First \u2014 what's the business scenario? What's the objective of this workflow, and why does it matter?</p> <p>You: I research LinkedIn prospects before sales outreach. The goal is to find people who'd be a good fit for our AI training programs, understand their background, and write personalized outreach messages. Right now it takes me about 45 minutes per prospect and I do maybe 10 a week.</p> <p>Model: Got it \u2014 LinkedIn prospect research for personalized sales outreach, with the goal of identifying fit and crafting tailored messages. That's a great workflow to deconstruct. Now, can you walk me through the high-level steps? Don't worry about being complete or precise \u2014 just describe what you typically do from start to finish, and we'll refine it together.</p> <p>You: I guess I start by finding people on LinkedIn, then I look at their profile, check their company, see if they've posted anything relevant, then I write the message. There's probably more to it but that's the gist.</p> <p>From there, the model takes your rough steps and systematically breaks each one down \u2014 uncovering the sub-steps, decisions, data, and context you didn't think to mention.</p>"},{"location":"business-first-ai-framework/deconstruct/#example-starting-with-a-problem-instead-of-a-workflow","title":"Example: Starting with a problem instead of a workflow","text":"<p>You don't need an existing process to use this prompt. If you have a gap or pain point, describe that \u2014 the model will help you design a workflow from scratch:</p> <p>Model: Let's start by understanding the workflow you want to deconstruct. First \u2014 what's the business scenario? What's the objective of this workflow, and why does it matter?</p> <p>You: I don't really have a workflow for this \u2014 it's more of a problem. People sign up for my online course but a lot of them never finish. I have no way to know who's dropping off, when they stop engaging, or how to follow up. I'm just losing students and I don't find out until it's too late.</p> <p>Model: Got it \u2014 so this isn't an existing process to break down, it's a gap you need to fill. Let me make sure I understand the problem before we design a solution. A few questions: What does \"signing up\" look like \u2014 is there a registration step, a payment, or both? And when you say people don't finish, do you have any data on where they tend to drop off, or is that part of the problem \u2014 you just don't know?</p> <p>You: They register and pay through my course platform. I can see completion rates in the dashboard but I don't check it regularly, and there's no alert or trigger when someone stops. I only notice if I happen to look.</p> <p>Model: That's clear. So the core gap is: no systematic way to detect drop-offs and no follow-up process when they happen. Let me propose a candidate workflow that would solve this, and you can tell me what fits and what doesn't.</p> <p>From there, the model proposes a step-by-step workflow to address the problem, asks you to react and refine, and then continues into the deep dive just like any other workflow.</p>"},{"location":"business-first-ai-framework/deconstruct/#not-sure-which-workflow-to-try","title":"Not sure which workflow to try?","text":"<p>Browse the AI Use Cases section for inspiration \u2014 it organizes examples by type (content creation, research, coding, data analysis, ideation, and automation) with department-specific scenarios.</p> <p>Or pick something you do regularly and could describe to a colleague over coffee. Here are some examples students have used:</p> <ul> <li>Weekly team status reporting \u2014 gathering updates from multiple sources, synthesizing, and distributing a summary</li> <li>New client onboarding \u2014 intake, account setup, kickoff scheduling, and initial deliverables</li> <li>Processing expense reports \u2014 collecting receipts, validating against policy, approving, and submitting for reimbursement</li> <li>Content publishing pipeline \u2014 drafting, editing, formatting, scheduling, and distributing across channels</li> <li>Candidate screening \u2014 reviewing applications, initial outreach, scheduling interviews, and tracking status</li> <li>Vendor evaluation \u2014 gathering proposals, comparing against criteria, scoring, and recommending a decision</li> <li>Course enrollment follow-up \u2014 people start signing up but don't finish, and there's no process to detect drop-offs or send reminders</li> </ul> <p>You don't need to know all the steps before you start \u2014 that's what the prompt helps you figure out. Even \"I onboard new clients and it takes forever\" is enough to begin. You can also start with a problem instead of a workflow \u2014 \"People drop off during enrollment and I have no way to follow up\" is a perfectly valid starting point.</p>"},{"location":"business-first-ai-framework/deconstruct/#what-to-expect","title":"What to Expect","text":"<p>Break Down Your Workflow (~15-25 minutes) \u2014 The model asks about your business scenario, objective, steps, and who's involved. Then it works through each step one by one, asking about sub-steps, decision points, data flows, context needs, and failure modes. For later steps, it switches to a \"propose and react\" pattern \u2014 presenting hypotheses for you to correct, which is faster and surfaces more detail. Produces a Workflow Definition.</p> <p>Most workflows expand from 5-8 rough steps to 12-20 refined steps after the deep dive. After the Workflow Definition is complete, take it to Step 3 \u2014 Build Workflows. The Build step starts with a Design phase where you choose your execution pattern and map each step to AI building blocks.</p>"},{"location":"business-first-ai-framework/deconstruct/#tips-for-better-results","title":"Tips for Better Results","text":"<ul> <li>Start with workflows you actually do. Real processes have real complexity that produces useful analysis. Hypothetical workflows tend to be too clean.</li> <li>Include the messy details. \"Sometimes I skip this step if the client is a repeat customer\" is exactly the kind of decision logic the model needs to capture.</li> <li>Don't over-prepare your steps. The model is designed to work with rough, incomplete descriptions. Let it do the work of refining and organizing.</li> <li>Gather your context resources early. The model will identify specific resources the workflow needs \u2014 documents like buyer personas and style guides, but also spreadsheets, databases, CRM access, application credentials, and sample data. If you already have these, have them ready. If you don't, the analysis will tell you exactly what to create or set up and what each resource should contain.</li> <li>Save your files. The Workflow Definition is your reference material. Keep it in a folder or version control \u2014 you'll use it throughout the Build step.</li> <li>Iterate the executable prompt. Once you generate it in Build, run it once, see what works and what doesn't, then refine. The first version is a strong draft, not a final product.</li> </ul>"},{"location":"business-first-ai-framework/deconstruct/#related","title":"Related","text":"<ul> <li>Previous step: Not sure which workflow to deconstruct? Start with Discover Workflows (Step 1) to identify your best candidates.</li> <li>Next step: Ready to build? Go to Build Workflows (Step 3) \u2014 starting with the Design phase to choose your execution pattern and map building blocks.</li> <li>Business-First AI Framework \u2014 the full three-step methodology</li> <li>Prompts</li> <li>Agents</li> </ul>"},{"location":"business-first-ai-framework/deconstruct/workflow-definition/","title":"Break Down Your Workflow","text":"<p>Part of: Deconstruct Workflows</p>"},{"location":"business-first-ai-framework/deconstruct/workflow-definition/#what-this-is","title":"What This Is","text":"<p>An interactive conversation where AI helps you break down a workflow into its component parts. You describe the process \u2014 rough and incomplete is fine \u2014 and the AI interviews you to surface every hidden step, decision, data handoff, and failure mode.</p> What you'll do Describe your workflow (or problem), then answer focused questions as the AI probes each step for sub-steps, decision points, data flows, context needs, and failure modes What you'll get A Workflow Definition \u2014 a structured Markdown file that captures everything discovered, ready for the Design phase Time ~15\u201325 minutes of interactive conversation"},{"location":"business-first-ai-framework/deconstruct/workflow-definition/#why-this-matters","title":"Why This Matters","text":"<p>Most people describe their workflows in 5\u20138 rough steps. But the real complexity \u2014 the decision points, data handoffs, exception paths, and hidden assumptions \u2014 lives in the gaps between those steps.</p> <p>This discovery process typically expands those 5\u20138 rough steps into 12\u201320 refined steps. That expansion is where the value is: each hidden detail you surface now is a potential failure point you won't have to debug later when AI is running the workflow.</p> <p>The prompt uses a 5-question framework (discrete steps, decision points, data flows, context needs, failure modes) applied systematically to every step. After the first few steps, it switches to a \"propose and react\" pattern \u2014 presenting hypotheses for you to correct \u2014 which is faster and surfaces details you wouldn't think to mention unprompted.</p>"},{"location":"business-first-ai-framework/deconstruct/workflow-definition/#how-to-use-this","title":"How to Use This","text":"<p>There are two ways to run this, depending on which tools you use:</p>"},{"location":"business-first-ai-framework/deconstruct/workflow-definition/#option-a-prompt-template-any-ai-tool","title":"Option A: Prompt template (any AI tool)","text":"<ol> <li>Copy the prompt from the code block below</li> <li>Start a new conversation in your preferred AI tool (Claude, ChatGPT, Gemini, M365 Copilot) and paste the prompt</li> <li>Press Enter \u2014 the model will read the instructions and ask about your business scenario</li> <li>Answer the questions \u2014 describe your workflow or problem, then work through the deep dive</li> <li>Download the Workflow Definition the model produces at the end \u2014 it will be a Markdown file named <code>[workflow-name]-definition.md</code> (e.g., <code>lead-qualification-definition.md</code>)</li> <li>Keep this file \u2014 you'll upload or paste it into Step 2, and you can share it with your team for feedback</li> </ol>"},{"location":"business-first-ai-framework/deconstruct/workflow-definition/#option-b-claude-skill","title":"Option B: Claude skill","text":"<p>Use the <code>deconstructing-workflows</code> skill from the Business-First AI plugin. It runs the same deep dive process and saves the Workflow Definition to a file automatically.</p> <ul> <li>Claude Code or Cowork \u2014 install the plugin (<code>/plugin install business-first-ai@handsonai</code>) and start with:     <pre><code>I want to deconstruct my [workflow name] workflow.\nHelp me build a Workflow Definition.\n</code></pre>     The Workflow Definition is saved to <code>outputs/[workflow-name]-definition.md</code>.</li> <li>Claude.ai \u2014 zip the <code>deconstructing-workflows</code> skill folder and upload it via Settings &gt; Capabilities &gt; Upload skill, then start a new chat with the same prompt above. See Using Skills in Claude.ai for detailed instructions.</li> </ul> <p>Budget ~15-25 minutes for this conversation</p> <p>This step covers the most interactive part of the process. The model will ask about your scenario, help you refine your steps, then systematically probe each step for sub-steps, decisions, data flows, context needs, and failure modes. The depth here directly determines the quality of everything that follows.</p>"},{"location":"business-first-ai-framework/deconstruct/workflow-definition/#the-prompt","title":"The Prompt","text":"<pre><code>You are an expert Workflow Designer who specializes in deconstructing business workflows for AI operationalization. Your job is to help me discover and deeply analyze a business workflow, then produce a structured Workflow Definition that captures everything needed for AI building block mapping.\n\nWork through the following two parts in order. Ask one question at a time during interactive sections. Wait for my response before moving on.\n\n---\n\n## Part 1 \u2014 Scenario Discovery\n\nStart by understanding the workflow I want to deconstruct.\n\nBefore asking me anything, check if you have access to any project files, memory, or conversation history that includes details related to workflows, processes, or tasks I perform. This could be standard operating procedures (SOPs), meeting notes, team structures, tool documentation, process descriptions, or anything that gives you context about how I work. If you find relevant context, summarize what you found and ask if that's the workflow I want to deconstruct \u2014 this saves us from starting from scratch. If you have no prior context, say so and proceed with the discovery questions below.\n\nAsk me for:\n\n1. **Business scenario and objective** \u2014 What is the workflow for? What outcome does it produce? Why does it matter? (If you don't have an existing workflow \u2014 you have a problem you want to solve or a gap you want to fill \u2014 describe that instead.)\n2. **The workflow** \u2014 What process do I want to break down? Give me permission to describe it roughly \u2014 you'll help me refine it.\n3. **High-level steps** \u2014 What are the main steps I already know? (Incomplete and messy is fine \u2014 we'll clean it up together.)\n4. **Who executes this today** \u2014 Is this just me, a team, or a mix? Are there handoffs between people?\n\nAsk these one at a time.\n\n**If I can only describe the outcome but not the steps:** Don't wait for me to list steps I can't articulate. Instead, propose 5-8 candidate steps based on the scenario and outcome I described, and ask me to react \u2014 \"yes,\" \"no,\" \"sort of,\" or \"I'd describe it differently.\" Use my reactions to build the step list collaboratively.\n\n**If I'm describing a problem, not an existing workflow:** I may not have a process to break down \u2014 I may have a gap or pain point that needs a new workflow designed from scratch. In that case, don't force me through questions 2-4 as written. Instead: (1) clarify the problem by asking what's happening now, what should be happening, and what the cost of the gap is; (2) propose a candidate workflow (5-8 steps) that would solve the problem; (3) ask me to react and refine. Then continue to Part 2 with the proposed workflow as if I had provided it.\n\n**Scope check \u2014 one trigger, one deliverable:** After gathering the scenario, test whether this is actually one workflow or several bundled together. A workflow has exactly **one trigger** (what kicks it off) and **one deliverable** (the tangible output it produces). Apply these diagnostic questions:\n\n1. **Triggers** \u2014 Does this process start from a single trigger, or does it have multiple independent starting points? If different parts are kicked off by different events (e.g., \"when a new lead comes in\" vs. \"at the end of each week\"), those are likely separate workflows.\n2. **Deliverables** \u2014 Does it produce one deliverable, or does it produce several distinct outputs at different points? If someone receives a deliverable midway through and the process continues toward a different output, the boundary between those deliverables is probably a workflow boundary.\n3. **Timeframes** \u2014 Does the entire process happen in one sitting or execution window? If parts run daily but other parts run weekly, or if there's a significant wait between phases (hours, days), those are often separate workflows.\n4. **Step count** \u2014 Based on what you've heard so far, would this likely expand to more than 15-20 refined steps? That's a signal it may be multiple workflows.\n\n**If the scope check reveals multiple workflows:** Don't proceed directly to the deep dive. Instead:\n\n1. Map out the separate workflows you see \u2014 give each one a working name, its trigger, and its deliverable\n2. Present this breakdown to me: \"Based on what you've described, I think this is actually [N] separate workflows: [list with trigger/deliverable for each]\"\n3. Ask me to confirm or adjust the boundaries\n4. Ask which workflow I want to deconstruct first \u2014 recommend starting with the one that runs most frequently or has the most pain\n\nThen continue with naming and the deep dive for the chosen workflow only.\n\n**Name the workflow** \u2014 After the scope check passes (or after choosing a single workflow to focus on), name the workflow before summarizing. Follow these rules:\n\n- **Workflow name**: 2-4 words, noun phrase (not verb phrase), Title Case. Pattern: `[Subject] [Action/Purpose]`. Must be self-explanatory without context.\n  - Good: \"Lead Qualification\", \"Newsletter Distribution\", \"Student Onboarding\"\n  - Avoid: verb phrases (\"Managing Email\"), too generic (\"Daily Task\"), 5+ words, tool-focused (\"Claude Email Tool\"), jargon (\"SOP-001\")\n- **Description**: 1-2 sentences. Structure: `[Action verb] [object] [context/condition]. [Outcome statement].`\n  - Good: \"Review Gmail for emails requiring responses and draft replies. Generates draft responses ready for user review.\"\n  - Avoid: overly detailed multi-sentence explanations, too vague (\"Handles email stuff\"), tool-focused (\"Uses Claude and Gmail to do email\")\n- **Workflow outcome**: 2-5 word noun phrase naming the tangible business deliverable \u2014 something that can be reviewed, sent, or measured. Not \"completed workflow\" or \"done.\"\n  - Good: \"Draft email responses\", \"Qualified lead list\", \"Published newsletter\"\n- **Trigger**: What starts this workflow \u2014 scheduled (daily, weekly, monthly), event-based (something happens, e.g., new student enrolls), or on-demand (run manually when needed).\n- **Type**: Overall classification \u2014 Manual (all human, no AI), Augmented (human-led with AI assistance at specific steps), or Automated (AI-led with human review at key gates).\n\nPresent 2-3 name options and let me pick one or suggest my own. Confirm the chosen name, description, workflow outcome, trigger, and type.\n\n**Part 1 summary** \u2014 After naming is confirmed, summarize what you've learned: workflow name, description, workflow outcome, trigger, type, business scenario and objective, high-level steps, and current ownership. Confirm you have it right before moving to Part 2.\n\n**Register to AI Registry (Claude users, optional):** If you're using Claude with the AI Registry plugin, you can register this workflow to your Workflows database now. The metadata you've confirmed maps directly:\n\n| Workflow Metadata | Notion Property |\n|---|---|\n| Name | Name (title) |\n| Description | Description |\n| Workflow outcome | Process Outcome |\n| Type | Type (Augmented / Automated / Manual) |\n| Trigger | Trigger |\n\nStatus defaults to \"Under Development.\" You can set the Business Process domain if you know which process this workflow belongs to.\n\nThis is optional \u2014 registering now creates a home for this workflow in your registry so you can track its progress from discovery through production.\n\n---\n\n## Part 2 \u2014 Deep Dive (5-Question Framework)\n\nNow systematically work through each step I provided using the 5-question framework. For every step, you need to understand:\n\n1. **Discrete steps** \u2014 Is this step actually multiple steps bundled together? If so, break it down further. Keep going until each step is a single, concrete action.\n2. **Decision points** \u2014 Are there any if/then branches, quality gates, or judgment calls in this step? What triggers each path?\n3. **Data flows** \u2014 What are the specific inputs to this step? What does it produce as output? Where does the input come from and where does the output go?\n4. **Context needs** \u2014 What specific documents, files, reference materials, examples, or data sources does this step require that are not in your training data? For each one, does it already exist or does it need to be created?\n5. **Failure modes** \u2014 What happens when this step fails or can't proceed? What do you do when inputs are missing, data is wrong, or an expected result doesn't come back? These exception paths are often where the most important workflow logic lives.\n\n### How to work through steps efficiently\n\nFor the **first 2-3 steps**, ask the five questions directly \u2014 one at a time, conversationally. This builds your understanding of how I think about the workflow.\n\n**From step 4 onward**, switch to a \"propose and react\" pattern to save time:\n- Present your best hypothesis for that step across all five dimensions (sub-steps, decisions, data, context, failures) based on what you've learned so far\n- Ask me: **\"What's right, what's wrong, and what am I missing?\"**\n- Use my corrections to refine, then move on\n\nThis is more efficient and produces better results \u2014 correcting a wrong assumption forces me to articulate details I might not think to mention in response to open-ended questions.\n\n**Probing for context artifacts:** When exploring context needs, push beyond vague answers like \"domain knowledge\" or \"background info.\" Identify the specific artifact \u2014 name it, describe what it should contain, and ask whether it already exists or needs to be created. Common examples: buyer persona documents, style guides, grading rubrics, product catalogs, pricing sheets, email templates, brand voice documents, org charts, decision criteria checklists, sample inputs, and sample outputs. If a step requires the model to match a standard, apply criteria, or follow a style, there is almost certainly a reference document behind it.\n\n**Probing for existing AI instructions:** For any step where AI is already being used, ask specifically: \"Do you have existing prompt instructions, project instructions, custom assistant configurations, or system prompts that tell the AI what to do at this step? If so, I'll need to see those \u2014 they contain workflow logic that belongs in your Baseline Prompt.\" Existing prompts and instructions are context too \u2014 they capture decisions about how the workflow should run.\n\nAfter completing all steps:\n\n1. Present the refined step-by-step breakdown.\n2. **Map the step sequence** \u2014 Identify which steps are sequential (must happen in order), which can run in parallel (independent of each other), and where the critical path is. Show this as a simple dependency list (e.g., \"Step 3 depends on Steps 1 and 2; Steps 4 and 5 can run in parallel\").\n3. **Consolidate context requirements** \u2014 Present a single rolled-up list of every context artifact identified across all steps. For each artifact, state: the artifact name, a one-line description of what it contains, which steps depend on it, and whether it already exists or needs to be created. If it needs to be created, note the key contents it should include so I know what to build. Frame this as my \"context shopping list\" \u2014 everything the workflow needs that the model won't know on its own.\n4. Ask me to confirm the breakdown, sequence, and context shopping list are accurate.\n\n---\n\n## Output \u2014 Workflow Definition\n\nAfter I confirm the breakdown is accurate, produce the **Workflow Definition** as a Markdown file. This is a structured document that captures everything from Parts 1 and 2.\n\n**File naming:** Name the file `[workflow-name]-definition.md` using the lowercase-with-hyphens version of the workflow name confirmed in Part 1 (e.g., if the workflow is \"Lead Qualification,\" the file is `lead-qualification-definition.md`).\n\nGenerate the Workflow Definition as a downloadable Markdown file. If your platform doesn't support file downloads, format it inside a single Markdown code block so I can copy and save it manually.\n\nThe Workflow Definition must include:\n\n### Scenario Metadata\n- Workflow name\n- Description\n- Workflow outcome\n- Trigger\n- Type\n- Business objective\n- Current owner(s)\n\n### Refined Steps\nFor each step:\n- Step number and name\n- Action (what happens)\n- Sub-steps (if any)\n- Decision points (if/then logic)\n- Data in (inputs and where they come from)\n- Data out (outputs and where they go)\n- Context needs (specific artifacts required)\n- Failure modes (what happens when this step fails)\n\n### Step Sequence and Dependencies\n- Which steps are sequential\n- Which steps can run in parallel\n- Critical path\n- Dependency map\n\n### Context Shopping List\nFor each artifact:\n- Artifact name\n- Description (what it contains)\n- Used by steps (step numbers)\n- Status (Exists / Needs Creation)\n- Key contents (what it should include \u2014 specific enough to build from)\n\n---\n\nAfter presenting the Workflow Definition, tell me:\n\n&gt; **Next step:** Download (or copy and save) the Workflow Definition file. Then go to [Design Your AI Workflow](https://handsonai.info/business-first-ai-framework/build/design/), copy that prompt into a new conversation, and upload or paste the Workflow Definition when the model asks for it.\n\n---\n\n## General Instructions\n\n- Ask one question at a time. Never present a wall of questions.\n- Probe for missing steps \u2014 most people undercount by 30-50%.\n- Surface hidden assumptions (\"How do you decide when X is good enough?\").\n- Use plain language. Avoid jargon unless I introduced it.\n- When in doubt about a classification, explain your reasoning and ask me to decide.\n</code></pre>"},{"location":"business-first-ai-framework/deconstruct/workflow-definition/#what-this-prompt-produces","title":"What This Prompt Produces","text":"<p>The Workflow Definition captures:</p> <ul> <li>Scenario metadata \u2014 name, description, outcome, trigger, type, objective, owners</li> <li>Refined step-by-step breakdown \u2014 each step with action, sub-steps, decision points, data in/out, context needs, failure modes</li> <li>Step sequence and dependencies \u2014 what's sequential, what's parallel, where the critical path is</li> <li>Context shopping list \u2014 every artifact the workflow needs, with status and key contents</li> </ul> <p>This Workflow Definition is the input for the Design phase in Step 3 \u2014 Build, where the model chooses an execution pattern, classifies each step on the autonomy spectrum, and maps it to AI building blocks.</p>"},{"location":"business-first-ai-framework/questions/how-do-i-find-workflows-worth-applying-ai-to/","title":"How do I find workflows worth applying AI to?","text":"<p>Short answer: Run a structured audit of your daily and weekly tasks across three categories \u2014 collaborative AI, deterministic workflows, and multi-agent systems \u2014 to find where AI can save time, reduce errors, or automate entire processes.</p>"},{"location":"business-first-ai-framework/questions/how-do-i-find-workflows-worth-applying-ai-to/#the-full-answer","title":"The Full Answer","text":"<p>Most people adopt AI reactively \u2014 they reach for ChatGPT when stuck on an email or ask Claude to summarize a document. That's useful, but it misses the bigger picture. The Business-First AI Framework provides a structured three-step approach to this question \u2014 discover where AI fits, deconstruct those workflows into building blocks, then build.</p> <p>A proactive, structured audit of your workflows will reveal opportunities you'd never notice in the moment: repetitive tasks that could run on autopilot, decisions that benefit from an AI collaborator, and multi-step processes that could be orchestrated end-to-end.</p> <p>The key is thinking in three categories. Collaborative AI covers tasks where you and AI work together in real time \u2014 drafting, brainstorming, reviewing, analyzing. Deterministic workflows are repeatable processes with clear inputs and outputs that AI can execute reliably with little supervision \u2014 formatting reports, processing forms, generating routine communications. Multi-agent systems are complex workflows where multiple AI agents coordinate across steps \u2014 research-to-report pipelines, intake-to-triage systems, monitoring-to-response workflows.</p> <p>To run the audit, use the Discover AI Workflow Opportunities \u2014 a meta prompt that guides an AI through a three-step process: scanning what it already knows about your work, interviewing you to fill gaps, then producing a categorized report with specific opportunities and actionable first steps.</p> <p>Once you've identified opportunities, use the Deconstruct Workflows to break individual workflows into AI building blocks and understand exactly where automation fits.</p>"},{"location":"business-first-ai-framework/questions/how-do-i-find-workflows-worth-applying-ai-to/#how-to-get-started","title":"How to Get Started","text":"<ol> <li>Enable memory in your AI tool of choice (Claude, ChatGPT, or Gemini) so the AI can draw on what it already knows about your work</li> <li>Copy the prompt from the Discover AI Workflow Opportunities</li> <li>Paste it into any conversation \u2014 the AI will scan its context, interview you, and produce a structured report</li> <li>Pick 1-2 opportunities to pilot first \u2014 don't try to pursue everything at once</li> </ol> <p>Start with Collaborative AI</p> <p>If you're new to AI, start with Collaborative AI opportunities \u2014 they're the easiest to try and lowest risk. Move to Deterministic Workflows once you've identified a process you repeat often. Explore Autonomous Agents when you have experience with the other two categories.</p>"},{"location":"business-first-ai-framework/questions/how-do-i-find-workflows-worth-applying-ai-to/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Don't wait for problems \u2014 proactively audit your workflows to find AI opportunities</li> <li>Think in three categories: deterministic workflows, collaborative AI, and autonomous agents</li> <li>Use the six use case primitives \u2014 content creation, research, coding, data analysis, ideation, and automation \u2014 to classify what type of work each opportunity involves</li> <li>Use the Discover AI Workflow Opportunities meta prompt to run a structured audit</li> <li>The richer context your AI has about your work, the better the recommendations</li> <li>Start small \u2014 pick 1-2 opportunities and pilot them before scaling</li> </ul>"},{"location":"business-first-ai-framework/questions/how-do-i-find-workflows-worth-applying-ai-to/#related-questions","title":"Related Questions","text":"<ul> <li>What is a system prompt?</li> </ul>"},{"location":"business-first-ai-framework/questions/how-do-i-identify-the-right-ai-tools-for-a-workflow/","title":"How do I identify the right AI tools for a workflow?","text":"<p>Short answer: Break your workflow into discrete steps using the 5-question framework (steps, decisions, data flows, context needs, failure modes), then map each step to AI building blocks like prompts, skills, agents, and connectors to see exactly what to build.</p>"},{"location":"business-first-ai-framework/questions/how-do-i-identify-the-right-ai-tools-for-a-workflow/#the-full-answer","title":"The Full Answer","text":"<p>You can't choose the right AI tools for a workflow you don't fully understand. The Business-First AI Framework addresses this with a structured approach: discover opportunities first, then deconstruct workflows into building blocks before selecting tools.</p> <p>Most people jump straight to tool selection \u2014 \"Should I use an agent? Do I need an API?\" \u2014 before they've properly decomposed what the workflow actually involves. The result is over-engineered solutions for simple problems, or under-powered tools for complex ones.</p> <p>The right approach is to deconstruct first, then map. Start by breaking your workflow into discrete steps using the 5-question framework: What are the individual steps? Where are the decision points? What data flows in and out? What context does each step need? What happens when this step fails? That last question surfaces the exception paths where the most important logic often lives.</p> <p>Once you have the refined step-by-step breakdown, map each step to one or more of the seven AI building blocks:</p> Building Block What It Is When to Use It Model The AI engine that processes inputs and generates outputs When the task requires specific capabilities (reasoning, multimodal, speed) Prompt A well-crafted instruction that tells the model what to do Single-step tasks with clear inputs and outputs Context Background information, reference docs, or examples Steps that need domain knowledge or specific data Skill A reusable routine \u2014 give it inputs, it follows a defined process, it produces consistent outputs Repeatable tasks you'll run many times Agent An autonomous AI that plans, uses tools, and executes multi-step work Complex steps requiring judgment and tool use MCP (Model Context Protocol) A connector to external tools, APIs, or databases Steps that need to read from or write to external systems Project A persistent workspace grouping prompts, context, skills, and agents Organizing everything for a specific workflow <p>Not every step needs AI. The deconstruction also classifies each step on an autonomy spectrum \u2014 from fully human to fully autonomous \u2014 so you can see which steps are candidates for AI and which should stay manual.</p>"},{"location":"business-first-ai-framework/questions/how-do-i-identify-the-right-ai-tools-for-a-workflow/#how-to-get-started","title":"How to Get Started","text":"<p>Use the Deconstruct Workflows to run through this process interactively. Paste it into any AI tool and it will:</p> <ol> <li>Discover your scenario \u2014 understand the workflow objective and rough steps</li> <li>Deep dive into each step \u2014 apply the 5-question framework</li> <li>Map to building blocks \u2014 classify each step and recommend the right AI tools</li> <li>Generate deliverables \u2014 produce a workflow analysis document and an executable prompt you can save and reuse</li> </ol> <p>Start with a workflow you actually do</p> <p>Real workflows produce the best analysis. The meta prompt is designed to work with rough, incomplete descriptions \u2014 don't over-prepare. Even \"I onboard new clients and it takes forever\" is enough to start. The model will find the hidden steps and assumptions you've internalized.</p>"},{"location":"business-first-ai-framework/questions/how-do-i-identify-the-right-ai-tools-for-a-workflow/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Deconstruct the workflow before choosing tools \u2014 you can't pick the right AI building blocks for a process you don't fully understand</li> <li>Use the 5-question framework: discrete steps, decision points, data flows, context needs, and failure modes</li> <li>Map each step to one or more of the seven building blocks: Model, Prompt, Context, Skill, Agent, MCP, or Project</li> <li>Not every step needs AI \u2014 the autonomy classification helps you see which steps are candidates and which should stay manual</li> <li>Use the Deconstruct Workflows to run through this process interactively</li> </ul>"},{"location":"business-first-ai-framework/questions/how-do-i-identify-the-right-ai-tools-for-a-workflow/#related-questions","title":"Related Questions","text":"<ul> <li>How do I find workflows worth applying AI to?</li> <li>What is a system prompt?</li> </ul>"},{"location":"courses/","title":"Courses","text":"<p>Structured learning paths with live instruction on Maven.</p>"},{"location":"courses/#available-courses","title":"Available Courses","text":""},{"location":"courses/#claude-and-claude-code-for-builders","title":"Claude and Claude Code for Builders","text":"<p>Transform from a Claude user into a Claude builder through hands-on experience with the complete AI builder stack.</p> <p>Duration: 5 weeks | Format: Live cohort-based</p> <p> Course details</p>"},{"location":"courses/#hands-on-agentic-ai-for-leaders","title":"Hands-on Agentic AI for Leaders","text":"<p>Learn to evaluate, implement, and lead AI initiatives that drive business value.</p> <p>Duration: 4 weeks | Format: Live cohort-based</p> <p> Course details</p>"},{"location":"courses/#about-these-courses","title":"About These Courses","text":"<p>Both courses are taught by James Gray on Maven. They emphasize:</p> <ul> <li>Hands-on practice - Build real systems, not just theory</li> <li>Live instruction - Interactive sessions with Q&amp;A</li> <li>Community - Private Slack workspace for peer collaboration</li> <li>Practical outcomes - Skills you can use immediately</li> </ul>"},{"location":"courses/#prerequisites","title":"Prerequisites","text":"<p>Each course has specific prerequisites. Generally you'll need:</p> <ul> <li>A Claude Pro, Max, or Team subscription</li> <li>macOS or Windows with admin access</li> <li>Willingness to work in the terminal</li> </ul>"},{"location":"courses/builders/","title":"Claude and Claude Code for Builders","text":"<p>From Claude user to Claude builder in 5 weeks. This cohort-based course teaches you to move beyond basic AI usage and build production-grade AI systems \u2014 configuring a complete builder infrastructure, creating reusable AI capabilities, developing autonomous workflows, and shipping applications using agentic coding principles.</p> <p>Enroll on Maven  View full syllabus </p>"},{"location":"courses/builders/#who-this-course-is-for","title":"Who This Course Is For","text":"<ul> <li>Operational Leaders building AI systems for their teams</li> <li>Builder-Founders prototyping quickly without engineering resources</li> <li>AI-First Professionals establishing AI-centered workflows</li> </ul>"},{"location":"courses/builders/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Configure a complete AI builder technology stack</li> <li>Design systematic workflow registries to track your AI operations</li> <li>Build Claude Skills for recurring tasks</li> <li>Create multi-agent systems with subagents</li> <li>Implement browser automation with Claude</li> <li>Write specifications and ship web applications using agentic coding</li> <li>Collaborate with Claude Cowork for knowledge work</li> </ul>"},{"location":"courses/builders/#what-youll-build","title":"What You'll Build","text":"<p>By the end of the course, you'll have five production-ready assets: 5+ Skills, 3+ Subagents, browser automations, and a working prototype \u2014 plus a capstone project demonstrating systematic AI implementation.</p>"},{"location":"courses/builders/#course-format","title":"Course Format","text":"Duration 5 weeks Commitment 4-6 hours per week Live Sessions Two 90-minute sessions per week Office Hours Optional Saturday sessions plus weekday availability Community Private Slack workspace for peer collaboration Recordings Lifetime access to all session recordings"},{"location":"courses/builders/#prerequisites","title":"Prerequisites","text":"<ul> <li>Claude paid subscription (Pro or higher)</li> <li>GitHub, Cursor or VS Code, Chrome installed</li> <li>macOS or Windows with admin access to install software</li> </ul> <p>Setup guides are available under Builder Setup.</p>"},{"location":"courses/builders/#instructor","title":"Instructor","text":"<p>James Gray \u2014 UC Berkeley AI instructor and former CIO/CPO. Previously spent 10 years at Microsoft building enterprise data platforms. Has trained 5,000+ executives globally in AI strategy.</p> <ul> <li>Maven Profile</li> <li>Other course: Hands-on Agentic AI for Leaders</li> </ul>"},{"location":"courses/builders/syllabus/","title":"Course Syllabus","text":"<p>Full syllabus for Claude and Claude Code for Builders.</p> <p>Enroll on Maven </p>"},{"location":"courses/builders/syllabus/#week-1-foundation-setup","title":"Week 1: Foundation &amp; Setup","text":"<p>Configure complete AI builder infrastructure with version control, work profiles, and operational playbook</p>"},{"location":"courses/builders/syllabus/#session-1-ai-builder-stack-setup","title":"Session 1: AI Builder Stack Setup","text":"<p>Establish your complete AI builder infrastructure by installing and configuring Cursor/VS Code, GitHub, Claude Code CLI, voice-to-text tools, and personalized Claude profiles across all platforms. This foundational toolkit enables every hands-on session throughout the course.</p> <p>Outcomes:</p> <ul> <li>Fully configured AI builder toolkit with Cursor/VS Code, GitHub account, Claude Code CLI, and voice-to-text integration ready for course work</li> <li>Personalized Claude profiles across Claude.ai, Desktop, and Code with custom memory settings, style preferences, and project configuration</li> <li>Verified technical environment with all prerequisites tested and troubleshooting completed</li> </ul> Module 1: Configure Your AI Builder Stack <p>Build the infrastructure that transforms AI from occasional tool to daily operating system. You'll configure code editors, GitHub, Claude Code, voice-to-text tools, and work profiles across Claude platforms\u2014establishing the complete technical foundation that enables all hands-on builder work throughout the course and beyond.</p> # Lesson Type Duration Resources 1 Configure Claude Personalization and Memory Settings  Slides 1 Configure Your AI Personalization Settings  Live 15 min  Slides 2 Implement Version Control for Your AI Building Blocks  Live  Slides 2 Configure AI Memory Systems  Live 20 min  Slides 3 Configure AI-Powered Code Editor  Live  Slides 4 Implement Voice-to-Text for Hands-Free AI Collaboration  Live  Slides Configure Claude Personalization and Memory Settings <p>Configure your Claude environment for maximum productivity throughout the course. You'll customize communication preferences, writing style, and feature settings, then activate Claude's memory system to maintain context across conversations. Proper configuration ensures Claude adapts to your workflow, remembers your preferences, and delivers responses aligned with your goals and communication style.</p> <p>Objectives:</p> <ul> <li>Configure Claude's personalization settings including communication style, tone preferences, response formatting, and feature toggles to match your workflow requirements</li> <li>Activate Claude's memory system and verify it's capturing conversation context, project details, and preferences across sessions</li> <li>Test personalized responses by comparing Claude's output before and after configuration to validate that settings are working as intended</li> </ul> Configure Your AI Personalization Settings <p>Configure your AI platforms to match your professional standards and communication style. You'll set up user preferences, define output formats, configure security settings including privacy controls and MFA, and establish baseline behaviors. By the end of this lesson, your AI tools will consistently deliver responses aligned with your professional requirements\u2014without needing to specify preferences in every conversation.</p> <p>Objectives:</p> <ul> <li>Configure personalized work profiles on your AI tools using custom instructions that reflect your role, work context, and response preferences</li> <li>Implement privacy and security protections across all platforms by disabling model training data sharing and enabling multi-factor authentication</li> <li>Apply personalization strategically across platforms based on each platform's available features (custom instructions, user preferences, style settings, output formats)</li> </ul> Implement Version Control for Your AI Building Blocks <p>Implement GitHub version control as your safety net for AI building block development. Create a repository to store Skills, Prompts, Agent configurations, and workflows with full change history. Master the create-commit-push workflow that professional developers use to track iterations, experiment without risk, collaborate across teams, and recover from mistakes\u2014critical infrastructure for building production AI systems.</p> <p>Objectives:</p> <ul> <li>Create a GitHub repository to store and version your AI building blocks (Skills, Prompts, Agents, configurations)</li> <li>Execute the create \u2192 commit \u2192 push workflow to save a building block to your repository</li> <li>Verify your repository syncs between local and cloud to protect your work</li> </ul> Configure AI Memory Systems <p>Activate AI memory systems that automatically retain your professional context across conversations. You'll enable persistent memory, populate your tools with key facts about your role and work, establish memory hygiene practices for reviewing and editing stored information, and set privacy boundaries. Your AI assistants will remember your context automatically\u2014no more re-explaining who you are or what you're working on every conversation.</p> <p>Objectives:</p> <ul> <li>Configure active memory systems on your AI platforms that retain key professional context across conversations without repeated explanations</li> <li>Implement memory settings across platforms by enabling persistent context between sessions</li> <li>Populate your AI memory with 2-3 critical professional facts about your role, work context, and communication preferences</li> <li>Apply memory hygiene practices by reviewing stored information and protecting sensitive data from AI memory</li> </ul> Configure AI-Powered Code Editor <p>Transform your development workflow with an AI-powered code editor (Cursor or VS Code). Configure AI model integration (Claude, ChatGPT, Gemini, or other CLI models) that lets you generate code through natural language, get instant explanations for complex logic, and refactor with AI assistance. This workspace becomes essential infrastructure for building Skills, workflows, and Agents\u2014enabling builders without deep coding backgrounds to create production-quality AI systems.</p> <p>Objectives:</p> <ul> <li>Configure an AI-powered code editor (Cursor or VS Code) as your workspace for AI building block development</li> <li>Install and authenticate at least one AI model integration (Claude Code, ChatGPT Codex, Gemini CLI, or similar)</li> <li>Create and preview a Markdown file to verify your editor is properly configured</li> </ul> Implement Voice-to-Text for Hands-Free AI Collaboration <p>Install and configure a voice-to-text application (Wispr Flow recommended) to enable hands-free interaction with AI tools and code editors throughout the course. You'll practice voice dictation, learn best practices for speaking with AI, and set up your environment for maximum productivity. Voice-first collaboration dramatically accelerates your workflow\u2014especially for complex prompts and multi-step instructions.</p> <p>Objectives:</p> <ul> <li>Install and configure a voice-to-text application (Wispr Flow or alternative) with proper permissions and settings for AI platform integration</li> <li>Practice voice dictation techniques including formatting commands, punctuation control, and natural speech patterns to achieve 90%+ accuracy</li> <li>Demonstrate hands-free AI collaboration by completing a workflow entirely through voice\u2014from initial prompt to refinement to final output</li> <li>Apply voice-first best practices for complex multi-step instructions, ensuring clarity and reducing the need for manual typing throughout the course</li> </ul>"},{"location":"courses/builders/syllabus/#session-2-workflow-deconstruction","title":"Session 2: Workflow Deconstruction","text":"<p>Apply a systematic framework to deconstruct your business processes into discrete workflows and identify AI automation opportunities. Build your AI Operations Registry in Notion\u2014a living catalog for tracking workflows, assets, and SOPs\u2014and connect it to Claude via MCP for collaborative workflow design.</p> <p>Outcomes:</p> <ul> <li>Agentic AI mental model established\u2014Understanding of Skills, Subagents, MCP servers, and Claude Projects as core building blocks for autonomous systems</li> <li>Process deconstruction framework applied\u2014At least one business process deconstructed into discrete workflows with AI automation opportunities identified</li> <li>Claude Project configured\u2014Project set up with memory enabled, custom instructions, and knowledge base populated with relevant context</li> <li>AI Operations Registry built\u2014Notion workspace configured with interconnected databases for tracking processes, workflows, AI assets, and SOPs</li> <li>MCP integrations active\u2014Notion MCP server connected to Claude Desktop, enabling collaborative workflow design and documentation</li> </ul> Module 2: Deconstruct &amp; Register Your Workflows <p>Transform chaotic AI experimentation into systematic operations. You'll deconstruct processes into discrete workflows, identify automation opportunities using proven frameworks, and build your Workflow Registry in Notion\u2014a living catalog that tracks all workflows, assets, and SOPs. Connect it to Claude via MCP so Claude helps you design, document, and organize everything as you build.</p> # Lesson Type Duration Resources Build Your Claude Project with Memory and Knowledge Base  Live 90 min  Slides 2 Deconstruct Your Work and Identify AI Building Blocks  Live 60 min  Slides 3 Build Your AI Operations Registry  Live 30 min  Slides 3 Set Up Your AI Workflow Registry  Live 30 min  Slides 4 Configure MCP Server Connections and Desktop Integrations  Live 90 min  Slides Build Your Claude Project with Memory and Knowledge Base <p>Build a dedicated Claude Project that maintains conversation memory and serves as a centralized knowledge repository. You'll configure project-level custom instructions, enable persistent memory that evolves with each interaction, and populate the knowledge base with reference files that Claude can access automatically\u2014eliminating repetitive file uploads and creating a workspace that gets smarter over time.</p> <p>Objectives:</p> <ul> <li>Build a Claude Project with custom instructions, persistent memory enabled, and project-specific settings configured for course workflows</li> <li>Populate the project knowledge base with essential reference files (workflows, documentation, templates) that Claude can access automatically across all conversations</li> <li>Test persistent context by verifying that Claude retains project-specific information across multiple sessions and references knowledge base files without re-uploading</li> <li>Apply project-based workflows by conducting a complete task entirely within the project to validate memory retention and knowledge base accessibility</li> </ul> Deconstruct Your Work and Identify AI Building Blocks <p>Turn implicit workflows into systematic AI operations. You'll deconstruct two real-world workflows\u2014one Collaborative AI, one Deterministic Automation\u2014using the 4-question framework to identify discrete steps, decision points, data flows, and context requirements. Then apply the meta-prompting technique to your own workflows, letting AI generate complete workflow specifications with building blocks mapped, ready for execution and version control.</p> <p>Objectives:</p> <ul> <li>Apply the deconstruction framework to break down a named workflow into detailed steps that reveal the process structure and implementation requirements</li> <li>Map AI building blocks (Prompt, Context, Skill, Agent, MCP, Project) to each workflow step, identifying which building blocks are needed to operationalize each step</li> <li>Generate three production-ready deliverables using the meta-prompt: workflow analysis document, executable baseline prompt, and skill build recommendations that provide the necessary detail to build the AI-powered workflow</li> </ul> Build Your AI Operations Registry <p>Implement your operational control center for managing AI workflows and assets. Students replicate the Notion registry template, configure tracking fields, and document their first complete workflow including SOP and building blocks. Claude users integrate Skills with Notion MCP to enable bidirectional collaboration for reading and writing workflow data throughout the course.</p> <p>Objectives:</p> <ul> <li>Implement your AI Operations Registry by replicating the Notion database template and configuring workflow tracking fields</li> <li>Integrate Claude Skills with your registry via Notion MCP to enable collaborative workflow management and building block documentation</li> <li>Document one end-to-end workflow in your registry including SOP and associated AI assets</li> </ul> Set Up Your AI Workflow Registry <p>Objectives:</p> <ul> <li>Create a systematic inventory cataloging at least 3 recurring workflows with their triggers, steps, and outcomes, and the AI assets (prompts, skills, agents, context files) linked to each workflow to visualize dependencies</li> <li>Build a relational database system in Notion with separate tables for Business Processes, Workflows, AI Assets, and Apps to serve as your living repository</li> <li>Identify at least 3 high-value recurring workflows from your actual work, documenting each with trigger conditions, step-by-step process, desired outcomes, and AI automation opportunities</li> <li>Catalog existing AI assets by type (prompts, skills, agents, context files), organize them in a structured repository, and establish relational links to the workflows that depend on them</li> </ul> Configure MCP Server Connections and Desktop Integrations <p>Extend Claude's capabilities by configuring connections to external systems through MCP (Model Context Protocol). You'll connect Claude to remote MCP servers for services like Slack, GitHub, and Google Drive, then configure desktop connectors to access local applications and your filesystem. These integrations enable Claude to read data, trigger actions, and automate workflows across your entire tech stack.</p> <p>Objectives:</p> <ul> <li>Configure MCP server connections to at least two remote services (e.g., Slack, GitHub, Google Drive, Notion) with proper authentication and permissions</li> <li>Implement desktop connectors to access local filesystem, applications, or services running on your machine</li> <li>Test integration functionality by executing Claude commands that read data from connected systems and trigger actions across multiple services</li> <li>Troubleshoot connection issues using MCP diagnostics to verify successful authentication, resolve permission errors, and validate data access</li> </ul>"},{"location":"courses/builders/syllabus/#week-2-building-skills","title":"Week 2: Building Skills","text":"<p>Build reusable Claude Skills and configure Projects with MCP integrations for collaborative augmentation workflows</p>"},{"location":"courses/builders/syllabus/#session-3-claude-skills","title":"Session 3: Claude Skills","text":"<p>Students deconstruct their workflows using the business process \u2192 workflow \u2192 skill framework to identify which patterns deserve packaging as reusable skills. Students package workflow instructions into Claude Skills with proper metadata, instructions, and bundled resources. Students deploy skills across Claude.ai, Desktop, and Claude Code, learning platform-specific deployment considerations.</p> Module 1: Build Agent Skills <p>Turn your expertise into reusable AI automation that scales across teams and organizations. You'll build production-ready Agent Skills that package your knowledge into instructions Claude can apply anywhere, save them to your Agentic AI Repository with version control, then publish them as installable plugins through GitHub-hosted marketplaces\u2014making your skills discoverable and distributable for internal teams, client delivery, or commercial licensing.</p> # Lesson Type Duration Resources 1 Analyze the Anatomy of an Agent Skill  Self-Paced 20 min  Slides 2 Connect AI to Your Business Apps via MCP  Live 10 min  Slides 3 Build Reusable Agent Skills with Claude  Live 60 min  Slides 4 Ship Your Skills for Reuse  Live 60 min Analyze the Anatomy of an Agent Skill <p>Dissect what Skills are\u2014reusable instruction sets that teach Claude how to execute your workflows consistently. Analyze their anatomy: metadata, instructions, and resources. Then distinguish when to use Skills versus Prompts, Projects, MCP, or Agents.</p> <p>Objectives:</p> <ul> <li>Analyze the anatomy of an Agent Skill including metadata, instructions, and resource structure</li> <li>Distinguish Skills from Prompts, Projects, MCP, and Subagents to select the right building block</li> <li>Identify when to use each agentic building block based on the workflow requirements</li> </ul> Connect AI to Your Business Apps via MCP <p>Objectives:</p> <ul> <li>Configure MCP connections to connect your AI assistant to external tools and data sources with proper authentication and permissions</li> <li>Set up working connectors for business applications (Gmail, Drive, Notion, Slack, HubSpot) relevant to your workflow</li> <li>Test each configured connector by executing prompts that successfully call external tools and retrieve data</li> <li>Distinguish between remote MCP servers (cloud-based) and local desktop extensions to select the right architecture for different use cases</li> </ul> Build Reusable Agent Skills with Claude <p>Transform your workflow knowledge into a production-ready Agent Skill from scratch. You'll structure your skill with proper metadata and instructions, test it in a live conversation, save it to your repository with version control, and export it to your local machine\u2014making it available across Claude.ai, Claude Code, and Cowork.</p> <p>Objectives:</p> <ul> <li>Build a production-ready Agent Skill that packages your expertise into reusable instructions for Claude</li> <li>Structure your skill with proper metadata, instructions, and supporting resources</li> <li>Save skills to your repository for version control and register them in your AI Assets database</li> <li>Export skills to your local machine for use across Claude platforms (Code, Cowork)</li> </ul> Ship Your Skills for Reuse <p>Package and ship your skills as installable resources. One command gives others access to your expertise\u2014team members, clients, or the broader AI community. Your workflow knowledge becomes reusable, distributable, scalable.</p> <p>Objectives:</p> <ul> <li>Create a properly structured marketplace.json file with plugin metadata for at least one skill</li> <li>Publish a GitHub repository containing their skill marketplace that others can add via /plugin marketplace add</li> <li>Configure distribution settings for three deployment scenarios: private team use, organizational access, and public community sharing</li> <li>Demonstrate the complete installation workflow by having another team member successfully install their published plugin</li> </ul>"},{"location":"courses/builders/syllabus/#session-4-collaborative-agentic-workflows","title":"Session 4: Collaborative Agentic Workflows","text":"<p>Students configure Claude Projects with custom instructions, knowledge bases, and context that persists across conversations. Students integrate MCP servers (Notion, Google Drive, Slack, etc.) to give Claude Projects tool access for context-aware collaboration. Students build collaborative workflows for research synthesis, document analysis, and content creation where Claude works WITH them as an intelligent partner.</p>"},{"location":"courses/builders/syllabus/#week-3-automation-agents","title":"Week 3: Automation &amp; Agents","text":"<p>Deploy autonomous Subagents and browser automations with scheduled workflows delegating 15-20 hours per week</p>"},{"location":"courses/builders/syllabus/#session-5-subagents-autonomous-workflows","title":"Session 5: Subagents &amp; Autonomous Workflows","text":"<p>Students design Subagents with appropriate tool permissions, system prompts, and constraints for autonomous operation. Students deploy specialized Subagents for code review, research analysis, data processing, and other domain-specific tasks. Students test Subagent reliability, identify failure modes, and refine prompts and permissions for consistent autonomous execution.</p> Module 10: Analyze and Design Agent Architectures <p>Understand what's happening under the hood, then design your own. You'll analyze the anatomy of AI agents and master orchestration patterns for multi-agent systems. Then you'll apply a systematic design process to deconstruct your workflows into platform-agnostic agent specifications. By the end, you'll have agent designs ready to implement on Claude Code, ChatGPT, Gemini, or any platform.</p> # Lesson Type Duration Resources 1 Analyze the Anatomy of an AI Agent  Live 10 min  Slides 2 Analyze Agent Capability Patterns  Live 15 min  Slides 3 Analyze Agent Orchestration Patterns  Live 15 min  Slides 4 Design Autonomous Workflows with Agents  Live 50 min  Slides Analyze the Anatomy of an AI Agent <p>Objectives:</p> <ul> <li>Distinguish between agents and workflows by comparing their autonomy levels, decision-making capabilities, and appropriate use cases on the agentic systems spectrum</li> <li>Identify the core components of an agent (LLM brain, tools, memory, instructions, knowledge) and explain how these components work together regardless of platform</li> <li>Evaluate business scenarios to determine when autonomous agents are appropriate versus structured workflows, based on task predictability, complexity, and need for dynamic planning</li> <li>Select optimal use cases for agentic implementation by matching task characteristics (open-ended problems, multi-step complexity, tool requirements) to agent capabilities</li> </ul> Analyze Agent Capability Patterns <p>Objectives:</p> <ul> <li>Distinguish the five agentic capability patterns (Reflection, Tool Use, Planning, Multi-agent Collaboration, Memory) by their role in agent execution</li> <li>Analyze how capability patterns work together using the customer exchange scenario</li> <li>Differentiate guardrails from human-in-the-loop controls for managing agent behavior</li> </ul> Analyze Agent Orchestration Patterns <p>Objectives:</p> <ul> <li>Analyze orchestration patterns for multi-agent systems: supervisor, swarm, hierarchical, and debate</li> <li>Compare pattern strengths and weaknesses for different task types and complexity levels</li> <li>Select the appropriate orchestration pattern for a given multi-agent workflow scenario</li> </ul> Design Autonomous Workflows with Agents <p>Objectives:</p> <ul> <li>Apply a systematic design process for agent systems by defining clear goals, processes, agent roles, instructions, and required tools</li> <li>Generate clear, unambiguous instructions for LLM agents using meta-prompting techniques and reasoning models to ensure reliable execution</li> <li>Design single-agent systems by specifying agent roles, responsibilities, and tool requirements for focused automation tasks</li> <li>Architect multi-agent systems by identifying and naming specialized agent roles that work together to accomplish complex goals</li> <li>Distinguish between single-agent and multi-agent approaches based on task complexity and the need for specialized expertise across different workflow components</li> </ul> Module 11: Build Autonomous Workflows with Claude Code Subagents <p>Build production-ready autonomous workflows using Claude Code Subagents. You'll translate your agent designs into working implementations, master single and multi-agent orchestration patterns, and operationalize workflows with scheduling and monitoring. By the end, you'll have autonomous AI systems executing complex workflows independently.</p> # Lesson Type Duration Resources 1 Analyze Claude Code Subagent Architecture and Use Cases  Live 60 min  Slides 2 Build Your First Claude Code Subagent  Live 60 min  Slides 4 Build Multi-Agent Systems with Claude Code  Live 60 min 5 Analyze Claude Code Subagent Orchestration Patterns  Live 60 min  Slides 6 Implement Scheduled Execution for Claude Code Subagents  Live 60 min  Slides 7 Analyze Claude Code Subagent Execution Traces  Live 60 min  Slides Analyze Claude Code Subagent Architecture and Use Cases <p>Understand what Claude Code subagents are, master the critical distinction between Skills and Subagents, and learn when to use each approach. Explore the mental model of building a specialized team of AI agents, develop a decision framework for choosing between Skills and Subagents, and identify appropriate use cases for subagent-based solutions in business contexts.</p> <p>Objectives:</p> <ul> <li>Define Claude Code subagents and explain their role in autonomous workflows</li> <li>Distinguish between Claude Skills (training manuals with shared context) and Subagents (specialized employees with isolated context) across key dimensions</li> <li>Apply a decision framework to determine when to use Skills, Subagents, or both for specific workflow requirements</li> <li>Analyze the \"dream team\" mental model to understand subagent specialization and delegation patterns</li> <li>Evaluate business scenarios to identify appropriate use cases for subagent-based autonomous workflows</li> </ul> Build Your First Claude Code Subagent <p>Transform your agent system design into a working implementation. Configure MCP tools in Claude Code, create your subagent with appropriate tool assignments and instructions, and test it with real tasks. Learn to debug, iterate, and refine subagent behavior through hands-on practice. Students complete this lesson with a fully functional subagent ready for real-world use.</p> <p>Objectives:</p> <ul> <li>Configure MCP tools in Claude Code to prepare tool access for subagent implementation</li> <li>Create a subagent by translating design specifications into Claude Code configuration (description, tools, model, system prompt)</li> <li>Evaluate subagent performance by testing with real tasks and observing delegation behavior</li> <li>Refine subagent configuration based on testing results to improve reliability and output quality</li> </ul> Build Multi-Agent Systems with Claude Code <p>Build complete multi-agent systems from your workflow specifications using Claude Code's AI-assisted configuration. You'll transform your Module 10 design into a working system\u2014single or multi-agent\u2014by prompting Claude Code to generate all necessary subagent configurations. Learn to review, refine, and validate auto-generated systems, ensuring proper orchestration and tool delegation. Master the AI-assisted workflow that makes complex agent systems buildable in minutes.</p> <p>Objectives:</p> <ul> <li>Build complete agent systems by prompting Claude Code to auto-generate configurations from workflow specifications</li> <li>Evaluate generated subagent configurations against design intent to ensure proper tool assignments and orchestration patterns</li> <li>Refine multi-agent systems by adjusting delegation logic, tool restrictions, and coordination patterns based on testing results</li> <li>Apply judgment to decide system architecture (single vs. multi-agent) and when to use AI-assisted generation versus manual configuration</li> </ul> Analyze Claude Code Subagent Orchestration Patterns <p>Master subagent execution from single-agent workflows to complex multi-agent orchestration. Learn three activation methods (explicit invocation, automatic delegation, chaining), understand when multiple agents outperform single-agent solutions, and apply orchestration patterns including sequential, parallel, and hybrid execution with hooks for reliable autonomous workflow behavior.</p> <p>Objectives:</p> <ul> <li>Execute Claude Code subagents using three activation methods (explicit invocation, automatic delegation, chaining) to accomplish single-task workflows</li> <li>Evaluate when to use multiple specialized agents versus a single agent based on workflow complexity and context isolation needs</li> <li>Design a multi-agent workflow using sequential, parallel, or hybrid orchestration patterns for a complex business use case</li> <li>Implement hooks (guardrails, logging, human-in-the-loop) to ensure reliable multi-agent system behavior</li> </ul> Implement Scheduled Execution for Claude Code Subagents <p>Learn to automate Claude Code subagent execution using native operating system schedulers. Configure Windows Task Scheduler and macOS cron jobs to run subagents on recurring schedules, implement error handling and notifications, and understand when scheduled execution is appropriate versus on-demand triggers. Students will schedule one of their existing Claude Code subagents to run automatically.</p> <p>Objectives:</p> <ul> <li>Configure OS-level scheduling (Windows Task Scheduler or macOS cron) to execute Claude Code subagents automatically</li> <li>Implement error handling and notification mechanisms for scheduled subagent runs</li> <li>Evaluate which workflows benefit from scheduled execution versus on-demand triggers</li> <li>Test and verify scheduled subagent execution with proper logging and output capture</li> </ul> Analyze Claude Code Subagent Execution Traces <p>Master Claude Code's built-in tracing capabilities to gain visibility into subagent execution. Learn to read execution traces, understand multi-agent delegation patterns, diagnose failures, and debug common issues. Students will add tracing to their multi-agent systems and use trace data to troubleshoot and optimize subagent behavior.</p> <p>Objectives:</p> <ul> <li>Analyze Claude Code execution traces to understand subagent delegation patterns and tool usage</li> <li>Diagnose subagent execution failures using trace data and error logs</li> <li>Evaluate subagent performance and identify optimization opportunities through tracing</li> <li>Implement tracing best practices for debugging multi-agent subagent workflows</li> </ul>"},{"location":"courses/builders/syllabus/#session-6-browser-automation-workflows-scheduling","title":"Session 6: Browser Automation, Workflows, Scheduling","text":"<p>Students use Claude in Chrome (browser automation) to extract data from web pages, fill forms, and navigate multi-step web processes. Students build complete browser automation workflows that combine data extraction, processing, and output generation. Students implement event-driven hooks and scheduled triggers to run autonomous workflows on a recurring basis without manual initiation.</p> Module 2: Deploy Automated Workflows <p>Automate repetitive web tasks end-to-end. You'll build browser automation workflows using Claude in Chrome for data extraction, form filling, and multi-step processes, then implement scheduled and event-driven triggers that run autonomously\u2014creating workflows that execute on their own without manual initiation, freeing you from repetitive browser-based work completely.</p> # Lesson Type Duration Resources 16 Lesson 6.1: Automate Web Tasks with Claude in Chrome  Live 17 Lesson 6.2: Build Complete Browser Automation Workflows  Live 18 Lesson 6.3: Implement Scheduled and Event-Driven Workflows  Live Lesson 6.1: Automate Web Tasks with Claude in Chrome <p>Students use Claude in Chrome (browser automation) to extract data from web pages, fill forms, and navigate multi-step web processes</p> Lesson 6.2: Build Complete Browser Automation Workflows <p>Students build complete browser automation workflows that combine data extraction, processing, and output generation</p> Lesson 6.3: Implement Scheduled and Event-Driven Workflows <p>Students implement event-driven hooks and scheduled triggers to run autonomous workflows on a recurring basis without manual initiation</p>"},{"location":"courses/builders/syllabus/#week-4-shipping-applications","title":"Week 4: Shipping Applications","text":"<p>Build and deploy web application prototype using Claude Code's agentic coding workflow</p>"},{"location":"courses/builders/syllabus/#session-7-product-specs-agentic-coding","title":"Session 7: Product Specs &amp; Agentic Coding","text":"<p>Students translate a business idea or problem into product specifications, breaking down requirements, defining user flows, and creating a development plan with Claude as thought partner. Students begin building the application using Claude Code's autonomous iteration cycle, experiencing agentic coding workflow where Claude builds, tests, and refines code independently based on product requirements.</p> Module 1: Build with Agentic Coding <p>Experience the future of software development. You'll transform business ideas into product specifications with Claude as thought partner, then watch Claude Code autonomously build, test, and refine your application from requirements\u2014experiencing agentic coding workflow that expands what non-engineers can create and accelerates what engineers can ship.</p> # Lesson Type Duration Resources 19 Lesson 7.1: Translate Business Ideas into Technical Specs  Live 20 Lesson 7.2: Configure Claude Code Workspace and Hooks  Live 21 Lesson 7.3: Build Application with Agentic Coding Workflow  Live Lesson 7.1: Translate Business Ideas into Technical Specs <p>Students translate a business idea or problem into technical specifications, breaking down requirements, defining user flows, and creating a development plan with Claude as thought partner</p> Lesson 7.2: Configure Claude Code Workspace and Hooks <p>Students set up their Claude Code workspace with appropriate hooks (pre-commit, post-deploy), plugins, and integrations for the project</p> Lesson 7.3: Build Application with Agentic Coding Workflow <p>Students begin building the application, learning to leverage Claude Code's autonomous iteration cycle for rapid development</p>"},{"location":"courses/builders/syllabus/#session-8-app-feature-development-testing-deployment","title":"Session 8: App Feature Development, Testing, Deployment","text":"<p>Students develop the core features of their application using Claude Code's collaborative build process. Students test and debug their application, using Claude to identify issues, propose fixes, and refine functionality. Students deploy their completed prototype to Vercel, configure production settings, and prepare the application for user feedback.</p> Module 2: Build and Deploy Your Application <p>Ship your vision to production. You'll develop core application features collaboratively with Claude Code and GitHub, test and debug using Claude to identify issues and propose fixes, then deploy your prototype to Vercel with production settings\u2014experiencing firsthand how agentic coding expands your ability to take vision and bring it to life without traditional engineering constraints.</p> # Lesson Type Duration Resources Lesson 8.2: Test and Debug with Claude Assistance  Live 22 Lesson 8.1: Develop Core Features Collaboratively  Live 24 Lesson 8.3: Deploy Prototype to Vercel for Production  Live Lesson 8.2: Test and Debug with Claude Assistance <p>Students test and debug their application, using Claude to identify issues, propose fixes, and refine functionality</p> Lesson 8.1: Develop Core Features Collaboratively <p>Students develop the core features of their application using Claude Code's collaborative build process</p> Lesson 8.3: Deploy Prototype to Vercel for Production <p>Students deploy their completed prototype to Vercel, configure production settings, and prepare the application for user feedback</p>"},{"location":"courses/builders/syllabus/#week-5-integration-demo","title":"Week 5: Integration &amp; Demo","text":"<p>Complete capstone project and present portfolio of production AI systems built throughout course</p>"},{"location":"courses/builders/syllabus/#session-9-capstone-build-claude-cowork","title":"Session 9: Capstone Build, Claude Cowork","text":"<p>Students choose their capstone project focus: advanced workflow automation, custom web application, or integration project combining multiple capabilities. Students design their implementation plan with clear deliverables, success criteria, and timeline for completion. Bonus lesson (Max subscribers only): Students collaborate with Claude Cowork on complex knowledge work tasks\u2014research synthesis, document formatting, spreadsheet analysis, presentation creation\u2014learning to delegate multi-step desktop productivity work.</p> Module 1: Build Your Capstone Project <p>Integrate everything into one demonstration of transformation. You'll choose your capstone focus (advanced workflow automation, custom application, or integration project), design your implementation plan with clear deliverables and success criteria, then build it using all course concepts\u2014creating a portfolio piece that proves your transformation from AI user to AI builder.</p> # Lesson Type Duration Resources 25 Lesson 9.1: Choose Your Capstone Project Focus  Live 26 Lesson 9.2: Design Capstone Implementation Plan  Live Lesson 9.1: Choose Your Capstone Project Focus <p>Students choose their capstone project focus: advanced workflow automation, custom web application, or integration project combining multiple capabilities</p> Lesson 9.2: Design Capstone Implementation Plan <p>Students design their implementation plan with clear deliverables, success criteria, and timeline for completion</p> Module 3: Cowork on Productivity Tasks <p>Cowork with Claude on productivity tasks. You'll collaborate on research synthesis, document formatting, spreadsheet analysis, and presentation creation\u2014experiencing how working alongside Claude amplifies your output and transforms how you approach knowledge work.</p> # Lesson Type Duration Resources 27 Lesson 9.3: Collaborate with Claude Cowork (Bonus)  Live Lesson 9.3: Collaborate with Claude Cowork (Bonus) <p>Bonus lesson (Max subscribers only): Students collaborate with Claude Cowork on complex knowledge work tasks\u2014research synthesis, document formatting, spreadsheet analysis, presentation creation</p>"},{"location":"courses/builders/syllabus/#session-10-capstone-demos-student-insights-synthesis","title":"Session 10: Capstone Demos, Student Insights &amp; Synthesis","text":"<p>Students present their capstone projects to the cohort, demonstrating the problem solved, approach taken, and results achieved. Cohort provides peer feedback through structured review and Q&amp;A. Instructor synthesizes course themes, discusses next steps for continued growth, and provides guidance on ongoing skill development and community resources.</p> Module 2: Build Your Capstone Project <p>Complete your transformation from AI user to AI builder. You'll showcase your capstone project demonstrating problem, approach, and results, share transformation insights\u2014what you learned, what surprised you, and what you can now build that wasn't possible before\u2014then chart your path forward with clear next steps for continued growth as an AI builder.</p> # Lesson Type Duration Resources 28 Lesson 10.1: Present Capstone Projects to Cohort  Live 29 Lesson 10.2: Provide Peer Feedback and Q&amp;A  Live 30 Lesson 10.3: Synthesize Course Themes and Next Steps  Live Lesson 10.1: Present Capstone Projects to Cohort <p>Students present their capstone projects to the cohort, demonstrating the problem solved, approach taken, and results achieved</p> Lesson 10.2: Provide Peer Feedback and Q&amp;A <p>Cohort provides peer feedback through structured review and Q&amp;A</p> Lesson 10.3: Synthesize Course Themes and Next Steps <p>Instructor synthesizes course themes, discusses next steps for continued growth, and provides guidance on ongoing skill development and community resources</p> <p>This syllabus is generated from the course database and may be updated between cohorts.</p>"},{"location":"courses/builders/week-0/","title":"Week 0: Course Orientation","text":"<p>Complete these materials before your first live session.</p>"},{"location":"courses/builders/week-0/#orientation-lessons","title":"Orientation Lessons","text":"Lesson Description Welcome and Course Structure How the course works, what you'll accomplish Identify Your AI Builder Stack Overview of tools you'll use Navigate Maven Platform How to access sessions and materials Access Support Resources Slack, office hours, coaching Maximize Your Learning Tips for success FAQ Common questions"},{"location":"courses/builders/week-0/#time-to-complete","title":"Time to Complete","text":"<p>Estimated time: 30-45 minutes to read through all orientation materials.</p>"},{"location":"courses/builders/week-0/#next-steps","title":"Next Steps","text":"<p>After completing orientation, proceed to Week 1: Configure AI Builder Stack to set up your tools.</p>"},{"location":"courses/builders/week-1/","title":"Week 1: Configure AI Builder Stack","text":"<p>Get your complete development environment set up for building with Claude.</p>"},{"location":"courses/builders/week-1/#lesson-version-control-your-ai-assets","title":"Lesson: Version Control Your AI Assets","text":"<p>Create a GitHub repository to store and version your AI prompts, skills, and reference files.</p> <p>Setup Guides (complete in order):</p> <ol> <li>Git Installation \u2014 Install Git on your machine</li> <li>Editor Setup \u2014 Install Cursor or VS Code</li> <li>GitHub Setup \u2014 Create account and clone repositories</li> </ol>"},{"location":"courses/builders/week-1/#lesson-configure-your-ai-code-editor","title":"Lesson: Configure Your AI Code Editor","text":"<p>Set up Claude Code for AI-assisted development in your editor and terminal.</p> <p>Setup Guide:</p> <ul> <li>Claude Code Setup \u2014 Install extension and CLI, configure your environment</li> </ul>"},{"location":"courses/builders/week-1/#lesson-implement-voice-to-text-for-hands-free-ai-collaboration","title":"Lesson: Implement Voice-to-Text for Hands-Free AI Collaboration","text":"<p>Enable voice input for hands-free AI collaboration.</p> <p>Setup Guide:</p> <ul> <li>Voice-to-Text Setup \u2014 Configure Wispr Flow and Claude Desktop Quick Entry</li> </ul>"},{"location":"courses/builders/week-1/#lesson-build-your-ai-registry","title":"Lesson: Build Your AI Registry","text":"<p>Create your central hub for managing all AI operations across your business.</p> <p>Setup Guide:</p> <ul> <li>Notion Registry Setup \u2014 Duplicate the Notion database templates and customize for your business</li> </ul>"},{"location":"courses/builders/week-1/#lesson-configure-mcp-server-connections","title":"Lesson: Configure MCP Server Connections","text":"<p>Connect Claude to external applications and MCP servers.</p> <p>Setup Guide:</p> <ul> <li>MCP Connectors Setup \u2014 Configure integrations, custom connectors, and desktop extensions</li> </ul>"},{"location":"courses/builders/week-1/#lesson-set-up-claude-projects-and-personalization","title":"Lesson: Set Up Claude Projects and Personalization","text":"<p>Configure Claude to work effectively with your context.</p> <p>Setup Guides:</p> <ul> <li>Claude Projects Setup \u2014 Organize your AI work with projects</li> <li>Claude Personalization Setup \u2014 Configure Claude to understand your context</li> </ul>"},{"location":"courses/builders/week-1/#questions","title":"Questions?","text":"<p>Post in Slack or attend office hours for setup support.</p>"},{"location":"courses/builders/lessons/analyze-agent-capability-patterns/","title":"Analyze Agent Capability Patterns","text":"Course Claude and Claude Code for Builders Session Session 5: Subagents &amp; Autonomous Workflows Module Analyze and Design Agent Architectures Type  Live Duration 15 min"},{"location":"courses/builders/lessons/analyze-agent-capability-patterns/#objectives","title":"Objectives","text":"<ul> <li>Distinguish the five agentic capability patterns (Reflection, Tool Use, Planning, Multi-agent Collaboration, Memory) by their role in agent execution</li> <li>Analyze how capability patterns work together using the customer exchange scenario</li> <li>Differentiate guardrails from human-in-the-loop controls for managing agent behavior</li> </ul>"},{"location":"courses/builders/lessons/analyze-agent-capability-patterns/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/analyze-agent-orchestration-patterns/","title":"Analyze Agent Orchestration Patterns","text":"Course Claude and Claude Code for Builders Session Session 5: Subagents &amp; Autonomous Workflows Module Analyze and Design Agent Architectures Type  Live Duration 15 min"},{"location":"courses/builders/lessons/analyze-agent-orchestration-patterns/#objectives","title":"Objectives","text":"<ul> <li>Analyze orchestration patterns for multi-agent systems: supervisor, swarm, hierarchical, and debate</li> <li>Compare pattern strengths and weaknesses for different task types and complexity levels</li> <li>Select the appropriate orchestration pattern for a given multi-agent workflow scenario</li> </ul>"},{"location":"courses/builders/lessons/analyze-agent-orchestration-patterns/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/analyze-claude-code-subagent-architecture-and-use-cases/","title":"Analyze Claude Code Subagent Architecture and Use Cases","text":"Course Claude and Claude Code for Builders Session Session 5: Subagents &amp; Autonomous Workflows Module Build Autonomous Workflows with Claude Code Subagents Type  Live Duration 60 min <p>Understand what Claude Code subagents are, master the critical distinction between Skills and Subagents, and learn when to use each approach. Explore the mental model of building a specialized team of AI agents, develop a decision framework for choosing between Skills and Subagents, and identify appropriate use cases for subagent-based solutions in business contexts.</p>"},{"location":"courses/builders/lessons/analyze-claude-code-subagent-architecture-and-use-cases/#objectives","title":"Objectives","text":"<ul> <li>Define Claude Code subagents and explain their role in autonomous workflows</li> <li>Distinguish between Claude Skills (training manuals with shared context) and Subagents (specialized employees with isolated context) across key dimensions</li> <li>Apply a decision framework to determine when to use Skills, Subagents, or both for specific workflow requirements</li> <li>Analyze the \"dream team\" mental model to understand subagent specialization and delegation patterns</li> <li>Evaluate business scenarios to identify appropriate use cases for subagent-based autonomous workflows</li> </ul>"},{"location":"courses/builders/lessons/analyze-claude-code-subagent-architecture-and-use-cases/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/analyze-claude-code-subagent-execution-traces/","title":"Analyze Claude Code Subagent Execution Traces","text":"Course Claude and Claude Code for Builders Session Session 5: Subagents &amp; Autonomous Workflows Module Build Autonomous Workflows with Claude Code Subagents Type  Live Duration 60 min <p>Master Claude Code's built-in tracing capabilities to gain visibility into subagent execution. Learn to read execution traces, understand multi-agent delegation patterns, diagnose failures, and debug common issues. Students will add tracing to their multi-agent systems and use trace data to troubleshoot and optimize subagent behavior.</p>"},{"location":"courses/builders/lessons/analyze-claude-code-subagent-execution-traces/#objectives","title":"Objectives","text":"<ul> <li>Analyze Claude Code execution traces to understand subagent delegation patterns and tool usage</li> <li>Diagnose subagent execution failures using trace data and error logs</li> <li>Evaluate subagent performance and identify optimization opportunities through tracing</li> <li>Implement tracing best practices for debugging multi-agent subagent workflows</li> </ul>"},{"location":"courses/builders/lessons/analyze-claude-code-subagent-execution-traces/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/analyze-claude-code-subagent-orchestration-patterns/","title":"Analyze Claude Code Subagent Orchestration Patterns","text":"Course Claude and Claude Code for Builders Session Session 5: Subagents &amp; Autonomous Workflows Module Build Autonomous Workflows with Claude Code Subagents Type  Live Duration 60 min <p>Master subagent execution from single-agent workflows to complex multi-agent orchestration. Learn three activation methods (explicit invocation, automatic delegation, chaining), understand when multiple agents outperform single-agent solutions, and apply orchestration patterns including sequential, parallel, and hybrid execution with hooks for reliable autonomous workflow behavior.</p>"},{"location":"courses/builders/lessons/analyze-claude-code-subagent-orchestration-patterns/#objectives","title":"Objectives","text":"<ul> <li>Execute Claude Code subagents using three activation methods (explicit invocation, automatic delegation, chaining) to accomplish single-task workflows</li> <li>Evaluate when to use multiple specialized agents versus a single agent based on workflow complexity and context isolation needs</li> <li>Design a multi-agent workflow using sequential, parallel, or hybrid orchestration patterns for a complex business use case</li> <li>Implement hooks (guardrails, logging, human-in-the-loop) to ensure reliable multi-agent system behavior</li> </ul>"},{"location":"courses/builders/lessons/analyze-claude-code-subagent-orchestration-patterns/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/analyze-the-anatomy-of-an-agent-skill/","title":"Analyze the Anatomy of an Agent Skill","text":"Course Claude and Claude Code for Builders Session Session 3: Claude Skills Module Build Agent Skills Type  Self-Paced Duration 20 min <p>Dissect what Skills are\u2014reusable instruction sets that teach Claude how to execute your workflows consistently. Analyze their anatomy: metadata, instructions, and resources. Then distinguish when to use Skills versus Prompts, Projects, MCP, or Agents.</p>"},{"location":"courses/builders/lessons/analyze-the-anatomy-of-an-agent-skill/#objectives","title":"Objectives","text":"<ul> <li>Analyze the anatomy of an Agent Skill including metadata, instructions, and resource structure</li> <li>Distinguish Skills from Prompts, Projects, MCP, and Subagents to select the right building block</li> <li>Identify when to use each agentic building block based on the workflow requirements</li> </ul>"},{"location":"courses/builders/lessons/analyze-the-anatomy-of-an-agent-skill/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/analyze-the-anatomy-of-an-ai-agent/","title":"Analyze the Anatomy of an AI Agent","text":"Course Claude and Claude Code for Builders Session Session 5: Subagents &amp; Autonomous Workflows Module Analyze and Design Agent Architectures Type  Live Duration 10 min"},{"location":"courses/builders/lessons/analyze-the-anatomy-of-an-ai-agent/#objectives","title":"Objectives","text":"<ul> <li>Distinguish between agents and workflows by comparing their autonomy levels, decision-making capabilities, and appropriate use cases on the agentic systems spectrum</li> <li>Identify the core components of an agent (LLM brain, tools, memory, instructions, knowledge) and explain how these components work together regardless of platform</li> <li>Evaluate business scenarios to determine when autonomous agents are appropriate versus structured workflows, based on task predictability, complexity, and need for dynamic planning</li> <li>Select optimal use cases for agentic implementation by matching task characteristics (open-ended problems, multi-step complexity, tool requirements) to agent capabilities</li> </ul>"},{"location":"courses/builders/lessons/analyze-the-anatomy-of-an-ai-agent/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/build-multi-agent-systems-with-claude-code/","title":"Build Multi-Agent Systems with Claude Code","text":"Course Claude and Claude Code for Builders Session Session 5: Subagents &amp; Autonomous Workflows Module Build Autonomous Workflows with Claude Code Subagents Type  Live Duration 60 min <p>Build complete multi-agent systems from your workflow specifications using Claude Code's AI-assisted configuration. You'll transform your Module 10 design into a working system\u2014single or multi-agent\u2014by prompting Claude Code to generate all necessary subagent configurations. Learn to review, refine, and validate auto-generated systems, ensuring proper orchestration and tool delegation. Master the AI-assisted workflow that makes complex agent systems buildable in minutes.</p>"},{"location":"courses/builders/lessons/build-multi-agent-systems-with-claude-code/#objectives","title":"Objectives","text":"<ul> <li>Build complete agent systems by prompting Claude Code to auto-generate configurations from workflow specifications</li> <li>Evaluate generated subagent configurations against design intent to ensure proper tool assignments and orchestration patterns</li> <li>Refine multi-agent systems by adjusting delegation logic, tool restrictions, and coordination patterns based on testing results</li> <li>Apply judgment to decide system architecture (single vs. multi-agent) and when to use AI-assisted generation versus manual configuration</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/build-reusable-agent-skills-with-claude/","title":"Build Reusable Agent Skills with Claude","text":"Course Claude and Claude Code for Builders Session Session 3: Claude Skills Module Build Agent Skills Type  Live Duration 60 min <p>Transform your workflow knowledge into a production-ready Agent Skill from scratch. You'll structure your skill with proper metadata and instructions, test it in a live conversation, save it to your repository with version control, and export it to your local machine\u2014making it available across Claude.ai, Claude Code, and Cowork.</p>"},{"location":"courses/builders/lessons/build-reusable-agent-skills-with-claude/#objectives","title":"Objectives","text":"<ul> <li>Build a production-ready Agent Skill that packages your expertise into reusable instructions for Claude</li> <li>Structure your skill with proper metadata, instructions, and supporting resources</li> <li>Save skills to your repository for version control and register them in your AI Assets database</li> <li>Export skills to your local machine for use across Claude platforms (Code, Cowork)</li> </ul>"},{"location":"courses/builders/lessons/build-reusable-agent-skills-with-claude/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/build-your-ai-operations-registry/","title":"Build Your AI Operations Registry","text":"Course Claude and Claude Code for Builders Session Session 2: Workflow Deconstruction Module Deconstruct &amp; Register Your Workflows Type  Live Duration 30 min <p>Implement your operational control center for managing AI workflows and assets. Students replicate the Notion registry template, configure tracking fields, and document their first complete workflow including SOP and building blocks. Claude users integrate Skills with Notion MCP to enable bidirectional collaboration for reading and writing workflow data throughout the course.</p>"},{"location":"courses/builders/lessons/build-your-ai-operations-registry/#objectives","title":"Objectives","text":"<ul> <li>Implement your AI Operations Registry by replicating the Notion database template and configuring workflow tracking fields</li> <li>Integrate Claude Skills with your registry via Notion MCP to enable collaborative workflow management and building block documentation</li> <li>Document one end-to-end workflow in your registry including SOP and associated AI assets</li> </ul>"},{"location":"courses/builders/lessons/build-your-ai-operations-registry/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/build-your-claude-project-with-memory-and-knowledge-base/","title":"Build Your Claude Project with Memory and Knowledge Base","text":"Course Claude and Claude Code for Builders Session Session 2: Workflow Deconstruction Module Deconstruct &amp; Register Your Workflows Type  Live Duration 90 min <p>Build a dedicated Claude Project that maintains conversation memory and serves as a centralized knowledge repository. You'll configure project-level custom instructions, enable persistent memory that evolves with each interaction, and populate the knowledge base with reference files that Claude can access automatically\u2014eliminating repetitive file uploads and creating a workspace that gets smarter over time.</p>"},{"location":"courses/builders/lessons/build-your-claude-project-with-memory-and-knowledge-base/#objectives","title":"Objectives","text":"<ul> <li>Build a Claude Project with custom instructions, persistent memory enabled, and project-specific settings configured for course workflows</li> <li>Populate the project knowledge base with essential reference files (workflows, documentation, templates) that Claude can access automatically across all conversations</li> <li>Test persistent context by verifying that Claude retains project-specific information across multiple sessions and references knowledge base files without re-uploading</li> <li>Apply project-based workflows by conducting a complete task entirely within the project to validate memory retention and knowledge base accessibility</li> </ul>"},{"location":"courses/builders/lessons/build-your-claude-project-with-memory-and-knowledge-base/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/build-your-first-claude-code-subagent/","title":"Build Your First Claude Code Subagent","text":"Course Claude and Claude Code for Builders Session Session 5: Subagents &amp; Autonomous Workflows Module Build Autonomous Workflows with Claude Code Subagents Type  Live Duration 60 min <p>Transform your agent system design into a working implementation. Configure MCP tools in Claude Code, create your subagent with appropriate tool assignments and instructions, and test it with real tasks. Learn to debug, iterate, and refine subagent behavior through hands-on practice. Students complete this lesson with a fully functional subagent ready for real-world use.</p>"},{"location":"courses/builders/lessons/build-your-first-claude-code-subagent/#objectives","title":"Objectives","text":"<ul> <li>Configure MCP tools in Claude Code to prepare tool access for subagent implementation</li> <li>Create a subagent by translating design specifications into Claude Code configuration (description, tools, model, system prompt)</li> <li>Evaluate subagent performance by testing with real tasks and observing delegation behavior</li> <li>Refine subagent configuration based on testing results to improve reliability and output quality</li> </ul>"},{"location":"courses/builders/lessons/build-your-first-claude-code-subagent/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/configure-ai-memory-systems/","title":"Configure AI Memory Systems","text":"Course Claude and Claude Code for Builders Session Session 1: AI Builder Stack Setup Module Configure Your AI Builder Stack Type  Live Duration 20 min <p>Activate AI memory systems that automatically retain your professional context across conversations. You'll enable persistent memory, populate your tools with key facts about your role and work, establish memory hygiene practices for reviewing and editing stored information, and set privacy boundaries. Your AI assistants will remember your context automatically\u2014no more re-explaining who you are or what you're working on every conversation.</p>"},{"location":"courses/builders/lessons/configure-ai-memory-systems/#objectives","title":"Objectives","text":"<ul> <li>Configure active memory systems on your AI platforms that retain key professional context across conversations without repeated explanations</li> <li>Implement memory settings across platforms by enabling persistent context between sessions</li> <li>Populate your AI memory with 2-3 critical professional facts about your role, work context, and communication preferences</li> <li>Apply memory hygiene practices by reviewing stored information and protecting sensitive data from AI memory</li> </ul>"},{"location":"courses/builders/lessons/configure-ai-memory-systems/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/configure-ai-powered-code-editor/","title":"Configure AI-Powered Code Editor","text":"Course Claude and Claude Code for Builders Session Session 1: AI Builder Stack Setup Module Configure Your AI Builder Stack Type  Live <p>Transform your development workflow with an AI-powered code editor (Cursor or VS Code). Configure AI model integration (Claude, ChatGPT, Gemini, or other CLI models) that lets you generate code through natural language, get instant explanations for complex logic, and refactor with AI assistance. This workspace becomes essential infrastructure for building Skills, workflows, and Agents\u2014enabling builders without deep coding backgrounds to create production-quality AI systems.</p>"},{"location":"courses/builders/lessons/configure-ai-powered-code-editor/#objectives","title":"Objectives","text":"<ul> <li>Configure an AI-powered code editor (Cursor or VS Code) as your workspace for AI building block development</li> <li>Install and authenticate at least one AI model integration (Claude Code, ChatGPT Codex, Gemini CLI, or similar)</li> <li>Create and preview a Markdown file to verify your editor is properly configured</li> </ul>"},{"location":"courses/builders/lessons/configure-ai-powered-code-editor/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/configure-claude-personalization-and-memory-settings/","title":"Configure Claude Personalization and Memory Settings","text":"Course Claude and Claude Code for Builders Session Session 1: AI Builder Stack Setup Module Configure Your AI Builder Stack Type <p>Configure your Claude environment for maximum productivity throughout the course. You'll customize communication preferences, writing style, and feature settings, then activate Claude's memory system to maintain context across conversations. Proper configuration ensures Claude adapts to your workflow, remembers your preferences, and delivers responses aligned with your goals and communication style.</p>"},{"location":"courses/builders/lessons/configure-claude-personalization-and-memory-settings/#objectives","title":"Objectives","text":"<ul> <li>Configure Claude's personalization settings including communication style, tone preferences, response formatting, and feature toggles to match your workflow requirements</li> <li>Activate Claude's memory system and verify it's capturing conversation context, project details, and preferences across sessions</li> <li>Test personalized responses by comparing Claude's output before and after configuration to validate that settings are working as intended</li> </ul>"},{"location":"courses/builders/lessons/configure-claude-personalization-and-memory-settings/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/configure-mcp-server-connections-and-desktop-integrations/","title":"Configure MCP Server Connections and Desktop Integrations","text":"Course Claude and Claude Code for Builders Session Session 2: Workflow Deconstruction Module Deconstruct &amp; Register Your Workflows Type  Live Duration 90 min <p>Extend Claude's capabilities by configuring connections to external systems through MCP (Model Context Protocol). You'll connect Claude to remote MCP servers for services like Slack, GitHub, and Google Drive, then configure desktop connectors to access local applications and your filesystem. These integrations enable Claude to read data, trigger actions, and automate workflows across your entire tech stack.</p>"},{"location":"courses/builders/lessons/configure-mcp-server-connections-and-desktop-integrations/#objectives","title":"Objectives","text":"<ul> <li>Configure MCP server connections to at least two remote services (e.g., Slack, GitHub, Google Drive, Notion) with proper authentication and permissions</li> <li>Implement desktop connectors to access local filesystem, applications, or services running on your machine</li> <li>Test integration functionality by executing Claude commands that read data from connected systems and trigger actions across multiple services</li> <li>Troubleshoot connection issues using MCP diagnostics to verify successful authentication, resolve permission errors, and validate data access</li> </ul>"},{"location":"courses/builders/lessons/configure-mcp-server-connections-and-desktop-integrations/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/configure-your-ai-personalization-settings/","title":"Configure Your AI Personalization Settings","text":"Course Claude and Claude Code for Builders Session Session 1: AI Builder Stack Setup Module Configure Your AI Builder Stack Type  Live Duration 15 min <p>Configure your AI platforms to match your professional standards and communication style. You'll set up user preferences, define output formats, configure security settings including privacy controls and MFA, and establish baseline behaviors. By the end of this lesson, your AI tools will consistently deliver responses aligned with your professional requirements\u2014without needing to specify preferences in every conversation.</p>"},{"location":"courses/builders/lessons/configure-your-ai-personalization-settings/#objectives","title":"Objectives","text":"<ul> <li>Configure personalized work profiles on your AI tools using custom instructions that reflect your role, work context, and response preferences</li> <li>Implement privacy and security protections across all platforms by disabling model training data sharing and enabling multi-factor authentication</li> <li>Apply personalization strategically across platforms based on each platform's available features (custom instructions, user preferences, style settings, output formats)</li> </ul>"},{"location":"courses/builders/lessons/configure-your-ai-personalization-settings/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/connect-ai-to-your-business-apps-via-mcp/","title":"Connect AI to Your Business Apps via MCP","text":"Course Claude and Claude Code for Builders Session Session 3: Claude Skills Module Build Agent Skills Type  Live Duration 10 min"},{"location":"courses/builders/lessons/connect-ai-to-your-business-apps-via-mcp/#objectives","title":"Objectives","text":"<ul> <li>Configure MCP connections to connect your AI assistant to external tools and data sources with proper authentication and permissions</li> <li>Set up working connectors for business applications (Gmail, Drive, Notion, Slack, HubSpot) relevant to your workflow</li> <li>Test each configured connector by executing prompts that successfully call external tools and retrieve data</li> <li>Distinguish between remote MCP servers (cloud-based) and local desktop extensions to select the right architecture for different use cases</li> </ul>"},{"location":"courses/builders/lessons/connect-ai-to-your-business-apps-via-mcp/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/deconstruct-your-work-and-identify-ai-building-blocks/","title":"Deconstruct Your Work and Identify AI Building Blocks","text":"Course Claude and Claude Code for Builders Session Session 2: Workflow Deconstruction Module Deconstruct &amp; Register Your Workflows Type  Live Duration 60 min <p>Turn implicit workflows into systematic AI operations. You'll deconstruct two real-world workflows\u2014one Collaborative AI, one Deterministic Automation\u2014using the 4-question framework to identify discrete steps, decision points, data flows, and context requirements. Then apply the meta-prompting technique to your own workflows, letting AI generate complete workflow specifications with building blocks mapped, ready for execution and version control.</p>"},{"location":"courses/builders/lessons/deconstruct-your-work-and-identify-ai-building-blocks/#objectives","title":"Objectives","text":"<ul> <li>Apply the deconstruction framework to break down a named workflow into detailed steps that reveal the process structure and implementation requirements</li> <li>Map AI building blocks (Prompt, Context, Skill, Agent, MCP, Project) to each workflow step, identifying which building blocks are needed to operationalize each step</li> <li>Generate three production-ready deliverables using the meta-prompt: workflow analysis document, executable baseline prompt, and skill build recommendations that provide the necessary detail to build the AI-powered workflow</li> </ul>"},{"location":"courses/builders/lessons/deconstruct-your-work-and-identify-ai-building-blocks/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/design-autonomous-workflows-with-agents/","title":"Design Autonomous Workflows with Agents","text":"Course Claude and Claude Code for Builders Session Session 5: Subagents &amp; Autonomous Workflows Module Analyze and Design Agent Architectures Type  Live Duration 50 min"},{"location":"courses/builders/lessons/design-autonomous-workflows-with-agents/#objectives","title":"Objectives","text":"<ul> <li>Apply a systematic design process for agent systems by defining clear goals, processes, agent roles, instructions, and required tools</li> <li>Generate clear, unambiguous instructions for LLM agents using meta-prompting techniques and reasoning models to ensure reliable execution</li> <li>Design single-agent systems by specifying agent roles, responsibilities, and tool requirements for focused automation tasks</li> <li>Architect multi-agent systems by identifying and naming specialized agent roles that work together to accomplish complex goals</li> <li>Distinguish between single-agent and multi-agent approaches based on task complexity and the need for specialized expertise across different workflow components</li> </ul>"},{"location":"courses/builders/lessons/design-autonomous-workflows-with-agents/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/implement-scheduled-execution-for-claude-code-subagents/","title":"Implement Scheduled Execution for Claude Code Subagents","text":"Course Claude and Claude Code for Builders Session Session 5: Subagents &amp; Autonomous Workflows Module Build Autonomous Workflows with Claude Code Subagents Type  Live Duration 60 min <p>Learn to automate Claude Code subagent execution using native operating system schedulers. Configure Windows Task Scheduler and macOS cron jobs to run subagents on recurring schedules, implement error handling and notifications, and understand when scheduled execution is appropriate versus on-demand triggers. Students will schedule one of their existing Claude Code subagents to run automatically.</p>"},{"location":"courses/builders/lessons/implement-scheduled-execution-for-claude-code-subagents/#objectives","title":"Objectives","text":"<ul> <li>Configure OS-level scheduling (Windows Task Scheduler or macOS cron) to execute Claude Code subagents automatically</li> <li>Implement error handling and notification mechanisms for scheduled subagent runs</li> <li>Evaluate which workflows benefit from scheduled execution versus on-demand triggers</li> <li>Test and verify scheduled subagent execution with proper logging and output capture</li> </ul>"},{"location":"courses/builders/lessons/implement-scheduled-execution-for-claude-code-subagents/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/implement-version-control-for-your-ai-building-blocks/","title":"Implement Version Control for Your AI Building Blocks","text":"Course Claude and Claude Code for Builders Session Session 1: AI Builder Stack Setup Module Configure Your AI Builder Stack Type  Live <p>Implement GitHub version control as your safety net for AI building block development. Create a repository to store Skills, Prompts, Agent configurations, and workflows with full change history. Master the create-commit-push workflow that professional developers use to track iterations, experiment without risk, collaborate across teams, and recover from mistakes\u2014critical infrastructure for building production AI systems.</p>"},{"location":"courses/builders/lessons/implement-version-control-for-your-ai-building-blocks/#objectives","title":"Objectives","text":"<ul> <li>Create a GitHub repository to store and version your AI building blocks (Skills, Prompts, Agents, configurations)</li> <li>Execute the create \u2192 commit \u2192 push workflow to save a building block to your repository</li> <li>Verify your repository syncs between local and cloud to protect your work</li> </ul>"},{"location":"courses/builders/lessons/implement-version-control-for-your-ai-building-blocks/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/implement-voice-to-text-for-hands-free-ai-collaboration/","title":"Implement Voice-to-Text for Hands-Free AI Collaboration","text":"Course Claude and Claude Code for Builders Session Session 1: AI Builder Stack Setup Module Configure Your AI Builder Stack Type  Live <p>Install and configure a voice-to-text application (Wispr Flow recommended) to enable hands-free interaction with AI tools and code editors throughout the course. You'll practice voice dictation, learn best practices for speaking with AI, and set up your environment for maximum productivity. Voice-first collaboration dramatically accelerates your workflow\u2014especially for complex prompts and multi-step instructions.</p>"},{"location":"courses/builders/lessons/implement-voice-to-text-for-hands-free-ai-collaboration/#objectives","title":"Objectives","text":"<ul> <li>Install and configure a voice-to-text application (Wispr Flow or alternative) with proper permissions and settings for AI platform integration</li> <li>Practice voice dictation techniques including formatting commands, punctuation control, and natural speech patterns to achieve 90%+ accuracy</li> <li>Demonstrate hands-free AI collaboration by completing a workflow entirely through voice\u2014from initial prompt to refinement to final output</li> <li>Apply voice-first best practices for complex multi-step instructions, ensuring clarity and reducing the need for manual typing throughout the course</li> </ul>"},{"location":"courses/builders/lessons/implement-voice-to-text-for-hands-free-ai-collaboration/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/lesson-101-present-capstone-projects-to-cohort/","title":"Lesson 10.1: Present Capstone Projects to Cohort","text":"Course Claude and Claude Code for Builders Session Session 10: Capstone Demos, Student Insights &amp; Synthesis Module Build Your Capstone Project Type  Live <p>Students present their capstone projects to the cohort, demonstrating the problem solved, approach taken, and results achieved</p> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/lesson-102-provide-peer-feedback-and-qa/","title":"Lesson 10.2: Provide Peer Feedback and Q&amp;A","text":"Course Claude and Claude Code for Builders Session Session 10: Capstone Demos, Student Insights &amp; Synthesis Module Build Your Capstone Project Type  Live <p>Cohort provides peer feedback through structured review and Q&amp;A</p> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/lesson-103-synthesize-course-themes-and-next-steps/","title":"Lesson 10.3: Synthesize Course Themes and Next Steps","text":"Course Claude and Claude Code for Builders Session Session 10: Capstone Demos, Student Insights &amp; Synthesis Module Build Your Capstone Project Type  Live <p>Instructor synthesizes course themes, discusses next steps for continued growth, and provides guidance on ongoing skill development and community resources</p> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/lesson-61-automate-web-tasks-with-claude-in-chrome/","title":"Lesson 6.1: Automate Web Tasks with Claude in Chrome","text":"Course Claude and Claude Code for Builders Session Session 6: Browser Automation, Workflows, Scheduling Module Deploy Automated Workflows Type  Live <p>Students use Claude in Chrome (browser automation) to extract data from web pages, fill forms, and navigate multi-step web processes</p> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/lesson-62-build-complete-browser-automation-workflows/","title":"Lesson 6.2: Build Complete Browser Automation Workflows","text":"Course Claude and Claude Code for Builders Session Session 6: Browser Automation, Workflows, Scheduling Module Deploy Automated Workflows Type  Live <p>Students build complete browser automation workflows that combine data extraction, processing, and output generation</p> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/lesson-63-implement-scheduled-and-event-driven-workflows/","title":"Lesson 6.3: Implement Scheduled and Event-Driven Workflows","text":"Course Claude and Claude Code for Builders Session Session 6: Browser Automation, Workflows, Scheduling Module Deploy Automated Workflows Type  Live <p>Students implement event-driven hooks and scheduled triggers to run autonomous workflows on a recurring basis without manual initiation</p> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/lesson-71-translate-business-ideas-into-technical-specs/","title":"Lesson 7.1: Translate Business Ideas into Technical Specs","text":"Course Claude and Claude Code for Builders Session Session 7: Product Specs &amp; Agentic Coding Module Build with Agentic Coding Type  Live <p>Students translate a business idea or problem into technical specifications, breaking down requirements, defining user flows, and creating a development plan with Claude as thought partner</p> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/lesson-72-configure-claude-code-workspace-and-hooks/","title":"Lesson 7.2: Configure Claude Code Workspace and Hooks","text":"Course Claude and Claude Code for Builders Session Session 7: Product Specs &amp; Agentic Coding Module Build with Agentic Coding Type  Live <p>Students set up their Claude Code workspace with appropriate hooks (pre-commit, post-deploy), plugins, and integrations for the project</p> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/lesson-73-build-application-with-agentic-coding-workflow/","title":"Lesson 7.3: Build Application with Agentic Coding Workflow","text":"Course Claude and Claude Code for Builders Session Session 7: Product Specs &amp; Agentic Coding Module Build with Agentic Coding Type  Live <p>Students begin building the application, learning to leverage Claude Code's autonomous iteration cycle for rapid development</p> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/lesson-81-develop-core-features-collaboratively/","title":"Lesson 8.1: Develop Core Features Collaboratively","text":"Course Claude and Claude Code for Builders Session Session 8: App Feature Development, Testing, Deployment Module Build and Deploy Your Application Type  Live <p>Students develop the core features of their application using Claude Code's collaborative build process</p> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/lesson-82-test-and-debug-with-claude-assistance/","title":"Lesson 8.2: Test and Debug with Claude Assistance","text":"Course Claude and Claude Code for Builders Session Session 8: App Feature Development, Testing, Deployment Module Build and Deploy Your Application Type  Live <p>Students test and debug their application, using Claude to identify issues, propose fixes, and refine functionality</p> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/lesson-83-deploy-prototype-to-vercel-for-production/","title":"Lesson 8.3: Deploy Prototype to Vercel for Production","text":"Course Claude and Claude Code for Builders Session Session 8: App Feature Development, Testing, Deployment Module Build and Deploy Your Application Type  Live <p>Students deploy their completed prototype to Vercel, configure production settings, and prepare the application for user feedback</p> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/lesson-91-choose-your-capstone-project-focus/","title":"Lesson 9.1: Choose Your Capstone Project Focus","text":"Course Claude and Claude Code for Builders Session Session 9: Capstone Build, Claude Cowork Module Build Your Capstone Project Type  Live <p>Students choose their capstone project focus: advanced workflow automation, custom web application, or integration project combining multiple capabilities</p> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/lesson-92-design-capstone-implementation-plan/","title":"Lesson 9.2: Design Capstone Implementation Plan","text":"Course Claude and Claude Code for Builders Session Session 9: Capstone Build, Claude Cowork Module Build Your Capstone Project Type  Live <p>Students design their implementation plan with clear deliverables, success criteria, and timeline for completion</p> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/lesson-93-collaborate-with-claude-cowork-bonus/","title":"Lesson 9.3: Collaborate with Claude Cowork (Bonus)","text":"Course Claude and Claude Code for Builders Session Session 9: Capstone Build, Claude Cowork Module Cowork on Productivity Tasks Type  Live <p>Bonus lesson (Max subscribers only): Students collaborate with Claude Cowork on complex knowledge work tasks\u2014research synthesis, document formatting, spreadsheet analysis, presentation creation</p> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/set-up-your-ai-workflow-registry/","title":"Set Up Your AI Workflow Registry","text":"Course Claude and Claude Code for Builders Session Session 2: Workflow Deconstruction Module Deconstruct &amp; Register Your Workflows Type  Live Duration 30 min"},{"location":"courses/builders/lessons/set-up-your-ai-workflow-registry/#objectives","title":"Objectives","text":"<ul> <li>Create a systematic inventory cataloging at least 3 recurring workflows with their triggers, steps, and outcomes, and the AI assets (prompts, skills, agents, context files) linked to each workflow to visualize dependencies</li> <li>Build a relational database system in Notion with separate tables for Business Processes, Workflows, AI Assets, and Apps to serve as your living repository</li> <li>Identify at least 3 high-value recurring workflows from your actual work, documenting each with trigger conditions, step-by-step process, desired outcomes, and AI automation opportunities</li> <li>Catalog existing AI assets by type (prompts, skills, agents, context files), organize them in a structured repository, and establish relational links to the workflows that depend on them</li> </ul>"},{"location":"courses/builders/lessons/set-up-your-ai-workflow-registry/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/lessons/ship-your-skills-for-reuse/","title":"Ship Your Skills for Reuse","text":"Course Claude and Claude Code for Builders Session Session 3: Claude Skills Module Build Agent Skills Type  Live Duration 60 min <p>Package and ship your skills as installable resources. One command gives others access to your expertise\u2014team members, clients, or the broader AI community. Your workflow knowledge becomes reusable, distributable, scalable.</p>"},{"location":"courses/builders/lessons/ship-your-skills-for-reuse/#objectives","title":"Objectives","text":"<ul> <li>Create a properly structured marketplace.json file with plugin metadata for at least one skill</li> <li>Publish a GitHub repository containing their skill marketplace that others can add via /plugin marketplace add</li> <li>Configure distribution settings for three deployment scenarios: private team use, organizational access, and public community sharing</li> <li>Demonstrate the complete installation workflow by having another team member successfully install their published plugin</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/builders/week-0/","title":"Week 0: Course Orientation","text":"<p>Welcome to the pre-course orientation for Claude and Claude Code for Builders. Complete these materials before your first live session.</p>"},{"location":"courses/builders/week-0/#whats-in-this-section","title":"What's in This Section","text":"<p>This orientation covers everything you need to prepare for the course:</p> Lesson Description Welcome and Course Structure How the course works, what you'll accomplish, and session format Identify Your AI Builder Stack Overview of tools you'll use throughout the course Navigate Maven Platform How to access sessions, recordings, and materials Access Support Resources Slack, office hours, and 1:1 coaching options Maximize Your Learning Tips for getting the most out of the course FAQ Common questions and answers"},{"location":"courses/builders/week-0/#before-you-begin","title":"Before You Begin","text":"<p>Recommended Preparation</p> <p>While detailed setup instructions are covered in Week 1 live sessions, reviewing the AI Builder Stack overview in this section will help you understand what tools you'll be working with.</p>"},{"location":"courses/builders/week-0/#time-to-complete","title":"Time to Complete","text":"<p>Estimated time: 30-45 minutes to read through all orientation materials.</p>"},{"location":"courses/builders/week-0/#next-steps","title":"Next Steps","text":"<p>Start with Welcome and Course Structure to understand how the course is organized and what to expect from each week.</p>"},{"location":"courses/builders/week-0/01-welcome-and-course-structure/","title":"Welcome and Course Structure","text":""},{"location":"courses/builders/week-0/01-welcome-and-course-structure/#welcome-to-claude-and-claude-code-for-builders","title":"Welcome to Claude and Claude Code for Builders","text":"<p>You're here because you're ready to move beyond prompting and start building AI systems that work for you. Over the next 5 weeks, we'll transform you from a Claude user into a Claude builder.</p> <p>This lesson covers how the course works, what you'll accomplish, and how live sessions are structured.</p>"},{"location":"courses/builders/week-0/01-welcome-and-course-structure/#what-youll-accomplish-in-this-course","title":"What You'll Accomplish in This Course","text":"<p>In 5 weeks, you'll build:</p> <p>Week 0 - Course Orientation (Pre-course) Week 0 provides an overview of all tools in the AI Builder Stack. While it's suggested to get started with setup before Week 1 if possible, detailed configuration instructions will be covered during Week 1 live sessions. Not all tools need to be configured before the course begins.</p> <p>Week 1 - Configure Your AI Builder Stack Build the infrastructure that transforms AI from occasional tool to daily operating system. You'll configure code editors, GitHub, Claude Code, voice-to-text tools, and work profiles across Claude platforms\u2014establishing the complete technical foundation that enables all hands-on builder work throughout the course and beyond.</p> <p>Week 2 - Build Reusable Claude Skills Turn your expertise into reusable AI automation. You'll build production-ready Claude Skills that package your knowledge into instructions Claude can apply across any conversation, deploy them across Claude.ai, Desktop, and Claude Code, and link them to workflows in your registry\u2014building an organized system that scales as you automate more.</p> <p>Week 3 - Build Multi-Agent Systems &amp; Deploy Automated Workflows Scale your productivity through autonomous AI agents and browser automation. You'll design Claude Subagents with specialized tool permissions, deploy domain-specific experts for code review and analysis, then build browser automation workflows using Claude in Chrome\u2014creating multi-agent systems that execute complex work independently while you focus on higher-level decisions.</p> <p>Week 4 - Build with Agentic Coding Experience the future of software development. You'll transform business ideas into product specifications with Claude as thought partner, then watch Claude Code autonomously build, test, and refine your application from requirements\u2014experiencing agentic coding workflow that expands what non-engineers can create and accelerates what engineers can ship.</p> <p>Week 5 - Build Your Capstone Project Complete your transformation from AI user to AI builder. You'll showcase your capstone project demonstrating problem, approach, and results, share transformation insights\u2014what you learned, what surprised you, and what you can now build that wasn't possible before\u2014then chart your path forward with clear next steps for continued growth as an AI builder.</p>"},{"location":"courses/builders/week-0/01-welcome-and-course-structure/#course-structure","title":"Course Structure","text":""},{"location":"courses/builders/week-0/01-welcome-and-course-structure/#live-sessions","title":"Live Sessions","text":"<p>Schedule: 2 sessions per week, 90 minutes each Days: Monday + Wednesday Format: Interactive instruction + hands-on implementation + Q&amp;A</p> <p>What to expect during live sessions: - Real-time teaching with screen sharing and demos - Step-by-step walkthroughs of technical setup and implementation - Live troubleshooting when you hit issues - Group discussions and peer learning - Dedicated Q&amp;A time for your specific questions</p> <p>Participation tips: - Come prepared with your AI Builder Stack configured (after Week 0) - Have questions ready based on pre-work or previous sessions - Share your screen when you need help troubleshooting - Use Zoom chat for quick questions, unmute for discussions - Don't be afraid to ask \"how\" and \"why\" questions</p>"},{"location":"courses/builders/week-0/01-welcome-and-course-structure/#session-recordings","title":"Session Recordings","text":"<p>Availability: All live sessions are automatically recorded Access: Recordings are posted to Maven within 24 hours of each session Retention: Lifetime access\u2014you can review recordings anytime</p> <p>How to find recordings: 1. Navigate to the course homepage on Maven 2. Click on the specific week/module 3. Scroll to \"Session Recordings\" 4. Click to watch</p> <p>Best practices: - If you miss a live session, watch the recording before the next session - Use recordings to review complex technical steps at your own pace - Speed up playback (1.5x or 2x) for review sessions - Take timestamped notes so you can jump back to specific moments</p>"},{"location":"courses/builders/week-0/01-welcome-and-course-structure/#time-commitment","title":"Time Commitment","text":"<p>Total commitment: 4-6 hours per week</p> <p>Breakdown: - Live sessions: 3 hours (2 x 90 minutes) - Exercises &amp; projects: 1-2 hours between sessions - Optional office hours: 1 hour (if you attend)</p> <p>How to manage your time: - Block calendar time for live sessions (non-negotiable) - Schedule 30-60 minutes after each session for exercises - Batch implementation work on weekends if needed - Attend office hours when you're stuck, not after you've fallen behind</p>"},{"location":"courses/builders/week-0/01-welcome-and-course-structure/#next-steps","title":"Next Steps","text":"<p>Continue to the next lesson: Access Support and Coaching Resources to learn about Slack, office hours, and 1:1 coaching.</p> <p>Quick actions: 1. \u2705 Block calendar time for Monday + Wednesday live sessions (90 minutes each) 2. \u2705 Note that recordings are available if you miss a session 3. \u2705 Plan for 4-6 hours total per week including exercises</p>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/","title":"Identify Your AI Builder Stack","text":""},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#introduction","title":"Introduction","text":"<p>This course transforms you from a Claude user into a Claude builder. That means working hands-on with a complete AI builder stack\u2014the same tools and infrastructure that power modern AI-first operations.</p> <p>This lesson sets expectations about what tools we'll use throughout the course. You're welcome to get a head start on setup, but Week 1 (Configure AI Builder Stack) will walk through detailed installation and configuration for everything listed here. Think of this as your shopping list and system check\u2014by the end of this lesson, you'll know exactly what you need and whether your current setup is ready.</p> <p>The AI Builder Stack isn't just a collection of tools. It's an integrated system where each component plays a specific role in how you build, deploy, and scale AI systems that work for you. Understanding this stack now will help you see how everything connects as we progress through the course.</p>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#estimated-costs","title":"Estimated Costs","text":"<p>Monthly Subscription Costs: - Claude Pro or Team: $20-30/month (required) - Wispr Flow: $15/month (optional, but recommended if using voice-to-text heavily) - All other tools: Free</p> <p>Total minimum monthly cost: $20/month (Claude subscription only)</p>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#setup-checklists","title":"Setup Checklists","text":""},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#before-week-1-starts-essential","title":"Before Week 1 Starts (Essential)","text":"<p>Complete these items before the first live session:</p> <ul> <li> Claude Pro or Team subscription active</li> <li> Operating system confirmed (macOS or Windows)</li> <li> Admin access confirmed on your machine</li> <li> Regional availability verified for Claude features</li> </ul> <p>Note: Some Claude features may have regional constraints. Review the tools below to ensure they're available in your region.</p>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#by-end-of-week-1-setup-goals","title":"By End of Week 1 (Setup Goals)","text":"<p>Week 1 will guide you through setting up these items. You're welcome to get a head start:</p> <ul> <li> GitHub account created</li> <li> Code editor downloaded (Cursor or VS Code)</li> <li> Chrome browser installed</li> <li> Claude Desktop App installed</li> <li> Claude in Chrome extension installed</li> <li> Claude Code CLI installed</li> <li> Slack invite received and accepted</li> <li> Agentic AI Registry created (Notion or alternative)</li> </ul>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#required-tools-overview","title":"Required Tools Overview","text":""},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#1-claude-subscription","title":"1. Claude Subscription","text":"<p>What: Your primary AI workspace Which tier: Claude Pro ($20/month minimum) or Claude Team recommended Why: Access to Claude Sonnet/Opus 4.5, Projects feature, and higher usage limits When we use it: Every week\u2014this is your command center Get started: Subscribe to Claude</p> <p>Note: If you plan to use Claude Code heavily (Weeks 4-5), consider upgrading to Claude Max for significantly higher usage limits.</p>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#2-github-account","title":"2. GitHub Account","text":"<p>What: Version control and code collaboration platform Cost: Free tier is sufficient Why: Essential for managing Skills, version control, and agentic coding workflow When we use it: Week 1 (setup), Week 2 (Skills deployment), Weeks 4-5 (Claude Code integration) Get started: Sign up for GitHub</p> <p>What you'll need: - GitHub account created - Basic familiarity with repos (we'll cover what you need) - Able to create repos and commit files</p>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#3-code-editor-cursor-or-vs-code","title":"3. Code Editor: Cursor or VS Code","text":"<p>What: Your code editing environment with AI assistance Which one: Cursor or VS Code Cost: Cursor has free tier; VS Code is free Why: Build and edit Skills, work with Claude Code, manage your Agentic AI Registry When we use it: Week 1 (Registry setup), Week 2 (Skills creation), Weeks 4-5 (agentic coding) Get started: Download Cursor or Download VS Code</p> <p>Cursor vs VS Code: - Cursor: Built-in Claude integration, optimized for AI-assisted coding, best for Week 4-5 prototyping. I will also demonstrate examples in Cursor. - VS Code: More familiar if you already use it, requires Claude Code extension</p>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#4-claude-desktop-app","title":"4. Claude Desktop App","text":"<p>What: Desktop application for Claude Cost: Free (included with Claude subscription) Why: Deploy and run Skills locally, develop and test workflows, connect to local tools via MCP (Model Context Protocol), and use the Cowork feature for real-time collaboration</p> <p>Note on MCP: MCP enables Claude to connect to your local applications and tools. You'll get the most value from this course if MCP integrations are available for the applications you want to use in your workflows and agents. When we use it: Throughout the course\u2014Week 1 (setup), Week 2 (Skills deployment and testing), Week 3 (Subagents and workflow development), ongoing for workflow execution Get started: Download Claude Desktop</p> <p>What you'll need: - Admin access to install software on your machine - macOS or Windows - Note: The Cowork feature is currently only available on macOS</p> <p>What you'll do with it: - Deploy Skills to your local environment - Develop and run workflows that connect to your local files and applications - Test Skills and Subagents before sharing them - Connect to local tools through MCP integrations - Use the Cowork feature for real-time collaboration (macOS only)</p>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#5-claude-code-cli","title":"5. Claude Code (CLI)","text":"<p>What: Command-line interface for agentic coding Cost: Free (usage counts against Claude subscription) Why: Autonomous coding agent that builds, tests, and iterates on your behalf When we use it: Weeks 4-5 (agentic coding workflow) Get started: Install Claude Code</p> <p>What you'll need: - Terminal/command line access - Comfortable running basic CLI commands (we'll teach what you need)</p>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#6-google-chrome-browser","title":"6. Google Chrome Browser","text":"<p>What: Browser for Claude in Chrome (browser automation) Cost: Free Why: Automate web tasks, extract data, fill forms, orchestrate multi-step processes When we use it: Week 3 (browser automation + Subagents) Get started: Download Chrome</p> <p>What you'll need: - Chrome installed (not Brave, Edge, or other Chromium browsers) - Ability to install Chrome extensions</p>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#7-claude-in-chrome-extension","title":"7. Claude in Chrome Extension","text":"<p>What: Browser extension that gives Claude control of Chrome Cost: Free beta (as of Jan 2025) Why: Enable Claude to interact with web pages, automate workflows, combine with Skills When we use it: Week 3 (browser automation) Get started: Install Claude in Chrome</p> <p>What you'll need: - Admin permission to install Chrome extensions - We'll cover installation in Week 1</p>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#optional-but-recommended-tools","title":"Optional But Recommended Tools","text":""},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#wispr-flow-voice-to-text","title":"Wispr Flow (Voice-to-Text)","text":"<p>What: Voice-to-text application for hands-free input and dictation Why: Dramatically speed up writing, communication, and interaction with Claude through natural speech When we use it: Throughout the course\u2014useful for any text input, documentation, or Claude interactions Cost: Varies by platform (check individual app pricing) Get started: Download Wispr Flow</p> <p>What you'll use it for: - Dictating prompts to Claude - Writing documentation and course notes - Faster communication in Slack - Creating Skills and workflow descriptions - Any text input across your system</p> <p>Alternatives: Use any voice-to-text solution you prefer\u2014built-in OS dictation, or other third-party apps. Wispr Flow is recommended but not required.</p>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#notion-agentic-ai-registry","title":"Notion (Agentic AI Registry)","text":"<p>What: Your central repository for business processes, workflows, and AI building blocks Why: Track and organize all the Skills, Subagents, and automations you build throughout the course When we use it: Week 1 (Registry setup), ongoing throughout course Cost: Free tier works; paid tier if you want advanced features Get started: Sign up for Notion</p> <p>What you'll store here: - Business processes you've decomposed - Workflows you've designed - Skills you've built - Subagents you've deployed - Automations you've created</p> <p>Alternatives: Obsidian, Coda, Airtable\u2014use what you prefer. We'll show Notion examples but principles apply anywhere.</p>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#slack-course-community","title":"Slack (Course Community)","text":"<p>What: Private course Slack workspace Why: Peer collaboration, troubleshooting, sharing wins When we use it: Throughout the course Cost: Free (invite-only course workspace)</p>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#system-requirements","title":"System Requirements","text":"<p>To participate fully in this course, you'll need:</p> <ul> <li>Admin access to install software on your machine</li> <li>Operating system: macOS or Windows</li> <li>Internet connection: Reliable connection for live sessions and API calls</li> <li>Disk space: ~2GB for tools, repos, and project files</li> <li>Permissions: Ability to install browser extensions and CLI tools</li> <li>Time commitment: Minimum 5 hours per week (includes two 90-minute live sessions plus hands-on building time)</li> </ul>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#preview-what-happens-in-week-1","title":"Preview: What Happens in Week 1","text":"<p>Week 1 (Configure AI Builder Stack) provides detailed setup instructions for:</p> <ol> <li>Verifying Claude subscription and usage limits</li> <li>Setting up GitHub</li> <li>Configuring code editor (Cursor or VS Code) with Claude integration</li> <li>Installing Claude Desktop and connecting your first MCP tool</li> <li>Installing Claude in Chrome extension and testing browser automation</li> <li>Installing Claude Code CLI and verifying setup</li> <li>Creating your Agentic AI Registry structure in Notion</li> <li>Testing the full stack with a simple end-to-end workflow</li> </ol> <p>You'll work through setup independently using the provided lessons and documentation. During live sessions, we'll troubleshoot any issues, answer questions, and ensure everyone's stack is working properly before we start building.</p>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#why-this-stack","title":"Why This Stack?","text":"<p>Every tool serves a specific purpose in your AI builder workflow:</p> <ul> <li>Claude.ai \u2192 Your command center, where you interact with Claude</li> <li>GitHub \u2192 Your version control system, where you manage and share Skills</li> <li>Cursor/VS Code \u2192 Your editing environment, where you create and refine Skills</li> <li>Claude Desktop \u2192 Your workflow development and execution environment, where you build, test, and run local workflows</li> <li>Claude Code \u2192 Your autonomous coding agent, where ideas become prototypes</li> <li>Claude in Chrome \u2192 Your automation layer, where you orchestrate web tasks</li> <li>Wispr Flow \u2192 Your voice interface, where speech becomes text across your entire workflow</li> <li>Notion (Registry) \u2192 Your organizational system, where you track everything you build</li> </ul> <p>Together, these tools form a complete AI Builder Stack\u2014the infrastructure you need to build, deploy, and scale AI systems that work for you.</p>"},{"location":"courses/builders/week-0/02-identify-your-ai-builder-stack/#questions","title":"Questions?","text":"<p>If you're uncertain about any of these tools or whether your setup will work, don't worry. Week 1 includes setup lessons for each tool, and we'll troubleshoot together during live sessions.</p> <p>Common questions we'll address in Week 1: - \"I don't have admin access\u2014can I still participate?\" - \"Can I use a different code editor?\" - \"What if Claude in Chrome isn't available in my region?\" - \"I've never used GitHub\u2014is that a problem?\"</p> <p>Come to Week 1 ready to configure your stack, and we'll make sure you're set up for success.</p>"},{"location":"courses/builders/week-0/03-navigate-maven-platform-and-course-materials/","title":"Navigate Maven Platform and Course Materials","text":""},{"location":"courses/builders/week-0/03-navigate-maven-platform-and-course-materials/#overview","title":"Overview","text":"<p>This lesson shows you how to navigate the Maven platform, find course materials, access recordings, and understand what's included in the course.</p>"},{"location":"courses/builders/week-0/03-navigate-maven-platform-and-course-materials/#navigating-the-maven-platform","title":"Navigating the Maven Platform","text":""},{"location":"courses/builders/week-0/03-navigate-maven-platform-and-course-materials/#course-homepage","title":"Course Homepage","text":"<p>Location: https://maven.com/james-gray/claude</p> <p>What you'll find: - Course syllabus with all modules and lessons - Live session schedule and Zoom links - Session recordings - Downloadable materials and resources - Community discussion boards</p>"},{"location":"courses/builders/week-0/03-navigate-maven-platform-and-course-materials/#module-structure","title":"Module Structure","text":"<p>Each module contains: - Written lessons - Read before live sessions (like this one!) - Live sessions - Interactive teaching and implementation - Exercises - Hands-on practice between sessions - Resources - Supplementary materials, links, downloads</p> <p>How to navigate modules: 1. Start with written lessons (pre-work) 2. Attend live sessions for instruction and Q&amp;A 3. Complete exercises to apply what you learned 4. Review resources for deeper understanding</p>"},{"location":"courses/builders/week-0/03-navigate-maven-platform-and-course-materials/#joining-live-sessions","title":"Joining Live Sessions","text":"<p>Before each session: 1. Log into Maven 5 minutes early 2. Navigate to the current week's module 3. Click \"Join Live Session\" (Zoom link) 4. Test your audio/video before session starts</p> <p>Technical requirements: - Stable internet connection (wired recommended) - Working webcam and microphone - Zoom installed and updated - Ability to share screen for troubleshooting</p>"},{"location":"courses/builders/week-0/03-navigate-maven-platform-and-course-materials/#downloading-materials","title":"Downloading Materials","text":"<p>Where to find downloads: - Source materials stored on Google Drive as Google Slides - Course resources available in the GitHub repository - Each module may have links to both Google Drive and GitHub resources</p> <p>Recommended downloads: - Save all materials to a dedicated course folder on your machine - Clone GitHub repos to your local environment - Bookmark frequently referenced resources</p> <p>Note on slide decks: - Slide decks are available as Google Slides - PDFs will be provided for students unable to access Google Drive links from corporate networks</p>"},{"location":"courses/builders/week-0/03-navigate-maven-platform-and-course-materials/#course-materials-resources","title":"Course Materials &amp; Resources","text":""},{"location":"courses/builders/week-0/03-navigate-maven-platform-and-course-materials/#whats-included","title":"What's Included","text":"<p>Live instruction: - 10 live sessions (2 per week for 5 weeks) - Real-time demos and walkthroughs - Interactive Q&amp;A and troubleshooting</p> <p>Recordings: - Lifetime access to all session recordings - Ability to review at your own pace - Downloadable for offline viewing</p> <p>Written materials: - Pre-session lessons and guides - Step-by-step implementation documentation - Supplementary reading and resources</p> <p>Code &amp; templates: - GitHub repository with all code examples - Notion templates for Agentic AI Registry - Claude Skills starter files and examples</p> <p>Community access: - Private Slack workspace - Peer collaboration and support - Monthly Builder Forum (LinkedIn Group with ongoing live sessions)</p> <p>Coaching: - On-demand 1:1 sessions with James (15 or 30 minutes, as many as you need) - Weekly office hours (Saturdays) - Direct instructor support in Slack</p>"},{"location":"courses/builders/week-0/03-navigate-maven-platform-and-course-materials/#external-tools-youll-use","title":"External Tools You'll Use","text":"<p>You'll work with tools outside of Maven. These are part of your AI Builder Stack:</p> <ul> <li>Claude.ai - Your primary AI workspace (requires paid subscription)</li> <li>GitHub - Version control for Skills and projects</li> <li>Cursor or VS Code - Code editor for building Skills</li> <li>Claude Desktop - Local Skills deployment and workflow execution</li> <li>Claude Code - Command-line agentic coding tool</li> <li>Google Chrome - Browser automation with Claude in Chrome extension</li> <li>Notion - Agentic AI Registry (optional but recommended)</li> </ul> <p>See the \"Identify Your AI Builder Stack\" lesson for complete details on required tools.</p>"},{"location":"courses/builders/week-0/03-navigate-maven-platform-and-course-materials/#quick-reference-links","title":"Quick Reference Links","text":"<p>Course homepage: https://maven.com/james-gray/claude Slack workspace: [Check email for invite] GitHub course repo: https://github.com/jamesgray-ai/claude-for-builders Calendly for 1:1 sessions: [Posted in Slack Week 1] Monthly Builder Forum: [Shared upon course completion]</p> <p>Support: - Slack: cohort channel - Email: james@jamesgray.ai - Office hours: Saturday mornings (schedule in Maven portal)</p>"},{"location":"courses/builders/week-0/03-navigate-maven-platform-and-course-materials/#next-steps","title":"Next Steps","text":"<p>Continue to the next lesson: Maximize Your Learning and Success to learn success strategies, what to do if you fall behind, and community guidelines.</p> <p>Quick actions: 1. \u2705 Bookmark the course homepage: https://maven.com/james-gray/claude 2. \u2705 Save the GitHub repo link: https://github.com/jamesgray-ai/claude-for-builders 3. \u2705 Create a dedicated folder on your machine for course materials 4. \u2705 Test joining a Zoom session to ensure your setup works</p>"},{"location":"courses/builders/week-0/04-access-support-and-coaching-resources/","title":"Access Support and Coaching Resources","text":""},{"location":"courses/builders/week-0/04-access-support-and-coaching-resources/#overview","title":"Overview","text":"<p>Success in this course depends on knowing where to get help when you need it. This lesson covers all the support resources available to you: Slack, office hours, and on-demand 1:1 coaching with James.</p>"},{"location":"courses/builders/week-0/04-access-support-and-coaching-resources/#private-slack-workspace","title":"Private Slack Workspace","text":"<p>Access: You'll receive a Slack invitation within 24 hours of enrollment Channel: #claude-cohort-[cohort-number] - Your dedicated cohort channel for all communication Purpose: Peer collaboration, troubleshooting, sharing wins, community support</p> <p>How to use Slack: - Course announcements and general discussion - Technical troubleshooting and setup questions - Share completed projects, breakthroughs, and victories - Post useful tools, articles, and discoveries - Off-topic chat, introductions, networking</p> <p>Slack etiquette: - Use threads to keep conversations organized - Share screenshots when asking for troubleshooting help - Search before asking\u2014someone may have already solved your issue - Pay it forward\u2014help others when you can - Celebrate others' wins (emoji reactions encouraged!)</p> <p>Response time: - Instructor responses within 24 hours on weekdays - Peer support is typically faster (minutes to hours) - Urgent technical issues flagged with @james get priority</p>"},{"location":"courses/builders/week-0/04-access-support-and-coaching-resources/#office-hours","title":"Office Hours","text":"<p>Schedule: Saturday mornings (optional) Duration: 60 minutes Format: Open Q&amp;A, troubleshooting, catch-up support Additional availability: 30-minute sessions available throughout the week upon student request</p> <p>When to attend office hours: - You're stuck on a technical setup step - You missed a live session and need catch-up support - You want feedback on your approach before diving deep - You have questions that don't fit neatly into live session topics</p> <p>How office hours work: - Show up with specific questions or problems - Share your screen to demonstrate issues - Get real-time guidance and troubleshooting - Learn from others' questions (often more valuable than your own!)</p> <p>Pro tip: Post your question in Slack before office hours so James can prepare.</p>"},{"location":"courses/builders/week-0/04-access-support-and-coaching-resources/#personalized-11-coaching","title":"Personalized 1:1 Coaching","text":"<p>What you get: On-demand 1:1 sessions with James throughout the course (15 or 30 minutes) Purpose: Personalized feedback on your projects, strategic guidance, custom troubleshooting Scheduling: Calendly links are available in the course syllabus\u2014book as many sessions as you need</p> <p>How to schedule your 1:1: 1. Use the Calendly link provided in the syllabus 2. Choose 15 or 30 minutes based on your needs (quick questions vs. deep dives) 3. Book a time that works for your schedule 4. Come prepared with specific goals for the session 5. Schedule additional sessions anytime you need support</p> <p>Best uses of your 1:1: - Get feedback on your Agentic AI Registry structure - Review your Skills architecture and deployment strategy - Discuss how to apply course concepts to your specific business - Troubleshoot a complex workflow or integration challenge - Strategic planning for AI implementation in your organization</p> <p>What to prepare: - Share your project/system before the session (Slack, GitHub, Notion link) - Come with 2-3 specific questions or goals - Be ready to share your screen and demonstrate what you've built</p>"},{"location":"courses/builders/week-0/04-access-support-and-coaching-resources/#when-to-use-each-support-channel","title":"When to Use Each Support Channel","text":"<p>Use Slack when: - You have a quick technical question - You want to share your progress or wins - You're looking for peer feedback - You found a useful resource to share</p> <p>Use Office Hours when: - You're stuck and need real-time troubleshooting - You missed a live session and need catch-up - You want to learn from others' questions - You have multiple small questions to batch together</p> <p>Use 1:1 Coaching when: - You need strategic guidance specific to your business - You want detailed feedback on your approach - You're working through a complex implementation challenge - You need extended time to work through a problem</p>"},{"location":"courses/builders/week-0/04-access-support-and-coaching-resources/#next-steps","title":"Next Steps","text":"<p>Continue to the next lesson: Navigate Maven Platform and Course Materials to learn how to access recordings, download materials, and use the Maven platform.</p> <p>Quick actions: 1. \u2705 Join the Slack workspace (check your email for invite) 2. \u2705 Introduce yourself in the Maven #intros 3. \u2705 Bookmark the Calendly link for 1:1 sessions 4. \u2705 Add Saturday office hours to your calendar (optional)</p>"},{"location":"courses/builders/week-0/05-maximize-your-learning-and-success/","title":"Maximize Your Learning and Success","text":""},{"location":"courses/builders/week-0/05-maximize-your-learning-and-success/#overview","title":"Overview","text":"<p>This lesson covers proven success strategies, how to handle falling behind, community guidelines, and what you'll walk away with after completing the course.</p>"},{"location":"courses/builders/week-0/05-maximize-your-learning-and-success/#success-strategies","title":"Success Strategies","text":""},{"location":"courses/builders/week-0/05-maximize-your-learning-and-success/#how-to-get-the-most-out-of-this-course","title":"How to Get the Most Out of This Course","text":"<p>1. Show up to live sessions - Attendance is the #1 predictor of success - Learning happens in real-time troubleshooting and discussion - Recordings are great for review, but live participation builds skills faster</p> <p>2. Do the exercises - Every lesson has a hands-on exercise - These aren't busywork\u2014they're how you build your production systems - Your capstone project builds on cumulative exercises</p> <p>3. Ask questions early - Don't wait until you're hopelessly stuck - Use Slack for quick questions between sessions - Save complex questions for live sessions or office hours</p> <p>4. Build in public - Share your work-in-progress in Slack - Learning from peers accelerates your progress - Helping others solidifies your own understanding</p> <p>5. Focus on implementation, not perfection - Build working systems first, refine later - \"Done\" is better than \"perfect\" - You can iterate on everything you create</p> <p>6. Connect concepts to your work - Apply every lesson to your actual business workflows - Build Skills for real problems you're facing - The best learning comes from solving your own challenges</p>"},{"location":"courses/builders/week-0/05-maximize-your-learning-and-success/#what-if-i-fall-behind","title":"What If I Fall Behind?","text":"<p>If you miss a session: 1. Watch the recording within 48 hours 2. Complete the exercise from that session 3. Post questions in Slack before the next session 4. Attend office hours if you need catch-up support</p> <p>If you get stuck: 1. Check course materials and supplementary docs 2. Search Slack to see if others solved the same issue 3. Post your question in Slack with screenshots 4. Attend office hours for real-time troubleshooting 5. Use your 1:1 session if the issue is complex or strategic</p> <p>If life happens: - Communicate in Slack if you need to step away - Recordings and materials are available for catch-up - Focus on core modules (Weeks 1-3) if time is limited - You can revisit advanced topics (Weeks 4-5) later</p>"},{"location":"courses/builders/week-0/05-maximize-your-learning-and-success/#community-guidelines","title":"Community Guidelines","text":""},{"location":"courses/builders/week-0/05-maximize-your-learning-and-success/#our-learning-environment","title":"Our Learning Environment","text":"<p>This is a collaborative, supportive community of builders. We're all here to learn, share, and grow together.</p> <p>Expected behavior: - Respect everyone's experience level and learning pace - Share generously\u2014knowledge compounds when shared - Ask questions without apology - Help others when you can - Celebrate wins, big and small</p>"},{"location":"courses/builders/week-0/05-maximize-your-learning-and-success/#monthly-builder-forum","title":"Monthly Builder Forum","text":"<p>What it is: Ongoing live sessions for course graduates via LinkedIn Group Purpose: Continue learning, share advanced implementations, stay current with Claude updates Access: Automatic enrollment upon course completion</p> <p>What to expect: - Monthly live sessions on advanced topics - Community showcase (members present their systems) - Updates on new Claude features and capabilities - Networking with other AI builders</p>"},{"location":"courses/builders/week-0/05-maximize-your-learning-and-success/#course-completion-your-capstone","title":"Course Completion &amp; Your Capstone","text":""},{"location":"courses/builders/week-0/05-maximize-your-learning-and-success/#what-youll-walk-away-with","title":"What You'll Walk Away With","text":"<p>If you do the work, you'll achieve the outcomes outlined in the course. The specific deliverables will vary by student based on your focus areas and business needs, but every student who completes the exercises will build:</p> <p>Core capabilities: - Design and implement systematic AI workflows - Build reusable AI assets that scale your expertise - Deploy autonomous systems that work without supervision - Prototype applications without waiting on engineering - Lead AI initiatives with hands-on credibility</p> <p>Your portfolio will include: - Production-ready Claude Skills deployed across platforms - Subagents handling complex autonomous workflows - Browser automations for repetitive tasks - Working prototypes built with agentic coding - Complete documentation in your Agentic AI Registry</p>"},{"location":"courses/builders/week-0/05-maximize-your-learning-and-success/#capstone-project","title":"Capstone Project","text":"<p>What it is: A complete AI system integrating Skills, Subagents, and automations to solve a real business problem</p> <p>Delivered in Week 5: - Final presentation to the cohort - Demo of your working system - Documentation in your Agentic AI Registry</p> <p>Evaluation criteria: - Does it solve a real problem in your business? - Is it built with reusable components (Skills, Subagents)? - Can others understand and reproduce your approach? - Does it demonstrate integration of course concepts?</p>"},{"location":"courses/builders/week-0/05-maximize-your-learning-and-success/#frequently-asked-questions","title":"Frequently Asked Questions","text":"<p>Quick answers to common questions: - Can't attend live? Watch recordings within 48 hours - Need coding experience? No\u2014we teach builders, not developers - All tools required before Week 1? No\u2014setup happens during Week 1 - Refund policy? Handled by Maven\u2014full refund up to 14 days - How many 1:1 sessions can I book? As many as you need\u2014they're on-demand throughout the course - What if I get stuck? Use Slack, office hours, or book a 1:1 session anytime</p> <p>For additional questions, post in Slack or book a 1:1 session with James.</p>"},{"location":"courses/builders/week-0/05-maximize-your-learning-and-success/#next-steps-get-ready-for-week-1","title":"Next Steps: Get Ready for Week 1","text":"<p>Right now: 1. \u2705 Join the Slack workspace (check your email for invite) 2. \u2705 Introduce yourself in Maven #intros channel 3. \u2705 Review \"Identify Your AI Builder Stack\" lesson 4. \u2705 Verify you meet system requirements</p> <p>Before Week 1: 1. \u2705 Block calendar time for live sessions 2. \u2705 If you have time, start configuring your AI Builder Stack (Week 0 lessons) 3. \u2705 Post any setup issues in Slack</p> <p>During the course: 1. Show up to live sessions 2. Complete exercises between sessions 3. Ask questions in Slack 4. Share your wins and progress 5. Help your peers when you can</p>"},{"location":"courses/builders/week-0/05-maximize-your-learning-and-success/#welcome-to-the-builder-community","title":"Welcome to the Builder Community","text":"<p>You're not just learning Claude\u2014you're joining a community of builders who see AI as infrastructure, not magic. Over the next 5 weeks, you'll build systems that compound your expertise, automate your operations, and give you hands-on credibility to lead AI initiatives.</p> <p>The agentic era rewards builders. Let's build together.</p> <p>See you in Week 1.</p> <p>\u2014James</p>"},{"location":"courses/builders/week-0/06-faq/","title":"Claude for Builders \u2014 Frequently Asked Questions","text":""},{"location":"courses/builders/week-0/06-faq/#course-logistics","title":"Course Logistics","text":"<p>Q: What if I can't attend a live session? A: Watch the recording within 48 hours and complete the exercise. Post questions in Slack before the next session.</p> <p>Q: Can I work ahead? A: Written lessons are available immediately, but live sessions follow the schedule. You can review recordings early, but wait for live instruction before building complex systems.</p> <p>Q: Are sessions recorded? A: Yes. All sessions are recorded and posted within 24 hours. You have lifetime access.</p> <p>Q: What's the refund policy? A: Maven handles refunds. Check Maven's terms or contact their support.</p> <p>Q: How do I join the Slack workspace? A: You'll receive an invitation within 24 hours of enrollment. Check your email for the invite link to join #claude-cohort-[cohort-number].</p> <p>Q: Can I get 1:1 time with James? A: Yes. Schedule 15 or 30-minute sessions at your convenience through the Calendly link provided in the course materials.</p>"},{"location":"courses/builders/week-0/06-faq/#technical-support","title":"Technical Support","text":"<p>Q: What if I get stuck on setup? A: Post in Slack with screenshots. Attend office hours for real-time troubleshooting. Use your 1:1 for complex issues.</p> <p>Q: Do I need coding experience? A: No. This course teaches builders, not developers. You'll work with code, but we provide templates and step-by-step guidance.</p> <p>Q: What if my machine doesn't meet requirements? A: Contact James in Slack immediately. We'll find workarounds where possible.</p> <p>Q: Do all tools need to be configured before Week 1? A: No. Week 0 provides an overview of required tools. Detailed setup happens during Week 1 live sessions. It's suggested to get started before Week 1 if possible, but not required.</p> <p>Q: I can't access Google Drive links from my corporate network. What should I do? A: PDF versions of all slide decks will be provided for students who cannot access Google Drive.</p> <p>Q: Where can I find the GitHub repository for the course? A: The course repo is at https://github.com/jamesgray-ai/claude-for-builders. You'll be added to a team with access to clone the repo.</p>"},{"location":"courses/builders/week-0/06-faq/#course-content","title":"Course Content","text":"<p>Q: Will this course be updated for new Claude features? A: Yes. Lesson materials are updated monthly and available as resources on Google Drive.</p> <p>Q: Can I take this course if I took Hands-on Agentic AI for Leaders? A: Yes. Leaders = AI fundamentals across tools (breadth). Builders = Deep Claude implementation (depth).</p> <p>Q: What's the difference between this course and other Claude courses? A: This course goes deep on building with Claude specifically\u2014Skills, Subagents, Claude Code, browser automation. Other courses cover AI fundamentals or multiple tools. This is for builders who want to master the Claude ecosystem.</p> <p>Q: What if I fall behind during the course? A: Watch recordings to catch up, complete exercises at your own pace, and attend office hours for support. All materials have lifetime access.</p>"},{"location":"courses/builders/week-0/06-faq/#tools-setup","title":"Tools &amp; Setup","text":"<p>Q: Do I need Claude Pro or can I use the free tier? A: You need a paid Claude subscription (Pro minimum, Max recommended for heavy Claude Code usage). The free tier won't provide enough usage limits for course work.</p> <p>Q: Can I use a different code editor besides Cursor or VS Code? A: Cursor or VS Code are required. Course instructions assume one of these editors. Other editors may work but won't be officially supported.</p> <p>Q: What if Claude in Chrome isn't available in my region? A: Contact James in Slack. We'll discuss alternative approaches for browser automation or work with you to access the extension if possible.</p> <p>Q: I've never used GitHub. Is that a problem? A: No problem. Week 1 covers GitHub setup and the basics you need. You don't need prior experience.</p> <p>Q: Can I use my company's Claude Team account? A: Yes, Claude Team accounts work well. Make sure you have permission to install tools and access external resources for the course.</p>"},{"location":"courses/builders/week-0/06-faq/#capstone-project","title":"Capstone Project","text":"<p>Q: What should my capstone project be? A: Choose something that solves a real problem in your work. It should integrate Skills, Subagents, or automation\u2014demonstrating what you've learned applied to your context.</p> <p>Q: How much time should I spend on the capstone? A: Plan for 3-5 hours of focused work during Week 5. You'll build on exercises from previous weeks, so it's more integration than starting from scratch.</p> <p>Q: Do I have to present my capstone to the cohort? A: Yes. Presentations are part of the learning experience. You'll demo your system, explain your approach, and get peer feedback.</p> <p>Q: What if my capstone doesn't work perfectly? A: Perfect doesn't matter. What matters is demonstrating your process, what you learned, and how you applied course concepts. Working systems are better than perfect systems.</p>"},{"location":"courses/builders/week-0/06-faq/#community-support","title":"Community &amp; Support","text":"<p>Q: What's the LinkedIn Private Group Forum? A: A LinkedIn Group for course graduates with ongoing monthly live sessions covering advanced topics, Claude updates, and community showcases. </p> <p>Q: Can I stay in touch with my cohort after the course? A: Yes. The Slack workspace remains active, and you'll have access to the LinkedIn group to continue learning with other graduates.</p> <p>Q: What if I need help after the course ends? A: You have lifetime access to recordings and materials. </p>"},{"location":"courses/builders/week-0/06-faq/#getting-started","title":"Getting Started","text":"<p>Q: What should I do right now? A: Join Slack, introduce yourself, review the \"Identify Your AI Builder Stack\" lesson, and verify you meet system requirements. Start setting up tools if you want a head start before Week 1.</p> <p>Q: How can I prepare before the first live session? A: Review Week 0 materials, join Slack, and start thinking about workflows in your business that you'd like to automate. The more you connect course concepts to real work, the better.</p> <p>Have a question not answered here? Post in Slack or bring it to office hours!</p>"},{"location":"courses/builders/week-1/mcp-connectors-setup/","title":"MCP Connectors Setup Guide","text":"<p>Quick reference for connecting Claude to external applications and MCP servers.</p>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#overview","title":"Overview","text":"<p>Claude can connect to external tools and data sources through:</p> <ol> <li>Integrations \u2014 Built-in connections to cloud services (Google Drive, Gmail, GitHub)</li> <li>Custom Connectors \u2014 Remote MCP servers you configure</li> <li>Desktop Extensions \u2014 Local MCP servers on your machine (Desktop only)</li> </ol>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#part-1-built-in-integrations","title":"Part 1: Built-in Integrations","text":"<p>Claude offers built-in integrations with popular services.</p>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#available-integrations","title":"Available Integrations","text":"Integration Free Pro Max Team Enterprise GitHub \u2713 \u2713 \u2713 \u2713 \u2713 Google Drive \u2713 \u2713 \u2713 \u2713 \u2713 Gmail \u2713 \u2713 \u2713 \u2713 \u2713 Google Calendar \u2713 \u2713 \u2713 \u2713 \u2713"},{"location":"courses/builders/week-1/mcp-connectors-setup/#enable-an-integration","title":"Enable an Integration","text":"<p>From the chat interface: 1. Click the + button in the lower left of the chat window 2. Select the integration you want to connect 3. Complete the authentication flow</p> <p>From settings: 1. Go to Settings \u2192 Connectors 2. Find the integration and click Connect 3. Complete the authentication flow</p>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#for-teamenterprise-plans","title":"For Team/Enterprise Plans","text":"<p>Organization Owners must first enable integrations: 1. Go to Admin settings \u2192 Connectors 2. Click Enable next to the integration 3. Team members can then connect individually through their settings</p>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#part-2-custom-connectors-remote-mcp-servers","title":"Part 2: Custom Connectors (Remote MCP Servers)","text":"<p>Custom connectors let you connect Claude to remote MCP servers.</p> <p>Available on: Claude web and Desktop (Pro, Max, Team, Enterprise)</p>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#add-a-custom-connector","title":"Add a Custom Connector","text":"<ol> <li>Go to Settings \u2192 Connectors</li> <li>Click Add custom connector</li> <li>Enter the remote MCP server URL</li> <li>(Optional) Configure OAuth credentials in Advanced settings</li> <li>Complete setup</li> </ol>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#enable-connectors-in-a-conversation","title":"Enable Connectors in a Conversation","text":"<ol> <li>Click the + button in the chat interface</li> <li>Select Connectors</li> <li>Toggle on the connectors you want to use</li> </ol>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#part-3-desktop-extensions-local-mcp-servers","title":"Part 3: Desktop Extensions (Local MCP Servers)","text":"<p>Desktop Extensions connect Claude to MCP servers running on your local machine.</p> <p>Available on: Claude Desktop only (not web)</p>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#browse-and-install-extensions","title":"Browse and Install Extensions","text":"<ol> <li>Open Claude Desktop</li> <li>Go to Settings \u2192 Extensions</li> <li>Browse available extensions</li> <li>Click to install</li> </ol>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#manual-configuration","title":"Manual Configuration","text":"<p>For custom MCP servers, edit the configuration file directly.</p> <p>Configuration file location:</p> Platform Path macOS <code>~/Library/Application Support/Claude/claude_desktop_config.json</code> Windows <code>%APPDATA%\\Claude\\claude_desktop_config.json</code> <p>Example configuration:</p> <pre><code>{\n  \"mcpServers\": {\n    \"my-server\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/your/server.js\"]\n    }\n  }\n}\n</code></pre> <p>After editing, restart Claude Desktop for changes to take effect.</p>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#configure-tool-permissions","title":"Configure Tool Permissions","text":"<p>Each connector has individual tool permissions that control when Claude can use specific capabilities.</p>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#access-tool-permissions","title":"Access Tool Permissions","text":"<ol> <li>Go to Settings \u2192 Connectors</li> <li>Click on a connected integration (e.g., Notion)</li> <li>View the Tool permissions section</li> </ol>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#permission-levels","title":"Permission Levels","text":"<p>Each tool can be set to one of three permission levels:</p> Icon Level Behavior \u2713 Always allow Claude can use without asking \u270b Ask each time Claude requests permission before using \u2298 Never Claude cannot use this tool"},{"location":"courses/builders/week-1/mcp-connectors-setup/#tool-categories","title":"Tool Categories","text":"<p>Tools are grouped by their capabilities:</p> <p>Read-only tools \u2014 Fetch and search data (lower risk) - Example: <code>notion-fetch</code>, <code>notion-search</code>, <code>notion-get-users</code> - Default: Often set to \"Always allow\"</p> <p>Write/delete tools \u2014 Create, modify, or delete data (higher risk) - Example: <code>notion-create-pages</code>, <code>notion-update-database</code>, <code>notion-move-pages</code> - Default: Often set to \"Ask each time\" or custom per-tool</p>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#recommended-approach","title":"Recommended Approach","text":"<ul> <li>Read-only tools: \"Always allow\" for smoother workflows</li> <li>Write/delete tools: \"Ask each time\" until you're comfortable with how Claude uses them</li> <li>Review permissions when first connecting a new integration</li> </ul>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#verify-connectors-are-working","title":"Verify Connectors Are Working","text":"<ol> <li>Start a new conversation</li> <li>Click the + button</li> <li>Hover over Connectors to see available servers</li> <li>Your configured connectors should appear in the list</li> </ol>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#security-considerations","title":"Security Considerations","text":"<ul> <li>Only connect to servers from organizations you trust</li> <li>Review permission requests during OAuth authentication</li> <li>All data transfers use encryption</li> <li>Integrations work only in private projects</li> <li>Chats with synced content cannot be shared</li> </ul>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#troubleshooting","title":"Troubleshooting","text":"<p>Integration not appearing? - Check you have the required plan - For Team/Enterprise, verify the Owner has enabled it - Try disconnecting and reconnecting</p> <p>Custom connector not connecting? - Verify the MCP server URL is correct - Check the server is running and accessible - Review OAuth credentials if required</p> <p>Desktop extension not loading? - Check the configuration file syntax (valid JSON) - Verify the path to your server is absolute - Restart Claude Desktop completely (quit, not just close window) - Check logs at <code>~/Library/Logs/Claude/mcp.log</code> (macOS)</p>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#next-steps","title":"Next Steps","text":"<ul> <li>Review the course slide deck for detailed walkthrough</li> <li>Explore the MCP server directory for available integrations</li> <li>Post in Slack if you encounter issues</li> </ul>"},{"location":"courses/builders/week-1/mcp-connectors-setup/#resources","title":"Resources","text":"<ul> <li>About Custom Integrations Using Remote MCP</li> <li>Setting Up Claude Integrations</li> <li>Model Context Protocol Documentation</li> <li>MCP Quickstart Guide</li> </ul>"},{"location":"courses/leaders/","title":"Hands-on Agentic AI for Leaders","text":"<p>From AI user to AI builder in 30 days. This cohort-based course goes beyond ChatGPT prompting to give you hands-on experience building AI-powered workflows, autonomous agents, and browser automations \u2014 the practical skills leaders need to reimagine business processes and communicate credibly with technical teams.</p> <p>Enroll on Maven  View full syllabus </p>"},{"location":"courses/leaders/#who-this-course-is-for","title":"Who This Course Is For","text":"<ul> <li>Leaders and professionals committed to learning AI through doing, not just reading</li> <li>Non-technical executives who want hands-on understanding of what AI can actually do</li> <li>Managers strengthening their collaboration with technical stakeholders</li> <li>No coding experience required</li> </ul>"},{"location":"courses/leaders/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Systematize AI-powered workflows with version-controlled asset libraries and opportunity catalogs</li> <li>Master agentic frameworks including the autonomy spectrum, seven building blocks, and twelve architecture patterns</li> <li>Build prompt workflows and project workspaces with memory systems and custom instructions across platforms</li> <li>Develop agent skills that package your expertise for reusable task execution</li> <li>Create browser automation workflows that execute multi-step web tasks hands-free</li> <li>Deploy autonomous agents across ChatGPT, Claude, M365 Copilot, and Google Workspace</li> </ul>"},{"location":"courses/leaders/#what-youll-build","title":"What You'll Build","text":"<p>By the end of the course, you'll ship workflows that save 5-10 hours weekly, complete 26 hands-on projects, and have the practical experience to reimagine business processes, identify automation patterns, and communicate credibly with technical teams.</p>"},{"location":"courses/leaders/#course-format","title":"Course Format","text":"Duration 4 weeks Commitment 5-8 hours per week Live Sessions Two session options per week (morning/evening US ET) Office Hours Optional Wednesday and Saturday sessions with 1:1 coaching Community Private LinkedIn group with bi-weekly updates post-course Recordings Lifetime access to all session recordings with monthly content updates"},{"location":"courses/leaders/#prerequisites","title":"Prerequisites","text":"<ul> <li>Paid subscription to ChatGPT, Claude, or Gemini</li> <li>macOS or Windows computer</li> <li>Comfort with small-group learning \u2014 no coding required</li> </ul>"},{"location":"courses/leaders/#instructor","title":"Instructor","text":"<p>James Gray \u2014 UC Berkeley AI instructor and former CIO/CPO. Previously spent 10 years at Microsoft building enterprise data platforms. Has trained 5,000+ executives globally in AI strategy.</p> <ul> <li>Maven Profile</li> <li>Other course: Claude and Claude Code for Builders</li> </ul>"},{"location":"courses/leaders/syllabus/","title":"Course Syllabus","text":"<p>Full syllabus for Hands-on Agentic AI for Leaders.</p> <p>Enroll on Maven </p>"},{"location":"courses/leaders/syllabus/#week-1-foundation-decomposition","title":"Week 1: Foundation &amp; Decomposition","text":"<ul> <li>Distinguish between automation, workflows, and agents on the autonomy spectrum</li> <li>Catalog your high-value workflows and AI assets in a structured Notion repository</li> <li>Build a version-controlled AI asset library using GitHub and Cursor</li> <li>Configure personalized work profiles and memory systems across AI platforms</li> <li>Select appropriate building blocks (Prompt, Context, Project, Skill, Agent, MCP) for your workflows</li> </ul>"},{"location":"courses/leaders/syllabus/#session-builder-stack-setup","title":"Session : Builder Stack Setup","text":"<p>Live step-by-step walkthrough of builder stack setup with real-time troubleshooting support.</p> <p>Outcomes:</p> <ul> <li>GitHub repository created and configured for AI building block version control</li> <li>AI code editor (Cursor, VS Code) installed, configured, and connected to AI models</li> <li>Voice-to-text tools integrated for hands-free AI collaboration</li> <li>Command-line tools (Google Gemini, OpenAI Codex, Claude Code) activated and tested with sample workflow</li> <li>AI personalization settings configured with custom instructions, privacy protections, and professional preferences</li> <li>Memory systems activated and populated with key professional context across AI platforms</li> </ul> Module 1: Builder Stack Setup <p>Build the infrastructure that transforms AI from an occasional tool to a daily operating system. You'll configure your complete AI builder stack\u2014code editor, work profiles, memory systems, voice-to-text, and version control\u2014creating the foundation that makes every workflow you automate organized, repeatable, and professional.</p> # Lesson Type Duration Resources 1 Configure Your AI Personalization Settings  Live 15 min  Slides 2 Version Control Your AI Assets  Self-Paced 10 min  Slides 2 Configure AI Memory Systems  Live 20 min  Slides 2 Configure Your AI Code Editor  Live 25 min  Slides 3 Configure Voice-to-Text for AI Collaboration  Self-Paced 5 min  Slides Configure Your AI Personalization Settings <p>Configure your AI platforms to match your professional standards and communication style. You'll set up user preferences, define output formats, configure security settings including privacy controls and MFA, and establish baseline behaviors. By the end of this lesson, your AI tools will consistently deliver responses aligned with your professional requirements\u2014without needing to specify preferences in every conversation.</p> <p>Objectives:</p> <ul> <li>Configure personalized work profiles on your AI tools using custom instructions that reflect your role, work context, and response preferences</li> <li>Implement privacy and security protections across all platforms by disabling model training data sharing and enabling multi-factor authentication</li> <li>Apply personalization strategically across platforms based on each platform's available features (custom instructions, user preferences, style settings, output formats)</li> </ul> Version Control Your AI Assets <p>Objectives:</p> <ul> <li>Create a GitHub repository to store and version your AI prompts, skills, and reference files</li> <li>Execute the create \u2192 commit \u2192 push workflow to save an AI asset to your repository</li> <li>Verify your repository syncs between local and cloud to protect your work</li> </ul> Configure AI Memory Systems <p>Activate AI memory systems that automatically retain your professional context across conversations. You'll enable persistent memory, populate your tools with key facts about your role and work, establish memory hygiene practices for reviewing and editing stored information, and set privacy boundaries. Your AI assistants will remember your context automatically\u2014no more re-explaining who you are or what you're working on every conversation.</p> <p>Objectives:</p> <ul> <li>Configure active memory systems on your AI platforms that retain key professional context across conversations without repeated explanations</li> <li>Implement memory settings across platforms by enabling persistent context between sessions</li> <li>Populate your AI memory with 2-3 critical professional facts about your role, work context, and communication preferences</li> <li>Apply memory hygiene practices by reviewing stored information and protecting sensitive data from AI memory</li> </ul> Configure Your AI Code Editor <p>Objectives:</p> <ul> <li>Install and configure an AI-powered code editor (Cursor or VS Code) as your workspace for AI asset development</li> <li>Connect at least one AI model (Claude, OpenAI, or Gemini) to your editor for AI-assisted work</li> <li>Create and preview a Markdown file to verify your editor is properly configured</li> </ul> Configure Voice-to-Text for AI Collaboration <p>Objectives:</p> <ul> <li>Configure voice-to-text capabilities to enable hands-free AI collaboration across your productivity stack</li> <li>Set up voice input methods using keyboard shortcuts (Caps Lock, fn button) to dictate prompts at 150+ words per minute vs. 40-60 wpm typing</li> <li>Apply multimodal prompting by combining voice instructions with screenshot capabilities for richer AI context</li> </ul> Module 1: Configure Your AI Builder Stack <p>Build the infrastructure that transforms AI from occasional tool to daily operating system. You'll configure code editors, GitHub, Claude Code, voice-to-text tools, and work profiles across Claude platforms\u2014establishing the complete technical foundation that enables all hands-on builder work throughout the course and beyond.</p> # Lesson Type Duration Resources 1 Configure Claude Personalization and Memory Settings  Slides 1 Configure Your AI Personalization Settings  Live 15 min  Slides 2 Implement Version Control for Your AI Building Blocks  Live  Slides 2 Configure AI Memory Systems  Live 20 min  Slides 3 Configure AI-Powered Code Editor  Live  Slides 4 Implement Voice-to-Text for Hands-Free AI Collaboration  Live  Slides Configure Claude Personalization and Memory Settings <p>Configure your Claude environment for maximum productivity throughout the course. You'll customize communication preferences, writing style, and feature settings, then activate Claude's memory system to maintain context across conversations. Proper configuration ensures Claude adapts to your workflow, remembers your preferences, and delivers responses aligned with your goals and communication style.</p> <p>Objectives:</p> <ul> <li>Configure Claude's personalization settings including communication style, tone preferences, response formatting, and feature toggles to match your workflow requirements</li> <li>Activate Claude's memory system and verify it's capturing conversation context, project details, and preferences across sessions</li> <li>Test personalized responses by comparing Claude's output before and after configuration to validate that settings are working as intended</li> </ul> Configure Your AI Personalization Settings <p>Configure your AI platforms to match your professional standards and communication style. You'll set up user preferences, define output formats, configure security settings including privacy controls and MFA, and establish baseline behaviors. By the end of this lesson, your AI tools will consistently deliver responses aligned with your professional requirements\u2014without needing to specify preferences in every conversation.</p> <p>Objectives:</p> <ul> <li>Configure personalized work profiles on your AI tools using custom instructions that reflect your role, work context, and response preferences</li> <li>Implement privacy and security protections across all platforms by disabling model training data sharing and enabling multi-factor authentication</li> <li>Apply personalization strategically across platforms based on each platform's available features (custom instructions, user preferences, style settings, output formats)</li> </ul> Implement Version Control for Your AI Building Blocks <p>Implement GitHub version control as your safety net for AI building block development. Create a repository to store Skills, Prompts, Agent configurations, and workflows with full change history. Master the create-commit-push workflow that professional developers use to track iterations, experiment without risk, collaborate across teams, and recover from mistakes\u2014critical infrastructure for building production AI systems.</p> <p>Objectives:</p> <ul> <li>Create a GitHub repository to store and version your AI building blocks (Skills, Prompts, Agents, configurations)</li> <li>Execute the create \u2192 commit \u2192 push workflow to save a building block to your repository</li> <li>Verify your repository syncs between local and cloud to protect your work</li> </ul> Configure AI Memory Systems <p>Activate AI memory systems that automatically retain your professional context across conversations. You'll enable persistent memory, populate your tools with key facts about your role and work, establish memory hygiene practices for reviewing and editing stored information, and set privacy boundaries. Your AI assistants will remember your context automatically\u2014no more re-explaining who you are or what you're working on every conversation.</p> <p>Objectives:</p> <ul> <li>Configure active memory systems on your AI platforms that retain key professional context across conversations without repeated explanations</li> <li>Implement memory settings across platforms by enabling persistent context between sessions</li> <li>Populate your AI memory with 2-3 critical professional facts about your role, work context, and communication preferences</li> <li>Apply memory hygiene practices by reviewing stored information and protecting sensitive data from AI memory</li> </ul> Configure AI-Powered Code Editor <p>Transform your development workflow with an AI-powered code editor (Cursor or VS Code). Configure AI model integration (Claude, ChatGPT, Gemini, or other CLI models) that lets you generate code through natural language, get instant explanations for complex logic, and refactor with AI assistance. This workspace becomes essential infrastructure for building Skills, workflows, and Agents\u2014enabling builders without deep coding backgrounds to create production-quality AI systems.</p> <p>Objectives:</p> <ul> <li>Configure an AI-powered code editor (Cursor or VS Code) as your workspace for AI building block development</li> <li>Install and authenticate at least one AI model integration (Claude Code, ChatGPT Codex, Gemini CLI, or similar)</li> <li>Create and preview a Markdown file to verify your editor is properly configured</li> </ul> Implement Voice-to-Text for Hands-Free AI Collaboration <p>Install and configure a voice-to-text application (Wispr Flow recommended) to enable hands-free interaction with AI tools and code editors throughout the course. You'll practice voice dictation, learn best practices for speaking with AI, and set up your environment for maximum productivity. Voice-first collaboration dramatically accelerates your workflow\u2014especially for complex prompts and multi-step instructions.</p> <p>Objectives:</p> <ul> <li>Install and configure a voice-to-text application (Wispr Flow or alternative) with proper permissions and settings for AI platform integration</li> <li>Practice voice dictation techniques including formatting commands, punctuation control, and natural speech patterns to achieve 90%+ accuracy</li> <li>Demonstrate hands-free AI collaboration by completing a workflow entirely through voice\u2014from initial prompt to refinement to final output</li> <li>Apply voice-first best practices for complex multi-step instructions, ensuring clarity and reducing the need for manual typing throughout the course</li> </ul>"},{"location":"courses/leaders/syllabus/#session-1-agentic-ai-foundations-workflow-identification","title":"Session 1: Agentic AI Foundations &amp; Workflow Identification","text":"<p>Understand the fundamentals of agentic AI and the six building blocks (Prompt, Context, Project, Skill, Agent, MCP) that power these systems. Then identify and categorize 2-3 workflow candidates from your work\u2014distinguishing between deterministic automation, collaborative AI workflows, and autonomous AI workflows with agents. Build self-awareness of where you struggle with workflow identification to focus Session 2's decomposition practice on your exact needs.</p> <p>Outcomes:</p> <ul> <li>Mental model of the autonomy spectrum distinguishing augmented AI (thought partner), structured workflows, and autonomous agents with clear selection criteria for each</li> <li>Understanding of 6 building blocks (Prompt, Context, Project, Skill, Agent, MCP) and when to apply each based on workflow autonomy requirements</li> <li>Cataloged 2-3 workflow candidates including one augmented workflow (AI as thought partner) and one autonomous workflow (fully automated execution)</li> <li>Identified where you get stuck when working with workflows\u2014selecting candidates, defining boundaries, articulating steps, or mapping building blocks\u2014to target Session 2 practice</li> </ul> Module 1: Assess Agentic Fundamentals and Workflow Opportunities <p>Gain clarity on what's actually possible with agentic AI\u2014and what's worth building first. You'll master the Building Blocks framework (Prompt, Context, Project, Skill, Agent, MCP) and the Autonomy Spectrum, then identify and categorize workflow candidates from your own work. By session end, you'll have prioritized workflows in your AI Registry ready for the hands-on modules ahead.</p> # Lesson Type Duration Resources 1 Understand the Agentic AI Landscape and AI Building Blocks  Live 60 min  Slides 2 Identify and Name Workflow Candidates  Live 60 min  Slides Understand the Agentic AI Landscape and AI Building Blocks <p>Master the foundational framework for building AI systems that scale. You'll learn the autonomy spectrum\u2014distinguishing automation, workflows, and agents\u2014and the six building blocks (Prompt, Context, Project, Skill, Agent, MCP) that professional builders use. By the end, you'll identify which building blocks any workflow needs, avoiding the common mistake of reaching for fully autonomous agents when simpler approaches work better.</p> <p>Objectives:</p> <ul> <li>Distinguish between automation, workflows, and agents on the autonomy spectrum</li> <li>Explain why agentic approaches outperform zero-shot prompting for multi-step tasks</li> <li>Identify which building blocks (Prompt, Context, Project, Skill, Agent, MCP) apply to a workflow</li> <li>Classify example workflows on the autonomy spectrum and identify building blocks in a sample workflow</li> </ul> Identify and Name Workflow Candidates <p>Examine concrete examples of deterministic automated, collaborative AI, and autonomous agent workflows. Then use a structured meta-prompt to discover AI workflow opportunities in your daily work and categorize each candidate by workflow type.</p> <p>Objectives:</p> <ul> <li>Distinguish deterministic automated workflows (rule-based, zero human input) from collaborative AI workflows (human-AI partnership) and autonomous agent workflows (goal-driven, adaptive) by analyzing concrete examples</li> <li>Apply a structured meta-prompt to systematically identify AI workflow opportunities across your daily work including high-frequency tasks, judgment-heavy processes, and repetitive operations</li> <li>Create clear, outcome-focused names (2-4 words) for identified workflow candidates using consistent noun phrase patterns that communicate purpose without requiring context</li> </ul>"},{"location":"courses/leaders/syllabus/#session-2-workflow-deconstruction","title":"Session 2: Workflow Deconstruction","text":"<p>Master workflow decomposition through live demonstration and hands-on practice. Learn to break workflows into discrete steps with appropriate detail, identify decision points and context requirements, and distinguish automation-suitable from human-judgment steps. Practice deconstructing one of your Session 1 workflows with real-time feedback, addressing your specific friction points from boundary definition to procedural articulation.</p> <p>Outcomes:</p> <ul> <li>Decomposition methodology for breaking workflows into discrete steps with appropriate granularity, decision points, and context requirements</li> <li>One fully decomposed workflow from Session 1 catalog with explicit steps, branching logic, data needs, and human-vs-automation decisions mapped</li> <li>Selected the appropriate building blocks for your workflow\u2014prompt chain, Skill, Subagent, or autonomous agent\u2014based on complexity and autonomy needs</li> <li>Common pitfall awareness avoiding too-high-level descriptions, missing implicit steps, and unclear decision criteria that block implementation</li> </ul> Module 2: Deconstruct &amp; Register Your Workflows <p>Transform chaotic AI experimentation into systematic operations. You'll deconstruct processes into discrete workflows, identify automation opportunities using proven frameworks, and build your Workflow Registry in Notion\u2014a living catalog that tracks all workflows, assets, and SOPs. Connect it to Claude via MCP so Claude helps you design, document, and organize everything as you build.</p> # Lesson Type Duration Resources Build Your Claude Project with Memory and Knowledge Base  Live 90 min  Slides 2 Deconstruct Your Work and Identify AI Building Blocks  Live 60 min  Slides 3 Build Your AI Operations Registry  Live 30 min  Slides 3 Set Up Your AI Workflow Registry  Live 30 min  Slides 4 Configure MCP Server Connections and Desktop Integrations  Live 90 min  Slides Build Your Claude Project with Memory and Knowledge Base <p>Build a dedicated Claude Project that maintains conversation memory and serves as a centralized knowledge repository. You'll configure project-level custom instructions, enable persistent memory that evolves with each interaction, and populate the knowledge base with reference files that Claude can access automatically\u2014eliminating repetitive file uploads and creating a workspace that gets smarter over time.</p> <p>Objectives:</p> <ul> <li>Build a Claude Project with custom instructions, persistent memory enabled, and project-specific settings configured for course workflows</li> <li>Populate the project knowledge base with essential reference files (workflows, documentation, templates) that Claude can access automatically across all conversations</li> <li>Test persistent context by verifying that Claude retains project-specific information across multiple sessions and references knowledge base files without re-uploading</li> <li>Apply project-based workflows by conducting a complete task entirely within the project to validate memory retention and knowledge base accessibility</li> </ul> Deconstruct Your Work and Identify AI Building Blocks <p>Turn implicit workflows into systematic AI operations. You'll deconstruct two real-world workflows\u2014one Collaborative AI, one Deterministic Automation\u2014using the 4-question framework to identify discrete steps, decision points, data flows, and context requirements. Then apply the meta-prompting technique to your own workflows, letting AI generate complete workflow specifications with building blocks mapped, ready for execution and version control.</p> <p>Objectives:</p> <ul> <li>Apply the deconstruction framework to break down a named workflow into detailed steps that reveal the process structure and implementation requirements</li> <li>Map AI building blocks (Prompt, Context, Skill, Agent, MCP, Project) to each workflow step, identifying which building blocks are needed to operationalize each step</li> <li>Generate three production-ready deliverables using the meta-prompt: workflow analysis document, executable baseline prompt, and skill build recommendations that provide the necessary detail to build the AI-powered workflow</li> </ul> Build Your AI Operations Registry <p>Implement your operational control center for managing AI workflows and assets. Students replicate the Notion registry template, configure tracking fields, and document their first complete workflow including SOP and building blocks. Claude users integrate Skills with Notion MCP to enable bidirectional collaboration for reading and writing workflow data throughout the course.</p> <p>Objectives:</p> <ul> <li>Implement your AI Operations Registry by replicating the Notion database template and configuring workflow tracking fields</li> <li>Integrate Claude Skills with your registry via Notion MCP to enable collaborative workflow management and building block documentation</li> <li>Document one end-to-end workflow in your registry including SOP and associated AI assets</li> </ul> Set Up Your AI Workflow Registry <p>Objectives:</p> <ul> <li>Create a systematic inventory cataloging at least 3 recurring workflows with their triggers, steps, and outcomes, and the AI assets (prompts, skills, agents, context files) linked to each workflow to visualize dependencies</li> <li>Build a relational database system in Notion with separate tables for Business Processes, Workflows, AI Assets, and Apps to serve as your living repository</li> <li>Identify at least 3 high-value recurring workflows from your actual work, documenting each with trigger conditions, step-by-step process, desired outcomes, and AI automation opportunities</li> <li>Catalog existing AI assets by type (prompts, skills, agents, context files), organize them in a structured repository, and establish relational links to the workflows that depend on them</li> </ul> Configure MCP Server Connections and Desktop Integrations <p>Extend Claude's capabilities by configuring connections to external systems through MCP (Model Context Protocol). You'll connect Claude to remote MCP servers for services like Slack, GitHub, and Google Drive, then configure desktop connectors to access local applications and your filesystem. These integrations enable Claude to read data, trigger actions, and automate workflows across your entire tech stack.</p> <p>Objectives:</p> <ul> <li>Configure MCP server connections to at least two remote services (e.g., Slack, GitHub, Google Drive, Notion) with proper authentication and permissions</li> <li>Implement desktop connectors to access local filesystem, applications, or services running on your machine</li> <li>Test integration functionality by executing Claude commands that read data from connected systems and trigger actions across multiple services</li> <li>Troubleshoot connection issues using MCP diagnostics to verify successful authentication, resolve permission errors, and validate data access</li> </ul>"},{"location":"courses/leaders/syllabus/#week-2-prompt-and-skill-powered-workflows","title":"Week 2: Prompt and Skill-Powered Workflows","text":"<ul> <li>By the end of Week 2, you will have built:</li> <li>One deterministic workflow - predictable, step-by-step execution using prompt chains</li> <li>One augmented workflow - AI assists your judgment while you make final decisions, powered by Skills</li> <li>You'll also have:</li> <li>Configured AI project workspaces with custom instructions and context files</li> <li>Created reusable Agent Skills that capture your expertise</li> <li>Connected AI to external tools using MCP (Model Context Protocol)</li> </ul>"},{"location":"courses/leaders/syllabus/#session-3-agent-skills","title":"Session 3: Agent Skills","text":"<p>Build production-ready Agent Skills using Claude.ai and Claude Code, connect them to your business apps via MCP, deploy them across all Claude platforms, and ship them as installable plugins for team reuse.</p> <p>Outcomes:</p> <ul> <li>Production-ready Agent Skills created using both Claude.ai and Claude Code, with proper structure, metadata, and instructions saved with version control and registered in your AI Assets database</li> <li>Working MCP connections configured to Gmail, Drive, Notion, Slack, or HubSpot that enable Skills to access external data</li> <li>Cross-platform Skills deployment demonstrated across Claude.ai, Claude Code, and Cowork</li> <li>Published skill marketplace on GitHub that team members can install via /plugin marketplace add command</li> </ul> Module 1: Build Agent Skills <p>Turn your expertise into reusable AI automation that scales across teams and organizations. You'll build production-ready Agent Skills that package your knowledge into instructions Claude can apply anywhere, save them to your Agentic AI Repository with version control, then publish them as installable plugins through GitHub-hosted marketplaces\u2014making your skills discoverable and distributable for internal teams, client delivery, or commercial licensing.</p> # Lesson Type Duration Resources 1 Analyze the Anatomy of an Agent Skill  Self-Paced 20 min  Slides 2 Connect AI to Your Business Apps via MCP  Live 10 min  Slides 3 Build Reusable Agent Skills with Claude  Live 60 min  Slides 4 Ship Your Skills for Reuse  Live 60 min Analyze the Anatomy of an Agent Skill <p>Dissect what Skills are\u2014reusable instruction sets that teach Claude how to execute your workflows consistently. Analyze their anatomy: metadata, instructions, and resources. Then distinguish when to use Skills versus Prompts, Projects, MCP, or Agents.</p> <p>Objectives:</p> <ul> <li>Analyze the anatomy of an Agent Skill including metadata, instructions, and resource structure</li> <li>Distinguish Skills from Prompts, Projects, MCP, and Subagents to select the right building block</li> <li>Identify when to use each agentic building block based on the workflow requirements</li> </ul> Connect AI to Your Business Apps via MCP <p>Objectives:</p> <ul> <li>Configure MCP connections to connect your AI assistant to external tools and data sources with proper authentication and permissions</li> <li>Set up working connectors for business applications (Gmail, Drive, Notion, Slack, HubSpot) relevant to your workflow</li> <li>Test each configured connector by executing prompts that successfully call external tools and retrieve data</li> <li>Distinguish between remote MCP servers (cloud-based) and local desktop extensions to select the right architecture for different use cases</li> </ul> Build Reusable Agent Skills with Claude <p>Transform your workflow knowledge into a production-ready Agent Skill from scratch. You'll structure your skill with proper metadata and instructions, test it in a live conversation, save it to your repository with version control, and export it to your local machine\u2014making it available across Claude.ai, Claude Code, and Cowork.</p> <p>Objectives:</p> <ul> <li>Build a production-ready Agent Skill that packages your expertise into reusable instructions for Claude</li> <li>Structure your skill with proper metadata, instructions, and supporting resources</li> <li>Save skills to your repository for version control and register them in your AI Assets database</li> <li>Export skills to your local machine for use across Claude platforms (Code, Cowork)</li> </ul> Ship Your Skills for Reuse <p>Package and ship your skills as installable resources. One command gives others access to your expertise\u2014team members, clients, or the broader AI community. Your workflow knowledge becomes reusable, distributable, scalable.</p> <p>Objectives:</p> <ul> <li>Create a properly structured marketplace.json file with plugin metadata for at least one skill</li> <li>Publish a GitHub repository containing their skill marketplace that others can add via /plugin marketplace add</li> <li>Configure distribution settings for three deployment scenarios: private team use, organizational access, and public community sharing</li> <li>Demonstrate the complete installation workflow by having another team member successfully install their published plugin</li> </ul>"},{"location":"courses/leaders/syllabus/#session-4-prompt-workflows","title":"Session 4: Prompt Workflows","text":"<p>Master prompt engineering fundamentals and build two types of production workflows: deterministic workflows that run autonomously with consistent results, and collaborative workflows where human judgment guides AI execution through structured checkpoints.</p> <p>Outcomes:</p> <ul> <li>Production-ready prompts using the 5-part scaffold (role, task, constraints, examples, format) with structured formatting and model-specific optimization</li> <li>Deterministic automated workflow that executes multi-step processes independently with consistent results, proper error handling, and documented SOP</li> <li>Collaborative human-AI workflow with defined review checkpoints, structured handoffs between AI drafts and human refinement, and clear decision criteria</li> <li>Workflows registered in your Agentic AI catalog with proper documentation and saved to your prompt library for reuse</li> </ul> <p>Prerequisites: - Identify at least one workflow you want to break down and operationalize. - Identify and gather the \u201ccontext\u201d (e.g., files, procedures, apps) that are required for the workflow</p> Module 3: Design Prompt Workflows <p>Put your prompt engineering skills to work by building two essential workflow types. You'll create a deterministic automated workflow that runs independently with consistent results, then build a collaborative AI workflow where you partner with AI through iterative refinement\u2014giving you both ends of the human-AI collaboration spectrum.</p> # Lesson Type Duration Resources 1 Distinguish Workflow Execution Patterns  Live 45 min  Slides 2 Build a Deterministic Automated Workflow  Live 60 min  Slides 3 Build a Collaborative AI Workflow  Live 60 min Distinguish Workflow Execution Patterns <p>Master the mental models that determine which AI workflow pattern fits your use case. You'll learn the seven patterns across the autonomy spectrum\u2014from deterministic prompt chains to fully autonomous agents\u2014and use the Pattern Selection Framework to match workflow characteristics to the right architecture before you build.</p> <p>Objectives:</p> <ul> <li>Distinguish between seven workflow architecture patterns and five agent capability patterns by categorizing them as execution structure vs. behavioral capabilities</li> <li>Analyze workflow characteristics (predictability, complexity, step count) to select appropriate patterns using the Pattern Selection Framework.</li> </ul> Build a Deterministic Automated Workflow <p>Design and build a workflow that runs independently once triggered\u2014producing consistent, repeatable results without human intervention. You'll sequence steps, define inputs and outputs between each stage, handle edge cases, and save your workflow to your prompt library for reuse.</p> <p>Objectives:</p> <ul> <li>Build a multi-step deterministic workflow using prompt chaining that produces consistent outputs from the same inputs</li> <li>Sequence workflow steps with clear input/output definitions between each stage</li> <li>Implement error handling and edge case logic to ensure reliable execution</li> <li>Document the workflow SOP and save it to your registry</li> </ul> Build a Collaborative AI Workflow <p>Design and build a workflow where you partner with AI to deliver outcomes that require human judgment. You'll identify where to place review checkpoints, structure handoffs between AI drafts and human refinement, and create feedback loops that leverage both AI capability and your expertise.</p> <p>Objectives:</p> <ul> <li>Build a collaborative workflow with defined checkpoints where human judgment guides AI execution</li> <li>Design handoff points that structure the flow between AI-generated drafts and human review/refinement</li> <li>Implement feedback loops that incorporate your input to improve AI outputs iteratively</li> <li>Document the workflow with clear decision criteria for when to accept, refine, or redirect AI outputs</li> </ul>"},{"location":"courses/leaders/syllabus/#week-3-autonomous-agents","title":"Week 3: Autonomous Agents","text":"<ul> <li>By the end of Week 3, you will have built:</li> <li>One autonomous workflow - AI handles end-to-end execution independently without human intervention</li> <li>You'll understand:</li> <li>When to use ChatGPT agents vs. Claude subagents vs. M365 Copilot agents</li> <li>How to deploy agents across different platforms (web-based, terminal-based, enterprise ecosystem)</li> <li>Agent architecture fundamentals: perception, reasoning, planning, and action</li> </ul>"},{"location":"courses/leaders/syllabus/#session-5-autonomous-agents-chatgpt-agent","title":"Session 5: Autonomous Agents &amp; ChatGPT Agent","text":"<p>Understand agent fundamentals\u2014anatomy, core components, and universal patterns\u2014then apply this foundation by building your first autonomous ChatGPT agent with instructions, knowledge files, and connected actions.</p> <p>Outcomes:</p> <ul> <li>Agent anatomy framework: perception, reasoning, planning, action</li> <li>Launch a ChatGPT agent with minimal configuration that autonomously executes a multi-step workflow and produces deliverables</li> <li>First autonomous agent executing multi-step workflows</li> </ul> Module 10: Analyze and Design Agent Architectures <p>Understand what's happening under the hood, then design your own. You'll analyze the anatomy of AI agents and master orchestration patterns for multi-agent systems. Then you'll apply a systematic design process to deconstruct your workflows into platform-agnostic agent specifications. By the end, you'll have agent designs ready to implement on Claude Code, ChatGPT, Gemini, or any platform.</p> # Lesson Type Duration Resources 1 Analyze the Anatomy of an AI Agent  Live 10 min  Slides 2 Analyze Agent Capability Patterns  Live 15 min  Slides 3 Analyze Agent Orchestration Patterns  Live 15 min  Slides 4 Design Autonomous Workflows with Agents  Live 50 min  Slides Analyze the Anatomy of an AI Agent <p>Objectives:</p> <ul> <li>Distinguish between agents and workflows by comparing their autonomy levels, decision-making capabilities, and appropriate use cases on the agentic systems spectrum</li> <li>Identify the core components of an agent (LLM brain, tools, memory, instructions, knowledge) and explain how these components work together regardless of platform</li> <li>Evaluate business scenarios to determine when autonomous agents are appropriate versus structured workflows, based on task predictability, complexity, and need for dynamic planning</li> <li>Select optimal use cases for agentic implementation by matching task characteristics (open-ended problems, multi-step complexity, tool requirements) to agent capabilities</li> </ul> Analyze Agent Capability Patterns <p>Objectives:</p> <ul> <li>Distinguish the five agentic capability patterns (Reflection, Tool Use, Planning, Multi-agent Collaboration, Memory) by their role in agent execution</li> <li>Analyze how capability patterns work together using the customer exchange scenario</li> <li>Differentiate guardrails from human-in-the-loop controls for managing agent behavior</li> </ul> Analyze Agent Orchestration Patterns <p>Objectives:</p> <ul> <li>Analyze orchestration patterns for multi-agent systems: supervisor, swarm, hierarchical, and debate</li> <li>Compare pattern strengths and weaknesses for different task types and complexity levels</li> <li>Select the appropriate orchestration pattern for a given multi-agent workflow scenario</li> </ul> Design Autonomous Workflows with Agents <p>Objectives:</p> <ul> <li>Apply a systematic design process for agent systems by defining clear goals, processes, agent roles, instructions, and required tools</li> <li>Generate clear, unambiguous instructions for LLM agents using meta-prompting techniques and reasoning models to ensure reliable execution</li> <li>Design single-agent systems by specifying agent roles, responsibilities, and tool requirements for focused automation tasks</li> <li>Architect multi-agent systems by identifying and naming specialized agent roles that work together to accomplish complex goals</li> <li>Distinguish between single-agent and multi-agent approaches based on task complexity and the need for specialized expertise across different workflow components</li> </ul> Module 12: Build Autonomous Workflows with ChatGPT <p>Stop manually orchestrating every step\u2014build workflows that think and adapt using ChatGPT's autonomous capabilities. You'll design agents with Agent Mode for multi-step reasoning and planning, build browser automation workflows with Atlas Browser for web data extraction and form filling, and implement persistent memory for cross-session context. Deploy workflows that adapt to unpredictable inputs without hardcoded paths.</p> # Lesson Type Duration Resources 1 Build Autonomous Agents with ChatGPT Agent Mode  Live 30 min  Slides 2 Build Browser Workflows with ChatGPT Atlas  Live 30 min  Slides Build Autonomous Agents with ChatGPT Agent Mode <p>Objectives:</p> <ul> <li>Configure a ChatGPT agent by defining a clear goal, selecting appropriate tools, and providing necessary context to create an autonomous agent that executes multi-step tasks independently</li> <li>Formulate effective agent goals that are specific enough to guide execution while allowing the agent flexibility to plan and adapt its approach dynamically</li> <li>Observe and analyze agent execution by examining the agent's reasoning process, tool selection, and decision-making patterns to understand how it autonomously achieves the goal</li> <li>Troubleshoot agent behavior by identifying common failure modes (over-planning, tool misuse, scope creep) and refining the goal and context to improve reliability and performance</li> </ul> Build Browser Workflows with ChatGPT Atlas <p>Objectives:</p> <ul> <li>Configure ChatGPT Atlas for browser-based automation</li> <li>\u25e6 Complete initial Atlas setup and authentication</li> <li>\u25e6 Configure the Atlas browser extension with appropriate permissions</li> <li>\u25e6 Adjust security and privacy settings for workflow execution</li> <li>Execute autonomous browser workflows using Atlas agent mode</li> <li>\u25e6 Navigate websites using Atlas autonomous mode</li> <li>\u25e6 Delegate multi-step browser tasks to Atlas agents</li> <li>\u25e6 Monitor agent execution and intervene when necessary</li> <li>Apply Canvas browser queries to extract website information</li> <li>\u25e6 Ask contextual questions about webpage content</li> <li>\u25e6 Extract structured data from websites using Canvas queries</li> <li>\u25e6 Distinguish when to use Canvas queries vs. autonomous agent mode</li> </ul>"},{"location":"courses/leaders/syllabus/#session-6-claude-code-subagents","title":"Session 6: Claude Code Subagents","text":"<p>Unlock Claude's autonomous potential by building Code Subagents for complex multi-step tasks and Claude in Chrome for browser-based workflows. Deploy specialized AI assistants with their own isolated context and tool access that work independently on code generation, file operations, and web automation.</p> <p>Outcomes:</p> <ul> <li>Skills-powered Claude Code Subagent with isolated context and tool access</li> <li>Browser-based autonomous agent built with Claude in Chrome</li> <li>Understanding of when to use Skills vs. Subagents vs. full agents</li> </ul> Module 11: Build Autonomous Workflows with Claude Code Subagents <p>Build production-ready autonomous workflows using Claude Code Subagents. You'll translate your agent designs into working implementations, master single and multi-agent orchestration patterns, and operationalize workflows with scheduling and monitoring. By the end, you'll have autonomous AI systems executing complex workflows independently.</p> # Lesson Type Duration Resources 1 Analyze Claude Code Subagent Architecture and Use Cases  Live 60 min  Slides 2 Build Your First Claude Code Subagent  Live 60 min  Slides 4 Build Multi-Agent Systems with Claude Code  Live 60 min 5 Analyze Claude Code Subagent Orchestration Patterns  Live 60 min  Slides 6 Implement Scheduled Execution for Claude Code Subagents  Live 60 min  Slides 7 Analyze Claude Code Subagent Execution Traces  Live 60 min  Slides Analyze Claude Code Subagent Architecture and Use Cases <p>Understand what Claude Code subagents are, master the critical distinction between Skills and Subagents, and learn when to use each approach. Explore the mental model of building a specialized team of AI agents, develop a decision framework for choosing between Skills and Subagents, and identify appropriate use cases for subagent-based solutions in business contexts.</p> <p>Objectives:</p> <ul> <li>Define Claude Code subagents and explain their role in autonomous workflows</li> <li>Distinguish between Claude Skills (training manuals with shared context) and Subagents (specialized employees with isolated context) across key dimensions</li> <li>Apply a decision framework to determine when to use Skills, Subagents, or both for specific workflow requirements</li> <li>Analyze the \"dream team\" mental model to understand subagent specialization and delegation patterns</li> <li>Evaluate business scenarios to identify appropriate use cases for subagent-based autonomous workflows</li> </ul> Build Your First Claude Code Subagent <p>Transform your agent system design into a working implementation. Configure MCP tools in Claude Code, create your subagent with appropriate tool assignments and instructions, and test it with real tasks. Learn to debug, iterate, and refine subagent behavior through hands-on practice. Students complete this lesson with a fully functional subagent ready for real-world use.</p> <p>Objectives:</p> <ul> <li>Configure MCP tools in Claude Code to prepare tool access for subagent implementation</li> <li>Create a subagent by translating design specifications into Claude Code configuration (description, tools, model, system prompt)</li> <li>Evaluate subagent performance by testing with real tasks and observing delegation behavior</li> <li>Refine subagent configuration based on testing results to improve reliability and output quality</li> </ul> Build Multi-Agent Systems with Claude Code <p>Build complete multi-agent systems from your workflow specifications using Claude Code's AI-assisted configuration. You'll transform your Module 10 design into a working system\u2014single or multi-agent\u2014by prompting Claude Code to generate all necessary subagent configurations. Learn to review, refine, and validate auto-generated systems, ensuring proper orchestration and tool delegation. Master the AI-assisted workflow that makes complex agent systems buildable in minutes.</p> <p>Objectives:</p> <ul> <li>Build complete agent systems by prompting Claude Code to auto-generate configurations from workflow specifications</li> <li>Evaluate generated subagent configurations against design intent to ensure proper tool assignments and orchestration patterns</li> <li>Refine multi-agent systems by adjusting delegation logic, tool restrictions, and coordination patterns based on testing results</li> <li>Apply judgment to decide system architecture (single vs. multi-agent) and when to use AI-assisted generation versus manual configuration</li> </ul> Analyze Claude Code Subagent Orchestration Patterns <p>Master subagent execution from single-agent workflows to complex multi-agent orchestration. Learn three activation methods (explicit invocation, automatic delegation, chaining), understand when multiple agents outperform single-agent solutions, and apply orchestration patterns including sequential, parallel, and hybrid execution with hooks for reliable autonomous workflow behavior.</p> <p>Objectives:</p> <ul> <li>Execute Claude Code subagents using three activation methods (explicit invocation, automatic delegation, chaining) to accomplish single-task workflows</li> <li>Evaluate when to use multiple specialized agents versus a single agent based on workflow complexity and context isolation needs</li> <li>Design a multi-agent workflow using sequential, parallel, or hybrid orchestration patterns for a complex business use case</li> <li>Implement hooks (guardrails, logging, human-in-the-loop) to ensure reliable multi-agent system behavior</li> </ul> Implement Scheduled Execution for Claude Code Subagents <p>Learn to automate Claude Code subagent execution using native operating system schedulers. Configure Windows Task Scheduler and macOS cron jobs to run subagents on recurring schedules, implement error handling and notifications, and understand when scheduled execution is appropriate versus on-demand triggers. Students will schedule one of their existing Claude Code subagents to run automatically.</p> <p>Objectives:</p> <ul> <li>Configure OS-level scheduling (Windows Task Scheduler or macOS cron) to execute Claude Code subagents automatically</li> <li>Implement error handling and notification mechanisms for scheduled subagent runs</li> <li>Evaluate which workflows benefit from scheduled execution versus on-demand triggers</li> <li>Test and verify scheduled subagent execution with proper logging and output capture</li> </ul> Analyze Claude Code Subagent Execution Traces <p>Master Claude Code's built-in tracing capabilities to gain visibility into subagent execution. Learn to read execution traces, understand multi-agent delegation patterns, diagnose failures, and debug common issues. Students will add tracing to their multi-agent systems and use trace data to troubleshoot and optimize subagent behavior.</p> <p>Objectives:</p> <ul> <li>Analyze Claude Code execution traces to understand subagent delegation patterns and tool usage</li> <li>Diagnose subagent execution failures using trace data and error logs</li> <li>Evaluate subagent performance and identify optimization opportunities through tracing</li> <li>Implement tracing best practices for debugging multi-agent subagent workflows</li> </ul> Module 13: Build Autonomous Workflows with M365 Copilot Agents <p>Bring agentic AI to the Microsoft ecosystem your organization already runs on. You'll build deterministic agents with Copilot Agent Flows for repeatable processes and autonomous agents with Copilot Studio for complex decision-making\u2014all integrated with Teams, SharePoint, and the tools your team uses daily.</p> # Lesson Type Duration Resources Build Autonomous Agents with M365 Copilot Studio  Live  Slides Build Autonomous Agents with M365 Copilot Studio Lite  Live  Slides Build Deterministic Agents with M365 Copilot Agent Flows  Self-Paced  Slides"},{"location":"courses/leaders/syllabus/#session-7-m365-copilot-agents","title":"Session 7: M365 Copilot Agents","text":"<p>Bring agentic AI to the Microsoft ecosystem your organization already runs on. Build deterministic agents with Copilot Agent Flows for repeatable processes and autonomous agents with Copilot Studio for complex decision-making\u2014all integrated with Teams, SharePoint, and the tools your team uses daily.</p> <p>Outcomes:</p> <ul> <li>M365 Copilot Agent configured in Copilot Studio</li> <li>Agent Flow for deterministic, repeatable workflow automation</li> <li>Integration with Microsoft ecosystem (Teams, SharePoint, Office apps)</li> <li>Understanding when to use M365 agents vs. Claude/ChatGPT agents</li> </ul> Module 13: Build Autonomous Workflows with M365 Copilot Agents <p>Bring agentic AI to the Microsoft ecosystem your organization already runs on. You'll build deterministic agents with Copilot Agent Flows for repeatable processes and autonomous agents with Copilot Studio for complex decision-making\u2014all integrated with Teams, SharePoint, and the tools your team uses daily.</p> # Lesson Type Duration Resources Build Autonomous Agents with M365 Copilot Studio  Live  Slides Build Autonomous Agents with M365 Copilot Studio Lite  Live  Slides Build Deterministic Agents with M365 Copilot Agent Flows  Self-Paced  Slides"},{"location":"courses/leaders/syllabus/#week-4-agentic-ai-operationalization","title":"Week 4: Agentic AI Operationalization","text":""},{"location":"courses/leaders/syllabus/#session-8-openai-google-agents","title":"Session 8: OpenAI + Google Agents","text":"<p>Deploy production agents across OpenAI and Google platforms using AgentKit for visual workflows, ChatKit for conversational UX, Chrome for browser automation, and Workspace Flows for Google ecosystem integration. Build cross-platform strategy for real-world deployment.</p> <p>Outcomes:</p> <ul> <li>OpenAI Assistant or Google Gemini agent deployed in your ecosystem</li> <li>Cross-platform agent strategy: understanding when to use which platform</li> <li>Agents integrated with existing business tools and workflows</li> </ul> Module : Build Autonomous Workflows with OpenAI Agents # Lesson Type Duration Resources 2 Build Agent Workflows Visually with OpenAI AgentKit  Live 60 min  Slides 3 Build Conversational Agent UX with OpenAI ChatKit  Live 30 min  Slides Module 14: Build Autonomous Workflows with Google Gemini <p>Unlock fully autonomous agents within the Google ecosystem your organization already uses. You'll build agents with Gemini Enterprise and Google Workspace Flows that plan their own steps, select their own tools, and execute multi-step workflows without predefined sequences.</p> # Lesson Type Duration Resources Build Autonomous Agents with Google Gemini Enterprise  Self-Paced  Slides Build Autonomous Agents with Google Workspace Flows  Live 20 min  Slides 4 Build Browser Workflows with Google Chrome  Live 15 min  Slides"},{"location":"courses/leaders/syllabus/#session-9-operationalization-demos-insights","title":"Session 9: Operationalization, Demos &amp; Insights","text":"<p>Share live demos and one breakthrough insight that transformed how you approach AI. Finalize your AI Registry and 30/60/90-day action plan while learning from peer implementations and charting your path to scaled automation.</p> <p>Outcomes:</p> <ul> <li>Fully populated Agentic AI Repository with workflows, skills, and agents</li> <li>30/60/90-day action plan for scaling AI automation in your organization</li> <li>One transformational takeaway you wouldn't have gained without this course</li> </ul> Module 3: Ship Production-Ready AI Workflows <p>Move from prototype to production. You'll schedule and automate AI workflow execution, evaluate agentic systems for reliability, and establish monitoring to manage what you've built. By the end, you'll ship your Agentic AI Repository\u2014ready to scale automation across your organization with confidence.</p> # Lesson Type Duration Resources Agentic System Tracing  Self-Paced Monitor and Manage Agentic Systems  Self-Paced 1 Evaluate Agentic Systems  Live 15 min  Slides 2 Schedule and Automate AI Workflow Execution  Live 20 min  Slides 3 Ship Your Agentic AI Repository  Live 20 min 4 Course wrap-up / Next steps  Live 20 min Module 4: Demo Workflows and Share Transformational Insights <p>Demo your production-ready workflows and share transformational insights with your cohort. You'll present workflows and AI assets cataloged in your AI registry and source code version-controlled in GitHub, articulate key learnings you couldn't have discovered alone, and celebrate your transformation from AI user to AI builder.</p> # Lesson Type Duration Resources Course Takeways and Your Next Steps  Live 20 min <p>This syllabus is generated from the course database and may be updated between cohorts.</p>"},{"location":"courses/leaders/lessons/agentic-system-tracing/","title":"Agentic System Tracing","text":"Course Hands-on Agentic AI for Leaders Session Session 9: Operationalization, Demos &amp; Insights Module Ship Production-Ready AI Workflows Type  Self-Paced <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/analyze-agent-capability-patterns/","title":"Analyze Agent Capability Patterns","text":"Course Hands-on Agentic AI for Leaders Session Session 5: Autonomous Agents &amp; ChatGPT Agent Module Analyze and Design Agent Architectures Type  Live Duration 15 min"},{"location":"courses/leaders/lessons/analyze-agent-capability-patterns/#objectives","title":"Objectives","text":"<ul> <li>Distinguish the five agentic capability patterns (Reflection, Tool Use, Planning, Multi-agent Collaboration, Memory) by their role in agent execution</li> <li>Analyze how capability patterns work together using the customer exchange scenario</li> <li>Differentiate guardrails from human-in-the-loop controls for managing agent behavior</li> </ul>"},{"location":"courses/leaders/lessons/analyze-agent-capability-patterns/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/analyze-agent-orchestration-patterns/","title":"Analyze Agent Orchestration Patterns","text":"Course Hands-on Agentic AI for Leaders Session Session 5: Autonomous Agents &amp; ChatGPT Agent Module Analyze and Design Agent Architectures Type  Live Duration 15 min"},{"location":"courses/leaders/lessons/analyze-agent-orchestration-patterns/#objectives","title":"Objectives","text":"<ul> <li>Analyze orchestration patterns for multi-agent systems: supervisor, swarm, hierarchical, and debate</li> <li>Compare pattern strengths and weaknesses for different task types and complexity levels</li> <li>Select the appropriate orchestration pattern for a given multi-agent workflow scenario</li> </ul>"},{"location":"courses/leaders/lessons/analyze-agent-orchestration-patterns/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/analyze-claude-code-subagent-architecture-and-use-cases/","title":"Analyze Claude Code Subagent Architecture and Use Cases","text":"Course Hands-on Agentic AI for Leaders Session Session 6: Claude Code Subagents Module Build Autonomous Workflows with Claude Code Subagents Type  Live Duration 60 min <p>Understand what Claude Code subagents are, master the critical distinction between Skills and Subagents, and learn when to use each approach. Explore the mental model of building a specialized team of AI agents, develop a decision framework for choosing between Skills and Subagents, and identify appropriate use cases for subagent-based solutions in business contexts.</p>"},{"location":"courses/leaders/lessons/analyze-claude-code-subagent-architecture-and-use-cases/#objectives","title":"Objectives","text":"<ul> <li>Define Claude Code subagents and explain their role in autonomous workflows</li> <li>Distinguish between Claude Skills (training manuals with shared context) and Subagents (specialized employees with isolated context) across key dimensions</li> <li>Apply a decision framework to determine when to use Skills, Subagents, or both for specific workflow requirements</li> <li>Analyze the \"dream team\" mental model to understand subagent specialization and delegation patterns</li> <li>Evaluate business scenarios to identify appropriate use cases for subagent-based autonomous workflows</li> </ul>"},{"location":"courses/leaders/lessons/analyze-claude-code-subagent-architecture-and-use-cases/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/analyze-claude-code-subagent-execution-traces/","title":"Analyze Claude Code Subagent Execution Traces","text":"Course Hands-on Agentic AI for Leaders Session Session 6: Claude Code Subagents Module Build Autonomous Workflows with Claude Code Subagents Type  Live Duration 60 min <p>Master Claude Code's built-in tracing capabilities to gain visibility into subagent execution. Learn to read execution traces, understand multi-agent delegation patterns, diagnose failures, and debug common issues. Students will add tracing to their multi-agent systems and use trace data to troubleshoot and optimize subagent behavior.</p>"},{"location":"courses/leaders/lessons/analyze-claude-code-subagent-execution-traces/#objectives","title":"Objectives","text":"<ul> <li>Analyze Claude Code execution traces to understand subagent delegation patterns and tool usage</li> <li>Diagnose subagent execution failures using trace data and error logs</li> <li>Evaluate subagent performance and identify optimization opportunities through tracing</li> <li>Implement tracing best practices for debugging multi-agent subagent workflows</li> </ul>"},{"location":"courses/leaders/lessons/analyze-claude-code-subagent-execution-traces/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/analyze-claude-code-subagent-orchestration-patterns/","title":"Analyze Claude Code Subagent Orchestration Patterns","text":"Course Hands-on Agentic AI for Leaders Session Session 6: Claude Code Subagents Module Build Autonomous Workflows with Claude Code Subagents Type  Live Duration 60 min <p>Master subagent execution from single-agent workflows to complex multi-agent orchestration. Learn three activation methods (explicit invocation, automatic delegation, chaining), understand when multiple agents outperform single-agent solutions, and apply orchestration patterns including sequential, parallel, and hybrid execution with hooks for reliable autonomous workflow behavior.</p>"},{"location":"courses/leaders/lessons/analyze-claude-code-subagent-orchestration-patterns/#objectives","title":"Objectives","text":"<ul> <li>Execute Claude Code subagents using three activation methods (explicit invocation, automatic delegation, chaining) to accomplish single-task workflows</li> <li>Evaluate when to use multiple specialized agents versus a single agent based on workflow complexity and context isolation needs</li> <li>Design a multi-agent workflow using sequential, parallel, or hybrid orchestration patterns for a complex business use case</li> <li>Implement hooks (guardrails, logging, human-in-the-loop) to ensure reliable multi-agent system behavior</li> </ul>"},{"location":"courses/leaders/lessons/analyze-claude-code-subagent-orchestration-patterns/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/analyze-the-anatomy-of-an-agent-skill/","title":"Analyze the Anatomy of an Agent Skill","text":"Course Hands-on Agentic AI for Leaders Session Session 3: Agent Skills Module Build Agent Skills Type  Self-Paced Duration 20 min <p>Dissect what Skills are\u2014reusable instruction sets that teach Claude how to execute your workflows consistently. Analyze their anatomy: metadata, instructions, and resources. Then distinguish when to use Skills versus Prompts, Projects, MCP, or Agents.</p>"},{"location":"courses/leaders/lessons/analyze-the-anatomy-of-an-agent-skill/#objectives","title":"Objectives","text":"<ul> <li>Analyze the anatomy of an Agent Skill including metadata, instructions, and resource structure</li> <li>Distinguish Skills from Prompts, Projects, MCP, and Subagents to select the right building block</li> <li>Identify when to use each agentic building block based on the workflow requirements</li> </ul>"},{"location":"courses/leaders/lessons/analyze-the-anatomy-of-an-agent-skill/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/analyze-the-anatomy-of-an-ai-agent/","title":"Analyze the Anatomy of an AI Agent","text":"Course Hands-on Agentic AI for Leaders Session Session 5: Autonomous Agents &amp; ChatGPT Agent Module Analyze and Design Agent Architectures Type  Live Duration 10 min"},{"location":"courses/leaders/lessons/analyze-the-anatomy-of-an-ai-agent/#objectives","title":"Objectives","text":"<ul> <li>Distinguish between agents and workflows by comparing their autonomy levels, decision-making capabilities, and appropriate use cases on the agentic systems spectrum</li> <li>Identify the core components of an agent (LLM brain, tools, memory, instructions, knowledge) and explain how these components work together regardless of platform</li> <li>Evaluate business scenarios to determine when autonomous agents are appropriate versus structured workflows, based on task predictability, complexity, and need for dynamic planning</li> <li>Select optimal use cases for agentic implementation by matching task characteristics (open-ended problems, multi-step complexity, tool requirements) to agent capabilities</li> </ul>"},{"location":"courses/leaders/lessons/analyze-the-anatomy-of-an-ai-agent/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-a-collaborative-ai-workflow/","title":"Build a Collaborative AI Workflow","text":"Course Hands-on Agentic AI for Leaders Session Session 4: Prompt Workflows Module Design Prompt Workflows Type  Live Duration 60 min <p>Design and build a workflow where you partner with AI to deliver outcomes that require human judgment. You'll identify where to place review checkpoints, structure handoffs between AI drafts and human refinement, and create feedback loops that leverage both AI capability and your expertise.</p>"},{"location":"courses/leaders/lessons/build-a-collaborative-ai-workflow/#objectives","title":"Objectives","text":"<ul> <li>Build a collaborative workflow with defined checkpoints where human judgment guides AI execution</li> <li>Design handoff points that structure the flow between AI-generated drafts and human review/refinement</li> <li>Implement feedback loops that incorporate your input to improve AI outputs iteratively</li> <li>Document the workflow with clear decision criteria for when to accept, refine, or redirect AI outputs</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-a-deterministic-automated-workflow/","title":"Build a Deterministic Automated Workflow","text":"Course Hands-on Agentic AI for Leaders Session Session 4: Prompt Workflows Module Design Prompt Workflows Type  Live Duration 60 min <p>Design and build a workflow that runs independently once triggered\u2014producing consistent, repeatable results without human intervention. You'll sequence steps, define inputs and outputs between each stage, handle edge cases, and save your workflow to your prompt library for reuse.</p>"},{"location":"courses/leaders/lessons/build-a-deterministic-automated-workflow/#objectives","title":"Objectives","text":"<ul> <li>Build a multi-step deterministic workflow using prompt chaining that produces consistent outputs from the same inputs</li> <li>Sequence workflow steps with clear input/output definitions between each stage</li> <li>Implement error handling and edge case logic to ensure reliable execution</li> <li>Document the workflow SOP and save it to your registry</li> </ul>"},{"location":"courses/leaders/lessons/build-a-deterministic-automated-workflow/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-agent-workflows-visually-with-openai-agentkit/","title":"Build Agent Workflows Visually with OpenAI AgentKit","text":"Course Hands-on Agentic AI for Leaders Session Session 8: OpenAI + Google Agents Module Build Autonomous Workflows with OpenAI Agents Type  Live Duration 60 min"},{"location":"courses/leaders/lessons/build-agent-workflows-visually-with-openai-agentkit/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-autonomous-agents-with-chatgpt-agent-mode/","title":"Build Autonomous Agents with ChatGPT Agent Mode","text":"Course Hands-on Agentic AI for Leaders Session Session 5: Autonomous Agents &amp; ChatGPT Agent Module Build Autonomous Workflows with ChatGPT Type  Live Duration 30 min"},{"location":"courses/leaders/lessons/build-autonomous-agents-with-chatgpt-agent-mode/#objectives","title":"Objectives","text":"<ul> <li>Configure a ChatGPT agent by defining a clear goal, selecting appropriate tools, and providing necessary context to create an autonomous agent that executes multi-step tasks independently</li> <li>Formulate effective agent goals that are specific enough to guide execution while allowing the agent flexibility to plan and adapt its approach dynamically</li> <li>Observe and analyze agent execution by examining the agent's reasoning process, tool selection, and decision-making patterns to understand how it autonomously achieves the goal</li> <li>Troubleshoot agent behavior by identifying common failure modes (over-planning, tool misuse, scope creep) and refining the goal and context to improve reliability and performance</li> </ul>"},{"location":"courses/leaders/lessons/build-autonomous-agents-with-chatgpt-agent-mode/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-autonomous-agents-with-google-gemini-enterprise/","title":"Build Autonomous Agents with Google Gemini Enterprise","text":"Course Hands-on Agentic AI for Leaders Session Session 8: OpenAI + Google Agents Module Build Autonomous Workflows with Google Gemini Type  Self-Paced"},{"location":"courses/leaders/lessons/build-autonomous-agents-with-google-gemini-enterprise/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-autonomous-agents-with-google-workspace-flows/","title":"Build Autonomous Agents with Google Workspace Flows","text":"Course Hands-on Agentic AI for Leaders Session Session 8: OpenAI + Google Agents Module Build Autonomous Workflows with Google Gemini Type  Live Duration 20 min"},{"location":"courses/leaders/lessons/build-autonomous-agents-with-google-workspace-flows/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-autonomous-agents-with-m365-copilot-studio-2/","title":"Build Autonomous Agents with M365 Copilot Studio","text":"Course Hands-on Agentic AI for Leaders Session Session 7: M365 Copilot Agents Module Build Autonomous Workflows with M365 Copilot Agents Type  Live"},{"location":"courses/leaders/lessons/build-autonomous-agents-with-m365-copilot-studio-2/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-autonomous-agents-with-m365-copilot-studio-lite-2/","title":"Build Autonomous Agents with M365 Copilot Studio Lite","text":"Course Hands-on Agentic AI for Leaders Session Session 7: M365 Copilot Agents Module Build Autonomous Workflows with M365 Copilot Agents Type  Live"},{"location":"courses/leaders/lessons/build-autonomous-agents-with-m365-copilot-studio-lite-2/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-autonomous-agents-with-m365-copilot-studio-lite/","title":"Build Autonomous Agents with M365 Copilot Studio Lite","text":"Course Hands-on Agentic AI for Leaders Session Session 6: Claude Code Subagents Module Build Autonomous Workflows with M365 Copilot Agents Type  Live"},{"location":"courses/leaders/lessons/build-autonomous-agents-with-m365-copilot-studio-lite/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-autonomous-agents-with-m365-copilot-studio/","title":"Build Autonomous Agents with M365 Copilot Studio","text":"Course Hands-on Agentic AI for Leaders Session Session 6: Claude Code Subagents Module Build Autonomous Workflows with M365 Copilot Agents Type  Live"},{"location":"courses/leaders/lessons/build-autonomous-agents-with-m365-copilot-studio/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-browser-workflows-with-chatgpt-atlas/","title":"Build Browser Workflows with ChatGPT Atlas","text":"Course Hands-on Agentic AI for Leaders Session Session 5: Autonomous Agents &amp; ChatGPT Agent Module Build Autonomous Workflows with ChatGPT Type  Live Duration 30 min"},{"location":"courses/leaders/lessons/build-browser-workflows-with-chatgpt-atlas/#objectives","title":"Objectives","text":"<ul> <li>Configure ChatGPT Atlas for browser-based automation</li> <li>\u25e6 Complete initial Atlas setup and authentication</li> <li>\u25e6 Configure the Atlas browser extension with appropriate permissions</li> <li>\u25e6 Adjust security and privacy settings for workflow execution</li> <li>Execute autonomous browser workflows using Atlas agent mode</li> <li>\u25e6 Navigate websites using Atlas autonomous mode</li> <li>\u25e6 Delegate multi-step browser tasks to Atlas agents</li> <li>\u25e6 Monitor agent execution and intervene when necessary</li> <li>Apply Canvas browser queries to extract website information</li> <li>\u25e6 Ask contextual questions about webpage content</li> <li>\u25e6 Extract structured data from websites using Canvas queries</li> <li>\u25e6 Distinguish when to use Canvas queries vs. autonomous agent mode</li> </ul>"},{"location":"courses/leaders/lessons/build-browser-workflows-with-chatgpt-atlas/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-browser-workflows-with-google-chrome/","title":"Build Browser Workflows with Google Chrome","text":"Course Hands-on Agentic AI for Leaders Session Session 8: OpenAI + Google Agents Module Build Autonomous Workflows with Google Gemini Type  Live Duration 15 min"},{"location":"courses/leaders/lessons/build-browser-workflows-with-google-chrome/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-conversational-agent-ux-with-openai-chatkit/","title":"Build Conversational Agent UX with OpenAI ChatKit","text":"Course Hands-on Agentic AI for Leaders Session Session 8: OpenAI + Google Agents Module Build Autonomous Workflows with OpenAI Agents Type  Live Duration 30 min"},{"location":"courses/leaders/lessons/build-conversational-agent-ux-with-openai-chatkit/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-deterministic-agents-with-m365-copilot-agent-flows-2/","title":"Build Deterministic Agents with M365 Copilot Agent Flows","text":"Course Hands-on Agentic AI for Leaders Session Session 7: M365 Copilot Agents Module Build Autonomous Workflows with M365 Copilot Agents Type  Self-Paced"},{"location":"courses/leaders/lessons/build-deterministic-agents-with-m365-copilot-agent-flows-2/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-deterministic-agents-with-m365-copilot-agent-flows/","title":"Build Deterministic Agents with M365 Copilot Agent Flows","text":"Course Hands-on Agentic AI for Leaders Session Session 6: Claude Code Subagents Module Build Autonomous Workflows with M365 Copilot Agents Type  Self-Paced"},{"location":"courses/leaders/lessons/build-deterministic-agents-with-m365-copilot-agent-flows/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-multi-agent-systems-with-claude-code/","title":"Build Multi-Agent Systems with Claude Code","text":"Course Hands-on Agentic AI for Leaders Session Session 6: Claude Code Subagents Module Build Autonomous Workflows with Claude Code Subagents Type  Live Duration 60 min <p>Build complete multi-agent systems from your workflow specifications using Claude Code's AI-assisted configuration. You'll transform your Module 10 design into a working system\u2014single or multi-agent\u2014by prompting Claude Code to generate all necessary subagent configurations. Learn to review, refine, and validate auto-generated systems, ensuring proper orchestration and tool delegation. Master the AI-assisted workflow that makes complex agent systems buildable in minutes.</p>"},{"location":"courses/leaders/lessons/build-multi-agent-systems-with-claude-code/#objectives","title":"Objectives","text":"<ul> <li>Build complete agent systems by prompting Claude Code to auto-generate configurations from workflow specifications</li> <li>Evaluate generated subagent configurations against design intent to ensure proper tool assignments and orchestration patterns</li> <li>Refine multi-agent systems by adjusting delegation logic, tool restrictions, and coordination patterns based on testing results</li> <li>Apply judgment to decide system architecture (single vs. multi-agent) and when to use AI-assisted generation versus manual configuration</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-reusable-agent-skills-with-claude/","title":"Build Reusable Agent Skills with Claude","text":"Course Hands-on Agentic AI for Leaders Session Session 3: Agent Skills Module Build Agent Skills Type  Live Duration 60 min <p>Transform your workflow knowledge into a production-ready Agent Skill from scratch. You'll structure your skill with proper metadata and instructions, test it in a live conversation, save it to your repository with version control, and export it to your local machine\u2014making it available across Claude.ai, Claude Code, and Cowork.</p>"},{"location":"courses/leaders/lessons/build-reusable-agent-skills-with-claude/#objectives","title":"Objectives","text":"<ul> <li>Build a production-ready Agent Skill that packages your expertise into reusable instructions for Claude</li> <li>Structure your skill with proper metadata, instructions, and supporting resources</li> <li>Save skills to your repository for version control and register them in your AI Assets database</li> <li>Export skills to your local machine for use across Claude platforms (Code, Cowork)</li> </ul>"},{"location":"courses/leaders/lessons/build-reusable-agent-skills-with-claude/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-your-ai-operations-registry/","title":"Build Your AI Operations Registry","text":"Course Hands-on Agentic AI for Leaders Session Session 2: Workflow Deconstruction Module Deconstruct &amp; Register Your Workflows Type  Live Duration 30 min <p>Implement your operational control center for managing AI workflows and assets. Students replicate the Notion registry template, configure tracking fields, and document their first complete workflow including SOP and building blocks. Claude users integrate Skills with Notion MCP to enable bidirectional collaboration for reading and writing workflow data throughout the course.</p>"},{"location":"courses/leaders/lessons/build-your-ai-operations-registry/#objectives","title":"Objectives","text":"<ul> <li>Implement your AI Operations Registry by replicating the Notion database template and configuring workflow tracking fields</li> <li>Integrate Claude Skills with your registry via Notion MCP to enable collaborative workflow management and building block documentation</li> <li>Document one end-to-end workflow in your registry including SOP and associated AI assets</li> </ul>"},{"location":"courses/leaders/lessons/build-your-ai-operations-registry/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-your-claude-project-with-memory-and-knowledge-base/","title":"Build Your Claude Project with Memory and Knowledge Base","text":"Course Hands-on Agentic AI for Leaders Session Session 2: Workflow Deconstruction Module Deconstruct &amp; Register Your Workflows Type  Live Duration 90 min <p>Build a dedicated Claude Project that maintains conversation memory and serves as a centralized knowledge repository. You'll configure project-level custom instructions, enable persistent memory that evolves with each interaction, and populate the knowledge base with reference files that Claude can access automatically\u2014eliminating repetitive file uploads and creating a workspace that gets smarter over time.</p>"},{"location":"courses/leaders/lessons/build-your-claude-project-with-memory-and-knowledge-base/#objectives","title":"Objectives","text":"<ul> <li>Build a Claude Project with custom instructions, persistent memory enabled, and project-specific settings configured for course workflows</li> <li>Populate the project knowledge base with essential reference files (workflows, documentation, templates) that Claude can access automatically across all conversations</li> <li>Test persistent context by verifying that Claude retains project-specific information across multiple sessions and references knowledge base files without re-uploading</li> <li>Apply project-based workflows by conducting a complete task entirely within the project to validate memory retention and knowledge base accessibility</li> </ul>"},{"location":"courses/leaders/lessons/build-your-claude-project-with-memory-and-knowledge-base/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/build-your-first-claude-code-subagent/","title":"Build Your First Claude Code Subagent","text":"Course Hands-on Agentic AI for Leaders Session Session 6: Claude Code Subagents Module Build Autonomous Workflows with Claude Code Subagents Type  Live Duration 60 min <p>Transform your agent system design into a working implementation. Configure MCP tools in Claude Code, create your subagent with appropriate tool assignments and instructions, and test it with real tasks. Learn to debug, iterate, and refine subagent behavior through hands-on practice. Students complete this lesson with a fully functional subagent ready for real-world use.</p>"},{"location":"courses/leaders/lessons/build-your-first-claude-code-subagent/#objectives","title":"Objectives","text":"<ul> <li>Configure MCP tools in Claude Code to prepare tool access for subagent implementation</li> <li>Create a subagent by translating design specifications into Claude Code configuration (description, tools, model, system prompt)</li> <li>Evaluate subagent performance by testing with real tasks and observing delegation behavior</li> <li>Refine subagent configuration based on testing results to improve reliability and output quality</li> </ul>"},{"location":"courses/leaders/lessons/build-your-first-claude-code-subagent/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/configure-ai-memory-systems-2/","title":"Configure AI Memory Systems","text":"Course Hands-on Agentic AI for Leaders Session Session : Builder Stack Setup Module Configure Your AI Builder Stack Type  Live Duration 20 min <p>Activate AI memory systems that automatically retain your professional context across conversations. You'll enable persistent memory, populate your tools with key facts about your role and work, establish memory hygiene practices for reviewing and editing stored information, and set privacy boundaries. Your AI assistants will remember your context automatically\u2014no more re-explaining who you are or what you're working on every conversation.</p>"},{"location":"courses/leaders/lessons/configure-ai-memory-systems-2/#objectives","title":"Objectives","text":"<ul> <li>Configure active memory systems on your AI platforms that retain key professional context across conversations without repeated explanations</li> <li>Implement memory settings across platforms by enabling persistent context between sessions</li> <li>Populate your AI memory with 2-3 critical professional facts about your role, work context, and communication preferences</li> <li>Apply memory hygiene practices by reviewing stored information and protecting sensitive data from AI memory</li> </ul>"},{"location":"courses/leaders/lessons/configure-ai-memory-systems-2/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/configure-ai-memory-systems/","title":"Configure AI Memory Systems","text":"Course Hands-on Agentic AI for Leaders Session Session : Builder Stack Setup Module Builder Stack Setup Type  Live Duration 20 min <p>Activate AI memory systems that automatically retain your professional context across conversations. You'll enable persistent memory, populate your tools with key facts about your role and work, establish memory hygiene practices for reviewing and editing stored information, and set privacy boundaries. Your AI assistants will remember your context automatically\u2014no more re-explaining who you are or what you're working on every conversation.</p>"},{"location":"courses/leaders/lessons/configure-ai-memory-systems/#objectives","title":"Objectives","text":"<ul> <li>Configure active memory systems on your AI platforms that retain key professional context across conversations without repeated explanations</li> <li>Implement memory settings across platforms by enabling persistent context between sessions</li> <li>Populate your AI memory with 2-3 critical professional facts about your role, work context, and communication preferences</li> <li>Apply memory hygiene practices by reviewing stored information and protecting sensitive data from AI memory</li> </ul>"},{"location":"courses/leaders/lessons/configure-ai-memory-systems/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/configure-ai-powered-code-editor/","title":"Configure AI-Powered Code Editor","text":"Course Hands-on Agentic AI for Leaders Session Session : Builder Stack Setup Module Configure Your AI Builder Stack Type  Live <p>Transform your development workflow with an AI-powered code editor (Cursor or VS Code). Configure AI model integration (Claude, ChatGPT, Gemini, or other CLI models) that lets you generate code through natural language, get instant explanations for complex logic, and refactor with AI assistance. This workspace becomes essential infrastructure for building Skills, workflows, and Agents\u2014enabling builders without deep coding backgrounds to create production-quality AI systems.</p>"},{"location":"courses/leaders/lessons/configure-ai-powered-code-editor/#objectives","title":"Objectives","text":"<ul> <li>Configure an AI-powered code editor (Cursor or VS Code) as your workspace for AI building block development</li> <li>Install and authenticate at least one AI model integration (Claude Code, ChatGPT Codex, Gemini CLI, or similar)</li> <li>Create and preview a Markdown file to verify your editor is properly configured</li> </ul>"},{"location":"courses/leaders/lessons/configure-ai-powered-code-editor/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/configure-claude-personalization-and-memory-settings/","title":"Configure Claude Personalization and Memory Settings","text":"Course Hands-on Agentic AI for Leaders Session Session : Builder Stack Setup Module Configure Your AI Builder Stack Type <p>Configure your Claude environment for maximum productivity throughout the course. You'll customize communication preferences, writing style, and feature settings, then activate Claude's memory system to maintain context across conversations. Proper configuration ensures Claude adapts to your workflow, remembers your preferences, and delivers responses aligned with your goals and communication style.</p>"},{"location":"courses/leaders/lessons/configure-claude-personalization-and-memory-settings/#objectives","title":"Objectives","text":"<ul> <li>Configure Claude's personalization settings including communication style, tone preferences, response formatting, and feature toggles to match your workflow requirements</li> <li>Activate Claude's memory system and verify it's capturing conversation context, project details, and preferences across sessions</li> <li>Test personalized responses by comparing Claude's output before and after configuration to validate that settings are working as intended</li> </ul>"},{"location":"courses/leaders/lessons/configure-claude-personalization-and-memory-settings/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/configure-mcp-server-connections-and-desktop-integrations/","title":"Configure MCP Server Connections and Desktop Integrations","text":"Course Hands-on Agentic AI for Leaders Session Session 2: Workflow Deconstruction Module Deconstruct &amp; Register Your Workflows Type  Live Duration 90 min <p>Extend Claude's capabilities by configuring connections to external systems through MCP (Model Context Protocol). You'll connect Claude to remote MCP servers for services like Slack, GitHub, and Google Drive, then configure desktop connectors to access local applications and your filesystem. These integrations enable Claude to read data, trigger actions, and automate workflows across your entire tech stack.</p>"},{"location":"courses/leaders/lessons/configure-mcp-server-connections-and-desktop-integrations/#objectives","title":"Objectives","text":"<ul> <li>Configure MCP server connections to at least two remote services (e.g., Slack, GitHub, Google Drive, Notion) with proper authentication and permissions</li> <li>Implement desktop connectors to access local filesystem, applications, or services running on your machine</li> <li>Test integration functionality by executing Claude commands that read data from connected systems and trigger actions across multiple services</li> <li>Troubleshoot connection issues using MCP diagnostics to verify successful authentication, resolve permission errors, and validate data access</li> </ul>"},{"location":"courses/leaders/lessons/configure-mcp-server-connections-and-desktop-integrations/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/configure-voice-to-text-for-ai-collaboration/","title":"Configure Voice-to-Text for AI Collaboration","text":"Course Hands-on Agentic AI for Leaders Session Session : Builder Stack Setup Module Builder Stack Setup Type  Self-Paced Duration 5 min"},{"location":"courses/leaders/lessons/configure-voice-to-text-for-ai-collaboration/#objectives","title":"Objectives","text":"<ul> <li>Configure voice-to-text capabilities to enable hands-free AI collaboration across your productivity stack</li> <li>Set up voice input methods using keyboard shortcuts (Caps Lock, fn button) to dictate prompts at 150+ words per minute vs. 40-60 wpm typing</li> <li>Apply multimodal prompting by combining voice instructions with screenshot capabilities for richer AI context</li> </ul>"},{"location":"courses/leaders/lessons/configure-voice-to-text-for-ai-collaboration/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/configure-your-ai-code-editor/","title":"Configure Your AI Code Editor","text":"Course Hands-on Agentic AI for Leaders Session Session : Builder Stack Setup Module Builder Stack Setup Type  Live Duration 25 min"},{"location":"courses/leaders/lessons/configure-your-ai-code-editor/#objectives","title":"Objectives","text":"<ul> <li>Install and configure an AI-powered code editor (Cursor or VS Code) as your workspace for AI asset development</li> <li>Connect at least one AI model (Claude, OpenAI, or Gemini) to your editor for AI-assisted work</li> <li>Create and preview a Markdown file to verify your editor is properly configured</li> </ul>"},{"location":"courses/leaders/lessons/configure-your-ai-code-editor/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/configure-your-ai-personalization-settings-2/","title":"Configure Your AI Personalization Settings","text":"Course Hands-on Agentic AI for Leaders Session Session : Builder Stack Setup Module Configure Your AI Builder Stack Type  Live Duration 15 min <p>Configure your AI platforms to match your professional standards and communication style. You'll set up user preferences, define output formats, configure security settings including privacy controls and MFA, and establish baseline behaviors. By the end of this lesson, your AI tools will consistently deliver responses aligned with your professional requirements\u2014without needing to specify preferences in every conversation.</p>"},{"location":"courses/leaders/lessons/configure-your-ai-personalization-settings-2/#objectives","title":"Objectives","text":"<ul> <li>Configure personalized work profiles on your AI tools using custom instructions that reflect your role, work context, and response preferences</li> <li>Implement privacy and security protections across all platforms by disabling model training data sharing and enabling multi-factor authentication</li> <li>Apply personalization strategically across platforms based on each platform's available features (custom instructions, user preferences, style settings, output formats)</li> </ul>"},{"location":"courses/leaders/lessons/configure-your-ai-personalization-settings-2/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/configure-your-ai-personalization-settings/","title":"Configure Your AI Personalization Settings","text":"Course Hands-on Agentic AI for Leaders Session Session : Builder Stack Setup Module Builder Stack Setup Type  Live Duration 15 min <p>Configure your AI platforms to match your professional standards and communication style. You'll set up user preferences, define output formats, configure security settings including privacy controls and MFA, and establish baseline behaviors. By the end of this lesson, your AI tools will consistently deliver responses aligned with your professional requirements\u2014without needing to specify preferences in every conversation.</p>"},{"location":"courses/leaders/lessons/configure-your-ai-personalization-settings/#objectives","title":"Objectives","text":"<ul> <li>Configure personalized work profiles on your AI tools using custom instructions that reflect your role, work context, and response preferences</li> <li>Implement privacy and security protections across all platforms by disabling model training data sharing and enabling multi-factor authentication</li> <li>Apply personalization strategically across platforms based on each platform's available features (custom instructions, user preferences, style settings, output formats)</li> </ul>"},{"location":"courses/leaders/lessons/configure-your-ai-personalization-settings/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/connect-ai-to-your-business-apps-via-mcp/","title":"Connect AI to Your Business Apps via MCP","text":"Course Hands-on Agentic AI for Leaders Session Session 3: Agent Skills Module Build Agent Skills Type  Live Duration 10 min"},{"location":"courses/leaders/lessons/connect-ai-to-your-business-apps-via-mcp/#objectives","title":"Objectives","text":"<ul> <li>Configure MCP connections to connect your AI assistant to external tools and data sources with proper authentication and permissions</li> <li>Set up working connectors for business applications (Gmail, Drive, Notion, Slack, HubSpot) relevant to your workflow</li> <li>Test each configured connector by executing prompts that successfully call external tools and retrieve data</li> <li>Distinguish between remote MCP servers (cloud-based) and local desktop extensions to select the right architecture for different use cases</li> </ul>"},{"location":"courses/leaders/lessons/connect-ai-to-your-business-apps-via-mcp/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/course-takeways-and-your-next-steps/","title":"Course Takeways and Your Next Steps","text":"Course Hands-on Agentic AI for Leaders Session Session 9: Operationalization, Demos &amp; Insights Module Demo Workflows and Share Transformational Insights Type  Live Duration 20 min <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/course-wrap-up-next-steps/","title":"Course wrap-up / Next steps","text":"Course Hands-on Agentic AI for Leaders Session Session 9: Operationalization, Demos &amp; Insights Module Ship Production-Ready AI Workflows Type  Live Duration 20 min <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/deconstruct-your-work-and-identify-ai-building-blocks/","title":"Deconstruct Your Work and Identify AI Building Blocks","text":"Course Hands-on Agentic AI for Leaders Session Session 2: Workflow Deconstruction Module Deconstruct &amp; Register Your Workflows Type  Live Duration 60 min <p>Turn implicit workflows into systematic AI operations. You'll deconstruct two real-world workflows\u2014one Collaborative AI, one Deterministic Automation\u2014using the 4-question framework to identify discrete steps, decision points, data flows, and context requirements. Then apply the meta-prompting technique to your own workflows, letting AI generate complete workflow specifications with building blocks mapped, ready for execution and version control.</p>"},{"location":"courses/leaders/lessons/deconstruct-your-work-and-identify-ai-building-blocks/#objectives","title":"Objectives","text":"<ul> <li>Apply the deconstruction framework to break down a named workflow into detailed steps that reveal the process structure and implementation requirements</li> <li>Map AI building blocks (Prompt, Context, Skill, Agent, MCP, Project) to each workflow step, identifying which building blocks are needed to operationalize each step</li> <li>Generate three production-ready deliverables using the meta-prompt: workflow analysis document, executable baseline prompt, and skill build recommendations that provide the necessary detail to build the AI-powered workflow</li> </ul>"},{"location":"courses/leaders/lessons/deconstruct-your-work-and-identify-ai-building-blocks/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/design-autonomous-workflows-with-agents/","title":"Design Autonomous Workflows with Agents","text":"Course Hands-on Agentic AI for Leaders Session Session 5: Autonomous Agents &amp; ChatGPT Agent Module Analyze and Design Agent Architectures Type  Live Duration 50 min"},{"location":"courses/leaders/lessons/design-autonomous-workflows-with-agents/#objectives","title":"Objectives","text":"<ul> <li>Apply a systematic design process for agent systems by defining clear goals, processes, agent roles, instructions, and required tools</li> <li>Generate clear, unambiguous instructions for LLM agents using meta-prompting techniques and reasoning models to ensure reliable execution</li> <li>Design single-agent systems by specifying agent roles, responsibilities, and tool requirements for focused automation tasks</li> <li>Architect multi-agent systems by identifying and naming specialized agent roles that work together to accomplish complex goals</li> <li>Distinguish between single-agent and multi-agent approaches based on task complexity and the need for specialized expertise across different workflow components</li> </ul>"},{"location":"courses/leaders/lessons/design-autonomous-workflows-with-agents/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/distinguish-workflow-execution-patterns/","title":"Distinguish Workflow Execution Patterns","text":"Course Hands-on Agentic AI for Leaders Session Session 4: Prompt Workflows Module Design Prompt Workflows Type  Live Duration 45 min <p>Master the mental models that determine which AI workflow pattern fits your use case. You'll learn the seven patterns across the autonomy spectrum\u2014from deterministic prompt chains to fully autonomous agents\u2014and use the Pattern Selection Framework to match workflow characteristics to the right architecture before you build.</p>"},{"location":"courses/leaders/lessons/distinguish-workflow-execution-patterns/#objectives","title":"Objectives","text":"<ul> <li>Distinguish between seven workflow architecture patterns and five agent capability patterns by categorizing them as execution structure vs. behavioral capabilities</li> <li>Analyze workflow characteristics (predictability, complexity, step count) to select appropriate patterns using the Pattern Selection Framework.</li> </ul>"},{"location":"courses/leaders/lessons/distinguish-workflow-execution-patterns/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/evaluate-agentic-systems/","title":"Evaluate Agentic Systems","text":"Course Hands-on Agentic AI for Leaders Session Session 9: Operationalization, Demos &amp; Insights Module Ship Production-Ready AI Workflows Type  Live Duration 15 min"},{"location":"courses/leaders/lessons/evaluate-agentic-systems/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/identify-and-name-workflow-candidates/","title":"Identify and Name Workflow Candidates","text":"Course Hands-on Agentic AI for Leaders Session Session 1: Agentic AI Foundations &amp; Workflow Identification Module Assess Agentic Fundamentals and Workflow Opportunities Type  Live Duration 60 min <p>Examine concrete examples of deterministic automated, collaborative AI, and autonomous agent workflows. Then use a structured meta-prompt to discover AI workflow opportunities in your daily work and categorize each candidate by workflow type.</p>"},{"location":"courses/leaders/lessons/identify-and-name-workflow-candidates/#objectives","title":"Objectives","text":"<ul> <li>Distinguish deterministic automated workflows (rule-based, zero human input) from collaborative AI workflows (human-AI partnership) and autonomous agent workflows (goal-driven, adaptive) by analyzing concrete examples</li> <li>Apply a structured meta-prompt to systematically identify AI workflow opportunities across your daily work including high-frequency tasks, judgment-heavy processes, and repetitive operations</li> <li>Create clear, outcome-focused names (2-4 words) for identified workflow candidates using consistent noun phrase patterns that communicate purpose without requiring context</li> </ul>"},{"location":"courses/leaders/lessons/identify-and-name-workflow-candidates/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/implement-scheduled-execution-for-claude-code-subagents/","title":"Implement Scheduled Execution for Claude Code Subagents","text":"Course Hands-on Agentic AI for Leaders Session Session 6: Claude Code Subagents Module Build Autonomous Workflows with Claude Code Subagents Type  Live Duration 60 min <p>Learn to automate Claude Code subagent execution using native operating system schedulers. Configure Windows Task Scheduler and macOS cron jobs to run subagents on recurring schedules, implement error handling and notifications, and understand when scheduled execution is appropriate versus on-demand triggers. Students will schedule one of their existing Claude Code subagents to run automatically.</p>"},{"location":"courses/leaders/lessons/implement-scheduled-execution-for-claude-code-subagents/#objectives","title":"Objectives","text":"<ul> <li>Configure OS-level scheduling (Windows Task Scheduler or macOS cron) to execute Claude Code subagents automatically</li> <li>Implement error handling and notification mechanisms for scheduled subagent runs</li> <li>Evaluate which workflows benefit from scheduled execution versus on-demand triggers</li> <li>Test and verify scheduled subagent execution with proper logging and output capture</li> </ul>"},{"location":"courses/leaders/lessons/implement-scheduled-execution-for-claude-code-subagents/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/implement-version-control-for-your-ai-building-blocks/","title":"Implement Version Control for Your AI Building Blocks","text":"Course Hands-on Agentic AI for Leaders Session Session : Builder Stack Setup Module Configure Your AI Builder Stack Type  Live <p>Implement GitHub version control as your safety net for AI building block development. Create a repository to store Skills, Prompts, Agent configurations, and workflows with full change history. Master the create-commit-push workflow that professional developers use to track iterations, experiment without risk, collaborate across teams, and recover from mistakes\u2014critical infrastructure for building production AI systems.</p>"},{"location":"courses/leaders/lessons/implement-version-control-for-your-ai-building-blocks/#objectives","title":"Objectives","text":"<ul> <li>Create a GitHub repository to store and version your AI building blocks (Skills, Prompts, Agents, configurations)</li> <li>Execute the create \u2192 commit \u2192 push workflow to save a building block to your repository</li> <li>Verify your repository syncs between local and cloud to protect your work</li> </ul>"},{"location":"courses/leaders/lessons/implement-version-control-for-your-ai-building-blocks/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/implement-voice-to-text-for-hands-free-ai-collaboration/","title":"Implement Voice-to-Text for Hands-Free AI Collaboration","text":"Course Hands-on Agentic AI for Leaders Session Session : Builder Stack Setup Module Configure Your AI Builder Stack Type  Live <p>Install and configure a voice-to-text application (Wispr Flow recommended) to enable hands-free interaction with AI tools and code editors throughout the course. You'll practice voice dictation, learn best practices for speaking with AI, and set up your environment for maximum productivity. Voice-first collaboration dramatically accelerates your workflow\u2014especially for complex prompts and multi-step instructions.</p>"},{"location":"courses/leaders/lessons/implement-voice-to-text-for-hands-free-ai-collaboration/#objectives","title":"Objectives","text":"<ul> <li>Install and configure a voice-to-text application (Wispr Flow or alternative) with proper permissions and settings for AI platform integration</li> <li>Practice voice dictation techniques including formatting commands, punctuation control, and natural speech patterns to achieve 90%+ accuracy</li> <li>Demonstrate hands-free AI collaboration by completing a workflow entirely through voice\u2014from initial prompt to refinement to final output</li> <li>Apply voice-first best practices for complex multi-step instructions, ensuring clarity and reducing the need for manual typing throughout the course</li> </ul>"},{"location":"courses/leaders/lessons/implement-voice-to-text-for-hands-free-ai-collaboration/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/monitor-and-manage-agentic-systems/","title":"Monitor and Manage Agentic Systems","text":"Course Hands-on Agentic AI for Leaders Session Session 9: Operationalization, Demos &amp; Insights Module Ship Production-Ready AI Workflows Type  Self-Paced <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/schedule-and-automate-ai-workflow-execution/","title":"Schedule and Automate AI Workflow Execution","text":"Course Hands-on Agentic AI for Leaders Session Session 9: Operationalization, Demos &amp; Insights Module Ship Production-Ready AI Workflows Type  Live Duration 20 min"},{"location":"courses/leaders/lessons/schedule-and-automate-ai-workflow-execution/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/set-up-your-ai-workflow-registry/","title":"Set Up Your AI Workflow Registry","text":"Course Hands-on Agentic AI for Leaders Session Session 2: Workflow Deconstruction Module Deconstruct &amp; Register Your Workflows Type  Live Duration 30 min"},{"location":"courses/leaders/lessons/set-up-your-ai-workflow-registry/#objectives","title":"Objectives","text":"<ul> <li>Create a systematic inventory cataloging at least 3 recurring workflows with their triggers, steps, and outcomes, and the AI assets (prompts, skills, agents, context files) linked to each workflow to visualize dependencies</li> <li>Build a relational database system in Notion with separate tables for Business Processes, Workflows, AI Assets, and Apps to serve as your living repository</li> <li>Identify at least 3 high-value recurring workflows from your actual work, documenting each with trigger conditions, step-by-step process, desired outcomes, and AI automation opportunities</li> <li>Catalog existing AI assets by type (prompts, skills, agents, context files), organize them in a structured repository, and establish relational links to the workflows that depend on them</li> </ul>"},{"location":"courses/leaders/lessons/set-up-your-ai-workflow-registry/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/ship-your-agentic-ai-repository/","title":"Ship Your Agentic AI Repository","text":"Course Hands-on Agentic AI for Leaders Session Session 9: Operationalization, Demos &amp; Insights Module Ship Production-Ready AI Workflows Type  Live Duration 20 min <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/ship-your-skills-for-reuse/","title":"Ship Your Skills for Reuse","text":"Course Hands-on Agentic AI for Leaders Session Session 3: Agent Skills Module Build Agent Skills Type  Live Duration 60 min <p>Package and ship your skills as installable resources. One command gives others access to your expertise\u2014team members, clients, or the broader AI community. Your workflow knowledge becomes reusable, distributable, scalable.</p>"},{"location":"courses/leaders/lessons/ship-your-skills-for-reuse/#objectives","title":"Objectives","text":"<ul> <li>Create a properly structured marketplace.json file with plugin metadata for at least one skill</li> <li>Publish a GitHub repository containing their skill marketplace that others can add via /plugin marketplace add</li> <li>Configure distribution settings for three deployment scenarios: private team use, organizational access, and public community sharing</li> <li>Demonstrate the complete installation workflow by having another team member successfully install their published plugin</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/understand-the-agentic-ai-landscape-and-ai-building-blocks/","title":"Understand the Agentic AI Landscape and AI Building Blocks","text":"Course Hands-on Agentic AI for Leaders Session Session 1: Agentic AI Foundations &amp; Workflow Identification Module Assess Agentic Fundamentals and Workflow Opportunities Type  Live Duration 60 min <p>Master the foundational framework for building AI systems that scale. You'll learn the autonomy spectrum\u2014distinguishing automation, workflows, and agents\u2014and the six building blocks (Prompt, Context, Project, Skill, Agent, MCP) that professional builders use. By the end, you'll identify which building blocks any workflow needs, avoiding the common mistake of reaching for fully autonomous agents when simpler approaches work better.</p>"},{"location":"courses/leaders/lessons/understand-the-agentic-ai-landscape-and-ai-building-blocks/#objectives","title":"Objectives","text":"<ul> <li>Distinguish between automation, workflows, and agents on the autonomy spectrum</li> <li>Explain why agentic approaches outperform zero-shot prompting for multi-step tasks</li> <li>Identify which building blocks (Prompt, Context, Project, Skill, Agent, MCP) apply to a workflow</li> <li>Classify example workflows on the autonomy spectrum and identify building blocks in a sample workflow</li> </ul>"},{"location":"courses/leaders/lessons/understand-the-agentic-ai-landscape-and-ai-building-blocks/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"courses/leaders/lessons/version-control-your-ai-assets/","title":"Version Control Your AI Assets","text":"Course Hands-on Agentic AI for Leaders Session Session : Builder Stack Setup Module Builder Stack Setup Type  Self-Paced Duration 10 min"},{"location":"courses/leaders/lessons/version-control-your-ai-assets/#objectives","title":"Objectives","text":"<ul> <li>Create a GitHub repository to store and version your AI prompts, skills, and reference files</li> <li>Execute the create \u2192 commit \u2192 push workflow to save an AI asset to your repository</li> <li>Verify your repository syncs between local and cloud to protect your work</li> </ul>"},{"location":"courses/leaders/lessons/version-control-your-ai-assets/#resources","title":"Resources","text":"<ul> <li> Slides</li> </ul> <p>Back to syllabus </p>"},{"location":"patterns/","title":"Patterns","text":"<p>Reusable patterns and best practices for designing and building AI-powered systems.</p>"},{"location":"patterns/#workflow-architecture-patterns","title":"Workflow Architecture Patterns","text":"<p>Seven architectural patterns for AI workflows, ranging from simple augmented LLMs to fully autonomous agents. Use these patterns to choose the right level of complexity for your workflow.</p> <p>Explore Workflow Architecture Patterns </p>"},{"location":"patterns/#categories","title":"Categories","text":""},{"location":"patterns/#prompting-patterns","title":"Prompting Patterns","text":"<p>Patterns for structuring and optimizing prompts. See the Prompt Engineering section for 14 detailed technique guides covering zero-shot, few-shot, chain-of-thought, and more.</p>"},{"location":"patterns/#agent-patterns","title":"Agent Patterns","text":"<p>Patterns for building reliable AI agents. See Agent Capability Patterns for seven patterns that make agents effective.</p>"},{"location":"patterns/#integration-patterns","title":"Integration Patterns","text":"<p>Patterns for robust API integration.</p>"},{"location":"patterns/#error-handling-patterns","title":"Error Handling Patterns","text":"<p>Patterns for graceful failure and recovery.</p>"},{"location":"patterns/#adding-a-pattern","title":"Adding a Pattern","text":"<p>Patterns use the topic template. Focus on:</p> <ol> <li>Problem - When to use this pattern</li> <li>Solution - The pattern structure</li> <li>Example - Working implementation</li> <li>Variations - Common adaptations</li> </ol> <p>See CONTRIBUTING.md for guidelines.</p>"},{"location":"patterns/workflow-architecture/","title":"Workflow Architecture Patterns","text":"<p>Every AI workflow falls somewhere on an autonomy spectrum. These seven patterns \u2014 drawn from Anthropic's research \u2014 provide a common vocabulary for describing how AI systems are structured, from simple tool-augmented models to fully autonomous agents.</p> <p>The right pattern depends on what your workflow actually needs, not on how sophisticated you want it to be. Start simple, upgrade when you hit limits.</p>"},{"location":"patterns/workflow-architecture/#the-autonomy-spectrum","title":"The Autonomy Spectrum","text":"<p>The patterns are organized into three tiers of increasing autonomy:</p>"},{"location":"patterns/workflow-architecture/#foundation","title":"Foundation","text":"Pattern Description Augmented LLM An LLM enhanced with retrieval, tools, and memory \u2014 the building block for all other patterns"},{"location":"patterns/workflow-architecture/#structured-workflows","title":"Structured Workflows","text":"Pattern Description Prompt Chaining Break a task into sequential steps, with validation gates between each step Routing Classify input and direct it to a specialized follow-up process Parallelization Run subtasks simultaneously and aggregate the results Orchestrator-Workers A central orchestrator dynamically breaks down tasks and delegates to specialized workers Evaluator-Optimizer Generate output, evaluate it against criteria, and refine iteratively until it meets quality standards"},{"location":"patterns/workflow-architecture/#autonomous","title":"Autonomous","text":"Pattern Description Autonomous Agents An LLM with tools, memory, and planning that independently executes multi-step tasks through a think-act-observe loop"},{"location":"patterns/workflow-architecture/#pattern-selection-framework","title":"Pattern Selection Framework","text":"<p>Use these three questions to identify which pattern your workflow needs:</p> <p>1. Is the task predictable or open-ended?</p> <ul> <li>Predictable (you can define the steps in advance) \u2192 Use a structured workflow pattern</li> <li>Open-ended (steps depend on what the AI discovers) \u2192 Consider an autonomous agent</li> </ul> <p>2. How many steps are involved?</p> <ul> <li>Single step \u2192 Augmented LLM</li> <li>Sequential steps \u2192 Prompt Chaining</li> <li>Branching paths \u2192 Routing</li> <li>Independent parallel steps \u2192 Parallelization</li> <li>Dynamic subtasks \u2192 Orchestrator-Workers</li> </ul> <p>3. Does the output need iterative refinement?</p> <ul> <li>Yes, with clear quality criteria \u2192 Evaluator-Optimizer</li> <li>Yes, with open-ended exploration \u2192 Autonomous Agent</li> </ul>"},{"location":"patterns/workflow-architecture/#decision-flow","title":"Decision Flow","text":"<pre><code>Start here: Can you define all the steps in advance?\n\u2502\n\u251c\u2500\u2500 YES \u2192 How many steps?\n\u2502   \u251c\u2500\u2500 One step \u2192 Augmented LLM\n\u2502   \u251c\u2500\u2500 Sequential steps with validation \u2192 Prompt Chaining\n\u2502   \u251c\u2500\u2500 Input determines the path \u2192 Routing\n\u2502   \u251c\u2500\u2500 Independent steps that can run simultaneously \u2192 Parallelization\n\u2502   \u2514\u2500\u2500 Steps need dynamic decomposition \u2192 Orchestrator-Workers\n\u2502\n\u251c\u2500\u2500 PARTIALLY \u2192 Does output need iterative refinement?\n\u2502   \u2514\u2500\u2500 YES \u2192 Evaluator-Optimizer\n\u2502\n\u2514\u2500\u2500 NO \u2192 Steps are unknown until runtime\n    \u2514\u2500\u2500 Autonomous Agent\n</code></pre> <p>Start simple, upgrade when needed</p> <p>Most workflows start as a single Augmented LLM or Prompt Chain. Only add complexity when you hit a concrete limitation \u2014 not because the problem seems complex.</p>"},{"location":"patterns/workflow-architecture/#how-these-patterns-relate-to-the-framework","title":"How These Patterns Relate to the Framework","text":"<p>The Build &gt; Design phase of the Business-First AI Framework uses an Execution Pattern Spectrum (Prompt \u2192 Skill-Powered Prompt \u2192 Single Agent \u2192 Multi-Agent) to classify workflows at a higher level. These seven architecture patterns provide the detailed implementation blueprints within that spectrum:</p> Framework Execution Pattern Architecture Patterns Prompt Augmented LLM Skill-Powered Prompt Prompt Chaining, Routing Single Agent Parallelization, Orchestrator-Workers, Evaluator-Optimizer Multi-Agent Orchestrator-Workers (multi-agent), Autonomous Agents"},{"location":"patterns/workflow-architecture/#credit","title":"Credit","text":"<p>Based on Building Effective Agents by Anthropic.</p>"},{"location":"patterns/workflow-architecture/#related","title":"Related","text":"<ul> <li>Build &gt; Design Your AI Workflow \u2014 choose an execution pattern for your workflow</li> <li>Agents \u2014 concepts for building AI agents</li> <li>Agent Capability Patterns \u2014 behavioral patterns (reflection, tool use, planning, etc.)</li> <li>Patterns Overview</li> </ul>"},{"location":"patterns/workflow-architecture/augmented-llm/","title":"Augmented LLM","text":"<p>An Augmented LLM combines the reasoning and generative abilities of an LLM with external tools, data, or systems to overcome its inherent limitations. It is the foundational building block for all other workflow architecture patterns.</p> <p>Think of it as an intelligent assistant that can access databases, search the web, run calculations, or interact with APIs \u2014 providing answers that go beyond what the model knows from training alone.</p>"},{"location":"patterns/workflow-architecture/augmented-llm/#why-it-matters","title":"Why It Matters","text":"<ul> <li>Enhanced capabilities \u2014 Augmentation lets the model fetch real-time information, query databases, or use tools for accurate, up-to-date, and customized responses</li> <li>Task specialization \u2014 Augmented LLMs excel at domain-specific tasks (financial analysis, customer service, medical diagnostics) because they pull in relevant data</li> <li>Adaptability \u2014 They integrate into existing workflows and leverage specialized tools, making them flexible across business applications</li> </ul>"},{"location":"patterns/workflow-architecture/augmented-llm/#key-components","title":"Key Components","text":"Component Purpose Example LLM Core Understands input, generates responses, decides which tasks require augmentation User asks \"What were our sales figures last month?\" \u2014 the model recognizes it needs to retrieve this data External Data Source Provides relevant, up-to-date, or domain-specific information (APIs, databases, cloud storage) Sales data in a company database queried for the latest figures Tools (Plugins) Specialized tools for calculations, data processing, or third-party interactions A spreadsheet plugin calculates revenue growth from retrieved data Orchestrator Oversees the process, ensuring seamless interaction between the LLM and external components Routes the query to the database and sends results back to the LLM User Input/Output The user's request in, and the enriched response out Input: \"What were last month's sales?\" \u2192 Output: \"Sales were $500,000, a 10% increase from the previous month.\""},{"location":"patterns/workflow-architecture/augmented-llm/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Real-time information needs \u2014 generating reports from live data, stock prices, or current metrics</li> <li>Complex tasks requiring multiple tools \u2014 financial analysis that involves querying a database, running calculations, and formatting results</li> <li>Domain-specific expertise \u2014 a healthcare LLM augmented with medical databases and imaging tools</li> </ul>"},{"location":"patterns/workflow-architecture/augmented-llm/#example-customer-support-chatbot","title":"Example: Customer Support Chatbot","text":"<p>A company uses an AI-powered chatbot augmented with external systems:</p> <ol> <li>The LLM understands the customer's issue</li> <li>It queries the company's knowledge base or CRM for specific information (e.g., order status)</li> <li>If needed, it uses tools like a refund calculator to generate a solution</li> <li>The response \u2014 enriched with real-time data \u2014 is delivered to the customer</li> </ol> <p>This pattern enables accurate, context-aware responses without requiring the model to have all information in its training data.</p>"},{"location":"patterns/workflow-architecture/augmented-llm/#how-to-implement","title":"How to Implement","text":"<ol> <li>Define the goal \u2014 What task does the augmented LLM need to perform? Real-time data retrieval, calculations, or insight generation?</li> <li>Integrate external data and tools \u2014 Connect the LLM to relevant APIs, databases, or plugins. Ensure the orchestrator routes tasks properly.</li> <li>Test iteratively \u2014 Validate with different inputs to ensure seamless, accurate responses</li> </ol> <p>Based on Building Effective Agents by Anthropic.</p>"},{"location":"patterns/workflow-architecture/augmented-llm/#related","title":"Related","text":"<ul> <li>Workflow Architecture Patterns Overview</li> <li>Prompt Chaining \u2014 the next step up in complexity</li> <li>MCP (Model Context Protocol) \u2014 the connector layer for giving models access to external tools</li> <li>Build &gt; Design Your AI Workflow</li> </ul>"},{"location":"patterns/workflow-architecture/autonomous-agents/","title":"Autonomous Agents","text":"<p>An autonomous agent is an LLM equipped with tools, memory, and planning logic that can interpret a high-level goal, break it into steps, execute actions in an external environment, evaluate feedback, and iterate until it finishes or hits a stop condition.</p> <p>Unlike the other workflow patterns where steps are predefined, agents decide in real time which tools to call and how many iterations they need. This gives them flexibility for open-ended, non-deterministic tasks.</p>"},{"location":"patterns/workflow-architecture/autonomous-agents/#why-it-matters","title":"Why It Matters","text":"Benefit Impact Flexibility Handles tasks where steps can't be pre-coded \u2014 multistep research, dynamic troubleshooting Ground-truth feedback Uses real tool outputs or API responses to self-correct, reducing hallucinations Human-like autonomy Mirrors expert work patterns (plan, do, check) and scales them across domains Rapid iteration Adds, repeats, or skips steps until quality criteria or iteration/time limits are hit"},{"location":"patterns/workflow-architecture/autonomous-agents/#key-components-the-agent-loop","title":"Key Components: The Agent Loop","text":"Element Purpose Example Human Issues the initial goal or provides feedback \"Draft a competitive analysis of ACME vs. BetaCo.\" LLM Call (Brain) Parses the goal, reasons, and chooses the next action Thought: \"I should collect market-share data.\" Action Invokes one or more tools (API, code, web search) Calls a market data API for ACME and BetaCo Environment The external system the action touches Market-data service returns JSON Feedback The result sent back to the LLM for reflection Observation: \"ACME 42%, BetaCo 35%.\" Stop Task complete or iteration/time cap reached \"Report ready \u2014 exit loop.\" <p>The agent cycles through think \u2192 act \u2192 observe until the task is complete or a stop condition is met.</p>"},{"location":"patterns/workflow-architecture/autonomous-agents/#when-to-use-it","title":"When to Use It","text":"Use an Agent When... Use a Workflow When... Steps are unknown until runtime (open-ended research, debugging) Steps are fixed and predictable (ETL, translation) Tool selection depends on intermediate results A single LLM call plus retrieval suffices Human oversight is only needed at checkpoints Tight latency or cost constraints dominate"},{"location":"patterns/workflow-architecture/autonomous-agents/#example-autonomous-customer-support-agent","title":"Example: Autonomous Customer Support Agent","text":"<p>A SaaS company wants an agent that triages inquiries, pulls user data, suggests answers, and closes tickets automatically when confident:</p> Loop Phase What Happens Goal \"Resolve Tier-1 tickets under 3 min average.\" Think Parse ticket, decide next action Act CRM API \u2192 fetch account history. KB search \u2192 retrieve relevant article. Observe CRM returns premium plan; KB returns refund policy article Think Compose personalized answer; confidence 0.92 Act Send reply + mark ticket solved Stop Confidence above 0.9 OR max 5 iterations <p>Results:</p> <ul> <li>Quality \u2014 Accurate, personalized resolutions</li> <li>Efficiency \u2014 60% of Tier-1 tickets auto-closed, cutting average handle time by 65%</li> <li>Scalability \u2014 Agent retrains on new KB content nightly, staying up-to-date</li> </ul>"},{"location":"patterns/workflow-architecture/autonomous-agents/#how-to-implement","title":"How to Implement","text":"<ol> <li>Define clear success criteria \u2014 Accuracy, format, KPIs that tell the agent when it's done</li> <li>Expose the right tools \u2014 Provide tools with explicit documentation and guardrails</li> <li>Set iteration/time caps \u2014 Prevent runaway loops with maximum iteration counts or time limits</li> <li>Test in a sandbox \u2014 Measure cost vs. quality, then graduate to production</li> </ol> <p>Based on Building Effective Agents by Anthropic.</p>"},{"location":"patterns/workflow-architecture/autonomous-agents/#related","title":"Related","text":"<ul> <li>Workflow Architecture Patterns Overview</li> <li>Orchestrator-Workers \u2014 dynamic task delegation without the autonomous loop</li> <li>Evaluator-Optimizer \u2014 iterative refinement with structured feedback</li> <li>Agents \u2014 concepts for building AI agents</li> <li>Agent Capability Patterns \u2014 behavioral patterns (reflection, tool use, planning, etc.)</li> <li>Build &gt; Design Your AI Workflow</li> </ul>"},{"location":"patterns/workflow-architecture/evaluator-optimizer/","title":"Evaluator-Optimizer","text":"<p>The evaluator-optimizer pattern uses iterative refinement through two components: a generator that produces output and an evaluator that assesses it against predefined criteria. The workflow cycles between generation and evaluation until the output meets quality standards.</p> <p>This mirrors how humans refine their work \u2014 drafting, reviewing, and editing \u2014 to achieve optimal outcomes.</p>"},{"location":"patterns/workflow-architecture/evaluator-optimizer/#why-it-matters","title":"Why It Matters","text":"<ul> <li>High-quality outputs \u2014 The evaluator catches and refines suboptimal results before delivery</li> <li>Adaptable to complex tasks \u2014 Ideal for nuanced or multi-faceted outputs that benefit from incremental improvement</li> <li>Human-like iteration \u2014 Mimics the draft-review-revise cycle that produces polished work</li> <li>Dynamic feedback \u2014 The evaluator can provide domain-specific feedback or adapt criteria, making it versatile across use cases</li> </ul>"},{"location":"patterns/workflow-architecture/evaluator-optimizer/#key-components","title":"Key Components","text":"Component Purpose Example Generator (LLM Call) Produces an initial solution or response Drafts a marketing tagline for a product Evaluator (LLM Call) Reviews output against evaluation criteria and provides actionable feedback Assesses whether the tagline aligns with brand voice and audience preferences Feedback Loop Iteratively refines output until it meets criteria If the tagline misses brand guidelines, the evaluator provides specific improvement guidance Accepted Output Delivers the finalized result once criteria are satisfied A polished tagline ready for the campaign"},{"location":"patterns/workflow-architecture/evaluator-optimizer/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Nuanced tasks \u2014 When outputs require multiple layers of refinement (creative content, technical documentation)</li> <li>High-stakes outputs \u2014 When accuracy and quality are critical (legal documents, strategic reports)</li> <li>Clear evaluation criteria \u2014 When you can define measurable standards for what \"good\" looks like</li> </ul>"},{"location":"patterns/workflow-architecture/evaluator-optimizer/#example-refining-a-marketing-campaign","title":"Example: Refining a Marketing Campaign","text":"<p>A company needs compelling marketing content (taglines, ad copy, social posts) that must reflect brand tone, resonate with the audience, and meet platform guidelines:</p> <ol> <li>Generator \u2014 Produces initial drafts of taglines, ad copy, and social media posts</li> <li>Evaluator \u2014 Reviews drafts against brand tone, audience fit, and platform requirements; provides actionable feedback (\"Make the tagline more emotionally engaging for the target audience\")</li> <li>Feedback Loop \u2014 Refines outputs iteratively until all criteria are met</li> <li>Accepted Output \u2014 Polished, ready-to-use marketing content aligned with campaign goals</li> </ol> <p>Results:</p> <ul> <li>Quality \u2014 High-quality outputs aligned with brand and audience</li> <li>Efficiency \u2014 Reduces manual editing, saving time and resources</li> <li>Consistency \u2014 Uniform tone and style across campaign elements</li> </ul>"},{"location":"patterns/workflow-architecture/evaluator-optimizer/#how-to-implement","title":"How to Implement","text":"<ol> <li>Define evaluation criteria \u2014 Establish clear, measurable standards (quality, alignment, tone)</li> <li>Set up the feedback loop \u2014 Ensure seamless communication between generator and evaluator for iterative refinement</li> <li>Set iteration limits \u2014 Prevent infinite loops by capping the number of refinement cycles</li> <li>Test the workflow \u2014 Validate that evaluator feedback effectively guides the generator toward desired outcomes</li> </ol> <p>Based on Building Effective Agents by Anthropic.</p>"},{"location":"patterns/workflow-architecture/evaluator-optimizer/#related","title":"Related","text":"<ul> <li>Workflow Architecture Patterns Overview</li> <li>Prompt Chaining \u2014 sequential steps with gates (but not iterative)</li> <li>Autonomous Agents \u2014 agents with built-in evaluation through the think-act-observe loop</li> <li>Build &gt; Design Your AI Workflow</li> </ul>"},{"location":"patterns/workflow-architecture/orchestrator-workers/","title":"Orchestrator-Workers","text":"<p>The orchestrator-workers pattern handles complex tasks where subtasks can't be defined in advance. A central orchestrator dynamically breaks down a task, delegates subtasks to specialized workers, and synthesizes their outputs into a final result.</p> <p>This pattern differs from parallelization because it emphasizes flexibility and adaptability \u2014 the orchestrator determines what needs to be done at runtime rather than following a predefined plan.</p>"},{"location":"patterns/workflow-architecture/orchestrator-workers/#why-it-matters","title":"Why It Matters","text":"<ul> <li>Flexibility for unknowns \u2014 Adapts dynamically to varying task requirements, ideal for unstructured or evolving problems</li> <li>Specialization \u2014 The orchestrator ensures each subtask goes to the most suitable worker</li> <li>Efficiency in complexity \u2014 Complex tasks are broken into manageable components and results are synthesized</li> <li>Scalability \u2014 Dynamic task assignment allows systems to scale for diverse and large workloads</li> </ul>"},{"location":"patterns/workflow-architecture/orchestrator-workers/#key-components","title":"Key Components","text":"Component Purpose Example Orchestrator Analyzes input, determines required subtasks, assigns them to appropriate workers Divides a customer query into legal, financial, and technical subtasks Workers (LLM Calls) Specialized models or systems that process each subtask Worker 1: legal analysis, Worker 2: financial evaluation, Worker 3: technical feasibility Synthesizer Combines worker outputs into a coherent final result Merges legal, financial, and technical findings into actionable recommendations Input/Output The original task in, the synthesized result out Input: multi-faceted customer request \u2192 Output: structured report addressing all aspects"},{"location":"patterns/workflow-architecture/orchestrator-workers/#predefined-vs-dynamic-workers","title":"Predefined vs. Dynamic Workers","text":"<p>The orchestrator can work with both:</p> <ul> <li>Predefined workers \u2014 Specialized for known task types (e.g., financial analysis, image recognition). The orchestrator routes to the right one.</li> <li>Dynamic workers \u2014 For tasks with unknown subtasks, the orchestrator creates workers on the fly:<ol> <li>Dynamic configuration \u2014 Tailors a general-purpose LLM with specific prompts to temporarily specialize it</li> <li>Tool integration \u2014 Activates external tools or APIs to augment the worker's capabilities</li> <li>On-the-fly instantiation \u2014 In advanced systems, generates new worker instances adapted to the task</li> </ol> </li> </ul> <p>Dynamic worker creation ensures the system handles unexpected inputs without needing pre-configured workflows for every scenario.</p>"},{"location":"patterns/workflow-architecture/orchestrator-workers/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Unstructured tasks \u2014 When subtasks can't be predicted or defined in advance</li> <li>Multi-domain expertise \u2014 When the task spans areas requiring different specialized knowledge</li> <li>Dynamic workloads \u2014 When new subtask types may emerge that weren't anticipated</li> </ul>"},{"location":"patterns/workflow-architecture/orchestrator-workers/#example-comprehensive-market-research","title":"Example: Comprehensive Market Research","text":"<p>A company entering a new market needs analysis across competitor strategy, customer segmentation, and regulatory compliance:</p> <ol> <li>Orchestrator breaks the task into three subtasks and assigns workers</li> <li>Worker 1 \u2014 Scans competitor pricing, products, and strategies</li> <li>Worker 2 \u2014 Processes demographic and survey data to generate customer segments</li> <li>Worker 3 \u2014 Reviews regulatory documents and flags compliance risks</li> <li>Synthesizer \u2014 Combines outputs into a unified market research report</li> </ol> <p>If a new subtask emerges (e.g., evaluating environmental impact), the orchestrator dynamically assigns or creates a new worker.</p> <p>Results:</p> <ul> <li>Speed \u2014 All subtasks processed simultaneously</li> <li>Specialization \u2014 Each domain handled by a focused worker</li> <li>Flexibility \u2014 New subtasks addressed without restructuring the workflow</li> </ul>"},{"location":"patterns/workflow-architecture/orchestrator-workers/#how-to-implement","title":"How to Implement","text":"<ol> <li>Design the orchestrator \u2014 Build the logic that analyzes inputs and determines subtask breakdown</li> <li>Define worker capabilities \u2014 Establish predefined workers for known task types and rules for dynamic creation</li> <li>Build the synthesizer \u2014 Define how worker outputs combine into a coherent final result</li> <li>Test with varied inputs \u2014 Ensure the orchestrator correctly identifies subtasks and routes to appropriate workers</li> </ol> <p>Based on Building Effective Agents by Anthropic.</p>"},{"location":"patterns/workflow-architecture/orchestrator-workers/#related","title":"Related","text":"<ul> <li>Workflow Architecture Patterns Overview</li> <li>Parallelization \u2014 similar structure but with predefined subtasks</li> <li>Autonomous Agents \u2014 the next step in autonomy</li> <li>Agents \u2014 concepts for building AI agents</li> <li>Build &gt; Design Your AI Workflow</li> </ul>"},{"location":"patterns/workflow-architecture/parallelization/","title":"Parallelization","text":"<p>Parallelization divides subtasks of a larger problem and processes them simultaneously through separate LLM calls. The outputs are then aggregated to produce the final result.</p> <p>This pattern has two primary variations:</p> <ul> <li>Sectioning \u2014 Breaking a task into independent subtasks, each processed in parallel</li> <li>Voting \u2014 Running the same task multiple times to generate diverse perspectives, then aggregating for higher confidence</li> </ul>"},{"location":"patterns/workflow-architecture/parallelization/#why-it-matters","title":"Why It Matters","text":"<ul> <li>Increased speed \u2014 Parallel processing reduces latency by distributing workloads, ideal for time-sensitive tasks</li> <li>Enhanced reliability \u2014 Multiple evaluations or diverse subtasks processed in parallel produce higher-confidence results</li> <li>Focused task management \u2014 Specialized LLM calls handle each subtask, improving accuracy through focused attention</li> <li>Scalability \u2014 Larger datasets or more complex workflows are handled without bottlenecking a single model</li> </ul>"},{"location":"patterns/workflow-architecture/parallelization/#key-components","title":"Key Components","text":"Component Purpose Example Parallel LLM Calls Each handles a different subtask (sectioning) or repeats the same task (voting) One call evaluates content for tone, another for factual accuracy, another for compliance Aggregator Combines parallel outputs into a unified result (consolidating, voting on best, or integrating insights) Merges flagged issues from parallel code reviews into a comprehensive report Input/Output Input initiates all parallel processes; output delivers aggregated results Input: a large dataset \u2192 Output: a combined analysis report"},{"location":"patterns/workflow-architecture/parallelization/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Speed-intensive tasks \u2014 Time-sensitive workflows requiring simultaneous processing</li> <li>Tasks with multiple dimensions \u2014 Multiple independent considerations that can be evaluated separately</li> <li>Higher confidence needs \u2014 Outputs requiring validation through multiple attempts or perspectives</li> </ul>"},{"location":"patterns/workflow-architecture/parallelization/#example-market-research-analysis","title":"Example: Market Research Analysis","text":"<p>A company needs comprehensive market analysis for a product launch covering competitor analysis, consumer trends, and regional insights:</p> <p>Sectioning approach:</p> <ol> <li>Parallel Call 1 \u2014 Evaluates competitors' pricing and positioning</li> <li>Parallel Call 2 \u2014 Analyzes customer preferences and behaviors</li> <li>Parallel Call 3 \u2014 Studies market potential across regions</li> <li>Aggregator \u2014 Combines all findings into one comprehensive report</li> </ol> <p>Voting approach (for uncertain predictions):</p> <ol> <li>Multiple models independently predict regional sales figures</li> <li>The aggregator evaluates and combines predictions for a well-rounded decision</li> </ol> <p>Results:</p> <ul> <li>Speed \u2014 All parts complete simultaneously instead of sequentially</li> <li>Focus \u2014 Each call specializes in its area, improving depth and quality</li> <li>Confidence \u2014 Voting reflects multiple viewpoints, reducing bias</li> </ul>"},{"location":"patterns/workflow-architecture/parallelization/#how-to-implement","title":"How to Implement","text":"<ol> <li>Identify subtasks \u2014 Break the problem into components that can be processed independently</li> <li>Determine parallelization type \u2014 Sectioning (dividing tasks) or voting (repeating with different approaches)</li> <li>Set up aggregation rules \u2014 Define how outputs combine (consensus, averaging, concatenating)</li> <li>Test and optimize \u2014 Ensure efficient operation and consistent, high-quality outputs</li> </ol> <p>Based on Building Effective Agents by Anthropic.</p>"},{"location":"patterns/workflow-architecture/parallelization/#related","title":"Related","text":"<ul> <li>Workflow Architecture Patterns Overview</li> <li>Routing \u2014 directs to one specialized path; parallelization runs multiple paths simultaneously</li> <li>Orchestrator-Workers \u2014 similar structure but with dynamic task decomposition</li> <li>Build &gt; Design Your AI Workflow</li> </ul>"},{"location":"patterns/workflow-architecture/prompt-chaining/","title":"Prompt Chaining","text":"<p>Prompt chaining breaks a complex task into a sequence of smaller steps. Each step (LLM call) builds on the output of the previous one, with intermediate gates that validate quality before proceeding. If an output fails validation, the process can exit early to prevent error propagation.</p> <p>Think of it as an assembly line where each station contributes a specific part to the final product.</p>"},{"location":"patterns/workflow-architecture/prompt-chaining/#why-it-matters","title":"Why It Matters","text":"<ul> <li>Increased accuracy \u2014 Each LLM call focuses on a specific goal, reducing errors and improving overall quality</li> <li>Modularity \u2014 You can inspect and debug intermediate steps, making the workflow easier to adapt and refine</li> <li>Enhanced reliability \u2014 Programmatic gates catch errors early, increasing confidence in the final output</li> <li>Efficiency trade-off \u2014 This workflow trades some latency (multiple steps) for more robust, higher-quality outputs</li> </ul>"},{"location":"patterns/workflow-architecture/prompt-chaining/#key-components","title":"Key Components","text":"Component Purpose Example LLM Call 1 Handles the initial step and produces the first output Generate a document outline based on user input Gate Validates the output of the previous call; continues or exits Check if the outline contains all necessary sections LLM Call 2 Processes the validated output from the previous step Expand the approved outline into a detailed draft LLM Call 3 Finalizes the task by refining or transforming the output Translate the draft or format it for publication Exit Ends the workflow early if validation fails Stop if the outline doesn't meet quality standards Output Delivers the final product after all steps complete successfully A polished, translated document ready for publication"},{"location":"patterns/workflow-architecture/prompt-chaining/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Multi-step processes \u2014 Tasks that naturally decompose into sequential steps (generate, validate, refine)</li> <li>Tasks requiring validation \u2014 When intermediate outputs need quality checks before proceeding</li> <li>Complex workflows \u2014 When different steps benefit from different prompts, models, or configurations</li> </ul>"},{"location":"patterns/workflow-architecture/prompt-chaining/#example-generating-marketing-materials","title":"Example: Generating Marketing Materials","text":"<p>A company needs product launch copy translated into multiple languages with consistent tone:</p> <ol> <li>LLM Call 1 \u2014 Generate initial marketing copy from product details and target audience</li> <li>Gate \u2014 Validate against tone guide and campaign goals</li> <li>LLM Call 2 \u2014 Translate the validated copy into multiple languages</li> <li>Gate \u2014 Ensure translations retain tone and key messages</li> <li>LLM Call 3 \u2014 Format translated copy for each platform (email, social media, website)</li> <li>Output \u2014 Finalized, multilingual marketing materials ready for deployment</li> </ol>"},{"location":"patterns/workflow-architecture/prompt-chaining/#how-to-implement","title":"How to Implement","text":"<ol> <li>Decompose the task \u2014 Identify the logical subtasks that make up the overall goal</li> <li>Define validation criteria \u2014 Establish clear checkpoints (gates) to evaluate outputs after each step</li> <li>Connect steps programmatically \u2014 Design the workflow so outputs from one step feed into the next</li> <li>Test and refine \u2014 Ensure each step performs as intended and adjust based on intermediate results</li> </ol> <p>Based on Building Effective Agents by Anthropic.</p>"},{"location":"patterns/workflow-architecture/prompt-chaining/#related","title":"Related","text":"<ul> <li>Workflow Architecture Patterns Overview</li> <li>Augmented LLM \u2014 the foundation this pattern builds on</li> <li>Routing \u2014 another structured workflow for branching paths</li> <li>Evaluator-Optimizer \u2014 iterative refinement with feedback loops</li> <li>Build &gt; Design Your AI Workflow</li> </ul>"},{"location":"patterns/workflow-architecture/routing/","title":"Routing","text":"<p>The routing pattern classifies input and directs it to a specialized follow-up task. By separating tasks into distinct categories and routing them to appropriate processes, this pattern enables separation of concerns and highly optimized handling for each input type.</p> <p>Without routing, optimizing a system for one type of input (e.g., simple queries) can degrade performance for other types (e.g., complex or edge-case queries).</p>"},{"location":"patterns/workflow-architecture/routing/#why-it-matters","title":"Why It Matters","text":"<ul> <li>Specialization improves performance \u2014 Each task type is handled by a tailored process, ensuring higher accuracy</li> <li>Efficiency \u2014 Tasks go to the most appropriate system, optimizing resource use and reducing computational costs</li> <li>Scalability \u2014 Varied input types are handled effectively by directing them to the right models or systems</li> <li>Reduced bottlenecks \u2014 No single model becomes overwhelmed by diverse inputs it isn't optimized for</li> </ul>"},{"location":"patterns/workflow-architecture/routing/#key-components","title":"Key Components","text":"Component Purpose Example Router (LLM Call) Classifies incoming tasks and directs them to the appropriate follow-up Determines if a customer query is general, refund-related, or technical Specialized Process 1 Handles one specific task category Responds to general inquiries (store hours, product info) Specialized Process 2 Handles a different task category Processes refund requests (checking order history, issuing refunds) Specialized Process 3 Handles complex or specialized tasks Resolves technical support issues with troubleshooting steps Output Consolidates results into the final response Delivers the resolved answer to the customer"},{"location":"patterns/workflow-architecture/routing/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Diverse input types \u2014 When the system handles inputs that differ in complexity or nature</li> <li>High-performance requirements \u2014 When optimizing for one input type risks degrading performance for others</li> <li>Resource optimization \u2014 When simple tasks can use smaller models while reserving powerful models for complex cases</li> </ul>"},{"location":"patterns/workflow-architecture/routing/#example-customer-service-automation","title":"Example: Customer Service Automation","text":"<p>A company automates customer service across varied query types:</p> <ol> <li>Router classifies each query:<ul> <li>General questions (\"What are your store hours?\")</li> <li>Refund requests (\"I want a refund for my last order.\")</li> <li>Technical issues (\"My device isn't turning on.\")</li> </ul> </li> <li>Process 1 handles general inquiries with predefined responses</li> <li>Process 2 processes refunds by accessing order history, validating claims, and initiating refunds</li> <li>Process 3 resolves technical issues with product-specific troubleshooting</li> <li>Output delivers the final response to the customer</li> </ol>"},{"location":"patterns/workflow-architecture/routing/#how-to-implement","title":"How to Implement","text":"<ol> <li>Define categories \u2014 Identify the distinct task or input types your system will handle</li> <li>Train or configure the router \u2014 Implement a classification mechanism (LLM or traditional classifier) to route inputs correctly</li> <li>Develop specialized workflows \u2014 Create tailored workflows or prompts for each category</li> <li>Test and refine \u2014 Evaluate routing accuracy and each specialized workflow's effectiveness</li> </ol> <p>Based on Building Effective Agents by Anthropic.</p>"},{"location":"patterns/workflow-architecture/routing/#related","title":"Related","text":"<ul> <li>Workflow Architecture Patterns Overview</li> <li>Prompt Chaining \u2014 sequential processing within a single path</li> <li>Parallelization \u2014 running multiple paths simultaneously</li> <li>Build &gt; Design Your AI Workflow</li> </ul>"},{"location":"platforms/","title":"Platforms","text":"<p>Platform-specific setup guides, topics, and Q&amp;A organized by AI platform.</p>"},{"location":"platforms/#choose-your-platform","title":"Choose Your Platform","text":"<ul> <li> <p> Claude</p> <p>Anthropic's Claude models, Claude Code CLI, and MCP integrations</p> <p> Claude guides</p> </li> <li> <p>:simple-openai:{ .lg .middle } OpenAI / ChatGPT</p> <p>GPT models, Assistants API, and function calling</p> <p> OpenAI guides</p> </li> <li> <p> Google Gemini</p> <p>Gemini models and Vertex AI</p> <p> Gemini guides</p> </li> <li> <p> M365 Copilot</p> <p>Microsoft 365 Copilot and Azure OpenAI</p> <p> M365 Copilot guides</p> </li> </ul>"},{"location":"platforms/overview/","title":"Platforms","text":"<p>Platform-specific documentation and guides.</p>"},{"location":"platforms/overview/#platforms_1","title":"Platforms","text":"Platform Description OpenAI GPT models, Assistants API, function calling Claude Anthropic's Claude models, tool use, artifacts Gemini Google's Gemini models and Vertex AI M365 Copilot Microsoft 365 Copilot and Azure OpenAI"},{"location":"platforms/overview/#cross-platform-topics","title":"Cross-Platform Topics","text":"<p>Topics will be listed here as they are added.</p>"},{"location":"platforms/overview/#related","title":"Related","text":"<ul> <li>Agentic Building Blocks</li> </ul>"},{"location":"platforms/resources/","title":"Platform Resources","text":"<p>Recommended articles, docs, and courses covering multiple AI platforms.</p> Resource Type Note"},{"location":"platforms/claude/","title":"Claude","text":"<p>Everything you need to work with Anthropic's Claude\u2014from initial setup to advanced automation.</p>"},{"location":"platforms/claude/#getting-started","title":"Getting Started","text":"<p>Set up your Claude environment:</p> Guide Description Claude Code Installation Install the CLI and VS Code extension Claude Personalization Configure Claude to understand your context"},{"location":"platforms/claude/#projects","title":"Projects","text":"Guide Description Claude Projects Organize your AI work with projects"},{"location":"platforms/claude/#agents","title":"Agents","text":"Guide Description Building Agents on Claude Custom subagents and agent teams for workflow automation Scheduling Subagents Set up automated agents on macOS or Windows Troubleshooting Common scheduling issues and fixes"},{"location":"platforms/claude/#topics","title":"Topics","text":"<ul> <li>Claude Overview</li> <li>Claude Resources</li> </ul>"},{"location":"platforms/claude/#questions","title":"Questions","text":"<ul> <li>Claude Q&amp;A</li> </ul>"},{"location":"platforms/claude/agents/building-agents/","title":"Building Agents on Claude","text":"<p>Part of: Build Workflows &gt; Agents</p> <p>Claude Code provides two approaches to building agents, each suited to different workflow patterns. Both use Markdown files with YAML frontmatter \u2014 no code required.</p> Approach Best for Complexity Custom subagents Focused, single-responsibility tasks Low \u2014 one <code>.md</code> file per agent Agent teams Multi-agent coordination with parallel execution Higher \u2014 experimental feature, multiple agents collaborating"},{"location":"platforms/claude/agents/building-agents/#custom-subagents","title":"Custom Subagents","text":"<p>A custom subagent is a Markdown file that defines an agent's role, instructions, and capabilities. Claude Code spawns it as a subprocess with its own context window, tools, and permissions.</p> <p>Official docs: Claude Code Sub-agents</p>"},{"location":"platforms/claude/agents/building-agents/#where-agent-files-live","title":"Where agent files live","text":"Location Scope <code>.claude/agents/</code> (in your project) Available to anyone working in this project <code>~/.claude/agents/</code> (in your home directory) Available across all your projects"},{"location":"platforms/claude/agents/building-agents/#agent-file-structure","title":"Agent file structure","text":"<p>Each agent is a single <code>.md</code> file with YAML frontmatter for configuration and Markdown body for instructions:</p> <pre><code>---\nname: research-analyst\ndescription: Use this agent to research companies and summarize findings\nmodel: sonnet\ntools:\n  - WebSearch\n  - WebFetch\n  - Read\n  - Write\n---\n\n# Research Analyst\n\nYou are a research analyst who investigates companies and produces structured briefs.\n\n## Process\n\n1. Search for the company using web search\n2. Visit the company website and key pages\n3. Summarize findings in a structured format\n\n## Output Format\n\nWrite findings to `outputs/[company-name]-research.md` with sections for:\n- Company overview\n- Key products/services\n- Recent news\n- Relevant insights\n</code></pre>"},{"location":"platforms/claude/agents/building-agents/#frontmatter-options","title":"Frontmatter options","text":"Field Required Description <code>name</code> No Display name (defaults to filename) <code>description</code> Yes When to use this agent \u2014 Claude reads this to decide whether to activate it <code>model</code> No Which model to use (<code>opus</code>, <code>sonnet</code>, <code>haiku</code>) <code>tools</code> No Which tools the agent can access (e.g., <code>Read</code>, <code>Write</code>, <code>WebSearch</code>, <code>Bash</code>) <code>permissionMode</code> No How tool permissions are handled (<code>default</code>, <code>acceptEdits</code>, <code>bypassPermissions</code>) <code>skills</code> No Skills the agent can use (list of skill names) <code>mcpServers</code> No MCP servers the agent can connect to <code>maxTurns</code> No Maximum number of turns before the agent stops <code>memory</code> No Path to a persistent memory file the agent can read and update <code>hooks</code> No Shell commands triggered by agent lifecycle events"},{"location":"platforms/claude/agents/building-agents/#creating-an-agent","title":"Creating an agent","text":"<p>Two options:</p> <ol> <li>Use the <code>/agents</code> command \u2014 Claude Code walks you through creating an agent interactively</li> <li>Create the file manually \u2014 Write a <code>.md</code> file in <code>.claude/agents/</code> following the structure above</li> </ol>"},{"location":"platforms/claude/agents/building-agents/#how-agents-activate","title":"How agents activate","text":"<p>When you describe a task in Claude Code, it checks agent descriptions to decide whether to delegate. You can also invoke an agent directly:</p> <pre><code># Run from the command line\nclaude --agent research-analyst\n\n# Or describe the task and let Claude choose the right agent\nclaude \"Research Acme Corp and write a brief\"\n</code></pre> <p>Agents can run in the foreground (you see their work in real-time) or in the background (they work independently while you continue).</p>"},{"location":"platforms/claude/agents/building-agents/#key-capabilities","title":"Key capabilities","text":"<ul> <li>Tool restrictions \u2014 limit which tools an agent can use, preventing unintended actions</li> <li>Skills \u2014 attach reusable skills that give the agent domain expertise</li> <li>MCP servers \u2014 connect to external services (databases, APIs, browsers) via the Model Context Protocol</li> <li>Persistent memory \u2014 give the agent a memory file it reads at startup and updates as it learns</li> <li>Hooks \u2014 trigger shell commands when the agent starts, stops, or encounters specific events</li> </ul>"},{"location":"platforms/claude/agents/building-agents/#mapping-your-design-blueprint","title":"Mapping your Design blueprint","text":"<p>Your Design phase produced a platform-agnostic agent blueprint. Here's how each component maps to a Claude Code agent file:</p> Design blueprint Claude Code agent file Name Filename (e.g., <code>research-analyst.md</code>) and optional <code>name</code> frontmatter Description <code>description</code> frontmatter \u2014 write it so Claude knows when to activate this agent Instructions Markdown body \u2014 the agent's role, process, constraints, and output format Model <code>model</code> frontmatter (<code>opus</code>, <code>sonnet</code>, <code>haiku</code>) Tools <code>tools</code> frontmatter (list of tool names) + <code>mcpServers</code> for external connections Context <code>skills</code> frontmatter + reference files mentioned in the instructions Goal Captured in the <code>description</code> (activation trigger) and instructions (success criteria)"},{"location":"platforms/claude/agents/building-agents/#agent-teams","title":"Agent Teams","text":"<p>Agent teams let multiple Claude Code instances work together on complex tasks \u2014 a team lead coordinates while teammates handle specialized subtasks in parallel.</p> <p>Official docs: Claude Code Agent Teams</p> <p>Experimental feature</p> <p>Agent teams require the <code>CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS</code> environment variable. The feature is under active development and behavior may change.</p>"},{"location":"platforms/claude/agents/building-agents/#how-teams-work","title":"How teams work","text":"<p>A team lead (a Claude Code agent) can spawn teammates \u2014 independent Claude Code instances that each get their own context window and tools. The team lead coordinates work through a shared task list and inter-agent messaging.</p> <pre><code>Team Lead\n\u251c\u2500\u2500 Teammate A (e.g., research analyst)\n\u251c\u2500\u2500 Teammate B (e.g., writer)\n\u2514\u2500\u2500 Teammate C (e.g., editor)\n</code></pre>"},{"location":"platforms/claude/agents/building-agents/#key-capabilities_1","title":"Key capabilities","text":"<ul> <li>Shared task list \u2014 the team lead creates tasks, teammates claim and complete them</li> <li>Inter-agent messaging \u2014 teammates can send messages to the team lead and to each other</li> <li>Parallel execution \u2014 teammates work simultaneously on independent tasks</li> <li>Plan approval \u2014 the team lead can present a plan for your approval before dispatching work</li> </ul>"},{"location":"platforms/claude/agents/building-agents/#when-to-use-teams-vs-single-agents","title":"When to use teams vs. single agents","text":"Use single agents when... Use agent teams when... The task has one focus area The task spans multiple expertise domains Steps are sequential Steps can run in parallel One agent can handle everything Different steps need different tools or knowledge You want simple, predictable execution You want to maximize throughput on complex tasks"},{"location":"platforms/claude/agents/building-agents/#good-use-cases-for-teams","title":"Good use cases for teams","text":"<ul> <li>Parallel research \u2014 multiple teammates research different aspects simultaneously</li> <li>Competing approaches \u2014 teammates try different solutions, team lead picks the best</li> <li>Cross-layer coordination \u2014 frontend, backend, and testing teammates work on related changes</li> <li>Pipeline processing \u2014 research \u2192 write \u2192 edit with specialized teammates for each stage</li> </ul>"},{"location":"platforms/claude/agents/building-agents/#mapping-your-design-blueprint_1","title":"Mapping your Design blueprint","text":"<p>For multi-agent workflows, the Design phase produced configurations for multiple agents. On Claude Code:</p> <ol> <li>Each specialist agent becomes a teammate definition</li> <li>The orchestrator becomes the team lead's instructions</li> <li>Handoff points map to task list entries and messaging patterns</li> <li>Human review gates map to plan approval checkpoints</li> </ol>"},{"location":"platforms/claude/agents/building-agents/#whats-next","title":"What's Next","text":"<ul> <li>Agents overview \u2014 the platform-agnostic agent decision framework</li> <li>Design Your AI Workflow \u2014 produce the agent blueprint that feeds into these implementations</li> <li>Scheduling Subagents \u2014 run agents automatically on a schedule</li> </ul>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/","title":"Claude Personalization and Memory Setup Guide","text":"<p>Quick reference for configuring Claude's personalization features and memory.</p>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#overview","title":"Overview","text":"<p>Claude offers three personalization features:</p> Feature Scope Availability Profile Preferences All conversations All plans Memory Standalone chats + per-project Pro, Max, Team, Enterprise Styles Response format/tone All plans"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#part-1-profile-preferences","title":"Part 1: Profile Preferences","text":"<p>Profile preferences are account-wide settings that apply to all your conversations.</p>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#set-up-profile-preferences","title":"Set Up Profile Preferences","text":"<ol> <li>Click your initials (lower left corner)</li> <li>Go to Settings</li> <li>Find \"What preferences should Claude consider in responses?\"</li> <li>Enter your preferences and save</li> </ol>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#what-to-include","title":"What to Include","text":"<ul> <li>Your role and professional context</li> <li>Preferred communication style (concise, detailed, formal, casual)</li> <li>Common terms or concepts you use</li> <li>Typical scenarios you encounter</li> <li>Technical preferences (languages, frameworks, tools)</li> </ul> <p>Example: <pre><code>I'm a product manager at a SaaS company. I prefer concise responses\nwith bullet points. When discussing technical topics, explain concepts\nsimply\u2014I'm not a developer. Default to Slack-friendly formatting.\n</code></pre></p>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#part-2-memory","title":"Part 2: Memory","text":"<p>Memory lets Claude remember context across conversations, building on what you've discussed before.</p> <p>Available on: Pro, Max, Team, Enterprise (web, desktop, mobile)</p>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#enable-memory","title":"Enable Memory","text":"<ol> <li>Go to Settings \u2192 Capabilities</li> <li>Toggle Memory on</li> <li>Grant any permissions if prompted</li> </ol> <p>Note: Enterprise members can only enable memory when their organization Owner has activated it.</p>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#how-memory-works","title":"How Memory Works","text":"<ul> <li>Claude automatically summarizes your conversations</li> <li>Creates a synthesis of key insights across your chat history</li> <li>Updates every 24 hours</li> <li>Provides context for new standalone conversations</li> <li>Each project has its own separate memory space</li> </ul>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#what-claude-remembers","title":"What Claude Remembers","text":"<p>Claude focuses on work-related context: - Your role, projects, and professional context - Communication and working style preferences - Technical and coding preferences - Project details and ongoing work</p>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#view-and-edit-memory","title":"View and Edit Memory","text":"<ol> <li>Go to Settings \u2192 Capabilities</li> <li>Click \"View and edit memory\"</li> <li>Review what Claude remembers</li> <li>Edit summaries directly or add specific information</li> </ol> <p>Tip: You can also tell Claude to remember something mid-conversation: \"Remember that I prefer Python over JavaScript.\"</p>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#manage-memory","title":"Manage Memory","text":"<p>Pause memory \u2014 Claude keeps existing memories but won't use them or create new ones</p> <p>Reset memory \u2014 Permanently deletes all memories (cannot be undone)</p> <p>To access these options, toggle memory off in Settings \u2192 Capabilities.</p>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#part-3-styles","title":"Part 3: Styles","text":"<p>Styles customize how Claude formats and delivers responses.</p>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#create-a-custom-style","title":"Create a Custom Style","text":"<ol> <li>Go to Settings \u2192 Styles</li> <li>Click Create style</li> <li>Define your preferred format and tone</li> <li>Save and apply to conversations</li> </ol>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#use-cases","title":"Use Cases","text":"<ul> <li>Switch between concise and detailed responses</li> <li>Match your writing style for drafts</li> <li>Adjust tone for different contexts (professional, casual)</li> </ul>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#chat-search-paid-plans","title":"Chat Search (Paid Plans)","text":"<p>Memory includes the ability to search past conversations.</p> <ol> <li>Go to Settings \u2192 Capabilities</li> <li>Ensure \"Search and reference chats\" is enabled</li> <li>Ask Claude naturally: \"What did we discuss about the Q3 roadmap?\"</li> </ol> <p>Claude uses RAG to find relevant past conversations.</p>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#troubleshooting","title":"Troubleshooting","text":"<p>Memory not available? - Requires Pro, Max, Team, or Enterprise plan - Check Settings \u2192 Capabilities to enable - Enterprise users: verify your admin has enabled the feature</p> <p>Claude not remembering things? - Memory updates within 24 hours of conversations - Project chats have separate memory from standalone chats - Check \"View and edit memory\" to see what's stored</p> <p>Want to exclude a conversation from memory? - Use incognito mode for chats you don't want saved - Deleted conversations are removed from memory synthesis</p>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#next-steps","title":"Next Steps","text":"<ul> <li>Review the course slide deck for detailed walkthrough</li> <li>Post in Slack if you encounter issues</li> </ul>"},{"location":"platforms/claude/getting-started/claude-personalization-setup/#resources","title":"Resources","text":"<ul> <li>Understanding Claude's Personalization Features</li> <li>Using Claude's Chat Search and Memory</li> <li>Importing and Exporting Your Memory</li> </ul>"},{"location":"platforms/claude/projects/claude-projects-setup/","title":"Claude Projects Setup Guide","text":"<p>Quick reference for creating and configuring Claude Projects for persistent context.</p>"},{"location":"platforms/claude/projects/claude-projects-setup/#what-are-projects","title":"What Are Projects?","text":"<p>Projects let you organize conversations around a specific topic or task. You can add:</p> <ul> <li>Project Knowledge \u2014 Documents, files, and code that Claude references in all chats</li> <li>Project Instructions \u2014 Custom guidelines that shape Claude's behavior</li> </ul> <p>Projects are available on all plans. Free users can create up to 5 projects.</p>"},{"location":"platforms/claude/projects/claude-projects-setup/#create-a-project","title":"Create a Project","text":"<ol> <li>Go to claude.ai/projects or click Projects in the sidebar</li> <li>Click + New Project in the upper right</li> <li>Enter a project name and description</li> <li>For Team/Enterprise: choose visibility (private or shared)</li> </ol>"},{"location":"platforms/claude/projects/claude-projects-setup/#add-project-knowledge","title":"Add Project Knowledge","text":"<p>Project knowledge provides context for all conversations within the project.</p> <ol> <li>Open your project</li> <li>Click the + button in the project knowledge section (right side)</li> <li>Upload documents, text files, or code</li> <li>Files are now available to Claude in all project chats</li> </ol> <p>Tips: - Add all relevant documents upfront\u2014more context helps Claude assist you better - Use clear, descriptive file names so Claude can find the right information - Paid plans automatically enable RAG mode when content approaches context limits</p>"},{"location":"platforms/claude/projects/claude-projects-setup/#set-project-instructions","title":"Set Project Instructions","text":"<p>Project instructions guide Claude's behavior across all chats in the project.</p> <ol> <li>Open your project</li> <li>Click Set project instructions</li> <li>Write your guidelines (tone, role, format preferences, etc.)</li> <li>Save</li> </ol> <p>Example instructions: <pre><code>You are helping me with [specific task].\n\nWhen responding:\n- Use a professional tone\n- Format code examples in Python\n- Ask clarifying questions before making assumptions\n</code></pre></p> <p>Note: Context is not shared across individual chats within a project\u2014only content in the project knowledge base is available to all chats.</p>"},{"location":"platforms/claude/projects/claude-projects-setup/#organize-your-projects","title":"Organize Your Projects","text":"<p>Star projects \u2014 Click the \u22ee menu or star icon to mark frequently-used projects for quick access</p> <p>Move chats to projects \u2014 Use the dropdown arrow next to a chat name to add standalone conversations to a project</p> <p>Archive projects \u2014 Click \u22ee menu \u2192 Archive (archived projects appear at the bottom of your list)</p> <p>Delete projects \u2014 Unarchive first, then use \u22ee menu to delete permanently</p>"},{"location":"platforms/claude/projects/claude-projects-setup/#share-projects-teamenterprise","title":"Share Projects (Team/Enterprise)","text":"<ol> <li>Click Share project next to the project name</li> <li>Add members by name or email</li> <li>Choose permission level:</li> <li>Can use \u2014 View contents and chat, but cannot edit</li> <li>Can edit \u2014 Modify instructions, knowledge, and member settings</li> <li>Shared projects appear in recipients' \"Shared with me\" tab</li> </ol>"},{"location":"platforms/claude/projects/claude-projects-setup/#troubleshooting","title":"Troubleshooting","text":"<p>Claude isn't using my uploaded files? - Verify files uploaded successfully (check project knowledge section) - Try asking Claude directly about the content: \"What files do you have access to?\" - For large knowledge bases, Claude uses RAG\u2014be specific in your questions</p> <p>Project instructions not being followed? - Check instructions are saved (re-open the project to verify) - Be explicit and specific in your instructions - Start a new chat within the project after updating instructions</p> <p>Can't share a project? - Sharing requires Team or Enterprise plan - Verify you have edit permissions on the project</p>"},{"location":"platforms/claude/projects/claude-projects-setup/#next-steps","title":"Next Steps","text":"<ul> <li>Review the course slide deck for detailed walkthrough</li> <li>Post in Slack if you encounter issues</li> </ul>"},{"location":"platforms/claude/projects/claude-projects-setup/#resources","title":"Resources","text":"<ul> <li>What Are Projects?</li> <li>How to Create and Manage Projects</li> <li>Project Visibility and Sharing</li> <li>Examples of Projects You Can Create</li> </ul>"},{"location":"platforms/claude/questions/","title":"Claude Questions","text":"<p>Questions specific to Anthropic's Claude models and API.</p>"},{"location":"platforms/claude/questions/#questions","title":"Questions","text":"Question Tags What is the best way to name Claude agent skills? <code>claude</code> How do I schedule an automated Claude subagent? <code>claude</code>"},{"location":"platforms/claude/questions/#related-resources","title":"Related Resources","text":"<ul> <li>Claude Topics</li> <li>Agentic Building Blocks</li> </ul>"},{"location":"platforms/claude/questions/how-do-i-schedule-an-automated-claude-subagent/","title":"How do I schedule an automated Claude subagent?","text":"<p>Short answer: Add scheduling instructions to your project's CLAUDE.md file, then ask Claude Code to schedule your subagent \u2014 it creates the wrapper scripts, logging, and OS-level scheduled task (launchd on macOS, Task Scheduler on Windows) automatically.</p>"},{"location":"platforms/claude/questions/how-do-i-schedule-an-automated-claude-subagent/#the-full-answer","title":"The Full Answer","text":"<p>Claude Code subagents can run on a schedule without any human interaction \u2014 like a research assistant that gathers information while you sleep, or a competitor monitor that runs every Monday morning. The key is that Claude Code handles all the platform-specific scheduling configuration for you. You don't need to write cron jobs, plist files, or PowerShell scripts yourself.</p> <p>The process has two prerequisites: Claude Code installed and authenticated, and a subagent already defined as a markdown file (e.g., <code>.claude/agents/my-agent.md</code>). Once those are in place, you add a scheduling section to your project's CLAUDE.md that tells Claude Code how to set up headless operation \u2014 using <code>--dangerously-skip-permissions</code> for unattended tool use, full paths to the Claude binary, and proper logging. Without these instructions, Claude Code won't know the special flags needed for scheduled operation and your subagent will fail silently.</p> <p>With the CLAUDE.md updated, scheduling is as simple as asking Claude Code: \"Schedule my research-daily subagent to run every weekday at 7:30 AM.\" Claude Code creates the wrapper script, configures the OS scheduler (launchd on macOS, Task Scheduler on Windows), sets up logging, and activates it. On macOS, if your machine is asleep at the scheduled time, the subagent runs when it wakes up.</p> <p>You manage scheduled subagents entirely through Claude Code \u2014 pausing, resuming, changing schedules, viewing logs, and removing tasks are all conversational commands.</p>"},{"location":"platforms/claude/questions/how-do-i-schedule-an-automated-claude-subagent/#how-to-get-started","title":"How to Get Started","text":"<p>Follow the step-by-step guide: Scheduling Claude Code Subagents</p> <p>The guide covers:</p> <ol> <li>Adding the required scheduling instructions to your CLAUDE.md</li> <li>Asking Claude Code to create the schedule</li> <li>Testing the subagent manually</li> <li>Managing and troubleshooting scheduled tasks</li> </ol>"},{"location":"platforms/claude/questions/how-do-i-schedule-an-automated-claude-subagent/#common-scheduling-patterns","title":"Common Scheduling Patterns","text":"Subagent Type Suggested Schedule Example Prompt Daily news/research Weekdays at 7\u20138 AM \"Run every weekday at 7:30 AM\" Competitor monitoring Weekly on Monday \"Run every Monday at 8:00 AM\" Weekly summaries Friday afternoon \"Run every Friday at 4:00 PM\" Frequent updates Every few hours \"Run every 4 hours during business hours\""},{"location":"platforms/claude/questions/how-do-i-schedule-an-automated-claude-subagent/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Claude Code handles all the OS-level scheduling configuration \u2014 you just ask it in natural language</li> <li>You must add scheduling instructions to your project's CLAUDE.md first, or headless operation will fail silently</li> <li>Subagents use <code>--dangerously-skip-permissions</code> to run unattended \u2014 review what your subagent does before enabling this</li> <li>On macOS, launchd catches up on missed runs when your machine wakes \u2014 your morning digest still gets created</li> <li>Manage everything through Claude Code: pause, resume, reschedule, view logs, and remove tasks conversationally</li> </ul>"},{"location":"platforms/claude/questions/how-do-i-schedule-an-automated-claude-subagent/#related-questions","title":"Related Questions","text":"<ul> <li>What is the best way to name Claude agent skills?</li> <li>Scheduled Subagent Troubleshooting</li> </ul>"},{"location":"platforms/claude/questions/what-is-the-best-way-to-name-claude-agent-skills/","title":"What is the best way to name Claude agent skills?","text":"<p>Short answer: Name skills using a verb-noun pattern that describes the action and its context, like 'writing-workflow-sops' or 'registering-building-blocks', so the name alone tells you what the skill does.</p>"},{"location":"platforms/claude/questions/what-is-the-best-way-to-name-claude-agent-skills/#the-full-answer","title":"The Full Answer","text":"<p>Anthropic's official best practices recommend using gerund form (verb + -ing) as the primary naming pattern for agent skills. This clearly describes the activity or capability the skill provides. For example, <code>processing-pdfs</code> immediately tells you the skill handles PDF processing, and <code>writing-documentation</code> tells you it writes docs.</p> <p>The <code>name</code> field in a skill's YAML frontmatter has specific technical constraints: maximum 64 characters, lowercase letters, numbers, and hyphens only. You cannot use XML tags or reserved words like \"anthropic\" or \"claude\" in the name. These constraints keep names clean, URL-friendly, and consistent across the platform.</p> <p>Beyond the gerund convention, the most important principle is consistency within your skill collection. If you name one skill <code>writing-workflow-sops</code>, don't name the next one <code>sop-writer</code> or <code>create-sops</code>. Pick a pattern and stick with it. Consistent naming makes skills easier to reference in documentation, understand at a glance, search through, and maintain as your library grows.</p> <p>Noun phrases like <code>pdf-processing</code> and action-oriented names like <code>process-pdfs</code> are acceptable alternatives, but mixing patterns within the same collection creates confusion.</p>"},{"location":"platforms/claude/questions/what-is-the-best-way-to-name-claude-agent-skills/#naming-examples","title":"Naming Examples","text":"<p>Gerund form (recommended):</p> Skill Name What It Does <code>processing-pdfs</code> Handles PDF text extraction and manipulation <code>analyzing-spreadsheets</code> Analyzes tabular data in spreadsheets <code>writing-documentation</code> Generates documentation content <code>managing-databases</code> Manages database operations <code>testing-code</code> Runs and manages code tests <p>Acceptable alternatives:</p> Pattern Example Noun phrase <code>pdf-processing</code>, <code>spreadsheet-analysis</code> Action-oriented <code>process-pdfs</code>, <code>analyze-spreadsheets</code> <p>Avoid these patterns:</p> Pattern Examples Why Vague names <code>helper</code>, <code>utils</code>, <code>tools</code> Tells you nothing about what the skill does Overly generic <code>documents</code>, <code>data</code>, <code>files</code> Too broad to be useful Reserved words <code>anthropic-helper</code>, <code>claude-tools</code> Blocked by the platform Inconsistent patterns Mixing <code>writing-docs</code> with <code>pdf-processor</code> Creates confusion in your library"},{"location":"platforms/claude/questions/what-is-the-best-way-to-name-claude-agent-skills/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Use gerund form (verb + -ing) as the default naming pattern: <code>writing-</code>, <code>processing-</code>, <code>analyzing-</code></li> <li>Keep names under 64 characters using only lowercase letters, numbers, and hyphens</li> <li>Be consistent across your entire skill collection \u2014 don't mix naming patterns</li> <li>The name should tell you what the skill does without reading the description</li> <li>Avoid reserved words (<code>anthropic</code>, <code>claude</code>) and vague names (<code>helper</code>, <code>utils</code>)</li> </ul>"},{"location":"platforms/claude/questions/what-is-the-best-way-to-name-claude-agent-skills/#related-questions","title":"Related Questions","text":"<ul> <li>Official Anthropic skill authoring best practices</li> </ul>"},{"location":"platforms/claude/skills/resources/","title":"Claude Skills Resources","text":"<p>Recommended docs, tutorials, and community links for Claude Agent Skills.</p>"},{"location":"platforms/claude/skills/resources/#get-started","title":"Get Started","text":"Resource Description Introducing Agent Skills Official announcement \u2014 what Skills are and why they matter What are Skills? Help Center overview of Skill types and how they work Skills Explained How Skills compares to prompts, Projects, MCP, and subagents Using Skills in Claude How to activate and use Skills in Claude.ai"},{"location":"platforms/claude/skills/resources/#documentation","title":"Documentation","text":"Resource Description Agent Skills Overview API docs \u2014 Skill structure, progressive disclosure, and platform support Skills in Claude Code Claude Code docs \u2014 creating, configuring, and sharing Skills How to Create Custom Skills Help Center guide to building your own Skills Teach Claude Your Way of Working Practical guide to encoding your workflows as Skills"},{"location":"platforms/claude/skills/resources/#learn","title":"Learn","text":"Resource Description A Complete Guide to Building Skills for Claude (PDF) In-depth blog guide covering structure, testing, and distribution Equipping Agents for the Real World with Agent Skills Engineering blog \u2014 architecture, progressive disclosure, and best practices Improving Frontend Design through Skills Applied AI team case study \u2014 using Skills to move beyond generic AI-generated aesthetics How to Create Skills Key steps, limitations, and examples \u2014 structured 5-step creation guide Extending Claude's Capabilities with Skills and MCP Servers How Skills and MCP work together for workflows and external tools Building Agents with Skills Equipping agents for specialized work with packaged domain expertise Agent Skills Webinar Recorded webinar with live demos from Anthropic's Applied AI team Claude Code: A Highly Agentic Coding Assistant DeepLearning.AI short course covering Claude Code, MCP, and practical projects"},{"location":"platforms/claude/skills/resources/#developer-resources","title":"Developer Resources","text":"Resource Description anthropics/skills Official Skills repo \u2014 example Skills, spec, and starter template Skills Cookbook Jupyter notebooks for building Skills with the API (document, financial, custom) Skills API Cookbook Interactive API cookbook \u2014 quick-start examples for pre-built Skills"},{"location":"platforms/claude/skills/resources/#community","title":"Community","text":"Resource Description Awesome Claude Skills Curated list of Skills resources, tools, and examples Claude Skills Hub Browsable directory of downloadable Claude Code Skills"},{"location":"platforms/claude/skills/resources/#watch","title":"Watch","text":"Resource Description Stop Reprompting \u2014 Start Building Skill-Powered Workflows Lightning Lesson on packaging expertise into reusable Skills that activate automatically"},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/","title":"How to Discover Your Best Claude Skills","text":""},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/#why-this-matters","title":"Why This Matters","text":"<p>Claude Skills make Claude specific to YOUR work \u2014 not generic, but tuned to your tasks, your standards, and your formats. The best skills don't come from tasks you invent. They come from tasks you already do \u2014 the repetitive, structured work where you follow the same steps every time but the content changes.</p> <p>This guide walks you through discovering those tasks, analyzing them, and evaluating which ones are worth building into skills. You'll walk away with 3-5 evaluated skill candidates ranked by value, with your #1 pick ready to build.</p> <p>This page covers discovery and evaluation only \u2014 helping you identify what to build. A separate lesson covers the actual skill-building process.</p>"},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/#before-you-start","title":"Before You Start","text":"<ul> <li>Claude Pro subscription (or higher) \u2014 you'll paste a prompt into Claude to run the analysis in Step 2</li> <li>A text editor for your answers \u2014 Word, Google Docs, Apple Notes, Notepad \u2014 anything you can type in. You'll build up your answers across all three steps in this document, so keep it open throughout.</li> <li>Some conversation history helps \u2014 Claude can scan your past conversations and memory for patterns you haven't noticed. The more history you have, the richer the analysis. If you're new to Claude, that's fine \u2014 the process still works.</li> </ul>"},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/#step-1-speed-round","title":"Step 1 \u2014 Speed Round","text":"<p>The goal of this step is to produce a written list of 10 answers you'll feed to Claude in Step 2. You're not using Claude yet \u2014 this is just you, thinking about your own work.</p> <p>What to do:</p> <ol> <li>Copy the 10 questions below into your text editor (use the copy button in the top-right corner of the code block)</li> <li>Write your answer directly below each question \u2014 keep the question text there so Claude can see which question you're answering in Step 2</li> <li>For each answer, give it a short label (2-5 words) followed by a one-sentence description</li> <li>If a question doesn't apply to you, write \"N/A\" below it and move on</li> </ol> <p>The 10 questions \u2014 copy this entire block:</p> <pre><code>1. What task do you do weekly that follows the same steps every time?\n\n2. What output do you produce repeatedly where the format stays the same but the content changes?\n\n3. What task do you give Claude the same context or instructions for every conversation?\n\n4. What task takes you 15-30 minutes but only 2-3 minutes of actual thinking \u2014 the rest is mechanical?\n\n5. What do you copy-paste between documents or apps regularly?\n\n6. What task would you delegate to a smart intern \u2014 straightforward judgment, tedious execution?\n\n7. What recurring task involves reading something long and producing something short?\n\n8. What process have you already built your own template, checklist, or SOP for?\n\n9. What task drops in quality when you're tired \u2014 where consistency matters more than creativity?\n\n10. What task do you use Claude for conversationally but wish it just \"knew how\" to do?\n</code></pre> <p>Your first instinct is usually right</p> <p>Don't try to think of the \"best\" answer. The point is to surface real work, not impressive-sounding work. If your answer is \"formatting invoices\" \u2014 that's a great candidate.</p> <p>Here's what your finished answers should look like. Notice the question stays \u2014 you type your answer on the line below it:</p> <ol> <li> <p>What task do you do weekly that follows the same steps every time? Weekly status report \u2014 Every Monday I gather updates from Slack, email, and our project board, then write a summary for my manager in the same format.</p> </li> <li> <p>What output do you produce repeatedly where the format stays the same but the content changes? Client proposal intro sections \u2014 Same structure every time: who we are, what we understand about their problem, proposed approach. Only the client details change.</p> </li> <li> <p>What task do you give Claude the same context or instructions for every conversation? Meeting notes cleanup \u2014 I paste raw meeting notes and ask Claude to extract action items, decisions, and owners. Same instructions every time.</p> </li> <li> <p>What task takes you 15-30 minutes but only 2-3 minutes of actual thinking \u2014 the rest is mechanical? N/A</p> </li> </ol> <p>(\u2026and so on for all 10 questions)</p> <p>Once you have all 10 answered in your text editor, move to Step 2.</p>"},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/#step-2-analyze-your-answers","title":"Step 2 \u2014 Analyze Your Answers","text":"<p>Now you'll hand your answers to Claude and let it do the analysis. Here's exactly what to do:</p> <ol> <li>Open a new conversation in Claude</li> <li>Copy the entire prompt below (use the copy button in the top-right corner of the code block)</li> <li>Before you send it: scroll to the bottom of the prompt and find the line that says <code>[PASTE YOUR 10 ANSWERS HERE]</code> \u2014 delete that line and paste in your questions and answers from Step 1 (the whole block \u2014 questions included)</li> <li>Send the prompt</li> </ol> <pre><code>You are a Skills Discovery Analyst. Your job is to analyze my work patterns and identify my strongest Claude Skill candidates \u2014 tasks that are repeatable, structured, and would benefit from being encoded as a reusable skill rather than re-prompted every time.\n\nI've answered 10 discovery questions below. Use them as your primary input.\n\nALSO DO THIS (mandatory):\n- Scan my conversation history for recurring tasks, repeated instructions, or patterns I might not have mentioned.\n- Check my memory for stored preferences, workflows, or context that suggests additional candidates.\n- If you find relevant patterns from history or memory, include them in your analysis and note where they came from.\n\n## Your Analysis\n\nProduce the following:\n\n### 1. Candidate Table\n\nA table of 5-8 skill candidates, ranked by Skill Score (highest first):\n\n| # | Candidate Name | What It Does | How Often | Skill Score (1-5) |\n|---|---------------|-------------|-----------|-------------------|\n\nSkill Score criteria:\n- **5** \u2014 Daily/weekly, identical steps every time, highly mechanical, clear input\u2192output\n- **4** \u2014 Weekly, mostly identical steps, some minor variation, clear format\n- **3** \u2014 Weekly/biweekly, consistent structure but moderate judgment needed\n- **2** \u2014 Monthly or variable frequency, some structure but significant judgment\n- **1** \u2014 Infrequent, loosely structured, mostly creative/judgment work\n\n### 2. Top 3 Deep Dive\n\nFor each of your top 3 candidates, explain:\n- **Why it scored high** \u2014 what makes this a strong skill candidate\n- **What the skill would do** \u2014 a 2-3 sentence description of the skill's function\n- **Input \u2192 Output** \u2014 what goes in, what comes out\n\n### 3. Patterns from History\n\nNote what you found (if anything) from scanning my conversation history and memory. Be specific \u2014 \"I noticed you've asked me to format meeting notes 12 times in the last month\" is useful. \"No additional patterns found\" is fine if there aren't any.\n\n---\n\n## My Speed Round Answers\n\n[PASTE YOUR 10 ANSWERS HERE]\n</code></pre> <p>Attach your documents for richer results</p> <p>If you have SOPs, templates, checklists, or process docs related to your answers, attach them to the conversation before sending the prompt. Claude will use them to produce more specific and accurate candidates.</p>"},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/#what-to-expect","title":"What to Expect","text":"<p>Claude will return:</p> <ul> <li>A table of 5-8 candidates sorted by Skill Score (highest first)</li> <li>A detailed breakdown of your top 3 \u2014 why they scored high, what the skill would do, and what goes in vs. comes out</li> <li>Notes on patterns it found in your conversation history (if any)</li> </ul> <p>The whole analysis typically fits in one response. Once you have it, copy Claude's candidate table into your text editor \u2014 you'll need it for Step 3.</p>"},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/#step-3-evaluate-your-candidates","title":"Step 3 \u2014 Evaluate Your Candidates","text":"<p>Don't build yet. Score each candidate first so you build the right one.</p> <p>Copy the scoring table below into your text editor, underneath Claude's analysis from Step 2. Fill in one row for each of your top candidates.</p> <p>Scoring dimensions (score each 1-5):</p> Dimension 1 (Low) 5 (High) Repeatability Rarely, unpredictable timing Daily or weekly, like clockwork Consistency Need Quality can vary, no one notices Must be the same quality every time, regardless of your energy Mechanical vs. Judgment Mostly creative thinking, unique decisions each time Mostly following steps, filling in templates, applying rules <p>Scoring table \u2014 copy this into your text editor and fill it in:</p> <pre><code>Candidate               | Repeatability (1-5) | Consistency (1-5) | Mechanical (1-5) | Total (/15)\n----------------------- | ------------------- | ----------------- | ----------------- | -----------\n                        |                     |                   |                   |\n                        |                     |                   |                   |\n                        |                     |                   |                   |\n                        |                     |                   |                   |\n</code></pre> <p>How to read your scores:</p> <ul> <li>12-15 \u2014 Strong skill candidate. Build it.</li> <li>9-11 \u2014 Decent candidate. Could be a skill, but check the decision framework below to confirm.</li> <li>Below 9 \u2014 A Claude Project with custom instructions is probably a better fit than a full skill.</li> </ul> <p>Your top 1-2 candidates are what you'll build in the next lesson.</p>"},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/#skill-project-or-prompt","title":"Skill, Project, or Prompt?","text":"<p>Not everything should be a skill. Here's how to tell which approach fits best.</p> <p>Walk through these four questions for any candidate you're considering:</p> <ol> <li> <p>Do you do this more than once a month?</p> <ul> <li>NO \u2192 Just use a prompt. Write it well, save it somewhere, and reuse it when you need it.</li> <li>YES \u2192 Continue to question 2.</li> </ul> </li> <li> <p>Do you follow the same steps each time?</p> <ul> <li>NO \u2192 Better as a Project with custom instructions. Projects give Claude ongoing context without rigid steps.</li> <li>YES \u2192 Continue to question 3.</li> </ul> </li> <li> <p>Does it require specific formatting or standards Claude doesn't know by default?</p> <ul> <li>NO \u2192 A saved prompt template may be enough. Try that first.</li> <li>YES \u2192 Continue to question 4.</li> </ul> </li> <li> <p>Do you give Claude the same instructions repeatedly for this task?</p> <ul> <li>YES \u2192 This is a strong Skill candidate. Build it.</li> <li>NO \u2192 Revisit whether a Project with good custom instructions would cover it.</li> </ul> </li> </ol>"},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/#comparison","title":"Comparison","text":"Approach Best For Example Prompt One-off or infrequent tasks \"Summarize this PDF\" Project Recurring context without rigid steps Client research workspace Skill Repeatable process with consistent format and standards Weekly status report generation"},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/#worked-example-meeting-notes-to-action-items","title":"Worked Example \u2014 Meeting Notes to Action Items","text":"<p>Here's the full journey for one candidate, so you can see what each step produces.</p>"},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/#step-1-speed-round-answer","title":"Step 1 \u2014 Speed Round Answer","text":"<p>Meeting notes cleanup \u2014 After every meeting, I paste raw notes into Claude and ask it to extract action items with owners, key decisions, and follow-ups. Same format every time, same instructions every time. I do this 4-5 times a week.</p>"},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/#step-2-what-claudes-analysis-produced","title":"Step 2 \u2014 What Claude's Analysis Produced","text":"# Candidate Name What It Does How Often Skill Score 1 Meeting Notes \u2192 Action Items Extracts structured action items, decisions, and follow-ups from raw meeting notes 4-5x/week 5 <p>Why it scored high: Daily frequency, identical instructions every time, clear input (raw notes) and output (formatted action items), almost entirely mechanical \u2014 the \"thinking\" is in the meeting, not in the extraction.</p> <p>What the skill would do: Accept raw meeting notes (pasted text or attached document), extract all action items with assigned owners and due dates, list key decisions made, flag open questions and follow-ups, and output everything in a consistent Markdown format.</p> <p>Input \u2192 Output: Raw meeting notes \u2192 Formatted document with Action Items table, Decisions list, and Follow-ups list.</p>"},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/#step-3-evaluation-scores","title":"Step 3 \u2014 Evaluation Scores","text":"<pre><code>Candidate                    | Repeatability | Consistency | Mechanical | Total\n---------------------------- | ------------- | ----------- | ---------- | -----\nMeeting Notes \u2192 Action Items | 5             | 5           | 4          | 14/15\n</code></pre> <ul> <li>Repeatability: 5 \u2014 4-5 times per week, every week</li> <li>Consistency Need: 5 \u2014 Team depends on the same format; inconsistency causes confusion about who owns what</li> <li>Mechanical: 4 \u2014 Almost entirely pattern extraction. The only judgment is occasionally deciding if something is an \"action item\" or just a \"discussion point\" \u2014 but even that follows a rule (does it have an owner and a deadline?)</li> </ul>"},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/#decision-framework-check","title":"Decision Framework Check","text":"<ol> <li>More than once a month? Yes (4-5x/week)</li> <li>Same steps each time? Yes (paste notes, extract items, format output)</li> <li>Requires specific formatting Claude doesn't know? Yes (custom action item template with owner, due date, priority)</li> <li>Same instructions repeatedly? Yes (identical prompt every time)</li> </ol> <p>Verdict: Build it as a skill.</p>"},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/#tips-for-better-results","title":"Tips for Better Results","text":"<ul> <li>Be specific in your Speed Round \u2014 \"client onboarding emails\" beats \"email stuff\"</li> <li>Use real pain \u2014 what actually frustrates you or eats your time, not what \"should\" be automated</li> <li>Trust the patterns \u2014 Claude spots repetition in your conversation history that you don't consciously see</li> <li>Start with your highest-scoring candidate, not your most ambitious idea</li> <li>Iterate after you build \u2014 v1.0 is always a draft. Use it a few times, then refine</li> </ul>"},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/#next-steps","title":"Next Steps","text":"<p>You now have evaluated skill candidates ranked by value. Here's what to do with them:</p> <ul> <li>Take your #1 candidate to the skill-building lesson and turn it into a working Claude Skill</li> <li>Save your candidate list \u2014 you'll likely come back and build 3-5 of them over time</li> <li>Re-run the discovery process in a few weeks \u2014 as you use Claude more, new patterns will emerge</li> </ul>"},{"location":"platforms/claude/skills/skills-discovery-meta-prompt/#related","title":"Related","text":"<ul> <li>Discover AI Workflow Opportunities \u2014 Discover which workflows have the highest AI potential</li> <li>Deconstruct Workflows \u2014 Break down complex workflows into discrete, automatable steps</li> <li>Write Custom Workspace Instructions \u2014 Set up Claude Projects with tailored instructions</li> <li>Claude Projects Setup \u2014 Set up Claude Projects for recurring work</li> </ul>"},{"location":"platforms/claude/subagents/scheduling-subagent-issues/","title":"Scheduled Subagent Troubleshooting","text":"<p>Common issues and solutions when running scheduled Claude Code subagents.</p>"},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#first-step-ask-claude-code","title":"First Step: Ask Claude Code","text":"<p>Before diving into manual troubleshooting, ask Claude Code to diagnose the problem:</p> <pre><code>My claude-research-daily subagent isn't working. Can you check what's wrong?\n</code></pre> <p>Claude Code can check your subagent's status, review logs, and identify common issues automatically.</p>"},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#quick-diagnosis-checklist","title":"Quick Diagnosis Checklist","text":"<p>If you prefer to check manually:</p> <ul> <li> Is Claude Code authenticated? (Ask: \"Are you authenticated?\")</li> <li> Is the script executable? (macOS only)</li> <li> Is the schedule loaded/active?</li> <li> Are logs being created?</li> <li> Does the subagent work when run manually?</li> </ul>"},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#common-issues","title":"Common Issues","text":""},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#both-platforms","title":"Both Platforms","text":""},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#claude-code-authentication-expired","title":"Claude Code Authentication Expired","text":"<p>Symptoms: - Subagent runs but produces no output - Logs show authentication error</p> <p>Solution:</p> <p>Ask Claude Code: \"Check if you're authenticated and help me log in if needed.\"</p> <p>Or run directly: <pre><code>claude auth status\nclaude auth login\n</code></pre></p> <p>After re-authenticating, your scheduled subagents will work again\u2014no need to recreate them.</p>"},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#subagent-runs-but-no-output-file-created","title":"Subagent Runs But No Output File Created","text":"<p>Symptoms: - Logs show subagent started - No error messages - Expected digest/report file doesn't exist</p> <p>Possible causes: 1. Wrong working directory - Subagent can't find its configuration file 2. Output path doesn't exist - The reports folder wasn't created 3. Subagent configuration issue - Something in the subagent's markdown file needs adjustment</p> <p>Solutions:</p> <p>Ask Claude Code: \"My claude-research-daily ran but I don't see the digest file. What happened?\"</p> <p>Or check manually: 1. Verify the subagent configuration file is in the working directory 2. Verify output directory exists (<code>~/reports/</code> or <code>C:\\Users\\YourName\\reports\\</code>) 3. Review logs to see what Claude actually did</p>"},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#subagent-works-manually-but-not-on-schedule","title":"Subagent Works Manually But Not On Schedule","text":"<p>Symptoms: - Running the script directly works fine - Scheduled runs fail or produce no output</p> <p>Solution:</p> <p>Ask Claude Code: \"My claude-research-daily works when I run it manually but not on schedule. What's different?\"</p> <p>Common causes: - Environment variables differ in scheduled context - Working directory is wrong - Path to <code>claude</code> command not found</p>"},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#macos-specific-issues","title":"macOS-Specific Issues","text":""},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#subagent-not-appearing-in-schedule-list","title":"Subagent Not Appearing in Schedule List","text":"<p>Symptoms: - <code>launchctl list | grep claude</code> shows nothing - You loaded the plist but nothing happened</p> <p>Solution:</p> <p>Ask Claude Code: \"I tried to set up my claude-research-daily subagent but it's not showing up in launchctl. Can you check the plist file?\"</p> <p>Claude Code will validate the plist syntax and check that the Label matches the filename.</p>"},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#permission-denied","title":"Permission Denied","text":"<p>Symptoms: - Error: \"Permission denied\" in logs - Script won't execute</p> <p>Solution:</p> <p>Ask Claude Code: \"My claude-research-daily script has a permission denied error. Can you fix it?\"</p> <p>Or run: <pre><code>chmod +x ~/scripts/ai-news-digest.sh\n</code></pre></p>"},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#windows-specific-issues","title":"Windows-Specific Issues","text":""},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#task-shows-but-doesnt-run","title":"Task Shows But Doesn't Run","text":"<p>Symptoms: - Task appears in Task Scheduler - \"Last Run Result\" shows error code - Task never actually executes</p> <p>Solution:</p> <p>Ask Claude Code: \"My claude-research-daily task is in Task Scheduler but shows an error. What's wrong?\"</p> <p>Common fixes: - Check \"Run whether user is logged on or not\" in task properties - Uncheck \"Start only if on AC power\" if on a laptop - Verify the script path is correct</p>"},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#powershell-execution-policy-error","title":"PowerShell Execution Policy Error","text":"<p>Symptoms: - Error about scripts being disabled</p> <p>Solution:</p> <p>Ask Claude Code: \"I'm getting a PowerShell execution policy error with my subagent. How do I fix it?\"</p> <p>The task action should use: <pre><code>powershell.exe -ExecutionPolicy Bypass -File \"C:\\Scripts\\your-script.ps1\"\n</code></pre></p>"},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#how-to-check-logs","title":"How to Check Logs","text":"<p>Ask Claude Code: <pre><code>Show me the logs from my claude-research-daily subagent's last run.\n</code></pre></p> <p>Or: <pre><code>Are there any errors in my subagent logs?\n</code></pre></p>"},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#manual-log-commands-reference","title":"Manual Log Commands (Reference)","text":"<p>macOS: <pre><code>cat $(ls -t ~/Library/Logs/claude-subagents/*.log | head -1)\n</code></pre></p> <p>Windows PowerShell: <pre><code>Get-Content (Get-ChildItem \"C:\\Users\\$env:USERNAME\\Logs\\claude-subagents\\*.log\" | Sort-Object LastWriteTime -Descending | Select-Object -First 1)\n</code></pre></p>"},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#how-to-remove-a-subagent","title":"How to Remove a Subagent","text":"<p>Ask Claude Code: <pre><code>Remove my claude-research-daily subagent completely, including all the files.\n</code></pre></p> <p>Claude Code will unload the schedule and delete the associated files for you.</p>"},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#manual-removal-reference","title":"Manual Removal (Reference)","text":"<p>macOS: <pre><code>launchctl unload ~/Library/LaunchAgents/local.claude.ainewsdigest.plist\nrm ~/Library/LaunchAgents/local.claude.ainewsdigest.plist\nrm ~/scripts/ai-news-digest.sh\n</code></pre></p> <p>Windows: - Open Task Scheduler \u2192 Find task \u2192 Right-click \u2192 Delete - Delete the script file from <code>C:\\Scripts\\</code></p>"},{"location":"platforms/claude/subagents/scheduling-subagent-issues/#getting-help","title":"Getting Help","text":"<p>If you've tried the above and still have issues:</p> <ol> <li> <p>Ask Claude Code for a full diagnosis: <pre><code>My claude-research-daily subagent isn't working. Run a full diagnosis and\ntell me everything that might be wrong.\n</code></pre></p> </li> <li> <p>Test Claude Code directly: <pre><code>cd ~/agents/ai-news\nclaude -p \"Test: what's the latest AI news today?\"\n</code></pre>    If this fails, the issue is with Claude Code itself, not the scheduling.</p> </li> <li> <p>Post in the course Slack with:</p> </li> <li>Your operating system</li> <li>The error message (exact text)</li> <li>What you've already tried</li> </ol>"},{"location":"platforms/claude/subagents/scheduling-subagents/","title":"Scheduling Claude Code Subagents","text":"<p>Set up your Claude Code subagents to run automatically on a schedule\u2014like a research assistant that gathers information while you sleep.</p> <p>Key concept: You already have a subagent defined. Now you're telling Claude Code to run it on a schedule. Claude Code creates all the configuration files and activates it for you.</p> <p>Official docs: Claude Code CLI Reference</p>"},{"location":"platforms/claude/subagents/scheduling-subagents/#prerequisites","title":"Prerequisites","text":"<ul> <li>Claude Code installed and authenticated (see Claude Code Setup Guide)</li> <li>A subagent already created with its configuration in a markdown file</li> <li>PowerShell access (Windows)</li> </ul>"},{"location":"platforms/claude/subagents/scheduling-subagents/#important-update-your-claudemd-first","title":"Important: Update Your CLAUDE.md First","text":"<p>Before scheduling any subagent, you must add scheduling instructions to your project's CLAUDE.md file. This tells Claude Code how to properly set up scheduled tasks (logging, permissions, etc.).</p> <p>Add this section to your CLAUDE.md:</p> macOSWindows <pre><code>## Scheduling Subagents\n\nWhen setting up scheduled tasks for subagents:\n- Use `claude -p \"prompt\" --dangerously-skip-permissions` to allow headless tool use (required for agents that write files)\n- Use the full path to claude binary (e.g., `~/.local/bin/claude`) since launchd runs with minimal PATH\n- Always include logging to capture stdout/stderr for troubleshooting\n- Store logs in the project's `logs/scheduled/` folder so they're easy to find\n- Include timestamps in log filenames for easy debugging\n</code></pre> <pre><code>## Scheduling Subagents\n\nWhen setting up scheduled tasks for subagents:\n- Use `claude -p \"prompt\" --dangerously-skip-permissions` to allow headless tool use (required for agents that write files)\n- Use the full path to claude binary (e.g., `%LOCALAPPDATA%\\Programs\\claude-code\\claude.exe`) since Task Scheduler runs with minimal PATH\n- Always include logging to capture stdout/stderr for troubleshooting\n- Store logs in the project's `logs/scheduled/` folder so they're easy to find\n- Include timestamps in log filenames for easy debugging\n\n### Windows-specific\n- **Always write PowerShell to `.ps1` files** rather than running inline commands - `$` variables get stripped when passing PowerShell through Git Bash\n- Create a runner script (e.g., `scripts/run-&lt;agent-name&gt;.ps1`) and a setup script (e.g., `scripts/setup-&lt;agent-name&gt;-schedule.ps1`)\n- Use `Register-ScheduledTask` in the setup script to register with Task Scheduler\n</code></pre> <p>Why is this necessary? Without these instructions, Claude Code won't know to use the special flags needed for scheduled (headless) operation, and your subagent will fail silently.</p> <p>Your project's CLAUDE.md should include these instructions.</p>"},{"location":"platforms/claude/subagents/scheduling-subagents/#example-scheduling-the-claude-research-daily-subagent","title":"Example: Scheduling the \"claude-research-daily\" Subagent","text":"<p>This repo includes a working example subagent called <code>claude-research-daily</code> that researches the latest Claude and Anthropic news. You can find it at:</p> <pre><code>.claude/agents/claude-research-daily.md\n</code></pre> <p>Let's schedule it to run automatically every weekday morning.</p>"},{"location":"platforms/claude/subagents/scheduling-subagents/#step-1-ask-claude-code-to-schedule-your-subagent","title":"Step 1: Ask Claude Code to Schedule Your Subagent","text":"<p>Open Claude Code in this repo folder, then use a prompt like this:</p> macOSWindows <pre><code>Schedule my claude-research-daily subagent to run every weekday at 7:30 AM on macOS.\n</code></pre> <pre><code>Schedule my claude-research-daily subagent to run every weekday at 7:30 AM on Windows.\n</code></pre> <p>Claude Code will automatically set up logging based on the instructions in your CLAUDE.md file.</p>"},{"location":"platforms/claude/subagents/scheduling-subagents/#step-2-claude-code-sets-everything-up","title":"Step 2: Claude Code Sets Everything Up","text":"<p>Claude Code will create everything for you:</p> macOSWindows <ol> <li><code>scripts/</code> folder - Contains the wrapper script for your subagent</li> <li>Wrapper script - Customized with your project's paths</li> <li>Schedule configuration - Tells macOS when to run it</li> <li>Logs folder - For troubleshooting</li> </ol> <ol> <li><code>scripts/</code> folder - Contains the PowerShell script for your subagent</li> <li>PowerShell script - Customized with your project's paths</li> <li>Scheduled task - Registered in Task Scheduler</li> <li>Logs folder - For troubleshooting</li> </ol> <p>You don't need to create or edit any files yourself\u2014Claude Code handles all of it and uses the correct paths for your machine.</p>"},{"location":"platforms/claude/subagents/scheduling-subagents/#step-3-test-it","title":"Step 3: Test It","text":"<p>Ask Claude Code to run the subagent now to make sure everything works:</p> <pre><code>Run my claude-research-daily subagent now so I can test it.\n</code></pre> <p>Then check that your research file was created:</p> <pre><code>Show me the output from claude-research-daily.\n</code></pre> <p>You should see a file in the <code>outputs/</code> folder like <code>claude-research-daily-2026-01-27.md</code>.</p>"},{"location":"platforms/claude/subagents/scheduling-subagents/#common-scheduling-patterns","title":"Common Scheduling Patterns","text":"<p>Here are typical schedules for different types of subagents:</p> Subagent Type Suggested Schedule Example Prompt Daily news/research Weekdays at 7-8 AM \"Run every weekday at 7:30 AM\" Competitor monitoring Weekly on Monday \"Run every Monday at 8:00 AM\" Weekly summaries Friday afternoon \"Run every Friday at 4:00 PM\" Frequent updates Every few hours \"Run every 4 hours during business hours\""},{"location":"platforms/claude/subagents/scheduling-subagents/#example-scheduling-a-weekly-subagent","title":"Example: Scheduling a Weekly Subagent","text":"<pre><code>Schedule my competitor-watch subagent to run every Monday at 8:00 AM.\n</code></pre>"},{"location":"platforms/claude/subagents/scheduling-subagents/#managing-your-subagents","title":"Managing Your Subagents","text":"<p>Ask Claude Code to manage your subagents\u2014no need to memorize commands.</p> What you want Ask Claude Code See your subagents \"What scheduled subagents do I have running?\" Pause a subagent \"Pause my claude-research-daily subagent\" Resume a subagent \"Resume my claude-research-daily subagent\" Change the schedule \"Change claude-research-daily to run at 6:00 AM instead\" Update the goal \"Update claude-research-daily to also include robotics news\" Remove a subagent \"Remove my claude-research-daily subagent schedule completely\" Check status \"Is my claude-research-daily subagent running properly?\" View logs \"Show me the logs from claude-research-daily's last run\""},{"location":"platforms/claude/subagents/scheduling-subagents/#example-updating-your-subagents-schedule","title":"Example: Updating Your Subagent's Schedule","text":"<pre><code>Change my claude-research-daily subagent to run at 6:00 AM instead of 7:30 AM.\n</code></pre> <p>Claude Code will update the configuration and reload it for you.</p>"},{"location":"platforms/claude/subagents/scheduling-subagents/#quick-troubleshooting","title":"Quick Troubleshooting","text":"<p>Subagent not running?</p> <p>Ask Claude Code: \"Check if my claude-research-daily subagent is working and tell me what's wrong.\"</p> <p>No output file created?</p> <p>Ask Claude Code: \"My claude-research-daily ran but I don't see an output file. What happened?\"</p> <p>Want to see what happened?</p> <p>Ask Claude Code: \"Show me the logs from claude-research-daily's last run.\"</p> <p>For more detailed troubleshooting, see Scheduled Subagent Troubleshooting.</p>"},{"location":"platforms/claude/subagents/scheduling-subagents/#how-it-works-behind-the-scenes","title":"How It Works (Behind the Scenes)","text":"macOSWindows <p>When Claude Code schedules a subagent on macOS, it uses launchd\u2014the built-in macOS scheduling system. Claude Code creates:</p> <ol> <li>Wrapper script - Runs your subagent with proper logging</li> <li>Plist file - Tells macOS when to run the script</li> </ol> <p>The wrapper script uses special flags for headless operation: - <code>--dangerously-skip-permissions</code> - Allows the agent to use tools (like writing files) without prompting for confirmation - Full path to claude binary - Since launchd runs with minimal PATH</p> <p>The nice thing about launchd: if your Mac is asleep at the scheduled time, it runs the subagent when your Mac wakes up. So your 7:30 AM research digest still gets created even if your Mac was closed.</p> <p>When Claude Code schedules a subagent on Windows, it uses Task Scheduler\u2014the built-in Windows scheduling system. Claude Code creates:</p> <ol> <li>PowerShell script - Runs your subagent with proper logging</li> <li>Scheduled task - Tells Windows when to run the script</li> </ol> <p>The PowerShell script uses special flags for headless operation: - <code>--dangerously-skip-permissions</code> - Allows the agent to use tools (like writing files) without prompting for confirmation - Full path to claude binary - Since Task Scheduler runs with minimal PATH</p> <p>Important PowerShell details:</p> <ul> <li>Always write PowerShell to <code>.ps1</code> files rather than running inline commands\u2014<code>$</code> variables get stripped when passing PowerShell through Git Bash</li> <li>Claude Code creates a runner script (e.g., <code>scripts/run-&lt;agent-name&gt;.ps1</code>) and a setup script (e.g., <code>scripts/setup-&lt;agent-name&gt;-schedule.ps1</code>)</li> <li>The setup script uses <code>Register-ScheduledTask</code> to register with Task Scheduler</li> </ul> <p>You can see your scheduled subagents in Task Scheduler if you're curious (press <code>Win + R</code>, type <code>taskschd.msc</code>), but you don't need to\u2014Claude Code can manage everything for you.</p> <p>macOS: Background Activity Notification</p> <p>The first time your scheduled subagent runs, macOS will show a notification about background activity.</p> <p>This is normal and expected. It's macOS letting you know a new scheduled task is running.</p> <p>If you click the notification, you'll see the Login Items &amp; Extensions panel in System Settings. Your script will appear in the list:</p> <p></p> <p></p> <p>Important:</p> <ul> <li>Keep the toggle ON (blue) \u2014 this allows your scheduled task to run</li> <li>\"Unidentified developer\" is normal \u2014 it's your own script, not from the App Store</li> <li>If you turn it OFF, your scheduled subagent will stop running</li> </ul> <p>If you accidentally turned it off:</p> <ol> <li>Open System Settings (click Apple menu  \u2192 System Settings)</li> <li>Click General in the left sidebar</li> <li>Click Login Items &amp; Extensions</li> <li>Scroll down to the App Background Activity section</li> <li>Find your script (e.g., <code>run-claude-research-daily.sh</code>)</li> <li>Toggle it back ON</li> </ol>"},{"location":"platforms/claude/subagents/scheduling-subagents/#next-steps","title":"Next Steps","text":"<ul> <li>Try scheduling the <code>claude-research-daily</code> subagent using the example above</li> <li>Test it manually before relying on the schedule</li> <li>Check the <code>outputs/</code> folder the next morning for your research digest</li> <li>Create your own subagents and schedule them the same way</li> </ul>"},{"location":"platforms/claude/topics/","title":"Claude","text":"<p>Documentation for Anthropic's Claude models.</p>"},{"location":"platforms/claude/topics/#topics","title":"Topics","text":"<p>Topics will be listed here as they are added.</p>"},{"location":"platforms/claude/topics/#key-features","title":"Key Features","text":"<ul> <li>Claude 3.5 Sonnet - Fast, capable model</li> <li>Claude 3 Opus - Most capable model</li> <li>Tool Use - Function calling and tool execution</li> <li>Vision - Image understanding</li> <li>Extended Context - Large context windows</li> </ul>"},{"location":"platforms/claude/topics/#resources","title":"Resources","text":"<ul> <li>Anthropic Documentation</li> <li>Claude API Reference</li> <li>Prompt Library</li> </ul>"},{"location":"platforms/claude/topics/resources/","title":"Claude Resources","text":"<p>Recommended articles, docs, and courses for Anthropic's Claude.</p>"},{"location":"platforms/claude/topics/resources/#get-started","title":"Get Started","text":"Resource Description claude.ai Claude web app Download Claude Desktop (macOS, Windows) and mobile (iOS, Android) apps Pricing Plans: Free, Pro, Team, Enterprise"},{"location":"platforms/claude/topics/resources/#learn","title":"Learn","text":"Resource Description Anthropic Academy Free courses with certificates (Claude 101, Claude Code in Action) AI Learning Hub Guides for building, work, and personal use Build with Claude Step-by-step API development guide Anthropic Courses on GitHub Official course materials and notebooks"},{"location":"platforms/claude/topics/resources/#documentation","title":"Documentation","text":"Resource Description Claude API Docs API reference and developer guides Claude Code Docs CLI tool documentation and quickstart Help Center FAQs, account help, and support Release Notes Product updates and changelog"},{"location":"platforms/claude/topics/resources/#developer-tools","title":"Developer Tools","text":"Resource Description Anthropic GitHub Official repositories Claude Code Agentic coding tool repo Claude Quickstarts Sample projects for API integration Official Plugins Anthropic-maintained Claude Code plugins Developer Platform API console and key management"},{"location":"platforms/claude/topics/resources/#stay-updated","title":"Stay Updated","text":"Resource Description Anthropic News Company announcements and product launches Engineering Blog Technical insights and best practices YouTube Product demos, conference talks, tutorials @AnthropicAI on X Company updates @claudeai on X Product updates and tips LinkedIn Company news Discord Developer community Developer Newsletter Monthly feature updates and best practices"},{"location":"platforms/claude/topics/resources/#research-safety","title":"Research &amp; Safety","text":"Resource Description Research Hub AI safety research Alignment Science Safety research notes System Status Real-time service monitoring"},{"location":"platforms/google-gemini/","title":"Google Gemini","text":"<p>Guides and resources for working with Google's Gemini models.</p>"},{"location":"platforms/google-gemini/#agents","title":"Agents","text":"Guide Description Building Agents on Google Agent Designer (no-code) and Agent Development Kit for custom agents"},{"location":"platforms/google-gemini/#topics","title":"Topics","text":"<ul> <li>Gemini Overview</li> <li>Gemini Resources</li> </ul>"},{"location":"platforms/google-gemini/#questions","title":"Questions","text":"<ul> <li>Gemini Q&amp;A</li> </ul>"},{"location":"platforms/google-gemini/agents/building-agents/","title":"Building Agents on Google","text":"<p>Part of: Build Workflows &gt; Agents</p> <p>Google offers three approaches to building agents on the Gemini platform, ranging from natural-language automation to full programmatic control.</p> Approach Best for Complexity Workspace Studio Non-technical users automating everyday work across Workspace apps Lowest \u2014 describe what you want in natural language Agent Designer Business users who want to build agents without writing code Low \u2014 no-code/low-code visual interface Agent Development Kit (ADK) Developers building custom agents for deployment on Vertex AI Higher \u2014 open-source framework, full programmatic control"},{"location":"platforms/google-gemini/agents/building-agents/#workspace-studio","title":"Workspace Studio","text":"<p>Workspace Studio is Google's natural-language automation platform built into Workspace. It lets anyone create automated workflows across Gmail, Drive, Sheets, and other Workspace apps by describing what they want in plain language \u2014 no coding or visual builder required.</p> <p>Official docs: Workspace Studio</p>"},{"location":"platforms/google-gemini/agents/building-agents/#what-you-can-build","title":"What you can build","text":"<ul> <li>Automated workflows for everyday tasks \u2014 email triage, meeting summaries, cross-app data transfer, report generation</li> <li>Multi-step automations that connect Workspace apps with third-party services</li> </ul>"},{"location":"platforms/google-gemini/agents/building-agents/#how-it-works","title":"How it works","text":"<ol> <li>Describe \u2014 tell Gemini what you want to automate in natural language</li> <li>Generate \u2014 Gemini creates a workflow from your description</li> <li>Refine \u2014 adjust the flow using pre-configured steps and connectors</li> <li>Manage \u2014 run, monitor, and edit workflows directly within Workspace apps</li> </ol>"},{"location":"platforms/google-gemini/agents/building-agents/#key-capabilities","title":"Key capabilities","text":"<ul> <li>Create automations using natural language \u2014 no code, no visual builder</li> <li>Pre-configured steps for common Workspace actions (send email, create doc, update sheet)</li> <li>Manage workflows in-app from Gmail, Chat, and Drive</li> <li>Third-party connectors for tools like Asana, Jira, Salesforce, and Mailchimp</li> <li>Included with Google Workspace Business and Enterprise plans</li> </ul>"},{"location":"platforms/google-gemini/agents/building-agents/#mapping-your-design-blueprint","title":"Mapping your Design blueprint","text":"Design blueprint Workspace Studio Name Workflow name in Studio Description Natural language description of the automation Instructions The plain-language prompt that generates the workflow Model Gemini (built-in, not configurable) Tools Workspace app actions and third-party connectors"},{"location":"platforms/google-gemini/agents/building-agents/#agent-designer","title":"Agent Designer","text":"<p>Agent Designer is a no-code, low-code platform within Gemini Enterprise for building AI agents using natural language and a visual workflow editor.</p> <p>Official docs: Agent Designer</p>"},{"location":"platforms/google-gemini/agents/building-agents/#what-you-can-build_1","title":"What you can build","text":"<ul> <li>Single-step agents \u2014 straightforward tasks with one action</li> <li>Multi-step agents \u2014 a primary agent coordinates with subagents on complex workflows</li> </ul>"},{"location":"platforms/google-gemini/agents/building-agents/#how-it-works_1","title":"How it works","text":"<p>The interface has two main sections:</p> <ul> <li>Chat pane \u2014 describe what you want the agent to do in natural language, and refine it conversationally</li> <li>Designer pane \u2014 visually edit agent workflows on an interactive canvas, plus schedule and test agents</li> </ul>"},{"location":"platforms/google-gemini/agents/building-agents/#key-capabilities_1","title":"Key capabilities","text":"<ul> <li>Create and preview agents using natural language prompts</li> <li>Visually edit agent workflows on an interactive canvas</li> <li>Connect to Google and third-party tools (Gmail, Drive, Jira)</li> <li>Schedule agent executions for recurring tasks</li> <li>No programming required for basic agent creation, with low-code options for more control</li> </ul>"},{"location":"platforms/google-gemini/agents/building-agents/#mapping-your-design-blueprint_1","title":"Mapping your Design blueprint","text":"Design blueprint Agent Designer Name Agent name in the Designer interface Description Agent description and purpose Instructions Natural language instructions in the chat pane, refined conversationally Model Gemini model selection (configured in the Designer) Tools Google and third-party tool connections (Gmail, Drive, Jira, etc.)"},{"location":"platforms/google-gemini/agents/building-agents/#agent-development-kit-adk","title":"Agent Development Kit (ADK)","text":"<p>The Agent Development Kit is an open-source framework for developing and deploying AI agents. It's designed to make agent development feel like software development \u2014 model-agnostic, deployment-agnostic, and compatible with other frameworks.</p> <p>Official docs: Agent Development Kit overview | Gemini Enterprise Agents</p>"},{"location":"platforms/google-gemini/agents/building-agents/#key-features","title":"Key features","text":"<ul> <li>Open-source \u2014 flexible and extensible framework</li> <li>Model-agnostic \u2014 optimized for Gemini but works with other models</li> <li>Deployment-agnostic \u2014 deploy anywhere, with managed hosting on Vertex AI Agent Engine</li> <li>Framework-compatible \u2014 built for interoperability with other agent frameworks</li> </ul>"},{"location":"platforms/google-gemini/agents/building-agents/#what-you-can-build_2","title":"What you can build","text":"<ul> <li>Custom agents with programmatic control over behavior and orchestration</li> <li>Multi-agent architectures with specialized agents coordinating on complex tasks</li> <li>Production agents deployed to Vertex AI Agent Engine (fully managed Google Cloud runtime)</li> </ul>"},{"location":"platforms/google-gemini/agents/building-agents/#tools-and-integrations","title":"Tools and integrations","text":"<p>ADK agents can use:</p> <ul> <li>Built-in tools \u2014 core capabilities provided by the framework</li> <li>Google Cloud tools \u2014 access to Google Cloud services</li> <li>MCP tools \u2014 connect to external services via the Model Context Protocol</li> <li>Ecosystem tools \u2014 third-party integrations</li> </ul>"},{"location":"platforms/google-gemini/agents/building-agents/#getting-started-paths","title":"Getting started paths","text":"Path Description Quickstart with Vertex AI Agent Engine Setup, development, deployment, and testing on Google Cloud Open-source quickstart Installation, basic agent setup with tools, local execution Agent Starter Pack Production-ready templates for Vertex AI Agent Engine"},{"location":"platforms/google-gemini/agents/building-agents/#mapping-your-design-blueprint_2","title":"Mapping your Design blueprint","text":"Design blueprint Agent Development Kit Name Agent name in your ADK configuration Description Agent description and metadata Instructions Agent instructions defined programmatically Model Model configuration (Gemini recommended, others supported) Tools Built-in tools, Google Cloud tools, MCP tools, or custom integrations"},{"location":"platforms/google-gemini/agents/building-agents/#whats-next","title":"What's Next","text":"<ul> <li>Agents overview \u2014 the platform-agnostic agent decision framework</li> <li>Design Your AI Workflow \u2014 produce the agent blueprint that feeds into these implementations</li> </ul>"},{"location":"platforms/google-gemini/questions/","title":"Gemini Questions","text":"<p>Questions specific to Google's Gemini models and Vertex AI.</p>"},{"location":"platforms/google-gemini/questions/#questions","title":"Questions","text":"Question Tags Questions will be listed here as they are added"},{"location":"platforms/google-gemini/questions/#related-resources","title":"Related Resources","text":"<ul> <li>Gemini Topics</li> <li>Agentic Building Blocks</li> </ul>"},{"location":"platforms/google-gemini/topics/","title":"Gemini","text":"<p>Documentation for Google's Gemini models and Vertex AI.</p>"},{"location":"platforms/google-gemini/topics/#topics","title":"Topics","text":"<p>Topics will be listed here as they are added.</p>"},{"location":"platforms/google-gemini/topics/#key-features","title":"Key Features","text":"<ul> <li>Gemini 1.5 Pro - Long context, multimodal</li> <li>Gemini 1.5 Flash - Fast, efficient</li> <li>Function Calling - Tool use</li> <li>Grounding - Google Search integration</li> <li>Vertex AI - Enterprise deployment</li> </ul>"},{"location":"platforms/google-gemini/topics/#resources","title":"Resources","text":"<ul> <li>Gemini Documentation</li> <li>Vertex AI Documentation</li> <li>API Reference</li> </ul>"},{"location":"platforms/google-gemini/topics/resources/","title":"Gemini Resources","text":"<p>Recommended articles, docs, and courses for Google's Gemini models.</p>"},{"location":"platforms/google-gemini/topics/resources/#get-started","title":"Get Started","text":"Resource Description gemini.google.com Gemini web app Download Gemini Mobile app (iOS, Android) Gemini FAQ What Gemini can do and how to access it Pricing Plans: Free, Google AI Pro, Google AI Ultra"},{"location":"platforms/google-gemini/topics/resources/#learn","title":"Learn","text":"Resource Description Google AI for Developers Developer hub for Gemini API, Gemma, and more AI Studio Quickstart Get started with Google AI Studio Gemini API Cookbook Tutorials, quick starts, and practical examples Gemini 101 Learning Path Step-by-step guide using AI Studio and Node.js"},{"location":"platforms/google-gemini/topics/resources/#documentation","title":"Documentation","text":"Resource Description Gemini API Docs API reference and developer guides Gemini Models Available models and capabilities Gemini Apps Help Center FAQs, tips, and troubleshooting API Changelog API updates and release notes App Release Notes Gemini app updates and improvements"},{"location":"platforms/google-gemini/topics/resources/#developer-tools","title":"Developer Tools","text":"Resource Description Google AI Studio Browser-based prompt prototyping and API code generation Google Gemini on GitHub Official repositories (CLI, cookbook, SDKs) Gemini CLI Open-source AI agent for the terminal Gemini Code Assist AI coding assistant for IDEs and GitHub Vertex AI Enterprise AI platform with Gemini models"},{"location":"platforms/google-gemini/topics/resources/#stay-updated","title":"Stay Updated","text":"Resource Description Google DeepMind Blog AI breakthroughs, projects, and updates Google AI Blog Product announcements and launches YouTube \u2014 Google DeepMind Research talks, demos, and documentaries @GoogleDeepMind on X Research updates @GeminiApp on X Product updates and tips Gemini Apps Community User forum for questions and feedback Gemini CLI Discussions Developer community for Gemini CLI"},{"location":"platforms/google-gemini/topics/resources/#gemini-enterprise","title":"Gemini Enterprise","text":"Resource Description What is Gemini Enterprise? Overview \u2014 intranet search, AI assistant, and agentic platform for organizations Get Started with Gemini Enterprise Quickstart tutorial to create your first Gemini Enterprise app Compare Editions Feature comparison across Standard, Plus, and Frontline editions Gemini Enterprise Resources Hub Admin support, setup guides, and documentation by edition Workspace with Gemini (Admin) Admin guide for Gemini in Google Workspace (Business/Enterprise) Gemini for Workspace FAQ Frequently asked questions about Gemini in Workspace apps Gemini AI in Workspace How Gemini features are included in Workspace subscriptions What is NotebookLM Enterprise? AI-powered research tool for enterprise \u2014 compliant, admin-managed Set Up NotebookLM Enterprise Admin setup guide for authentication, IAM roles, and data residency Release Notes Latest updates including Gemini 3 Flash, Agent Designer, and semantic search"},{"location":"platforms/google-gemini/topics/resources/#gemini-in-chrome","title":"Gemini in Chrome","text":"Resource Description Gemini in Chrome Official overview \u2014 AI assistance right in your browser Chrome AI Innovations Feature showcase for Gemini-powered Chrome capabilities Chrome Gets Gemini 3 Features Google blog \u2014 side panel, auto browse, image generation, and more New AI Features for Chrome Earlier Chrome AI features including tab organization and writing help"},{"location":"platforms/google-gemini/topics/resources/#research-safety","title":"Research &amp; Safety","text":"Resource Description Google DeepMind Research AI research publications Responsibility &amp; Safety AI safety principles and practices Google Workspace Status Service status dashboard (includes Gemini)"},{"location":"platforms/m365-copilot/","title":"M365 Copilot","text":"<p>Guides and resources for working with Microsoft 365 Copilot.</p>"},{"location":"platforms/m365-copilot/#agents","title":"Agents","text":"Guide Description Building Agents on M365 Copilot Declarative agents (no-code/low-code) and custom engine agents for developers"},{"location":"platforms/m365-copilot/#topics","title":"Topics","text":"<ul> <li>M365 Copilot Overview</li> <li>M365 Copilot Resources</li> </ul>"},{"location":"platforms/m365-copilot/agents/building-agents/","title":"Building Agents on M365 Copilot","text":"<p>Part of: Build Workflows &gt; Agents</p> <p>Microsoft 365 Copilot extends its built-in capabilities through agents \u2014 specialized AI assistants tailored to specific domains. Agents can retrieve information, summarize data, and take actions like sending emails or updating records, all within the Microsoft 365 apps where you already work.</p> <p>Official docs: Agents for Microsoft 365 Copilot</p> <p>There are two approaches to building agents, depending on how much control you need.</p> Approach Best for Complexity Declarative agents Business users and developers who want agents within Copilot's orchestration Low to moderate \u2014 no-code (Copilot Studio) or pro-code (Agents Toolkit) Custom engine agents Developers who need custom orchestration, models, or external integrations Higher \u2014 bring your own orchestrator and models"},{"location":"platforms/m365-copilot/agents/building-agents/#agent-core-components","title":"Agent Core Components","text":"<p>All M365 Copilot agents share these building blocks:</p> <ul> <li>Knowledge \u2014 specialized instructions and data sources that shape the agent's responses</li> <li>Actions \u2014 triggers and workflows that automate business processes</li> <li>Orchestrator \u2014 the engine that manages how the agent interacts with knowledge and actions</li> <li>Foundation models \u2014 the AI models powering reasoning and language understanding</li> <li>User experience layer \u2014 how users interact with the agent across Microsoft 365 apps</li> </ul>"},{"location":"platforms/m365-copilot/agents/building-agents/#declarative-agents","title":"Declarative Agents","text":"<p>Declarative agents use Copilot's built-in AI infrastructure, model, and orchestrator. You configure them by adding custom instructions, knowledge, and actions \u2014 no hosting required. Because they run on Copilot's infrastructure, they inherit Microsoft 365 security, compliance, and Responsible AI standards.</p>"},{"location":"platforms/m365-copilot/agents/building-agents/#what-you-configure","title":"What you configure","text":"<ul> <li>Custom instructions \u2014 shape Copilot's responses for your organization's workflows</li> <li>Custom knowledge \u2014 connect Microsoft 365 data sources (Teams, SharePoint, OneDrive) or external data via Copilot connectors</li> <li>Custom actions \u2014 integrate with APIs to interact with external systems in real-time</li> </ul>"},{"location":"platforms/m365-copilot/agents/building-agents/#how-to-build-them","title":"How to build them","text":"Tool Audience Copilot Studio Low-code \u2014 business users and citizen developers Microsoft 365 Agents Toolkit (Visual Studio / VS Code) Pro-code \u2014 developers who want more control"},{"location":"platforms/m365-copilot/agents/building-agents/#where-they-run","title":"Where they run","text":"<p>Declarative agents run within Microsoft 365 Copilot and Microsoft 365 apps \u2014 Teams, Word, Excel, Outlook, and SharePoint. Users invoke them via @mentions or in business chats.</p>"},{"location":"platforms/m365-copilot/agents/building-agents/#when-to-use-declarative-agents","title":"When to use declarative agents","text":"<ul> <li>You want agents within Copilot's orchestration with built-in security and compliance</li> <li>Your users work within Microsoft 365 apps and want agents in that context</li> <li>You want faster implementation with no-code or low-code tools</li> <li>You don't need custom AI models or external hosting</li> </ul>"},{"location":"platforms/m365-copilot/agents/building-agents/#mapping-your-design-blueprint","title":"Mapping your Design blueprint","text":"Design blueprint Declarative agent Name Agent name in Copilot Studio or Agents Toolkit Description Agent purpose and scenario description Instructions Custom instructions that shape Copilot's responses Model Copilot's built-in foundation models (not configurable) Tools Custom actions (API integrations) + custom knowledge (Microsoft 365 data sources, connectors)"},{"location":"platforms/m365-copilot/agents/building-agents/#custom-engine-agents","title":"Custom Engine Agents","text":"<p>Custom engine agents are fully customized AI assistants. You bring your own orchestrator, choose your own models, and host the agent outside of Microsoft 365. This gives you full control over workflows, business logic, and integrations \u2014 but you're responsible for compliance, security, and hosting.</p>"},{"location":"platforms/m365-copilot/agents/building-agents/#what-you-configure_1","title":"What you configure","text":"<ul> <li>Custom orchestration \u2014 full control over workflows, with one or more language models</li> <li>Custom models \u2014 choose any model (foundation, fine-tuned, or industry-specific)</li> <li>Autonomy \u2014 agents can initiate workflows proactively, make decisions, and escalate tasks</li> </ul>"},{"location":"platforms/m365-copilot/agents/building-agents/#how-to-build-them_1","title":"How to build them","text":"Tool Audience Copilot Studio Low-code \u2014 simpler custom engine setups Microsoft 365 Agents Toolkit (Visual Studio / VS Code) Pro-code \u2014 .NET, Python, JavaScript Frameworks Semantic Kernel, LangChain, or other orchestration frameworks"},{"location":"platforms/m365-copilot/agents/building-agents/#where-they-run_1","title":"Where they run","text":"<p>Custom engine agents run in Microsoft 365 apps (Teams, Word, Outlook) and external apps and websites \u2014 customer service portals, internal dashboards, or any web application.</p>"},{"location":"platforms/m365-copilot/agents/building-agents/#when-to-use-custom-engine-agents","title":"When to use custom engine agents","text":"<ul> <li>You need custom orchestration for complex workflows or specific business logic</li> <li>You want to use your own AI models (domain-specific, fine-tuned, or multimodal)</li> <li>You need group collaboration where multiple users interact with the same agent</li> <li>You want agents available outside Microsoft 365</li> <li>You need proactive messaging \u2014 agents that trigger actions without user input</li> <li>You're integrating an existing conversational assistant with Microsoft 365</li> </ul>"},{"location":"platforms/m365-copilot/agents/building-agents/#mapping-your-design-blueprint_1","title":"Mapping your Design blueprint","text":"Design blueprint Custom engine agent Name Agent name in your code or Copilot Studio Description Agent purpose and scenario description Instructions Custom orchestration logic and agent behavior Model Your chosen model (Azure OpenAI, open-source, fine-tuned, etc.) Tools API integrations, Microsoft Graph, external system connections <p>For multi-agent workflows, custom engine agents support agent-to-agent communication \u2014 agents can delegate tasks and coordinate workflows across your organization.</p>"},{"location":"platforms/m365-copilot/agents/building-agents/#choosing-between-approaches","title":"Choosing Between Approaches","text":"Feature Declarative agents Custom engine agents Hosting Hosted in Microsoft 365 \u2014 no additional infrastructure Requires external hosting (Azure or other cloud) Models Copilot's built-in models Any model you choose Customization Instructions, knowledge, and actions within Copilot's framework Fully customizable orchestration, models, and logic Proactive actions User-initiated only Can trigger actions automatically Where it runs Microsoft 365 apps only Microsoft 365 apps + external apps and websites Compliance Inherits Microsoft 365 standards You manage compliance and security <p>Start with declarative agents if your workflow fits within Microsoft 365 and you want built-in security and faster setup. Move to custom engine agents when you need custom models, external integrations, or proactive behavior.</p>"},{"location":"platforms/m365-copilot/agents/building-agents/#whats-next","title":"What's Next","text":"<ul> <li>Agents overview \u2014 the platform-agnostic agent decision framework</li> <li>Design Your AI Workflow \u2014 produce the agent blueprint that feeds into these implementations</li> </ul>"},{"location":"platforms/m365-copilot/topics/","title":"M365 Copilot","text":"<p>Documentation for Microsoft 365 Copilot and Azure OpenAI.</p>"},{"location":"platforms/m365-copilot/topics/#topics","title":"Topics","text":"<p>Topics will be listed here as they are added.</p>"},{"location":"platforms/m365-copilot/topics/#key-features","title":"Key Features","text":"<ul> <li>M365 Copilot - AI assistant in Microsoft 365 apps</li> <li>Azure OpenAI - Enterprise OpenAI deployment</li> <li>Copilot Studio - Custom copilot builder</li> <li>Microsoft Graph - Data integration</li> <li>Semantic Index - Enterprise search</li> </ul>"},{"location":"platforms/m365-copilot/topics/#resources","title":"Resources","text":"<ul> <li>M365 Copilot Documentation</li> <li>Azure OpenAI Documentation</li> <li>Copilot Studio</li> </ul>"},{"location":"platforms/m365-copilot/topics/resources/","title":"M365 Copilot Resources","text":"<p>Recommended articles, docs, and courses for Microsoft 365 Copilot.</p>"},{"location":"platforms/m365-copilot/topics/resources/#get-started","title":"Get Started","text":"Resource Description Microsoft 365 Copilot Product overview Copilot Chat Web-based Copilot chat Pricing \u2014 Individuals Personal and family plans Pricing \u2014 Business Business and enterprise plans"},{"location":"platforms/m365-copilot/topics/resources/#learn","title":"Learn","text":"Resource Description Copilot Adoption Hub Deployment guides, scenarios, and Day in the Life resources Introduction to M365 Copilot Free Microsoft Learn training module Copilot Help &amp; Learning How-to guides for Copilot in M365 apps Prompt Gallery Microsoft-curated prompts for key scenarios"},{"location":"platforms/m365-copilot/topics/resources/#documentation","title":"Documentation","text":"Resource Description M365 Copilot Hub Central documentation hub on Microsoft Learn Copilot Studio Docs Build and customize agents Release Notes Feature updates by platform Copilot Troubleshooters License and connectivity diagnostics"},{"location":"platforms/m365-copilot/topics/resources/#developer-tools","title":"Developer Tools","text":"Resource Description Copilot Studio Build custom agents with connectors and AI Copilot Studio VS Code Extension Build agents from VS Code M365 Developer Center SDKs, samples, and documentation Microsoft 365 Docs on GitHub Open-source documentation repository"},{"location":"platforms/m365-copilot/topics/resources/#stay-updated","title":"Stay Updated","text":"Resource Description Microsoft Copilot Blog Product announcements and feature deep-dives Microsoft 365 Blog Platform updates across M365 Tech Community \u2014 M365 Copilot Community posts and discussions YouTube \u2014 Microsoft 365 Demos, tutorials, and event recordings @MSFTCopilot on X Product updates and tips @Microsoft on X Company updates"},{"location":"platforms/m365-copilot/topics/resources/#service-health","title":"Service Health","text":"Resource Description Microsoft 365 Service Health Real-time service status for M365 Microsoft Service Health Status across all Microsoft cloud services"},{"location":"platforms/openai/","title":"OpenAI / ChatGPT","text":"<p>Guides and resources for working with OpenAI's GPT models.</p>"},{"location":"platforms/openai/#agents","title":"Agents","text":"Guide Description Building Agents on OpenAI ChatGPT Agent Mode, AgentKit, Agents SDK, and Frontier"},{"location":"platforms/openai/#topics","title":"Topics","text":"<ul> <li>OpenAI Overview</li> <li>OpenAI Resources</li> </ul>"},{"location":"platforms/openai/#questions","title":"Questions","text":"<ul> <li>OpenAI Q&amp;A</li> </ul>"},{"location":"platforms/openai/agents/building-agents/","title":"Building Agents on OpenAI","text":"<p>Part of: Build Workflows &gt; Agents</p> <p>OpenAI offers four approaches to building agents, ranging from no-code chat interactions to full programmatic control.</p> Approach Best for Complexity ChatGPT Agent Mode Non-technical users running single-agent tasks in ChatGPT Low \u2014 conversational, no setup required AgentKit Business users building agent workflows with a visual canvas Low to moderate \u2014 no-code visual builder Agents SDK Developers building custom agents with Python or TypeScript Higher \u2014 full programmatic control Frontier Enterprises orchestrating custom, OpenAI, and third-party agents Enterprise \u2014 managed platform (limited availability)"},{"location":"platforms/openai/agents/building-agents/#chatgpt-agent-mode","title":"ChatGPT Agent Mode","text":"<p>Agent Mode is available directly in ChatGPT. It lets ChatGPT autonomously browse the web, run code, analyze files, and take multi-step actions to complete a task \u2014 all from a single conversation.</p> <p>Official docs: ChatGPT Agent Mode</p>"},{"location":"platforms/openai/agents/building-agents/#when-to-use-it","title":"When to use it","text":"<ul> <li>You want a quick, single-agent approach with no setup</li> <li>The task can be completed in one conversation with web browsing, code execution, or file analysis</li> <li>You don't need custom tools, integrations, or multi-agent coordination</li> </ul>"},{"location":"platforms/openai/agents/building-agents/#mapping-your-design-blueprint","title":"Mapping your Design blueprint","text":"Design blueprint ChatGPT Agent Mode Instructions Your message describing what you want done Tools Built-in capabilities (web browsing, code interpreter, file analysis) <p>Agent Mode is best suited for the Prompt execution pattern \u2014 paste your instructions, let ChatGPT execute autonomously, review the output.</p>"},{"location":"platforms/openai/agents/building-agents/#agentkit","title":"AgentKit","text":"<p>AgentKit is OpenAI's modular toolkit for creating, deploying, and refining agent systems using a visual canvas. Agent Builder \u2014 the core creation interface \u2014 lets you design agent workflows by connecting pre-built components without writing code.</p> <p>Official docs: AgentKit guide</p>"},{"location":"platforms/openai/agents/building-agents/#key-capabilities","title":"Key capabilities","text":"<ul> <li>Build \u2014 visual workflow design with integrated models, tools, and logic nodes</li> <li>Deploy \u2014 embed agents into applications using ChatKit</li> <li>Optimize \u2014 evaluation platform for monitoring and improving agent performance</li> </ul>"},{"location":"platforms/openai/agents/building-agents/#who-its-for","title":"Who it's for","text":"<p>Business-oriented users who want to create agent workflows visually. AgentKit bridges the gap between no-code simplicity and the flexibility needed for production agent systems.</p>"},{"location":"platforms/openai/agents/building-agents/#mapping-your-design-blueprint_1","title":"Mapping your Design blueprint","text":"Design blueprint AgentKit Name Agent name in the Builder interface Description Agent purpose and activation context Instructions Agent instructions configured in the visual canvas Model Model selection in the Builder Tools Tool nodes connected in the visual workflow"},{"location":"platforms/openai/agents/building-agents/#agents-sdk","title":"Agents SDK","text":"<p>The Agents SDK is a developer library for building agentic applications with full programmatic control. Agents can use tools, hand off to other specialized agents, stream partial results, and maintain execution traces.</p> <p>Official docs: Agents SDK guide</p>"},{"location":"platforms/openai/agents/building-agents/#language-support","title":"Language support","text":"Language Repository Python openai-agents-python TypeScript/JavaScript openai-agents-js"},{"location":"platforms/openai/agents/building-agents/#key-features","title":"Key features","text":"<ul> <li>Tool integration \u2014 connect agents to external services and data sources</li> <li>Agent-to-agent handoffs \u2014 specialized agents delegate to each other</li> <li>Streaming \u2014 stream intermediate results as the agent works</li> <li>Execution tracing \u2014 full trace of what happened for debugging and monitoring</li> <li>Safety guardrails \u2014 built-in patterns for safe agent behavior</li> </ul>"},{"location":"platforms/openai/agents/building-agents/#mapping-your-design-blueprint_2","title":"Mapping your Design blueprint","text":"Design blueprint Agents SDK Name Agent name in your code Description Agent description and metadata Instructions System prompt and instructions defined programmatically Model Model parameter in agent configuration Tools Tool definitions and integrations <p>For multi-agent workflows, the SDK's handoff mechanism maps directly to the agent handoffs defined in your Design blueprint.</p>"},{"location":"platforms/openai/agents/building-agents/#frontier","title":"Frontier","text":"<p>OpenAI Frontier is an enterprise platform for orchestrating AI agents at scale. It brings together custom agents, OpenAI-built agents, and third-party agents into a unified management layer.</p> <p>Official docs: OpenAI Frontier</p> <p>Limited availability</p> <p>Frontier is currently available to select enterprise customers. Broader availability is expected in the coming months.</p>"},{"location":"platforms/openai/agents/building-agents/#what-it-includes","title":"What it includes","text":"<ul> <li>Custom agents \u2014 agents you build using the Agents SDK or AgentKit</li> <li>OpenAI agents \u2014 pre-built agents from OpenAI for common enterprise tasks</li> <li>Third-party agents \u2014 agents from partner ecosystems integrated into the platform</li> </ul>"},{"location":"platforms/openai/agents/building-agents/#when-to-use-it_1","title":"When to use it","text":"<ul> <li>You need enterprise-grade agent orchestration with governance and compliance</li> <li>Your organization runs multiple agent types (custom, OpenAI, third-party) that need unified management</li> <li>You want a managed platform for deploying and monitoring agents at scale</li> </ul>"},{"location":"platforms/openai/agents/building-agents/#mapping-your-design-blueprint_3","title":"Mapping your Design blueprint","text":"<p>For multi-agent workflows, Frontier provides the orchestration layer:</p> Design blueprint Frontier Specialist agents Custom, OpenAI, or third-party agents configured on the platform Orchestrator Frontier's agent orchestration and management layer Human review gates Enterprise governance and approval workflows"},{"location":"platforms/openai/agents/building-agents/#whats-next","title":"What's Next","text":"<ul> <li>Agents overview \u2014 the platform-agnostic agent decision framework</li> <li>Design Your AI Workflow \u2014 produce the agent blueprint that feeds into these implementations</li> </ul>"},{"location":"platforms/openai/questions/","title":"OpenAI Questions","text":"<p>Questions specific to OpenAI's GPT models, Assistants API, and platform features.</p>"},{"location":"platforms/openai/questions/#questions","title":"Questions","text":"Question Tags Questions will be listed here as they are added"},{"location":"platforms/openai/questions/#related-resources","title":"Related Resources","text":"<ul> <li>OpenAI Topics</li> <li>Agentic Building Blocks</li> </ul>"},{"location":"platforms/openai/topics/","title":"OpenAI","text":"<p>Documentation for OpenAI's GPT models and APIs.</p>"},{"location":"platforms/openai/topics/#topics","title":"Topics","text":"<p>Topics will be listed here as they are added.</p>"},{"location":"platforms/openai/topics/#key-features","title":"Key Features","text":"<ul> <li>GPT-4o - Latest multimodal model</li> <li>Assistants API - Stateful conversation threads</li> <li>Function Calling - Tool use and structured outputs</li> <li>Vision - Image understanding</li> <li>Audio - Speech-to-text and text-to-speech</li> </ul>"},{"location":"platforms/openai/topics/#resources","title":"Resources","text":"<ul> <li>OpenAI Documentation</li> <li>OpenAI Cookbook</li> <li>API Reference</li> </ul>"},{"location":"platforms/openai/topics/resources/","title":"OpenAI Resources","text":"<p>Recommended articles, docs, and courses for OpenAI and GPT models.</p>"},{"location":"platforms/openai/topics/resources/#get-started","title":"Get Started","text":"Resource Description chatgpt.com ChatGPT web app Download ChatGPT Desktop (macOS, Windows) and mobile (iOS, Android) apps Pricing Plans: Free, Go, Plus, Pro, Business, Enterprise"},{"location":"platforms/openai/topics/resources/#learn","title":"Learn","text":"Resource Description OpenAI for Developers Developer hub for APIs, models, and ChatGPT apps OpenAI Cookbook Examples and guides for using the OpenAI API Cookbook on GitHub Source notebooks and community contributions Build for ChatGPT Build apps and experiences for ChatGPT users"},{"location":"platforms/openai/topics/resources/#documentation","title":"Documentation","text":"Resource Description Platform Docs API reference and developer guides API Pricing Token-based pricing for API usage Help Center FAQs, account help, and support ChatGPT Release Notes Product updates and changelog Developer Changelog API and platform updates"},{"location":"platforms/openai/topics/resources/#developer-tools","title":"Developer Tools","text":"Resource Description OpenAI Platform API console, key management, and usage dashboard OpenAI on GitHub Official repositories Python SDK Official Python library for the OpenAI API Node SDK Official JavaScript/TypeScript library Codex Autonomous coding agent"},{"location":"platforms/openai/topics/resources/#stay-updated","title":"Stay Updated","text":"Resource Description OpenAI News Company announcements and product launches Developer Community Forum for questions, guides, and feedback YouTube Product demos, DevDay talks, and tutorials @OpenAI on X Company updates @OpenAINewsroom on X Official press and announcements LinkedIn Company news"},{"location":"platforms/openai/topics/resources/#research-safety","title":"Research &amp; Safety","text":"Resource Description Research Publications and technical reports Safety &amp; Responsibility Safety principles and preparedness framework Safety Evaluations Hub Model safety evaluation results System Status Real-time service monitoring"},{"location":"resources/","title":"Resources","text":"<p>Curated reports and guides from leading AI organizations. Each resource includes a summary, key takeaways, and a downloadable PDF so you always have access \u2014 even if the original link breaks.</p> Resource Source Topic Identifying and Scaling AI Use Cases OpenAI Enterprise AI adoption strategy and the six use case primitives 2026 Agentic Coding Trends Report Anthropic Eight trends reshaping software development with coding agents The Complete Guide to Building Skills for Claude Anthropic End-to-end guide to planning, building, testing, and distributing Claude skills"},{"location":"resources/#how-these-connect-to-the-cookbook","title":"How These Connect to the Cookbook","text":"<p>These resources informed key sections of the cookbook:</p> <ul> <li>OpenAI Use Cases Report \u2014 the foundation for the six use case primitives used throughout the cookbook</li> <li>Anthropic Coding Trends \u2014 context for the Coding use case and Agents building block</li> <li>Anthropic Skills Guide \u2014 the authoritative reference for the Skills building block and Build (Plugins) section</li> </ul>"},{"location":"resources/anthropic-coding-trends/","title":"2026 Agentic Coding Trends Report","text":"<p>Source: Anthropic \u00b7 PDF \u00b7 Published 2026</p>"},{"location":"resources/anthropic-coding-trends/#why-this-matters","title":"Why This Matters","text":"<p>This report captures the shift from AI as a coding assistant to AI as a collaborative development partner. It identifies eight trends across three categories \u2014 foundation, capability, and impact \u2014 that define where agentic coding is heading. If you're building with AI coding tools or managing teams that use them, this is the landscape you're operating in.</p>"},{"location":"resources/anthropic-coding-trends/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>The software development lifecycle is being restructured. Traditional SDLC stages remain, but agent-driven implementation, automated testing, and inline documentation collapse cycle time from weeks to hours. Engineers shift from writing code to orchestrating agents and making architectural decisions.</li> <li>Single agents are evolving into coordinated teams. Multi-agent architectures \u2014 where an orchestrator coordinates specialized sub-agents working in parallel \u2014 handle task complexity that a single agent cannot. This mirrors the orchestrator-workers pattern in human teams.</li> <li>Long-running agents build complete systems. Task horizons are expanding from minutes to days or weeks. Agents can now plan, iterate, and refine across dozens of work sessions, maintaining coherent state throughout complex projects.</li> <li>Human oversight scales through intelligent collaboration. Engineers use AI in roughly 60% of their work but can only \"fully delegate\" 0\u201320% of tasks. Effective AI coding is fundamentally collaborative \u2014 agents learn when to ask for help, and teams build quality control systems that escalate boundary cases to humans.</li> <li>Agentic coding expands beyond engineering. Non-technical roles (product managers, designers, marketers) increasingly use coding agents for prototyping, data analysis, and workflow automation \u2014 extending productivity gains across the organization.</li> <li>Security becomes a first-class concern. Dual-use risk (agents that can build can also introduce vulnerabilities) requires security-first architecture, automated code review, and oversight systems designed for agent-generated code at scale.</li> </ul>"},{"location":"resources/anthropic-coding-trends/#how-the-cookbook-uses-this","title":"How the Cookbook Uses This","text":"<p>This report provides context for the Coding use case primitive and the Agents building block. The multi-agent and orchestrator-workers trends connect directly to the cookbook's workflow architecture patterns, particularly Orchestrator-Workers and Autonomous Agents.</p>"},{"location":"resources/anthropic-coding-trends/#access","title":"Access","text":"<p> Download PDF</p> <p>View original </p>"},{"location":"resources/anthropic-skills-guide/","title":"The Complete Guide to Building Skills for Claude","text":"<p>Source: Anthropic \u00b7 PDF \u00b7 Published 2026</p>"},{"location":"resources/anthropic-skills-guide/#why-this-matters","title":"Why This Matters","text":"<p>Skills are one of the most powerful ways to customize Claude. Instead of re-explaining your preferences, processes, and domain expertise in every conversation, skills let you teach Claude once and benefit every time. This guide is the authoritative reference for building effective skills \u2014 covering structure, design principles, testing, distribution, and real-world patterns.</p>"},{"location":"resources/anthropic-skills-guide/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>A skill is a folder, not a file. At minimum, a skill contains a <code>SKILL.md</code> file with YAML frontmatter and markdown instructions. It can optionally include <code>scripts/</code>, <code>references/</code>, and <code>assets/</code> directories for executable code, documentation, and templates.</li> <li>Progressive disclosure keeps skills efficient. Skills use a three-level system: the YAML frontmatter (always loaded), the SKILL.md body (loaded when relevant), and linked files (loaded on demand). This minimizes token usage while maintaining deep expertise.</li> <li>Two paths through the guide. Standalone skill builders focus on fundamentals, planning, and design. MCP builders also learn how skills layer on top of MCP server connections to add workflows and best practices to raw tool access.</li> <li>Testing is iterative, not one-shot. The guide recommends testing skills across diverse scenarios, edge cases, and different conversation contexts. Expect 15\u201330 minutes to build and test your first working skill.</li> <li>Distribution scales from personal to organizational. Skills work identically across Claude.ai, Claude Code, and the API. Share via file sharing, Git repositories, or plugin marketplaces.</li> <li>Patterns cover common use cases. The guide includes patterns for content generation, code review, data analysis, research workflows, and multi-step processes \u2014 each with structural guidance and troubleshooting tips.</li> </ul>"},{"location":"resources/anthropic-skills-guide/#how-the-cookbook-uses-this","title":"How the Cookbook Uses This","text":"<p>This guide is the primary reference for the Skills building block and directly informs the cookbook's Build (Plugins) section. The skill structure and progressive disclosure concepts appear throughout the cookbook's plugin development guides.</p>"},{"location":"resources/anthropic-skills-guide/#access","title":"Access","text":"<p> Download PDF</p> <p>View original </p>"},{"location":"resources/openai-use-cases-report/","title":"Identifying and Scaling AI Use Cases","text":"<p>Source: OpenAI \u00b7 PDF \u00b7 Published 2025</p>"},{"location":"resources/openai-use-cases-report/#why-this-matters","title":"Why This Matters","text":"<p>This report is the foundation for the cookbook's six use case primitives. OpenAI analyzed over 600 enterprise AI deployments and found that nearly all use cases fall into six categories \u2014 Content Creation, Research, Coding, Data Analysis, Ideation &amp; Strategy, and Automation. Understanding these primitives helps you classify your own workflows and find the right building blocks faster.</p>"},{"location":"resources/openai-use-cases-report/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Six primitives cover nearly all enterprise AI use cases. Rather than treating every AI application as unique, the report groups them into six fundamental types of work that apply across departments and industries.</li> <li>Start with repetitive tasks, skill bottlenecks, and ambiguity. The report identifies three areas where AI delivers immediate value: automating tedious work, bridging expertise gaps between teams, and helping employees navigate open-ended challenges.</li> <li>Leadership sets the pace. Organizations where leadership actively encourages AI adoption see faster results than those relying on bottom-up experimentation alone.</li> <li>Simple use cases beat complex ones for building momentum. Empowering individual employees to find use cases that work for them is often more effective than launching large, complex AI initiatives.</li> <li>Prioritize by impact and feasibility. The report provides a framework for gathering use case ideas from across the organization and ranking them by business value, data readiness, and implementation effort.</li> <li>Department workflow mapping accelerates discovery. Beyond individual use cases, the report recommends mapping entire department workflows to surface systemic AI opportunities.</li> </ul>"},{"location":"resources/openai-use-cases-report/#how-the-cookbook-uses-this","title":"How the Cookbook Uses This","text":"<p>The six primitives from this report are the backbone of the cookbook's Use Cases section. Each primitive has its own page with platform-agnostic examples mapped to Agentic Building Blocks. The report's discovery methodology also influenced the Discover Workflows step of the Business-First AI Framework.</p>"},{"location":"resources/openai-use-cases-report/#access","title":"Access","text":"<p> Download PDF</p> <p>View original </p>"},{"location":"use-cases/","title":"AI Use Cases","text":"<p>OpenAI's analysis of over 600 enterprise AI deployments found that nearly all use cases fall into six primitives. These primitives describe the type of work AI does, not the tools or platforms involved. Understanding them helps you classify your own workflows and find the right building blocks faster.</p> <p>The six primitives and department examples in this section are adapted from OpenAI's Identifying and Scaling AI Use Cases and made platform-agnostic.</p> <p>Connecting to the Framework</p> <p>The Business-First AI Framework helps you find opportunities (Step 1 \u2014 Discover) and deconstruct them into building blocks (Step 2). Use these six primitives to classify the opportunities you find \u2014 they tell you what type of AI work each opportunity involves, which makes choosing the right building blocks easier.</p>"},{"location":"use-cases/#the-six-primitives","title":"The Six Primitives","text":"Primitive What AI Does Typical Building Blocks Example Content Creation Drafts, edits, translates, repurposes Prompt, Context, Skill, Project First-draft blog posts in brand voice Research Searches, synthesizes, structures information Prompt, Context, Agent, MCP Multi-source competitive analysis Coding Generates, debugs, ports, explains code Prompt, Context, Agent Python scripts for non-coders Data Analysis Harmonizes data, identifies trends, visualizes Prompt, Context, Skill Expense analysis across sources Ideation &amp; Strategy Brainstorms, plans, gives feedback, models scenarios Prompt, Context, Project Campaign ideation with constraints Automation Executes repeatable routine tasks with minimal human involvement Skill, Agent, MCP Weekly competitive update pipeline"},{"location":"use-cases/#content-creation","title":"Content Creation","text":"<p>AI drafts, edits, translates, and repurposes content across formats. This is the most common entry point for teams adopting AI \u2014 nearly every department produces written content, and AI can handle first drafts, formatting, and adaptation between audiences.</p> <p>Content creation works best when you provide context (brand voice, style guides, examples) so the AI produces output that matches your standards rather than generic copy.</p> <p> Content Creation detail</p>"},{"location":"use-cases/#research","title":"Research","text":"<p>AI searches, synthesizes, and structures information from multiple sources. Research use cases replace the hours spent gathering, reading, and summarizing \u2014 the AI handles the collection while you focus on judgment and decision-making.</p> <p>Research primitives are particularly powerful when combined with MCP connections to external data sources, letting the AI pull from your actual tools rather than just web search.</p> <p> Research detail</p>"},{"location":"use-cases/#coding","title":"Coding","text":"<p>AI generates, debugs, ports, and explains code. This primitive isn't limited to software engineers \u2014 it extends to anyone who needs to create scripts, formulas, queries, or technical artifacts as part of their work.</p> <p>Coding use cases range from simple formula generation (Excel, SQL) to full application development with agents that plan, write, test, and iterate autonomously.</p> <p> Coding detail</p>"},{"location":"use-cases/#data-analysis","title":"Data Analysis","text":"<p>AI harmonizes data from multiple sources, identifies trends, and produces visualizations. Data analysis use cases turn raw information into structured insights \u2014 the AI handles cleaning, formatting, and pattern recognition while you direct the analysis.</p> <p>This primitive often pairs with coding (generating analysis scripts) and research (interpreting results in context).</p> <p> Data Analysis detail</p>"},{"location":"use-cases/#ideation-strategy","title":"Ideation &amp; Strategy","text":"<p>AI brainstorms ideas, plans approaches, provides feedback, and runs scenario analysis. This is the most collaborative primitive \u2014 AI serves as a thinking partner rather than an executor, helping you explore possibilities you wouldn't consider alone.</p> <p>Ideation works best in project workspaces where the AI has persistent context about your goals, constraints, and past decisions.</p> <p> Ideation &amp; Strategy detail</p>"},{"location":"use-cases/#automation","title":"Automation","text":"<p>AI executes repeatable routine tasks with minimal human involvement. Automation is the highest-autonomy primitive \u2014 once configured, these workflows run on schedule or in response to triggers, producing consistent results without manual intervention.</p> <p>Automation typically builds on the other primitives. A content creation workflow becomes automation when it runs on a schedule. A research workflow becomes automation when it monitors sources continuously.</p> <p> Automation detail</p>"},{"location":"use-cases/#classifying-your-use-cases","title":"Classifying Your Use Cases","text":"<p>When a use case seems to span multiple primitives, identify the primary output to pick the right one:</p> If the main output is... The primary primitive is... Even though it also involves... A written document Content Creation Research to gather source material A structured summary of findings Research Content creation to format the report A working script or application Coding Research to find the right approach Charts, trends, or insights from data Data Analysis Coding to build the analysis A plan, list of options, or recommendation Ideation &amp; Strategy Research to inform the strategy A pipeline that runs without you Automation Any of the above as individual steps <p>Most real workflows combine two or three primitives. The classification helps you find the right starting point and examples \u2014 not a rigid box.</p>"},{"location":"use-cases/#primitives-vs-building-blocks","title":"Primitives vs. Building Blocks","text":"<p>These are different lenses on the same work:</p> Concept What it answers Where to learn more Primitives (this section) What type of work is AI doing? You're here Building Blocks How do you implement it? Agentic Building Blocks Autonomy Levels How much AI involvement? Business-First AI Framework <p>Primitives help you browse use cases by category. Building blocks help you assemble the implementation. Autonomy levels help you decide how much control to hand over. All three work together.</p>"},{"location":"use-cases/#related","title":"Related","text":"<ul> <li>Business-First AI Framework \u2014 find and prioritize AI opportunities</li> <li>Discover Workflows \u2014 structured audit to surface workflow candidates</li> <li>Agentic Building Blocks \u2014 the seven components for implementing AI workflows</li> <li>Build Workflows \u2014 worked examples across the autonomy spectrum</li> <li>Plugin Marketplace \u2014 pre-built agents and skills you can install</li> </ul>"},{"location":"use-cases/automation-resources/","title":"Automation Resources","text":"<p>Curated external resources for the Automation use case.</p> Resource Source Notes"},{"location":"use-cases/automation/","title":"Automation","text":""},{"location":"use-cases/automation/#what-automation-is","title":"What Automation Is","text":"<p>Automation use cases have AI execute repeatable routine tasks with minimal human involvement. Unlike the other primitives where you interact with AI in real time, automation runs on its own \u2014 on a schedule, in response to a trigger, or as part of a pipeline. You configure it once, and it produces consistent results without manual intervention.</p> <p>This is the highest-autonomy primitive. Automation typically builds on the other five primitives: a content creation workflow becomes automation when it runs weekly without prompting. A research workflow becomes automation when it monitors sources continuously. A data analysis workflow becomes automation when it generates reports on a schedule.</p> <p>Automation delivers the largest time savings because it eliminates recurring manual work entirely. But it also requires the most upfront investment in configuration, testing, and monitoring \u2014 you're trusting AI to act independently, so the instructions, guardrails, and error handling need to be robust.</p> <p>Automation is one of six use case primitives identified in OpenAI's Identifying and Scaling AI Use Cases guide. The examples here are adapted to be platform-agnostic and mapped to Agentic Building Blocks.</p>"},{"location":"use-cases/automation/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Runs without real-time human involvement \u2014 the workflow executes on a schedule, trigger, or as part of a pipeline</li> <li>Builds on other primitives \u2014 automation is rarely a primitive by itself; it's the operational wrapper around content creation, research, coding, data analysis, or ideation tasks</li> <li>Requires robust instructions \u2014 since nobody is there to course-correct in real time, the instructions must handle edge cases, errors, and unexpected inputs</li> <li>Monitoring matters \u2014 automated workflows need logging, alerting, and periodic review to ensure they're still producing quality output</li> <li>Compounds over time \u2014 each automated workflow frees up recurring hours, and the savings accumulate week over week</li> </ul>"},{"location":"use-cases/automation/#when-to-apply-this-primitive","title":"When to Apply This Primitive","text":"<p>Use Automation when:</p> <ul> <li>A workflow runs on a predictable schedule (daily, weekly, monthly)</li> <li>The same steps execute with different inputs each time</li> <li>The workflow has clear success criteria that don't require subjective judgment</li> <li>Speed and consistency matter more than creative nuance</li> </ul> <p>NOT the right primitive when:</p> <ul> <li>The task requires real-time human judgment or creative direction (use the underlying primitive directly)</li> <li>The workflow is unpredictable \u2014 different steps, different logic each time</li> <li>You're still iterating on the workflow design (automate after you've proven the process works manually)</li> </ul>"},{"location":"use-cases/automation/#department-examples","title":"Department Examples","text":"Department Use Case What AI Does Typical Building Blocks Marketing Weekly competitive update Monitors competitor sites, compiles changes, and distributes a summary report every Monday Agent, MCP, Skill Sales Lead enrichment pipeline Automatically researches new leads, scores them, and populates CRM fields when leads enter the pipeline Agent, MCP, Skill Finance Recurring report generation Pulls data from accounting systems, generates formatted reports, and distributes to stakeholders on schedule Agent, MCP, Skill HR Onboarding document preparation Generates customized onboarding packets when a new hire is confirmed, pulling role-specific content and formatting Agent, Skill, Context Product Release communication Generates release notes, changelog entries, and customer-facing announcements when new versions are deployed Agent, MCP, Skill IT/Operations System health summaries Aggregates monitoring data, identifies trends, and produces daily operational summaries Agent, MCP, Skill"},{"location":"use-cases/automation/#building-block-patterns","title":"Building Block Patterns","text":"Complexity Building Blocks Example Simple Skill (scheduled) A skill that runs daily to format and distribute yesterday's key metrics from a spreadsheet Intermediate Agent + MCP An agent that monitors a data source via MCP, detects changes, and takes predefined actions Advanced Agent + MCP + multiple Skills A pipeline agent that orchestrates multiple skills \u2014 gathering data, analyzing it, generating content, and distributing results \u2014 all running on a schedule"},{"location":"use-cases/automation/#use-cases","title":"Use Cases","text":"Department Marketing Autonomy level Autonomous Building blocks Agent, MCP, Skill Problem The competitive intelligence report takes 4 hours every Monday \u2014 manually checking competitor websites, noting changes, comparing positioning, and formatting a summary for the team Solution A scheduled agent runs every Sunday night: checks competitor sites via MCP, compares against the previous week's snapshot, generates a structured delta report using a content skill, and posts the summary to the team Slack channel Department Sales Autonomy level Autonomous Building blocks Agent, MCP, Skill Problem New leads sit in the CRM with minimal information \u2014 reps spend the first 15 minutes of every outreach sequence manually researching the company and contact before they can personalize their approach Solution A triggered agent fires when a new lead enters the CRM: researches the company and contact via web search and LinkedIn, scores the lead against ideal customer criteria, and populates CRM fields with enriched data \u2014 so reps start every outreach with full context Department Finance Autonomy level Autonomous Building blocks Agent, MCP, Skill Problem Monthly board reporting requires pulling data from four systems, formatting it into the approved template, calculating variances, and writing commentary \u2014 the same process every month with different numbers Solution A monthly agent pulls data from accounting, CRM, HR, and product analytics via MCP, populates the board report template, calculates period-over-period variances, drafts commentary on significant changes, and places the draft report in the CFO's review folder"},{"location":"use-cases/automation/#common-mistakes","title":"Common Mistakes","text":"<p>Automating before the process is proven. Automate workflows that you've run manually at least several times and are confident work correctly. Automating an untested process just means you'll produce bad output faster and more consistently.</p> <p>No monitoring or alerting. Automated workflows fail silently. Build in logging, periodic output review, and alerting for failures or anomalous results. The worst automation failures are the ones nobody notices for weeks.</p> <p>Over-automating judgment calls. Automation works best for structured, predictable tasks. If a workflow step requires nuanced judgment (should we respond to this complaint? is this data anomaly real or a reporting error?), keep a human in the loop \u2014 even if that means the workflow pauses for review at that step.</p>"},{"location":"use-cases/automation/#related","title":"Related","text":"<ul> <li>AI Use Cases Overview \u2014 all six primitives at a glance</li> <li>Agents \u2014 the building block that powers most automation</li> <li>MCP \u2014 connecting automated workflows to external systems</li> <li>Skills \u2014 reusable routines that agents invoke during automation</li> <li>Scheduling Subagents \u2014 how to schedule automated agents on Claude</li> <li>Build Workflows \u2014 worked examples including autonomous agent workflows</li> <li>Automation Resources \u2014 curated reports, guides, and references</li> </ul>"},{"location":"use-cases/coding-resources/","title":"Coding Resources","text":"<p>Curated external resources for the Coding use case.</p> Resource Source Notes 2026 Agentic Coding Trends Report Anthropic Industry trends and data on AI-assisted coding"},{"location":"use-cases/coding/","title":"Coding","text":""},{"location":"use-cases/coding/#what-coding-is","title":"What Coding Is","text":"<p>Coding use cases have AI generate, debug, port, refactor, and explain code. This primitive extends far beyond traditional software engineering \u2014 it includes anyone who needs to create scripts, formulas, queries, macros, or technical artifacts as part of their work.</p> <p>A marketing manager writing an Excel formula, a data analyst creating a SQL query, an operations lead building a Google Apps Script, and a software engineer writing a microservice \u2014 all of these are coding use cases. The AI handles the translation from intent to working technical implementation.</p> <p>Coding is the primitive where AI agents are most mature. Modern AI coding agents can plan an approach, write code, run tests, debug failures, and iterate \u2014 handling multi-file changes across entire projects with minimal human guidance.</p> <p>Coding is one of six use case primitives identified in OpenAI's Identifying and Scaling AI Use Cases guide. The examples here are adapted to be platform-agnostic and mapped to Agentic Building Blocks.</p>"},{"location":"use-cases/coding/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Output is executable \u2014 the deliverable is code, scripts, formulas, or queries that run and produce results</li> <li>Testable and verifiable \u2014 unlike content or research, code either works or it doesn't, making quality assessment straightforward</li> <li>Amplifies non-technical users \u2014 people who understand what they need but can't write code can now create technical solutions</li> <li>Benefits from iteration \u2014 AI can write, run, see errors, and fix them in a loop, converging on working solutions</li> <li>Context accelerates quality \u2014 existing codebase, documentation, and examples help AI produce code that fits your patterns and standards</li> </ul>"},{"location":"use-cases/coding/#when-to-apply-this-primitive","title":"When to Apply This Primitive","text":"<p>Use Coding when:</p> <ul> <li>The deliverable is something that executes \u2014 code, scripts, formulas, queries, or macros</li> <li>You need to translate a business requirement into a technical implementation</li> <li>You're debugging, refactoring, or porting existing code</li> <li>Non-technical team members need technical artifacts (Excel formulas, SQL queries, simple scripts)</li> </ul> <p>NOT the right primitive when:</p> <ul> <li>The main output is a written document (that's Content Creation)</li> <li>You're analyzing data and the insight is the deliverable, not the analysis code (that's Data Analysis)</li> <li>You're creating a pipeline that runs autonomously (that's Automation \u2014 though coding may be a step within it)</li> </ul>"},{"location":"use-cases/coding/#department-examples","title":"Department Examples","text":"Department Use Case What AI Does Typical Building Blocks Engineering Feature development Plans, writes, tests, and debugs features across multiple files Agent, Context, MCP Marketing Dashboard formulas Creates complex spreadsheet formulas and Google Sheets scripts from plain-language descriptions Prompt, Context Finance Financial models Builds Excel models and Python scripts for scenario analysis Prompt, Context, Skill Sales CRM automation scripts Writes scripts to automate CRM data entry, lead scoring, and pipeline management Prompt, Context, Agent HR Workflow automation Creates Google Apps Scripts or Power Automate flows for approval processes Prompt, Context IT/Operations Infrastructure scripts Generates deployment scripts, monitoring configurations, and automation tooling Agent, Context, MCP"},{"location":"use-cases/coding/#building-block-patterns","title":"Building Block Patterns","text":"Complexity Building Blocks Example Simple Prompt + Context Ask AI to write a VLOOKUP formula, providing the spreadsheet structure as context Intermediate Agent + Context An AI agent that reads your codebase, writes a new feature, runs the tests, and iterates until they pass Advanced Agent + MCP + Context An agent connected to your repository (via MCP) that handles pull requests end-to-end \u2014 writing code, running CI, addressing review comments"},{"location":"use-cases/coding/#use-cases","title":"Use Cases","text":"Department Finance Autonomy level Collaborative Building blocks Prompt, Context Problem Building financial models in Excel takes hours of formula debugging \u2014 nested IF statements, VLOOKUP chains, and array formulas are error-prone and hard to verify Solution Describe the model logic in plain language with sample data as context. AI generates the formulas, explains each step, and troubleshoots errors when the results don't match expectations Department Engineering Autonomy level Autonomous Building blocks Agent, Context, MCP Problem Routine development tasks (bug fixes, test writing, dependency updates, small features) consume senior engineer time that should go to architecture and design Solution An AI coding agent reads the issue, explores the codebase, writes the implementation, runs tests, and creates a pull request. Senior engineers review the output rather than writing it themselves Department Marketing Autonomy level Collaborative Building blocks Prompt, Context, Skill Problem The marketing team needs data pulled from multiple spreadsheets and combined into reports, but they depend on engineering for any formula or script work \u2014 creating a bottleneck Solution A skill that takes a plain-language description of what data to combine and how, generates the appropriate Google Sheets formulas or Apps Script, and explains how to use it. Marketing becomes self-sufficient for routine data tasks"},{"location":"use-cases/coding/#common-mistakes","title":"Common Mistakes","text":"<p>Accepting code without testing it. AI-generated code often works but may have subtle bugs, security issues, or edge cases. Always run the code, verify the output, and test edge cases before deploying \u2014 especially for code that handles sensitive data or runs in production.</p> <p>Providing requirements without examples. \"Build a script that processes our invoices\" is vague. \"Build a script that reads CSV files with columns [date, vendor, amount, category], groups by category, and outputs a summary with totals \u2014 here's a sample file\" produces working code on the first try.</p> <p>Confusing coding with data analysis. If the goal is the insight (what are our spending trends?), the primitive is Data Analysis. If the goal is the tool (build me a script that analyzes spending), the primitive is Coding. The distinction matters because it changes how you evaluate the output.</p>"},{"location":"use-cases/coding/#related","title":"Related","text":"<ul> <li>AI Use Cases Overview \u2014 all six primitives at a glance</li> <li>Agents \u2014 autonomous coding agents that plan, write, test, and iterate</li> <li>Context \u2014 providing codebases, documentation, and examples</li> <li>Data Analysis \u2014 when the insight is the goal, not the code</li> <li>Automation \u2014 when code runs as part of an unattended pipeline</li> <li>Coding Resources \u2014 curated reports, guides, and references</li> </ul>"},{"location":"use-cases/content-creation-resources/","title":"Content Creation Resources","text":"<p>Curated external resources for the Content Creation use case.</p> Resource Source Notes"},{"location":"use-cases/content-creation/","title":"Content Creation","text":""},{"location":"use-cases/content-creation/#what-content-creation-is","title":"What Content Creation Is","text":"<p>Content creation is the most common AI use case primitive. AI drafts, edits, translates, reformats, and repurposes written and visual content \u2014 handling the production work so you can focus on message, strategy, and quality control.</p> <p>This primitive covers any workflow where the primary output is a piece of content: emails, reports, blog posts, social media, presentations, documentation, training materials, and more. The AI handles first drafts, tone adjustments, format conversions, and audience adaptation. You provide direction, context, and final judgment.</p> <p>Content creation use cases scale from simple (rewriting an email for a different audience) to complex (generating a complete content calendar with drafts for each piece, adapted to platform-specific requirements).</p> <p>Content Creation is one of six use case primitives identified in OpenAI's Identifying and Scaling AI Use Cases guide. The examples here are adapted to be platform-agnostic and mapped to Agentic Building Blocks.</p>"},{"location":"use-cases/content-creation/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Output is written or visual content \u2014 the deliverable is something people read, watch, or interact with</li> <li>Quality depends on context \u2014 brand voice, style guides, examples, and audience knowledge dramatically improve output</li> <li>Human review is essential for quality \u2014 AI produces strong first drafts but needs human judgment for nuance, accuracy, and brand alignment</li> <li>Highly reusable \u2014 the same content creation workflow (write a blog post, draft an email, create a summary) runs repeatedly with different inputs</li> <li>Scales across formats \u2014 one piece of source content can be adapted to multiple formats and audiences</li> </ul>"},{"location":"use-cases/content-creation/#when-to-apply-this-primitive","title":"When to Apply This Primitive","text":"<p>Use Content Creation when:</p> <ul> <li>The primary deliverable is a written document, message, or media asset</li> <li>You're producing similar content repeatedly (weekly reports, social posts, email templates)</li> <li>You need to adapt content for different audiences, formats, or languages</li> <li>The task involves editing, proofreading, or reformatting existing content</li> </ul> <p>NOT the right primitive when:</p> <ul> <li>The main goal is gathering and synthesizing information (that's Research)</li> <li>You're generating code, scripts, or technical artifacts (that's Coding)</li> <li>The content is a plan, strategy, or set of recommendations (that's Ideation &amp; Strategy)</li> </ul>"},{"location":"use-cases/content-creation/#department-examples","title":"Department Examples","text":"Department Use Case What AI Does Typical Building Blocks Marketing Social media content calendar Drafts platform-specific posts from a single brief, adapting tone for each channel Prompt, Context, Skill, Project Sales Proposal and pitch decks Generates first-draft proposals using client context and past winning proposals Prompt, Context, Project HR Job descriptions and offer letters Drafts job descriptions from role requirements, ensures consistent format and inclusive language Prompt, Context, Skill Finance Executive summaries Transforms detailed financial reports into concise summaries for leadership Prompt, Context, Skill Product Release notes and changelogs Converts technical commit logs into user-facing release notes Prompt, Context, Skill Legal Contract summaries Produces plain-language summaries of contract terms for non-legal stakeholders Prompt, Context"},{"location":"use-cases/content-creation/#building-block-patterns","title":"Building Block Patterns","text":"Complexity Building Blocks Example Simple Prompt + Context Paste a style guide and ask AI to rewrite an email in brand voice Intermediate Project + Skill A \"Weekly Newsletter\" project with a skill that drafts each edition from bullet-point inputs Advanced Agent + MCP + Skill An agent that pulls data from your CMS, drafts content using a brand-voice skill, and publishes drafts for review"},{"location":"use-cases/content-creation/#use-cases","title":"Use Cases","text":"Department Marketing Autonomy level Collaborative Building blocks Prompt, Context, Skill, Project Problem Writing social posts for each platform takes 3+ hours per campaign \u2014 each channel has different format requirements, character limits, and tone expectations Solution A project workspace with brand guidelines and platform specs as context. A skill takes a single campaign brief and produces platform-adapted drafts for LinkedIn, X, Instagram, and email Department Sales Autonomy level Collaborative Building blocks Prompt, Context, Project Problem Custom proposals take 4-6 hours each because reps start from scratch or copy outdated templates, leading to inconsistent messaging and missed value propositions Solution A proposal project with winning past proposals, product sheets, and pricing guidelines as context. Reps provide client-specific details and get a structured first draft that follows the team's best patterns Department HR Autonomy level Deterministic Building blocks Prompt, Context, Skill Problem Job descriptions are inconsistent across teams \u2014 different formats, missing sections, and language that may not meet inclusivity standards Solution A skill that takes role requirements as input and produces a consistently formatted job description with inclusive language, following the company's standard template and compliance requirements"},{"location":"use-cases/content-creation/#common-mistakes","title":"Common Mistakes","text":"<p>Skipping context and expecting brand-quality output. Generic AI content sounds generic. The difference between \"AI-generated\" and \"AI-assisted\" content is the context you provide \u2014 brand voice docs, examples of good content, audience profiles, and style guides.</p> <p>Using AI for final copy instead of first drafts. AI-generated content should be a starting point, not a finished product. Plan for human review and editing, especially for external-facing content where accuracy and nuance matter.</p> <p>One-size-fits-all content across channels. A LinkedIn post is not a tweet is not a blog paragraph. Effective content creation workflows include format-specific instructions and examples, not just \"make this shorter.\"</p>"},{"location":"use-cases/content-creation/#related","title":"Related","text":"<ul> <li>AI Use Cases Overview \u2014 all six primitives at a glance</li> <li>Prompts \u2014 writing effective instructions for content generation</li> <li>Context \u2014 providing brand voice, style guides, and examples</li> <li>Skills \u2014 packaging content creation workflows for reuse</li> <li>Projects \u2014 persistent workspaces for recurring content workflows</li> <li>Content Creation Resources \u2014 curated reports, guides, and references</li> </ul>"},{"location":"use-cases/data-analysis-resources/","title":"Data Analysis Resources","text":"<p>Curated external resources for the Data Analysis use case.</p> Resource Source Notes"},{"location":"use-cases/data-analysis/","title":"Data Analysis","text":""},{"location":"use-cases/data-analysis/#what-data-analysis-is","title":"What Data Analysis Is","text":"<p>Data analysis use cases have AI harmonize data from multiple sources, identify trends and patterns, and produce visualizations and insights. The AI handles the tedious work \u2014 cleaning, formatting, merging, and pattern recognition \u2014 while you direct the analysis and interpret the results.</p> <p>This primitive covers any workflow where the primary output is an insight derived from data: trend reports, anomaly detection, forecasting, benchmarking, and exploratory analysis. The data can come from spreadsheets, databases, APIs, or documents \u2014 the AI adapts to whatever format you provide.</p> <p>Data analysis is often the highest-value primitive for teams that have data but lack the time or technical skills to extract meaning from it. AI dramatically lowers the barrier to working with data, letting anyone ask questions of their datasets in plain language.</p> <p>Data Analysis is one of six use case primitives identified in OpenAI's Identifying and Scaling AI Use Cases guide. The examples here are adapted to be platform-agnostic and mapped to Agentic Building Blocks.</p>"},{"location":"use-cases/data-analysis/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Output is insights, not raw data \u2014 the deliverable is an interpretation, trend, pattern, or recommendation based on data</li> <li>Source data quality is everything \u2014 AI can't fix garbage data, but it can identify inconsistencies and suggest cleanup steps</li> <li>Exploratory by nature \u2014 the best data analysis is iterative: initial findings suggest new questions worth investigating</li> <li>Visual outputs are powerful \u2014 charts, graphs, and dashboards often communicate insights more effectively than text summaries</li> <li>Combines well with other primitives \u2014 data analysis frequently feeds into content creation (reports), ideation (strategy), and automation (alerting)</li> </ul>"},{"location":"use-cases/data-analysis/#when-to-apply-this-primitive","title":"When to Apply This Primitive","text":"<p>Use Data Analysis when:</p> <ul> <li>You have data and need to extract meaning, patterns, or trends from it</li> <li>You need to harmonize data from multiple sources into a single view</li> <li>The deliverable is a chart, dashboard, trend report, or data-driven recommendation</li> <li>You want to explore a dataset to find what's interesting before deciding what to investigate further</li> </ul> <p>NOT the right primitive when:</p> <ul> <li>The main output is code or a reusable tool for analyzing data (that's Coding)</li> <li>You're gathering qualitative information from documents and sources (that's Research)</li> <li>You're running a data pipeline on a schedule without human involvement (that's Automation)</li> </ul>"},{"location":"use-cases/data-analysis/#department-examples","title":"Department Examples","text":"Department Use Case What AI Does Typical Building Blocks Finance Expense analysis Harmonizes expense data from multiple systems, categorizes spending, and identifies anomalies Prompt, Context, Skill Marketing Campaign performance Combines data from ad platforms, web analytics, and CRM to show what's working and what isn't Prompt, Context, Agent Sales Pipeline analysis Analyzes deal stage durations, conversion rates, and win/loss patterns across the pipeline Prompt, Context, Skill HR Workforce analytics Identifies retention patterns, compensation benchmarks, and headcount trends from HR data Prompt, Context Product Usage analytics Analyzes product usage data to identify adoption patterns, feature engagement, and churn indicators Prompt, Context, Agent Operations Process efficiency Measures cycle times, bottlenecks, and throughput across operational workflows Prompt, Context, Skill"},{"location":"use-cases/data-analysis/#building-block-patterns","title":"Building Block Patterns","text":"Complexity Building Blocks Example Simple Prompt + Context Upload a CSV and ask AI to identify the top trends, outliers, and patterns Intermediate Skill + Context A skill that takes monthly sales data, compares to previous periods, and produces a formatted performance report with charts Advanced Agent + MCP + Skill An agent that pulls data from multiple sources via MCP, harmonizes it, runs analysis, and produces a dashboard with commentary"},{"location":"use-cases/data-analysis/#use-cases","title":"Use Cases","text":"Department Finance Autonomy level Collaborative Building blocks Prompt, Context, Skill Problem Monthly expense reporting requires manually downloading data from three systems, reformatting columns, reconciling categories, and producing summary charts \u2014 a full day of work that delays month-end close Solution A skill that takes the three data exports as input, harmonizes column names and categories, flags discrepancies, and produces a summary report with breakdowns by department, category, and variance from budget Department Marketing Autonomy level Collaborative Building blocks Prompt, Context, Agent Problem Campaign performance data lives in five different platforms (Google Ads, Meta, LinkedIn, HubSpot, GA4), making cross-channel comparison a manual spreadsheet exercise that's always out of date Solution An agent that ingests data exports from each platform, normalizes metrics (impressions, clicks, conversions, cost), and produces a unified performance view with channel comparison and recommendations for budget reallocation Department HR Autonomy level Collaborative Building blocks Prompt, Context Problem Leadership wants quarterly retention and compensation insights but the HR team spends weeks pulling data, anonymizing it, and creating visualizations \u2014 by the time it's ready, the data is already old Solution Upload anonymized HR data and ask AI to analyze retention patterns by department, tenure, and compensation band. AI identifies at-risk segments, produces visualizations, and suggests areas for deeper investigation"},{"location":"use-cases/data-analysis/#common-mistakes","title":"Common Mistakes","text":"<p>Uploading data without explaining what it is. A CSV with columns \"A, B, C, D\" gives the AI nothing to work with. Provide column descriptions, units, time periods, and what questions you want answered. The better you describe your data, the better the analysis.</p> <p>Expecting AI to validate its own analysis. AI can identify patterns, but it can't tell you whether those patterns are meaningful in your business context. A correlation in the data might be a real signal or a coincidence \u2014 that judgment requires your domain expertise.</p> <p>Skipping data cleaning. AI can work with messy data, but inconsistent formats, missing values, and duplicate records will produce unreliable results. Ask AI to identify data quality issues first, fix them, then run the analysis.</p>"},{"location":"use-cases/data-analysis/#related","title":"Related","text":"<ul> <li>AI Use Cases Overview \u2014 all six primitives at a glance</li> <li>Context \u2014 providing datasets and domain knowledge</li> <li>Skills \u2014 packaging analysis workflows for repeatable use</li> <li>Coding \u2014 when the goal is the analysis tool itself, not the insight</li> <li>Automation \u2014 running analysis workflows on a schedule</li> <li>Data Analysis Resources \u2014 curated reports, guides, and references</li> </ul>"},{"location":"use-cases/ideation-and-strategy-resources/","title":"Ideation &amp; Strategy Resources","text":"<p>Curated external resources for the Ideation &amp; Strategy use case.</p> Resource Source Notes"},{"location":"use-cases/ideation-and-strategy/","title":"Ideation &amp; Strategy","text":""},{"location":"use-cases/ideation-and-strategy/#what-ideation-strategy-is","title":"What Ideation &amp; Strategy Is","text":"<p>Ideation and strategy use cases have AI serve as a thinking partner \u2014 brainstorming ideas, planning approaches, providing structured feedback, and running scenario analysis. This is the most collaborative primitive. Rather than producing a finished deliverable, the AI helps you think through problems, explore possibilities, and stress-test your plans.</p> <p>This primitive covers any workflow where the primary output is a set of ideas, a plan, a recommendation, or an evaluation: campaign brainstorming, product roadmap planning, risk analysis, decision frameworks, and structured feedback on drafts or proposals.</p> <p>Unlike the other primitives where AI executes work, ideation and strategy is about augmenting your thinking. The AI brings breadth (more options than you'd generate alone), structure (frameworks and evaluation criteria), and perspective (challenging assumptions you didn't realize you were making).</p> <p>Ideation &amp; Strategy is one of six use case primitives identified in OpenAI's Identifying and Scaling AI Use Cases guide. The examples here are adapted to be platform-agnostic and mapped to Agentic Building Blocks.</p>"},{"location":"use-cases/ideation-and-strategy/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Output is ideas, plans, or evaluations \u2014 the deliverable is thinking, not execution</li> <li>Highly interactive \u2014 the best results come from multi-turn conversations where you refine direction as ideas develop</li> <li>Benefits from constraints \u2014 \"brainstorm marketing ideas\" produces generic results; \"brainstorm marketing ideas for a B2B SaaS launch with a $5K budget targeting enterprise CFOs\" produces actionable ones</li> <li>Persistent context is key \u2014 the more the AI knows about your goals, constraints, past decisions, and domain, the more relevant its suggestions become</li> <li>Pairs with every other primitive \u2014 ideation often precedes content creation, research, coding, or data analysis</li> </ul>"},{"location":"use-cases/ideation-and-strategy/#when-to-apply-this-primitive","title":"When to Apply This Primitive","text":"<p>Use Ideation &amp; Strategy when:</p> <ul> <li>You need to generate options, alternatives, or creative approaches</li> <li>You want structured feedback on a plan, draft, or proposal</li> <li>You're making a decision that requires weighing multiple factors</li> <li>You need to explore scenarios (what if X happens? what are the risks of Y?)</li> </ul> <p>NOT the right primitive when:</p> <ul> <li>You need to find facts or gather information (that's Research)</li> <li>The deliverable is a finished document for an audience (that's Content Creation)</li> <li>You're analyzing numerical data to find patterns (that's Data Analysis)</li> </ul>"},{"location":"use-cases/ideation-and-strategy/#department-examples","title":"Department Examples","text":"Department Use Case What AI Does Typical Building Blocks Marketing Campaign ideation Brainstorms campaign concepts within budget, audience, and brand constraints Prompt, Context, Project Product Feature prioritization Evaluates proposed features against a scoring framework (impact, effort, alignment) Prompt, Context, Project Sales Objection handling Generates responses to common objections, tailored to specific deal contexts Prompt, Context, Skill Finance Scenario modeling Explores what-if scenarios for budget decisions, investments, or pricing changes Prompt, Context, Project Engineering Architecture reviews Evaluates proposed system designs against quality attributes (scalability, security, maintainability) Prompt, Context HR Program design Brainstorms engagement initiatives, training programs, or policy changes with trade-off analysis Prompt, Context, Project"},{"location":"use-cases/ideation-and-strategy/#building-block-patterns","title":"Building Block Patterns","text":"Complexity Building Blocks Example Simple Prompt + Context Share a project brief and ask AI to brainstorm 10 approaches with pros and cons for each Intermediate Project + Context A strategy project with company goals, competitive landscape, and past decisions as persistent context \u2014 every brainstorming session builds on shared knowledge Advanced Project + Agent + Context A strategy project with a feedback agent that evaluates proposals against a scoring rubric, challenges assumptions, and suggests improvements"},{"location":"use-cases/ideation-and-strategy/#use-cases","title":"Use Cases","text":"Department Marketing Autonomy level Collaborative Building blocks Prompt, Context, Project Problem Campaign brainstorming sessions produce safe, repetitive ideas because the team defaults to what worked before \u2014 there's no structured way to explore new directions while staying within brand and budget constraints Solution A strategy project loaded with brand guidelines, past campaign performance data, and audience research. Team members brainstorm with AI that suggests unexpected angles, challenges assumptions, and evaluates ideas against the constraints \u2014 producing a wider range of options than group brainstorming alone Department Product Autonomy level Collaborative Building blocks Prompt, Context, Project Problem Feature prioritization decisions are driven by the loudest voice in the room rather than structured analysis \u2014 the team lacks a consistent framework for evaluating trade-offs Solution A project workspace with the product roadmap, OKRs, user research, and a prioritization framework (RICE, value/effort, or custom). For each proposed feature, AI evaluates it against the framework, identifies risks, and compares it to alternatives \u2014 giving the team data-informed starting points for discussion Department Finance Autonomy level Collaborative Building blocks Prompt, Context, Project Problem Budget planning is a linear process \u2014 the team builds one plan and defends it, rather than exploring multiple scenarios and understanding the trade-offs between them Solution A project with financial data, company goals, and market assumptions as context. AI generates multiple budget scenarios (aggressive growth, conservative, balanced), identifies the key trade-offs between them, and highlights the assumptions each scenario depends on"},{"location":"use-cases/ideation-and-strategy/#common-mistakes","title":"Common Mistakes","text":"<p>Under-constraining the brainstorm. \"Give me ideas\" produces generic output. The more specific your constraints \u2014 budget, timeline, audience, brand, past failures to avoid \u2014 the more creative and useful the AI's suggestions become. Constraints don't limit creativity; they focus it.</p> <p>Treating AI suggestions as decisions. AI is a brainstorming partner, not a decision-maker. It generates options and analysis, but the judgment about which option to pursue requires your understanding of politics, relationships, timing, and context that the AI doesn't have.</p> <p>Forgetting to share context about past decisions. AI will suggest things you've already tried and rejected if it doesn't know your history. Use project workspaces with persistent context so the AI builds on your past thinking rather than starting from scratch every time.</p>"},{"location":"use-cases/ideation-and-strategy/#related","title":"Related","text":"<ul> <li>AI Use Cases Overview \u2014 all six primitives at a glance</li> <li>Projects \u2014 persistent workspaces for ongoing strategic work</li> <li>Context \u2014 providing goals, constraints, and history</li> <li>Prompts \u2014 crafting effective brainstorming and evaluation prompts</li> <li>Discover Workflows \u2014 using ideation to find AI opportunities</li> <li>Ideation &amp; Strategy Resources \u2014 curated reports, guides, and references</li> </ul>"},{"location":"use-cases/research-resources/","title":"Research Resources","text":"<p>Curated external resources for the Research use case.</p> Resource Source Notes"},{"location":"use-cases/research/","title":"Research","text":""},{"location":"use-cases/research/#what-research-is","title":"What Research Is","text":"<p>Research use cases have AI search, synthesize, and structure information from multiple sources. Instead of spending hours reading, comparing, and summarizing, you direct the AI on what to investigate and it handles the collection and organization \u2014 you focus on interpretation and decisions.</p> <p>This primitive covers any workflow where the primary output is structured knowledge: competitive analysis, market research, literature reviews, due diligence reports, vendor comparisons, and internal knowledge synthesis. The AI gathers information, identifies patterns, and presents findings in a format you specify.</p> <p>Research becomes particularly powerful when paired with MCP connections to your actual data sources \u2014 the AI can pull from your CRM, project management tools, internal wikis, and external databases rather than relying solely on web search or uploaded documents.</p> <p>Research is one of six use case primitives identified in OpenAI's Identifying and Scaling AI Use Cases guide. The examples here are adapted to be platform-agnostic and mapped to Agentic Building Blocks.</p>"},{"location":"use-cases/research/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Output is structured knowledge \u2014 findings, summaries, comparisons, or recommendations derived from multiple sources</li> <li>Source quality matters \u2014 the value of research depends on what sources the AI can access and how well it evaluates them</li> <li>Synthesis is the differentiator \u2014 the hard part isn't finding information, it's combining insights from multiple sources into something actionable</li> <li>Benefits from iteration \u2014 initial research reveals new questions worth investigating, making multi-turn conversations more effective than single prompts</li> <li>Scales with tool access \u2014 research that connects to live data sources (via MCP or agents) is vastly more useful than research limited to the model's training data</li> </ul>"},{"location":"use-cases/research/#when-to-apply-this-primitive","title":"When to Apply This Primitive","text":"<p>Use Research when:</p> <ul> <li>You need to gather and compare information from multiple sources</li> <li>The deliverable is a summary, analysis, or structured set of findings</li> <li>You're making a decision that requires understanding a landscape (vendors, competitors, options)</li> <li>You need to monitor ongoing changes in a domain (market shifts, regulatory updates, competitive moves)</li> </ul> <p>NOT the right primitive when:</p> <ul> <li>The main output is a written piece for an audience (that's Content Creation)</li> <li>You're exploring ideas and strategies rather than gathering facts (that's Ideation &amp; Strategy)</li> <li>You're analyzing structured numerical data (that's Data Analysis)</li> </ul>"},{"location":"use-cases/research/#department-examples","title":"Department Examples","text":"Department Use Case What AI Does Typical Building Blocks Marketing Competitive analysis Monitors competitor websites, press releases, and social media for positioning changes Agent, MCP, Skill Product User research synthesis Aggregates feedback from support tickets, surveys, and reviews into themed summaries Prompt, Context, Agent Sales Account research Compiles prospect background, recent news, financial data, and mutual connections before calls Agent, MCP, Skill Legal Regulatory monitoring Tracks regulatory changes relevant to the business and flags items requiring review Agent, MCP Finance Market intelligence Synthesizes analyst reports, earnings calls, and market data into briefings Prompt, Context, Agent IT/Operations Vendor evaluation Compares vendor capabilities, pricing, and reviews against requirements Prompt, Context, Project"},{"location":"use-cases/research/#building-block-patterns","title":"Building Block Patterns","text":"Complexity Building Blocks Example Simple Prompt + Context Upload three analyst reports and ask AI to compare their conclusions on a specific topic Intermediate Project + Agent A research project where an agent searches the web, reads sources, and produces a structured brief Advanced Agent + MCP + Skill An agent that monitors competitor websites via MCP, synthesizes changes weekly, and produces a formatted intelligence report using a skill"},{"location":"use-cases/research/#use-cases","title":"Use Cases","text":"Department Sales Autonomy level Autonomous Building blocks Agent, MCP, Skill Problem Reps spend 30+ minutes researching each prospect before calls \u2014 manually checking LinkedIn, news, company website, and CRM history \u2014 and still miss relevant context Solution An agent that takes a prospect name and company, searches multiple sources (LinkedIn, news, CRM via MCP), and produces a structured one-page brief with company overview, recent events, mutual connections, and suggested talking points Department Marketing Autonomy level Autonomous Building blocks Agent, MCP, Skill Problem Competitive intelligence is always stale \u2014 the team only updates competitive positioning quarterly, missing real-time changes in competitor messaging, pricing, and features Solution A scheduled agent monitors competitor websites and social channels weekly via MCP, compares changes against the previous snapshot, and produces a delta report highlighting what changed and why it matters Department Product Autonomy level Collaborative Building blocks Prompt, Context, Agent Problem User feedback is scattered across support tickets, NPS surveys, app reviews, and Slack channels \u2014 synthesizing it into actionable themes takes days of manual review Solution An agent ingests feedback from multiple sources, categorizes it by theme and sentiment, and produces a prioritized summary with representative quotes and frequency data for each theme"},{"location":"use-cases/research/#common-mistakes","title":"Common Mistakes","text":"<p>Treating AI research as authoritative without verification. AI can synthesize information effectively, but it can also miss nuance, misinterpret sources, or lack access to the most current data. Use AI research as a starting point for human analysis, not a replacement.</p> <p>Asking for research without specifying the decision it supports. \"Research our competitors\" produces generic results. \"Compare our top three competitors' pricing models so we can decide whether to offer a free tier\" produces actionable analysis. Frame research around the decision you need to make.</p> <p>Ignoring source limitations. AI can only research what it can access. If your research requires proprietary databases, paywalled content, or internal systems, you need MCP connections or uploaded documents \u2014 not just a prompt asking the AI to \"look into it.\"</p>"},{"location":"use-cases/research/#related","title":"Related","text":"<ul> <li>AI Use Cases Overview \u2014 all six primitives at a glance</li> <li>Agents \u2014 autonomous AI that can plan and execute multi-step research</li> <li>MCP \u2014 connecting AI to external data sources for live research</li> <li>Context \u2014 providing source documents and background knowledge</li> <li>Automation \u2014 running research workflows on a schedule</li> <li>Research Resources \u2014 curated reports, guides, and references</li> </ul>"},{"location":"use-the-cookbook/","title":"Use the Cookbook","text":"<p>The Hands-on AI Cookbook isn't just a reference site \u2014 it's a toolkit you can use directly inside your AI tools. Cook alone with instant answers and pre-built tools, or cook together in a live cohort course.</p> <ul> <li> <p> Ask (MCP Server)</p> <p>Get instant answers from the cookbook inside Claude, ChatGPT, Claude Code, or any MCP-compatible tool. Connect once, ask anytime.</p> <p> Connect now</p> </li> <li> <p> Build (Plugins)</p> <p>Install pre-built agents and skills that give Claude expert knowledge in business workflows, writing, research, and more.</p> <p> Browse plugins</p> </li> <li> <p> Learn (Courses)</p> <p>Join a cohort course for structured, hands-on learning with live instruction and peer collaboration.</p> <p> Browse courses</p> </li> </ul>"},{"location":"use-the-cookbook/ask/","title":"MCP Server","text":"<p>The Hands-on AI Cookbook is available as an MCP (Model Context Protocol) server, so you can get cookbook-informed answers directly in your AI tools \u2014 no API keys or authentication required.</p> <p>MCP server URL: <code>https://mcp.handsonai.info/mcp</code></p>"},{"location":"use-the-cookbook/ask/#what-you-get","title":"What You Get","text":"<p>The MCP server gives your AI assistant access to:</p> <ul> <li>Search across all cookbook pages by keyword</li> <li>Read the full content of any page</li> <li>Browse sections like Building Blocks, Framework, Use Cases, and more</li> <li>Deep dive into building blocks or framework steps with all sub-pages</li> <li>Q&amp;A lookup with quick answers from the cookbook's question pages</li> <li>Setup guides for every tool in the Builder Stack</li> </ul>"},{"location":"use-the-cookbook/ask/#connect-from-claude","title":"Connect from Claude","text":"<p>Claude supports remote MCP servers as custom connectors across all its products. Add the connector once, and it's available in Claude chat, Claude Desktop, and Cowork.</p>"},{"location":"use-the-cookbook/ask/#claude-claudeai-and-claude-desktop","title":"Claude (claude.ai) and Claude Desktop","text":"<ol> <li>Go to Settings \u2192 Connectors</li> <li>Scroll to the bottom and click Add custom connector</li> <li>Enter the MCP server URL: <code>https://mcp.handsonai.info/mcp</code></li> <li>Click Add</li> </ol> <p>To use it in a conversation, click the + button in the chat input area, select Connectors, and toggle the Hands-on AI Cookbook connector on.</p> <p>Works on Pro, Max, Team, and Enterprise plans</p> <p>Custom connectors are available on all paid Claude plans. Team and Enterprise owners configure connectors in Organization settings \u2192 Connectors, then members enable them individually in their personal settings.</p>"},{"location":"use-the-cookbook/ask/#claude-cowork","title":"Claude Cowork","text":"<p>Once you've added the connector using the steps above, it's automatically available in Cowork. When Cowork runs a task, it can use the cookbook connector to search for relevant content, look up setup guides, or reference building block definitions.</p>"},{"location":"use-the-cookbook/ask/#claude-code","title":"Claude Code","text":"<p>Run this command in your terminal:</p> <pre><code>claude mcp add handsonai-cookbook --transport http https://mcp.handsonai.info/mcp\n</code></pre> <p>That's it. Claude Code will now have access to all cookbook tools in every conversation.</p>"},{"location":"use-the-cookbook/ask/#connect-from-chatgpt","title":"Connect from ChatGPT","text":"<p>ChatGPT supports remote MCP servers as apps. Available on Plus, Pro, Team, Enterprise, and Edu plans.</p> <p>Enable Developer Mode (one-time setup):</p> <ol> <li>Go to Settings \u2192 Apps</li> <li>Under Advanced settings, toggle Developer Mode on</li> </ol> <p>Add the app:</p> <ol> <li>In Settings \u2192 Apps, click Create app</li> <li>Fill in:<ul> <li>Name: Hands-on AI Cookbook</li> <li>URL: <code>https://mcp.handsonai.info/mcp</code></li> </ul> </li> <li>Check the box confirming you trust this application</li> <li>Click Create</li> </ol> <p>Use it in a conversation:</p> <ol> <li>Start a new chat</li> <li>Click + \u2192 More \u2192 Developer Mode</li> <li>Select the Hands-on AI Cookbook app to enable it</li> </ol> <p>Enable per conversation</p> <p>The app must be explicitly added to each new chat session via Developer Mode. It works in both regular chat and Deep Research mode.</p>"},{"location":"use-the-cookbook/ask/#connect-from-other-mcp-clients","title":"Connect from Other MCP Clients","text":"<p>Any MCP client that supports Streamable HTTP transport can connect:</p> <ul> <li>URL: <code>https://mcp.handsonai.info/mcp</code></li> <li>Transport: Streamable HTTP (POST with JSON-RPC 2.0)</li> <li>Authentication: None required (public, read-only)</li> </ul>"},{"location":"use-the-cookbook/ask/#available-tools","title":"Available Tools","text":"Tool Description <code>search_cookbook</code> Search pages by keyword, optionally filtered to a section <code>get_page</code> Get the full content of a specific page by path <code>list_section</code> List all pages in a section (building-blocks, framework, use-cases, etc.) <code>get_building_block</code> Get a building block and all its sub-pages (prompts, agents, mcp, etc.) <code>get_framework_step</code> Get a framework step and all its sub-pages (discover, deconstruct, build) <code>list_questions</code> List all Q&amp;A pages with question text and short answers <code>get_setup_guide</code> Get a Builder Stack setup guide (terminal, editor, git, claude-code, etc.)"},{"location":"use-the-cookbook/ask/#example-prompts","title":"Example Prompts","text":"<p>Once connected, try asking your AI assistant:</p> <ul> <li>\"What are the agentic building blocks?\"</li> <li>\"How do I set up Claude Code?\"</li> <li>\"Search the cookbook for prompt engineering techniques\"</li> <li>\"What's the Business-First AI Framework?\"</li> <li>\"Show me the automation use case\"</li> </ul> <p>The AI will use the cookbook MCP tools to pull relevant content and answer with cookbook knowledge.</p>"},{"location":"use-the-cookbook/ask/#analytics-privacy","title":"Analytics &amp; Privacy","text":"<p>No personally identifiable information is collected</p> <p>This MCP server does not collect personally identifiable information. There are no user accounts, no IP addresses, no cookies, no tracking identifiers, and no conversation content stored \u2014 ever. We cannot identify who you are or what you asked your AI assistant.</p> <p>What is logged: Each MCP tool call records the tool name, search keywords or page path requested, a timestamp, approximate country (from Cloudflare's network), client type (User-Agent header), and response time. Only tool calls and resource reads are logged \u2014 protocol handshake messages are not.</p> <p>Why: We use this aggregate data to understand which topics people search for most and where content gaps exist, so we can create new pages and improve existing ones. The goal is to make the cookbook more useful for everyone.</p> <p>Retention: Analytics data is retained for 12 months, then deleted.</p> <p>Storage: Data is stored in a private database accessible only to the cookbook maintainer. It is never shared, sold, or used for advertising.</p>"},{"location":"use-the-cookbook/build/","title":"Plugin Marketplace","text":""},{"location":"use-the-cookbook/build/#why-plugins","title":"Why Plugins?","text":"<p>Out of the box, Claude is a generalist. It can write, research, and analyze \u2014 but it doesn't know your standards, your workflows, or your preferred formats. Every time you start a new conversation, you'd need to re-explain how you want things done.</p> <p>Plugins solve this. Each plugin packages domain expertise \u2014 writing standards, naming conventions, research processes, editorial criteria \u2014 into a format Claude can use automatically. Install a plugin once and Claude gains that expertise across every session.</p> <p>A plugin can bundle several types of components:</p> <ul> <li>Agents \u2014 Expert personalities that Claude activates automatically. Ask for a LinkedIn post and Claude brings in a writing specialist. Ask for an AI news briefing and a research specialist takes over.</li> <li>Skills \u2014 Step-by-step workflows that teach Claude specific tasks. A skill might encode your editorial standards, your workflow naming conventions, or your documentation templates.</li> <li>Commands \u2014 Slash commands that trigger specific actions (like <code>/commit</code> for git workflows).</li> <li>Hooks \u2014 Automations that run in response to events (e.g., running a linter after every file edit).</li> <li>MCP servers \u2014 Connections to external tools and services (e.g., Notion, GitHub, Slack).</li> </ul> <p>The plugins in this marketplace currently focus on agents and skills. For the full plugin format, see the official Plugin structure overview.</p> <p>The result: Instead of writing long prompts to explain what you want, you describe your goal in plain language and Claude applies the right expertise automatically.</p> <p>New to plugins? Start with the Getting Started guide for a step-by-step walkthrough, or browse the available plugins below.</p>"},{"location":"use-the-cookbook/build/#add-this-marketplace","title":"Add This Marketplace","text":"<p>In your Claude Code session, type this once to register the Hands-on AI marketplace:</p> <pre><code>/plugin marketplace add jamesgray-ai/handsonai\n</code></pre> <p>Then install any plugin below with a single command. All <code>/plugin</code> commands are typed inside Claude Code, not in a regular terminal.</p> <p>For the full details on how marketplaces and plugin installation work, see the official Discover and install plugins documentation.</p>"},{"location":"use-the-cookbook/build/#business-first-ai","title":"Business-First AI","text":"<p>The Business-First AI Framework as executable Claude Code skills. Discover AI workflow opportunities (Step 1), deconstruct workflows into AI building blocks (Step 2), and build working AI workflows (Step 3).</p> <pre><code>/plugin install business-first-ai@handsonai\n</code></pre> Agents included (8) Agent Step What it does <code>workflow-deconstructor</code> 1-3 Orchestrates the end-to-end Discover, Deconstruct, and Build process. Runs candidate discovery, deep deconstruction, design, and build sequentially with file-based handoffs. <code>tech-executive-writer</code> 3 Writes business-focused content about AI and technology. LinkedIn posts, magazine articles, executive briefs, and thought leadership pieces. <code>hbr-editor</code> 3 Reviews drafts against HBR editorial standards. Provides prescriptive feedback on structure, evidence quality, voice, and argument strength. <code>hbr-publisher</code> 3 Formats finalized articles for web publication and PDF distribution. Handles SEO metadata, social snippets, and professional layout. <code>ai-productivity-researcher</code> 3 Finds documented case studies of companies using AI for productivity gains. Prioritizes HBR-caliber sources with quantified outcomes. <code>meeting-prep-researcher</code> 3 Researches meeting attendees and companies, then produces a structured prep brief with profiles, talking points, and suggested questions. <code>ai-news-researcher</code> Utility Scans news outlets, blogs, YouTube channels, podcasts, and communities for the latest AI developments. <code>claude-research-daily</code> Utility Produces a daily brief on Anthropic, Claude, Claude Code, and Cowork from the last 24 hours. Skills included (5) Skill Step What it does <code>discovering-workflows</code> 1 Structured audit of your workflows to discover where AI can help. Produces a categorized opportunity report with structured workflow candidates. <code>deconstructing-workflows</code> 2 Interactively deconstructs a business workflow into a structured Workflow Definition using the 5-question framework. <code>building-workflows</code> 3 Designs the AI implementation (execution pattern, building blocks, skill candidates, agent configs) and constructs the Baseline Workflow Prompt. <code>editing-hbr-articles</code> 3 HBR editorial criteria for article editing. Used by the <code>hbr-editor</code> agent. <code>preparing-meeting-briefs</code> 3 Structured research workflow for meeting preparation. Used by the <code>meeting-prep-researcher</code> agent. Prompts included (3) Prompt What it does <code>linkedin-prospect-research</code> Deterministic prospecting prompt \u2014 finds and qualifies LinkedIn prospects against a buyer persona. <code>buyer-persona-revenue-leader-rachel</code> Example buyer persona used as input to the prospect research workflow. <code>meeting-prep-quick</code> Portable one-shot meeting prep prompt for any AI tool. Example usage <pre><code>\"Help me discover AI workflow opportunities\"\n\u2192 discovering-workflows runs a structured audit and produces an opportunity report\n\n\"I want to deconstruct my client onboarding workflow\"\n\u2192 workflow-deconstructor walks you through the full deconstruction process\n\n\"Write a LinkedIn post about how RAG is transforming enterprise search\"\n\u2192 tech-executive-writer drafts the article\n\n\"Review this article for HBR quality\"\n\u2192 hbr-editor provides structured editorial feedback\n\n\"I have a meeting with Sarah Chen from Acme Corp tomorrow. Help me prepare.\"\n\u2192 meeting-prep-researcher researches the attendee and company, produces a prep brief\n\n\"What's new in AI today?\"\n\u2192 ai-news-researcher scans sources and produces a categorized briefing\n</code></pre>"},{"location":"use-the-cookbook/build/#ai-registry","title":"AI Registry","text":"<p>Document, name, register, and sync AI operational workflows and skills.</p> <p>Note</p> <p>This plugin requires a Notion account and the Notion MCP connector. Without it, Claude can follow the naming and writing conventions but cannot save entries to Notion.</p> <pre><code>/plugin install ai-registry@handsonai\n</code></pre> Skills included Skill What it does <code>naming-workflows</code> Generates consistent, outcome-focused names and descriptions for business workflows. Follows domain-specific naming patterns (Sales, Marketing, Product, etc.) and creates entries in the Notion Workflows database. <code>writing-workflow-sops</code> Writes Standard Operating Procedure documentation for workflows. Adapts SOP templates for Manual, Augmented, and Automated workflow types. Saves SOPs to Notion workflow page bodies. <code>writing-process-guides</code> Writes Business Process Guide documentation explaining when, why, and how to execute a complete business process with its component workflows. Covers strategic context while linking to individual SOPs for tactical details. <code>registering-building-blocks</code> Registers or updates AI building blocks (Skills, Agents, Prompts, Context MDs) in the Notion AI Building Blocks database. Resolves asset type automatically, extracts metadata, generates Quick Start Prompts, and handles duplicate detection. <code>syncing-skills-to-github</code> Syncs skills from <code>~/.claude/skills/</code> to a GitHub repository. Detects changes, generates semantic commit messages, pushes to remote, and updates Notion AI Building Blocks with GitHub URLs. Recommended workflow <ol> <li>Name \u2014 Use <code>naming-workflows</code> to create a consistent workflow entry in Notion</li> <li>Document \u2014 Use <code>writing-workflow-sops</code> to write the SOP for each workflow</li> <li>Connect \u2014 Use <code>writing-process-guides</code> to document how workflows fit together in a business process</li> <li>Register \u2014 Use <code>registering-building-blocks</code> to track building blocks in Notion AI Building Blocks</li> <li>Sync \u2014 Use <code>syncing-skills-to-github</code> to version-control everything in GitHub</li> </ol> <pre><code>\"Name a workflow for drafting email responses\"\n\u2192 naming-workflows generates options and creates a Notion entry\n\n\"Write an SOP for the Email Response Drafting workflow\"\n\u2192 writing-workflow-sops produces a complete SOP in Notion\n\n\"Write a process guide for the Email Management business process\"\n\u2192 writing-process-guides documents the end-to-end process\n\n\"Register the email-response-drafting skill in Notion\"\n\u2192 registering-building-blocks adds it to the AI Building Blocks database\n\n\"Sync all changed skills to GitHub\"\n\u2192 syncing-skills-to-github commits and pushes with Notion tracking\n</code></pre>"},{"location":"use-the-cookbook/build/#quick-reference","title":"Quick Reference","text":"Plugin Agents Skills Prompts Install command <code>business-first-ai</code> 8 5 3 <code>/plugin install business-first-ai@handsonai</code> <code>ai-registry</code> 0 5 0 <code>/plugin install ai-registry@handsonai</code> <p>All plugins are maintained in the handsonai GitHub repository.</p>"},{"location":"use-the-cookbook/build/ai-registry/","title":"AI Registry","text":"<p>Skills for building a structured registry of your AI workflows and skills. This plugin gives Claude the conventions for naming workflows, writing documentation (SOPs and process guides), registering skills in Notion, and syncing everything to GitHub. Use it to build an organized, searchable inventory of your AI operations.</p> <p>Prerequisites</p> <p>This plugin requires a Notion account and the Notion MCP connector. Without it, Claude can follow the naming and documentation conventions but cannot save entries to Notion. See Notion Registry Setup for configuration instructions.</p>"},{"location":"use-the-cookbook/build/ai-registry/#install","title":"Install","text":"<pre><code>/plugin install ai-registry@handsonai\n</code></pre>"},{"location":"use-the-cookbook/build/ai-registry/#components","title":"Components","text":""},{"location":"use-the-cookbook/build/ai-registry/#skills","title":"Skills","text":""},{"location":"use-the-cookbook/build/ai-registry/#naming-workflows","title":"<code>naming-workflows</code>","text":"<p>What it does: Generates consistent, outcome-focused names and descriptions for business workflows, then creates entries in your Notion Workflows database. Follows domain-specific naming patterns so your registry stays organized as it grows.</p> <p>When to use it: Use this when you have a new workflow to document, need to standardize existing workflow names, or want to add a workflow entry to Notion. Also useful when you're not sure what to call a workflow.</p> <p>How it works:</p> <ol> <li>You describe the workflow (what it does, what domain it's in)</li> <li>Claude identifies the domain (Sales, Marketing, Product, Education, Operations, etc.)</li> <li>Claude generates 2-3 name options following the naming pattern for that domain</li> <li>Claude writes a 1-2 sentence description (action + outcome) and suggests a process outcome (the concrete deliverable)</li> <li>Claude searches your Notion Business Processes database to suggest where the workflow fits</li> <li>After you confirm, Claude creates the entry in Notion with all properties filled in</li> </ol> <p>Naming conventions:</p> Domain Pattern Examples Sales [Prospect Type] [Action] Student Enrollment, Lead Qualification Marketing [Content Type] [Action/Purpose] Newsletter Distribution, Content Repurposing Product [Deliverable] [Action] Lesson Content Creation, Exercise Development Education [Student/Cohort] [Activity] Student Onboarding, Live Session Delivery Operations [Function] [Process] Email Response Drafting, Calendar Management <p>Names are always 2-4 words, noun phrases (not verb phrases), in Title Case.</p> <p>Example prompts:</p> <pre><code>\"Name a workflow for drafting email responses\"\n\u2192 Suggests options like \"Email Response Drafting\" with description\n  and process outcome, then creates the Notion entry\n\n\"I need to name a workflow for turning lesson recordings into\nsocial media content\"\n\u2192 Suggests \"Content Repurposing\" (Marketing pattern), writes the\n  description, and creates the entry\n</code></pre> <p>What you'll get: A named workflow entry in your Notion Workflows database with: name, description, process outcome, business process link, sequence number, status, type, and trigger.</p> <p>Platform compatibility: Claude Code \u2713 | Claude.ai \u2713 (Notion MCP required)</p>"},{"location":"use-the-cookbook/build/ai-registry/#writing-workflow-sops","title":"<code>writing-workflow-sops</code>","text":"<p>What it does: Writes Standard Operating Procedure documentation for workflows and saves it directly to the Notion workflow page body. Adapts the SOP template based on whether the workflow is Manual, Augmented, or Automated.</p> <p>When to use it: Use this when you have a workflow entry in Notion and need to document how it's actually executed \u2014 step-by-step procedures, prerequisites, quality checks, and troubleshooting guidance.</p> <p>How it works:</p> <ol> <li>Claude fetches the workflow from Notion to get context (name, description, type, trigger, apps, assets used)</li> <li>Claude asks clarifying questions about the procedure details</li> <li>Claude writes the SOP using a template adapted for the workflow type:<ul> <li>Manual: Detailed human steps with time estimates and exact UI paths</li> <li>Augmented: Steps marked as (AI) or (Human) with clear handoff points</li> <li>Automated: Focus on monitoring, intervention points, and error handling</li> </ul> </li> <li>After your review and approval, Claude updates the workflow page body in Notion</li> </ol> <p>SOP sections:</p> Section Purpose Overview 1-2 sentence summary Prerequisites Access, data, and tools needed Trigger When and how the workflow starts Procedure Step-by-step instructions (action verbs, one action per step) Outputs Deliverables with destinations Quality Checks How to verify success Troubleshooting Common problems and fixes Automation Notes For Augmented/Automated types only <p>Example prompts:</p> <pre><code>\"Write an SOP for the Email Response Drafting workflow\"\n\u2192 Fetches the workflow from Notion, asks about procedure details,\n  produces a complete SOP, and saves it to the workflow page\n\n\"Document how the Student Onboarding workflow works\"\n\u2192 Walks through the SOP writing process, produces Manual-type\n  documentation with detailed steps and time estimates\n</code></pre> <p>What you'll get: A complete SOP saved directly to your Notion workflow page body, with all sections filled in and adapted for the workflow type.</p> <p>Platform compatibility: Claude Code \u2713 | Claude.ai \u2713 (Notion MCP required)</p>"},{"location":"use-the-cookbook/build/ai-registry/#writing-process-guides","title":"<code>writing-process-guides</code>","text":"<p>What it does: Writes Business Process Guide documentation that explains the strategic context and rhythm of a complete business process \u2014 when to execute it, why it matters, and how its component workflows fit together. This is the strategic companion to the tactical SOPs.</p> <p>When to use it: Use this when you need to document how multiple workflows connect into a larger business process. Process guides answer \"when, why, and what order\" while SOPs answer \"how.\"</p> <p>How it works:</p> <ol> <li>Claude fetches the business process from Notion to get context and linked workflows</li> <li>Claude fetches each linked workflow for sequence and trigger details</li> <li>Claude asks clarifying questions about timing and decision points</li> <li>Claude writes the Process Guide using a structured template</li> <li>After your review, Claude updates the business process page body in Notion</li> </ol> <p>Process Guide sections:</p> Section Purpose Purpose Why this process exists and its business impact When to Execute Triggers, frequency, timing Process Overview Visual flow of workflows in sequence Workflow Sequence Each workflow with trigger, duration, and output Decision Points Key choices during the process Success Criteria How to know the process worked Common Pitfalls What typically goes wrong <p>Example prompts:</p> <pre><code>\"Write a process guide for the Email Management business process\"\n\u2192 Fetches the process and its workflows from Notion, documents\n  the end-to-end flow, decision points, and success criteria\n\n\"How do the Student Enrollment and Student Onboarding workflows\nconnect? Document the full process.\"\n\u2192 Creates a process guide showing the workflow sequence,\n  handoffs, and timing\n</code></pre> <p>What you'll get: A complete Business Process Guide saved to your Notion business process page body. Scannable in 2 minutes, focused on the strategic \"when/why/what order\" rather than tactical how-to details.</p> <p>Platform compatibility: Claude Code \u2713 | Claude.ai \u2713 (Notion MCP required)</p>"},{"location":"use-the-cookbook/build/ai-registry/#registering-building-blocks","title":"<code>registering-building-blocks</code>","text":"<p>Migration note</p> <p>This skill replaces <code>registering-skills</code> (v2.0.0). It handles all AI building block types \u2014 Skills, Agents, Prompts, and Context MDs \u2014 using the same registration workflow. If you previously used <code>registering-skills</code>, update your plugin to v3.0.0.</p> <p>What it does: Registers or updates any AI building block \u2014 Skills, Agents, Prompts, or Context MDs \u2014 in your Notion AI Building Blocks database. Automatically resolves the asset type from your request, extracts metadata from the appropriate source file, generates a Quick Start Prompt, checks for duplicates, and creates or updates the registry entry.</p> <p>When to use it: Use this immediately after creating, packaging, or updating any Claude building block to keep your AI Building Blocks database current. Also useful for batch-registering multiple building blocks at once (which can mix asset types).</p> <p>How it works:</p> <ol> <li>Claude resolves the asset type from your request (keywords, file paths, or asks if ambiguous)</li> <li>Claude reads metadata from the appropriate source \u2014 <code>SKILL.md</code> frontmatter for skills, agent <code>.md</code> files for agents, or user input for prompts and context MDs</li> <li>Claude generates a Quick Start Prompt \u2014 a single, copy-paste-ready sentence that demonstrates the building block's primary use case (Context MDs typically skip this)</li> <li>Claude searches your Notion AI Building Blocks database for an existing entry with the exact same name (to prevent duplicates)</li> <li>If found: updates the existing entry with the latest description and Quick Start Prompt</li> <li>If not found: creates a new entry with name, description, asset type, platform (Claude), and Quick Start Prompt</li> </ol> <p>For batch registration, Claude searches for each building block individually first, builds separate update and create lists, then processes them.</p> <p>Example prompts:</p> <pre><code>\"Register the email-response-drafting skill in Notion\"\n\u2192 Reads the SKILL.md, generates a Quick Start Prompt, checks for\n  duplicates, and creates or updates the AI Building Blocks entry\n\n\"Register the cookbook-question-answerer agent in Notion\"\n\u2192 Reads the agent .md file, generates a Quick Start Prompt, and\n  creates an entry with Asset Type = \"Agent\"\n\n\"Register all skills and agents in Notion\"\n\u2192 Batch processes every building block, reporting X created and\n  Y updated (broken down by asset type)\n</code></pre> <p>What you'll get: An entry (or updated entry) in your Notion AI Building Blocks database with: name, description, asset type (Skill, Agent, Prompt, or Context MD), platform, Quick Start Prompt, and GitHub URL (if applicable).</p> <p>Platform compatibility: Claude Code \u2713 | Claude.ai \u2713 (Notion MCP required)</p>"},{"location":"use-the-cookbook/build/ai-registry/#syncing-skills-to-github","title":"<code>syncing-skills-to-github</code>","text":"<p>What it does: Syncs Claude Skills from your local <code>~/.claude/skills/</code> directory to a GitHub repository. Detects changes, generates semantic commit messages, pushes to remote, and updates Notion AI Building Blocks with GitHub URLs.</p> <p>When to use it: Use this after creating or updating skills locally, after exporting skills from cloud to local, or as part of a weekly batch sync. This is Part 2 of the export-to-sync workflow (Part 1 is exporting skills from the cloud to your local machine).</p> <p>How it works:</p> <ol> <li>Detect changes in <code>~/.claude/skills/</code> using git status</li> <li>Review what changed \u2014 new files, modifications, deletions</li> <li>Identify which skill directories are affected</li> <li>Generate semantic commit messages with prefixes: <code>[CREATE]</code>, <code>[UPDATE]</code>, <code>[FIX]</code>, <code>[SYNC]</code>, <code>[RETIRE]</code></li> <li>Commit changes to the local git repository</li> <li>Push to GitHub remote</li> <li>Update Notion AI Building Blocks database with GitHub URLs and set status to \"Deployed\"</li> <li>Regenerate the README.md skill index</li> </ol> <p>Three usage modes:</p> <ul> <li>Single skill sync \u2014 \"Sync the writing-linkedin-posts skill to GitHub\" \u2014 commits and pushes just that skill</li> <li>Batch sync \u2014 \"Sync all changed skills to GitHub\" \u2014 detects all changes, commits everything, updates Notion for each</li> <li>Dry run \u2014 \"Show what would sync to GitHub\" \u2014 previews changes and commit message without actually committing</li> </ul> <p>Example prompts:</p> <pre><code>\"Sync all changed skills to GitHub\"\n\u2192 Detects 3 changes (1 new, 2 modified), generates a batch\n  commit message, pushes, updates Notion for all 3 skills,\n  and regenerates the README\n\n\"Show what would sync to GitHub\"\n\u2192 Previews the changes and generated commit message, asks for\n  confirmation before proceeding\n</code></pre> <p>What you'll get: Skills committed and pushed to GitHub with descriptive commit messages, Notion AI Building Blocks entries updated with GitHub URLs, and an auto-generated README index.</p> <p>Platform compatibility: Claude Code \u2713 (requires terminal access and git credentials)</p>"},{"location":"use-the-cookbook/build/ai-registry/#recommended-workflow","title":"Recommended Workflow","text":"<p>These skills work best in sequence, building from naming through to version control:</p> <ol> <li>Name your workflow \u2014 Use <code>naming-workflows</code> to create a consistent entry in Notion</li> <li>Document the procedure \u2014 Use <code>writing-workflow-sops</code> to write the SOP for the workflow</li> <li>Connect workflows \u2014 Use <code>writing-process-guides</code> to document how workflows fit together in a business process</li> <li>Register your building blocks \u2014 Use <code>registering-building-blocks</code> to track Skills, Agents, Prompts, and Context MDs in the AI Building Blocks database</li> <li>Version control everything \u2014 Use <code>syncing-skills-to-github</code> to push skills to GitHub with Notion tracking</li> </ol>"},{"location":"use-the-cookbook/build/ai-registry/#faq","title":"FAQ","text":"<p>Do I need all five skills? No. Each skill works independently. Start with <code>naming-workflows</code> if you're building a registry from scratch, or <code>registering-building-blocks</code> if you just want to track your existing Claude building blocks (skills, agents, prompts, etc.).</p> <p>What if I don't have Notion set up? Claude will still follow the naming conventions, SOP templates, and documentation patterns \u2014 it just won't save to Notion. See Notion Registry Setup to configure the MCP connector.</p> <p>What's the difference between a Process Guide and an SOP? A Process Guide is strategic: when to execute, why it matters, what order the workflows go in. An SOP is tactical: step-by-step instructions for executing a single workflow. Think of the Process Guide as the playbook and SOPs as the play pages.</p>"},{"location":"use-the-cookbook/build/business-first-ai/","title":"Business-First AI","text":"<p>This plugin implements the Business-First AI Framework as executable Claude Code agents and skills. It covers all three steps: discover where AI fits in your workflows, deconstruct those workflows into AI building blocks, and build working AI workflows \u2014 from context and prompts through skills, agents, and MCP connections. Install it to get a complete toolkit for going from \"where should I use AI?\" to working AI workflows.</p>"},{"location":"use-the-cookbook/build/business-first-ai/#install","title":"Install","text":"<pre><code>/plugin install business-first-ai@handsonai\n</code></pre>"},{"location":"use-the-cookbook/build/business-first-ai/#how-to-use-this-plugin","title":"How to Use This Plugin","text":"<p>How you use this plugin depends on your platform:</p> Claude CodeCoworkClaude.ai <p>Install the plugin and everything is available immediately. Agents activate automatically when your prompt matches \u2014 just describe what you need and Claude handles the rest.</p> <pre><code>/plugin install business-first-ai@handsonai\n</code></pre> <p>Recommended path:</p> <ol> <li>Say \"Help me discover AI workflow opportunities\" \u2192 the <code>discovering-workflows</code> skill runs Step 1</li> <li>Say \"I want to deconstruct my [workflow] into AI building blocks\" \u2192 the <code>workflow-deconstructor</code> agent orchestrates Steps 2 and 3</li> <li>Review your outputs in the <code>outputs/</code> folder</li> </ol> <p>Use this if you have Claude Desktop on macOS. Cowork supports the same plugins as Claude Code through a visual interface \u2014 no terminal needed.</p> <ol> <li>Open Cowork \u2014 launch Claude Desktop and click Cowork in the sidebar</li> <li>Add the plugin \u2014 click the + button, select Add plugins..., then upload the plugin ZIP</li> <li>Use the same prompts as Claude Code \u2014 say \"Help me discover AI workflow opportunities\" for Step 1, or \"I want to deconstruct my [workflow] into AI building blocks\" for Step 2. Claude uses the plugin automatically.</li> </ol> <p>For detailed Cowork setup, see Using Plugins in Cowork.</p> <p>How to get the plugin ZIP</p> <p>The Business-First AI plugin isn't in Cowork's built-in directory yet. Download the plugin folder from GitHub, zip it, and upload to Cowork. Or install via Claude Code first (<code>/plugin install business-first-ai@handsonai</code>) and the plugin files are already on your machine.</p> <p>Individual skills (not agents) can be uploaded to Claude.ai as ZIP files. You need Claude Code installed first to access the skill files.</p> <ol> <li>Install the plugin in Claude Code \u2014 <code>/plugin install business-first-ai@handsonai</code></li> <li>Find the skill folder \u2014 navigate to <code>~/.claude/plugins/marketplaces/handsonai/plugins/business-first-ai/skills/</code></li> <li>Zip the skill you want (e.g., the <code>discovering-workflows</code> folder)</li> <li>Upload it in Claude.ai under Settings &gt; Capabilities &gt; Upload skill</li> <li>Start a new chat \u2014 Claude uses the skill automatically</li> </ol> <p>For detailed upload instructions, see Using Skills in Claude.ai.</p> <p>Agents don't work in Claude.ai</p> <p>The <code>workflow-deconstructor</code> agent (which orchestrates all steps in one session) only works in Claude Code or Cowork. In Claude.ai, upload and run the skills individually: <code>discovering-workflows</code> \u2192 <code>deconstructing-workflows</code> \u2192 <code>building-workflows</code>.</p>"},{"location":"use-the-cookbook/build/business-first-ai/#platform-compatibility","title":"Platform Compatibility","text":"Component Type Claude Code Cowork Claude.ai <code>workflow-deconstructor</code> Agent Yes Yes No <code>discovering-workflows</code> Skill Yes Yes Yes <code>deconstructing-workflows</code> Skill Yes Yes Yes <code>building-workflows</code> Skill Yes Yes Yes <code>tech-executive-writer</code> Agent Yes Yes No <code>hbr-editor</code> Agent Yes Yes No <code>hbr-publisher</code> Agent Yes Yes No <code>ai-productivity-researcher</code> Agent Yes Yes No <code>meeting-prep-researcher</code> Agent Yes Yes No <code>ai-news-researcher</code> Agent Yes Yes No <code>claude-research-daily</code> Agent Yes Yes No <code>editing-hbr-articles</code> Skill Yes Yes No <code>preparing-meeting-briefs</code> Skill Yes Yes Yes <p>Agents activate automatically in Claude Code when your prompt matches. In Cowork, describe your task using the prompts above and Claude activates the right agent. Skills marked \"Yes\" for Claude.ai can be uploaded as ZIP files.</p>"},{"location":"use-the-cookbook/build/business-first-ai/#components","title":"Components","text":""},{"location":"use-the-cookbook/build/business-first-ai/#step-13-full-orchestration","title":"Step 1\u20133 \u2014 Full Orchestration","text":""},{"location":"use-the-cookbook/build/business-first-ai/#workflow-deconstructor","title":"<code>workflow-deconstructor</code>","text":"<p>What it does: Orchestrates the end-to-end Discover, Deconstruct, and Build process. Runs candidate discovery, deep deconstruction, design, and build sequentially, with file-based handoffs between stages so you can also run each step individually in separate conversations.</p> <p>When to use it: Use this when you want to go through the entire process in one session. The agent manages the flow between steps, saves intermediate files, and keeps you involved at each stage. If you prefer to work step-by-step across separate conversations, invoke the individual skills instead.</p> <p>How it works: The agent runs three skills in sequence:</p> <ol> <li>Discover (<code>discovering-workflows</code>) \u2014 Audit your workflows, interview you about your work, and produce an opportunity report with structured candidates. If you already know which workflow to deconstruct, this step is brief.</li> <li>Deconstruct (<code>deconstructing-workflows</code>) \u2014 Interactive deep-dive that decomposes the workflow into refined steps using the 5-question framework. Produces the Workflow Definition.</li> <li>Build (<code>building-workflows</code>) \u2014 Design phase: choose an execution pattern, classify steps, map building blocks, identify skill candidates, configure agents. Construct phase: generate the Baseline Workflow Prompt and auto-generate skills/agents on the Claude platform.</li> </ol> <p>Files are saved to <code>outputs/</code> using kebab-case workflow names (e.g., <code>outputs/lead-qualification-definition.md</code>).</p> <p>Example prompts:</p> <pre><code>\"I want to deconstruct my client onboarding workflow\"\n\u2192 Walks you through all three steps, asking questions during\n  discovery, presenting the analysis for review, and generating\n  the build deliverables\n\n\"People keep dropping off during enrollment. Help me build\na workflow for that.\"\n\u2192 Starts from a problem description, proposes a candidate\n  workflow, then deconstructs and designs it\n\n\"Help me figure out which parts of my weekly reporting process\ncould be automated with AI\"\n\u2192 Decomposes the reporting process, chooses an execution pattern,\n  and identifies quick wins vs. complex automation opportunities\n</code></pre> <p>What you'll get: Multiple files in <code>outputs/</code>:</p> <ol> <li>Opportunity Report \u2014 <code>ai-opportunity-report.md</code> \u2014 categorized opportunities with structured workflow candidates (if generated)</li> <li>Workflow Definition \u2014 <code>[name]-definition.md</code> \u2014 structured decomposition of every step</li> <li>AI Building Block Spec \u2014 <code>[name]-building-block-spec.md</code> \u2014 execution pattern, autonomy classifications, building block mapping, skill candidates, agent configs</li> <li>Baseline Workflow Prompt \u2014 <code>[name]-prompt.md</code> \u2014 ready-to-use prompt (skill-aware if applicable)</li> </ol> <p>Plus auto-generated skills and agents on the Claude platform when the execution pattern calls for them.</p>"},{"location":"use-the-cookbook/build/business-first-ai/#step-1-discover-workflows","title":"Step 1 \u2014 Discover Workflows","text":"<p>Find which workflows are candidates for AI.</p>"},{"location":"use-the-cookbook/build/business-first-ai/#discovering-workflows","title":"<code>discovering-workflows</code>","text":"<p>What it does: Runs a structured audit of your workflows to discover where AI can help. Scans memory and conversation history, interviews you about your work, then produces a prioritized opportunity report with structured workflow candidates ready for the Deconstruct step.</p> <p>When to use it: Use this when you want to figure out where AI fits in your work. Especially useful when you're new to AI and need a starting point, or when you want a systematic review before choosing which workflow to deconstruct.</p> <p>How it works:</p> <ol> <li>Memory &amp; history scan \u2014 Claude reviews everything it knows about you from prior conversations, memory, and project files. Presents findings for you to confirm or correct.</li> <li>Targeted discovery interview \u2014 Claude asks focused questions one at a time about your role, repetitive tasks, information synthesis, multi-step processes, quality issues, communication overhead, and decision-making. Follows up based on your answers.</li> <li>Opportunity analysis &amp; report \u2014 Produces a summary table and detailed opportunity cards grouped by category (Deterministic Workflows, Collaborative AI, Autonomous Agents), ordered by impact.</li> <li>Workflow candidate summary \u2014 You pick your top candidates, and Claude produces structured metadata for each: name, description, category, pain point, AI opportunity, frequency, priority, and reasoning. Recommends which to deconstruct first.</li> </ol> <p>Example prompts:</p> <pre><code>\"Help me discover AI workflow opportunities\"\n\u2192 Runs the full audit and produces a categorized opportunity\n  report with structured workflow candidates\n\n\"I want to figure out which parts of my job could benefit from AI\"\n\u2192 Interactive discovery session followed by a structured report\n  with specific, actionable recommendations\n</code></pre> <p>What you'll get: An opportunity report (<code>outputs/ai-opportunity-report.md</code>) with a summary table, detailed cards for each opportunity, and a structured workflow candidate summary with metadata for each candidate you select.</p> <p>Platform compatibility: Claude Code \u2713 | Claude.ai \u2713</p>"},{"location":"use-the-cookbook/build/business-first-ai/#step-2-deconstruct-workflows","title":"Step 2 \u2014 Deconstruct Workflows","text":"<p>Break workflows into structured definitions.</p>"},{"location":"use-the-cookbook/build/business-first-ai/#deconstructing-workflows","title":"<code>deconstructing-workflows</code>","text":"<p>What it does: Interactively deconstructs a business workflow into a structured Workflow Definition using the 5-question framework. This is the Deconstruct step.</p> <p>When to use it: Use this when you want to thoroughly document a workflow's steps, decisions, data flows, and failure modes. Also useful standalone when you just need a structured breakdown of a complex process \u2014 even without planning to automate it.</p> <p>How it works:</p> <ol> <li>Scenario discovery \u2014 Claude asks about the business scenario, objective, high-level steps, and ownership. One question at a time. If you describe a problem instead of a workflow, Claude proposes a candidate workflow for you to react to.</li> <li>Scope check \u2014 Claude assesses whether this is one workflow or multiple bundled together. If multiple, it recommends splitting and asks which to start with.</li> <li>Name the workflow \u2014 Claude presents 2-3 name options (2-4 word noun phrases, Title Case) and confirms name, description, outcome, trigger, and type.</li> <li>Deep dive \u2014 For each step, Claude probes five dimensions:<ul> <li>Discrete steps (is this actually multiple steps?)</li> <li>Decision points (if/then branches, quality gates)</li> <li>Data flows (inputs, outputs, sources, destinations)</li> <li>Context needs (specific documents, files, reference materials)</li> <li>Failure modes (what happens when this step fails)</li> </ul> </li> <li>Propose and react \u2014 From step 4 onward, Claude proposes a hypothesis across all five dimensions and asks \"What's right, what's wrong, what am I missing?\"</li> <li>Map sequence \u2014 Claude identifies sequential vs. parallel steps and the critical path</li> <li>Consolidate context \u2014 Claude presents a rolled-up \"context shopping list\" of every artifact the workflow needs</li> <li>Generate Workflow Definition \u2014 Claude writes the structured Workflow Definition to the output file</li> </ol> <p>Example prompts:</p> <pre><code>\"Use deconstructing-workflows to break down my expense reporting process\"\n\u2192 Interactive discovery session producing\n  outputs/expense-reporting-definition.md\n\n\"I need to document how our team handles customer escalations\"\n\u2192 Walks through the discovery process, probing for hidden steps\n  and decision points\n</code></pre> <p>What you'll get: A Workflow Definition file (<code>outputs/[name]-definition.md</code>) containing: scenario metadata, refined steps (with sub-steps, decision points, data flows, context needs, and failure modes for each), step sequence and dependencies, and a context shopping list.</p> <p>Platform compatibility: Claude Code \u2713 | Claude.ai \u2713</p>"},{"location":"use-the-cookbook/build/business-first-ai/#step-3-build-workflows","title":"Step 3 \u2014 Build Workflows","text":"<p>Design your AI implementation and construct the workflow.</p>"},{"location":"use-the-cookbook/build/business-first-ai/#building-workflows","title":"<code>building-workflows</code>","text":"<p>What it does: Takes a Workflow Definition and runs the full Build process: Design (execution pattern, autonomy classification, building block mapping, skill candidates, agent configuration) and Construct (Baseline Workflow Prompt, auto-generated skills and agents on Claude). This is the Build step.</p> <p>When to use it: Use this when you have a Workflow Definition (from the Deconstruct step) and want to design and build your AI workflow. The Design phase produces the AI Building Block Spec; the Construct phase generates everything you need to run the workflow.</p> <p>How it works:</p> <p>Design phase:</p> <ol> <li>Load Workflow Definition \u2014 Claude reads the Workflow Definition from <code>outputs/</code></li> <li>Confirm understanding \u2014 Claude summarizes the workflow and asks you to confirm</li> <li>Execution pattern assessment \u2014 Claude walks you through the four execution patterns (Prompt, Skill-Powered Prompt, Single Agent, Multi-Agent) and recommends one based on your workflow's needs</li> <li>Classify each step \u2014 Autonomy level, AI building blocks, tools, human review gates</li> <li>Identify skill candidates \u2014 Steps tagged for skill creation with generation-ready detail</li> <li>Agent configuration (when applicable) \u2014 Platform-agnostic agent blueprint</li> <li>Generate AI Building Block Spec \u2014 Complete design document</li> </ol> <p>Construct phase:</p> <ol> <li>Pattern-specific build path \u2014 Only the steps relevant to your chosen execution pattern</li> <li>Generate Baseline Workflow Prompt \u2014 Self-contained, ready-to-use prompt</li> <li>Auto-generate skills and agents (Claude platform) \u2014 SKILL.md and agent .md files from the Design output</li> </ol> <p>Example prompts:</p> <pre><code>\"Use building-workflows on my workflow definition\"\n\u2192 Reads the most recent Workflow Definition, runs Design and\n  Construct, produces all build deliverables\n\n\"Design and build the expense-reporting workflow\"\n\u2192 Reads outputs/expense-reporting-definition.md, recommends\n  an execution pattern, and generates the full build output\n</code></pre> <p>What you'll get:</p> <ul> <li>AI Building Block Spec (<code>outputs/[name]-building-block-spec.md</code>) \u2014 execution pattern, step classifications, skill candidates, agent configs, implementation order</li> <li>Baseline Workflow Prompt (<code>outputs/[name]-prompt.md</code>) \u2014 self-contained prompt you can run immediately</li> <li>Skills (<code>.claude/skills/*/SKILL.md</code>) \u2014 auto-generated on Claude platform when applicable</li> <li>Agents (<code>.claude/agents/*.md</code>) \u2014 auto-generated on Claude platform when applicable</li> </ul> <p>Platform compatibility: Claude Code \u2713 | Claude.ai \u2713</p>"},{"location":"use-the-cookbook/build/business-first-ai/#tech-executive-writer","title":"<code>tech-executive-writer</code>","text":"<p>What it does: Writes business-focused content about AI and technology, translating complex technical concepts for non-technical audiences. Combines deep technical understanding with executive-level communication skills.</p> <p>When to use it: Use this when you need to write LinkedIn posts, magazine articles, executive briefs, or thought leadership pieces about AI topics. Especially useful when you need to explain technical concepts (like RAG, fine-tuning, or agentic AI) to business leaders.</p> <p>How it works: Claude adopts the persona of a seasoned technology executive with 20+ years of experience and published articles in HBR and MIT Sloan Management Review. It first clarifies your audience, platform, length, and core message, then outlines an approach before drafting. Every piece is optimized for the target format \u2014 LinkedIn posts get strong hooks and hashtags, magazine articles get executive summaries and frameworks, executive briefs lead with recommendations.</p> <p>Example prompts:</p> <pre><code>\"Write a LinkedIn post about how RAG is transforming enterprise search\"\n\u2192 Drafts a 1,200-1,500 character post with a strong opening hook,\n  plain-language explanation of RAG, business implications, and\n  engagement prompt\n\n\"Turn this technical documentation about our ML pipeline into an\narticle suitable for Harvard Business Review\"\n\u2192 Produces a 2,000-4,000 word article with executive summary,\n  concrete analogies, named case studies, and actionable takeaways\n</code></pre> <p>What you'll get: Polished content tailored to your target platform and audience \u2014 ready to publish or use as a strong first draft. LinkedIn posts include hashtag suggestions. Articles include framework structures. Briefs lead with actionable recommendations.</p>"},{"location":"use-the-cookbook/build/business-first-ai/#hbr-editor","title":"<code>hbr-editor</code>","text":"<p>What it does: Reviews business articles against Harvard Business Review editorial standards. Provides prescriptive feedback \u2014 not just what's wrong, but exactly how to fix it.</p> <p>When to use it: Use this when you have a draft article intended for a professional business audience and want publication-quality editorial feedback. Works for thought leadership pieces, feature articles, essays, and book chapters.</p> <p>How it works: Claude adopts the persona of a senior HBR editor with 20+ years of experience. It reads your complete draft, then evaluates it against HBR's specific standards: the \"Big Idea\" test (is the central argument clear and compelling?), audience alignment, structure and flow, evidence quality, and voice. The agent loads the <code>editing-hbr-articles</code> skill for detailed editorial criteria, then provides structured feedback with line-level edits.</p> <p>Example prompts:</p> <pre><code>\"Review this article for HBR quality\"\n\u2192 Reads the full piece, provides an overall assessment, evaluates\n  the central argument, identifies structural issues, flags weak\n  evidence, and delivers line-level edits with before/after examples\n</code></pre> <p>What you'll get: A structured editorial review with: overall assessment, Big Idea evaluation, structure and flow analysis, evidence gaps, voice and language feedback, line-level edits (original \u2192 suggested \u2192 rationale), and a prioritized list of the 3-5 most important revisions.</p>"},{"location":"use-the-cookbook/build/business-first-ai/#hbr-publisher","title":"<code>hbr-publisher</code>","text":"<p>What it does: Formats finalized articles for web publication and PDF distribution. Handles SEO metadata, social media snippets, and professional layout.</p> <p>When to use it: Use this after your article has been through writing and editing stages and is ready for publication. It's the final step in the content pipeline: write \u2192 edit \u2192 publish.</p> <p>How it works: Claude validates that the content is complete (title, author, abstract, body, citations), then produces two outputs. For web, it structures content with proper HTML-semantic headings, creates meta descriptions, suggests tags, adds pull quotes, and writes social media snippets for LinkedIn and X. For PDF, it creates a professionally formatted document with HBR-style headers, title page, typography hierarchy, page numbers, and proper citations.</p> <p>Example prompts:</p> <pre><code>\"The article on leadership trends is edited and ready. Prepare it\nfor publication.\"\n\u2192 Validates completeness, formats for web with SEO metadata and\n  social snippets, creates PDF-ready document with professional\n  layout\n</code></pre> <p>What you'll get: Two deliverables: (1) web-ready Markdown with SEO metadata, structured headings, pull quotes, and social media snippets; (2) a PDF-ready document with professional formatting, title page, and citations.</p>"},{"location":"use-the-cookbook/build/business-first-ai/#ai-productivity-researcher","title":"<code>ai-productivity-researcher</code>","text":"<p>What it does: Finds documented case studies of companies using AI for productivity gains. Prioritizes HBR-caliber sources with quantified outcomes \u2014 suitable for articles, presentations, and executive briefings.</p> <p>When to use it: Use this when you need credible, data-backed examples of enterprise AI adoption for business writing, presentations, or research. Especially useful when building the evidence base for thought leadership pieces.</p> <p>How it works: Claude conducts research across a tiered source hierarchy: Tier 1 (HBR, McKinsey, peer-reviewed journals, earnings calls), Tier 2 (WSJ, FT, TechCrunch, company newsrooms), and Tier 3 (conference presentations, verified LinkedIn posts). For each case study, it captures the company profile, specific AI implementation, quantified outcomes with timeframes, source attribution, and a credibility assessment.</p> <p>Example prompts:</p> <pre><code>\"Find examples of companies using AI agents for customer support\"\n\u2192 Researches documented implementations with specific metrics,\n  company contexts, and credible source citations\n</code></pre> <p>What you'll get: Structured case study briefs with: company profile, AI implementation details, measurable outcomes, full source citations, credibility assessment, and relevance tags. Output format adapts to your need \u2014 executive summary, case study brief, comparative analysis, data table, or annotated bibliography.</p>"},{"location":"use-the-cookbook/build/business-first-ai/#meeting-prep-researcher","title":"<code>meeting-prep-researcher</code>","text":"<p>What it does: Researches meeting attendees and companies, then produces a structured prep brief with profiles, talking points, and suggested questions.</p> <p>When to use it: Use this before any meeting where you need context on the people or company \u2014 sales calls, partnership discussions, interviews, or client meetings. Especially valuable when meeting someone for the first time.</p> <p>How it works: Claude gathers meeting details (who, what company, meeting type, your goal), then researches attendees (LinkedIn, recent posts, public statements, decision-making authority) and the company (recent news, strategic direction, competitive landscape, leadership changes). Findings are synthesized into a scannable brief designed to be read in under 5 minutes. The agent loads the <code>preparing-meeting-briefs</code> skill for the structured research workflow.</p> <p>Example prompts:</p> <pre><code>\"I have a meeting with Sarah Chen from Acme Corp tomorrow.\nHelp me prepare.\"\n\u2192 Researches Sarah's role, recent activity, and conversation\n  starters, plus Acme Corp's recent news, strategy, and\n  competitive position\n</code></pre> <p>What you'll get: A Meeting Prep Brief with: attendee profiles (background, recent activity, conversation starters), company snapshot (what they do, size, recent news, strategic priorities), suggested talking points with rationale, questions that demonstrate preparation and advance your goals, and watch-outs (sensitive topics, potential objections).</p>"},{"location":"use-the-cookbook/build/business-first-ai/#editing-hbr-articles","title":"<code>editing-hbr-articles</code>","text":"<p>What it does: Teaches Claude specific editorial criteria for editing articles to HBR publication quality. Loaded automatically by the <code>hbr-editor</code> agent, but can also be invoked directly.</p> <p>When to use it: Use this when you want Claude to make direct, prescriptive edits to an article rather than just providing feedback. The skill focuses on hands-on editing rather than review.</p> <p>How it works:</p> <ol> <li>Read the article completely before making any edits</li> <li>Assess against HBR editorial criteria (structure, evidence, voice, length)</li> <li>Make direct edits to the file, prioritizing highest-impact issues first</li> <li>Provide an editorial summary: major changes, tightening metrics, and remaining considerations</li> </ol> <p>Example prompts:</p> <pre><code>\"Edit this article to HBR quality\"\n\u2192 Makes direct edits to the file following the priority order,\n  then provides a summary of changes and word count reduction\n</code></pre> <p>What you'll get: Your article file edited in place, plus an editorial summary with major changes listed, word count reduction percentage, and optional improvements for the author to consider.</p> <p>Platform compatibility: Claude Code \u2713</p>"},{"location":"use-the-cookbook/build/business-first-ai/#preparing-meeting-briefs","title":"<code>preparing-meeting-briefs</code>","text":"<p>What it does: Provides a structured research workflow for meeting preparation. Loaded automatically by the <code>meeting-prep-researcher</code> agent, but can also be invoked directly.</p> <p>When to use it: Use this when you want the step-by-step meeting research process without the full agent persona \u2014 useful when you want more control over the research flow.</p> <p>How it works:</p> <ol> <li>Gather meeting details \u2014 attendee name(s), company, meeting type, and your goal</li> <li>Research attendees \u2014 LinkedIn profiles, recent posts, public activity</li> <li>Research company \u2014 recent news (last 90 days), strategic direction, relevant context</li> <li>Synthesize into a formatted Meeting Prep Brief</li> <li>Refine with you \u2014 ask if any section needs more depth or adjustment</li> </ol> <p>Example prompts:</p> <pre><code>\"Research John Park from Stripe before my call on Thursday\"\n\u2192 Walks through the 5-step workflow, producing a scannable brief\n</code></pre> <p>What you'll get: A structured Meeting Prep Brief with attendee profiles, company snapshot, talking points, questions to ask, and watch-outs.</p> <p>Platform compatibility: Claude Code \u2713 | Claude.ai \u2713</p>"},{"location":"use-the-cookbook/build/business-first-ai/#utility","title":"Utility","text":"<p>Agents for staying current on AI developments.</p>"},{"location":"use-the-cookbook/build/business-first-ai/#ai-news-researcher","title":"<code>ai-news-researcher</code>","text":"<p>What it does: Scans news outlets, blogs, YouTube channels, podcasts, and communities for the latest AI developments. Categorizes findings by significance and topic.</p> <p>When to use it: Use this when you want to stay current on AI industry news \u2014 product releases, research papers, company updates, regulatory changes, and notable community discussions. Works as a daily briefing or for targeted research on specific topics.</p> <p>How it works: Claude systematically searches across multiple source tiers: major tech news outlets (TechCrunch, The Verge, Wired), AI-specific publications (The Decoder, Import AI), official company blogs, social media, newsletters (The Batch, Ben's Bites, TLDR AI), community discussions (Hacker News, Reddit), product aggregators, podcasts (Latent Space, Practical AI), and YouTube channels. Each finding is categorized and rated by significance (Major, Notable, Minor).</p> <p>Example prompts:</p> <pre><code>\"What's new in AI today?\"\n\u2192 Produces a categorized news summary covering product releases,\n  research papers, company updates, YouTube content, podcasts,\n  and community highlights\n</code></pre> <p>What you'll get: A categorized news report saved as a Markdown file in <code>ai-news-reports/</code>. Sections include: Product Releases &amp; Updates, Research &amp; Papers, Company Updates (with Anthropic/Claude highlighted), YouTube Content, Podcasts, Community Highlights, and Key Takeaways.</p>"},{"location":"use-the-cookbook/build/business-first-ai/#claude-research-daily","title":"<code>claude-research-daily</code>","text":"<p>What it does: Produces a daily brief on Anthropic, Claude, Claude Code, and Cowork. Covers official announcements, tech news, video content, tutorials, and community discussions from the last 24 hours.</p> <p>When to use it: Use this as a morning briefing to stay current on the Claude ecosystem. Also useful when you need to check if Anthropic has made any recent announcements or when looking for new Claude-related content.</p> <p>How it works: Claude searches official channels first (anthropic.com, GitHub releases), then news sites (TechCrunch, The Verge, Hacker News), community sources (Reddit, developer forums), video content (YouTube channels like AI Explained, Fireship, Matt Wolfe), and newsletters. It strictly filters for content from the last 24 hours \u2014 quiet days are reported as such rather than padded with older content.</p> <p>Example prompts:</p> <pre><code>\"What's the latest news about Claude and Anthropic?\"\n\u2192 Produces a structured daily brief covering top headlines,\n  product updates, notable videos, tutorials, and community buzz\n</code></pre> <p>What you'll get: A daily brief saved as <code>outputs/claude-research-daily-YYYY-MM-DD.md</code>. Sections include: Top Headlines, Product Updates, Notable Videos, Examples &amp; Tutorials, Research &amp; Technical, Quick Links, and Brief Info (sources checked, coverage window).</p>"},{"location":"use-the-cookbook/build/business-first-ai/#prompts","title":"Prompts","text":""},{"location":"use-the-cookbook/build/business-first-ai/#linkedin-prospect-research","title":"<code>linkedin-prospect-research</code>","text":"<p>What it does: A deterministic prospecting prompt that finds and qualifies LinkedIn prospects against a buyer persona. Works with any AI tool \u2014 no plugin required.</p>"},{"location":"use-the-cookbook/build/business-first-ai/#buyer-persona-revenue-leader-rachel","title":"<code>buyer-persona-revenue-leader-rachel</code>","text":"<p>What it does: An example buyer persona used as input to the LinkedIn prospect research workflow. Defines the ideal customer profile for a revenue-focused SaaS leader.</p>"},{"location":"use-the-cookbook/build/business-first-ai/#meeting-prep-quick","title":"<code>meeting-prep-quick</code>","text":"<p>What it does: A portable one-shot meeting prep prompt. Copy and paste into any AI tool for quick meeting preparation without the full agent workflow.</p>"},{"location":"use-the-cookbook/build/business-first-ai/#recommended-workflow","title":"Recommended Workflow","text":"<p>The plugin covers the full Business-First AI Framework. Here's the recommended path:</p> <ol> <li>Discover \u2014 Run <code>discovering-workflows</code> to audit your workflows and identify where AI creates the most value</li> <li>Deconstruct \u2014 Pick your highest-impact candidate and run it through the <code>workflow-deconstructor</code> agent (or use the skills individually: <code>deconstructing-workflows</code> \u2192 <code>building-workflows</code>)</li> <li>Build \u2014 Use the Baseline Workflow Prompt on a real scenario, then build skills in priority order from the recommendations. Study the Step 3 agents and skills as working examples.</li> </ol>"},{"location":"use-the-cookbook/build/business-first-ai/#faq","title":"FAQ","text":"<p>Which step should I start with? Start with Step 1 (Discover) if you're not sure where AI fits in your work. Browse AI Use Cases to see what types of work AI handles \u2014 content creation, research, coding, data analysis, ideation, and automation. Start with Step 2 (Deconstruct) if you already know which workflow you want to automate. Start with Step 3 (Build) if you want to study working examples before deconstructing your own workflows.</p> <p>Can I start from a problem instead of a workflow? Yes. Tell the <code>workflow-deconstructor</code> agent about your problem (e.g., \"people keep dropping off during enrollment\") and it will propose a candidate workflow for you to refine during discovery.</p> <p>What if I lose context mid-conversation? The file-based handoffs mean you can continue in a new conversation. Just invoke the next skill and point it at the file from the previous step (e.g., \"Use deconstructing-workflows on outputs/lead-qualification-definition.md\").</p> <p>What are AI building blocks? The categories used during analysis: Prompt (single instruction), Context (reference material), Skill (multi-step workflow), Agent (autonomous personality), MCP (external tool connection), and Project (workspace configuration). Each step gets mapped to one or more of these.</p> <p>Do I need Claude Code for all of this? No. Skills and agents work differently across platforms \u2014 see the Platform Compatibility table above. All skills and agents work in both Claude Code and Cowork (Claude Desktop on macOS). Skills marked \"Yes\" for Claude.ai can also be uploaded as ZIP files. Agents don't work in Claude.ai \u2014 use the individual skills instead. The prompt templates on the framework pages work in any AI tool \u2014 no plugin required.</p>"},{"location":"use-the-cookbook/build/getting-started/","title":"Getting Started with Plugins","text":"<p>Plugins give Claude domain expertise \u2014 writing standards, naming conventions, research processes \u2014 that it applies automatically. This guide walks you through installing your first plugin in three steps.</p> <p>Not sure what plugins are? Read the Plugin Marketplace overview first.</p>"},{"location":"use-the-cookbook/build/getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Claude Code installed and working (Installation Guide)</li> <li>An active Claude Pro, Max, Team, or Enterprise subscription (plugins are not available on the free plan)</li> </ul>"},{"location":"use-the-cookbook/build/getting-started/#step-1-add-the-marketplace","title":"Step 1: Add the Marketplace","text":"<p>A marketplace is a collection of plugins hosted online. Adding it tells Claude Code where to find plugins you can install. You only need to add it once.</p> <p>In your Claude Code session, type:</p> <pre><code>/plugin marketplace add jamesgray-ai/handsonai\n</code></pre> <p>This tells Claude Code where to find the Hands-on AI plugins. It does not install anything yet. For more on how marketplaces work, see the official Discover and install plugins guide.</p> <p>Tip</p> <p>You can see which marketplaces you've added with <code>/plugin marketplace list</code>.</p>"},{"location":"use-the-cookbook/build/getting-started/#step-2-install-a-plugin","title":"Step 2: Install a Plugin","text":"<p>Browse the Plugin Marketplace to find a plugin that matches your workflow. Each plugin lists the agents and skills it includes.</p> <p>To install a plugin, type the install command shown on the marketplace page in your Claude Code session:</p> <pre><code>/plugin install &lt;plugin-name&gt;@handsonai\n</code></pre> <p>For example:</p> <pre><code>/plugin install business-first-ai@handsonai\n</code></pre> <p>After installing, the plugin's agents and skills are available in your Claude Code session. Installed plugins are stored in <code>~/.claude/plugins/</code> on your machine.</p> <p>Tip</p> <p>You can install as many plugins as you like. They don't conflict with each other.</p>"},{"location":"use-the-cookbook/build/getting-started/#step-3-use-plugin-commands","title":"Step 3: Use Plugin Commands","text":"<p>Installed plugins add agents and skills that Claude Code can use automatically. You don't need to call them by name \u2014 just describe what you need and Claude will use the right agent or skill.</p> <p>Example prompts:</p> <ul> <li>\"Write a LinkedIn post about how RAG is transforming enterprise search\"</li> <li>\"What's new in AI today?\"</li> <li>\"Write an SOP for the Email Response Drafting workflow\"</li> </ul> <p>Each plugin on the marketplace page includes a recommended workflow and example prompts so you know exactly what to ask.</p> <p>Want to use plugins outside Claude Code?</p> <p>Skills from plugins also work in Claude.ai, Claude Cowork, and the Claude API. See Using Plugins for setup instructions on every platform.</p>"},{"location":"use-the-cookbook/build/getting-started/#updating-plugins","title":"Updating Plugins","text":"<p>When a plugin is updated with new agents, skills, or improvements, pull the latest version:</p> <pre><code>/plugin update &lt;plugin-name&gt;@handsonai\n</code></pre> <p>Or update all installed plugins at once:</p> <pre><code>/plugin update --all\n</code></pre>"},{"location":"use-the-cookbook/build/getting-started/#enabling-auto-updates","title":"Enabling Auto-Updates","text":"<p>By default, Claude Code only auto-updates official Anthropic marketplaces. Third-party marketplaces like Hands-on AI have auto-updates disabled, so you won't receive new agents, skills, or fixes automatically.</p> <p>To enable auto-updates for the Hands-on AI marketplace:</p> <ol> <li>Run <code>/plugin</code> to open the plugin manager</li> <li>Select the Marketplaces tab</li> <li>Choose handsonai from the list</li> <li>Select Enable auto-update</li> </ol> <p></p> <p>Once enabled, Claude Code refreshes the marketplace and updates installed plugins each time it starts. If any plugins were updated, you'll see a notification suggesting you restart Claude Code.</p> <p>Tip</p> <p>You can still update manually at any time with <code>/plugin update --all</code> \u2014 auto-update just makes it happen automatically at startup.</p> <p>For more details on auto-update behavior and environment variables, see the official Configure auto-updates documentation.</p>"},{"location":"use-the-cookbook/build/getting-started/#uninstalling","title":"Uninstalling","text":"<p>To remove a plugin you no longer need:</p> <pre><code>/plugin uninstall &lt;plugin-name&gt;@handsonai\n</code></pre> <p>To remove the marketplace entirely:</p> <pre><code>/plugin marketplace remove handsonai\n</code></pre>"},{"location":"use-the-cookbook/build/getting-started/#troubleshooting","title":"Troubleshooting","text":""},{"location":"use-the-cookbook/build/getting-started/#marketplace-not-found","title":"\"Marketplace not found\"","text":"<p>Make sure you've added the marketplace first:</p> <pre><code>/plugin marketplace add jamesgray-ai/handsonai\n</code></pre>"},{"location":"use-the-cookbook/build/getting-started/#plugin-not-found","title":"\"Plugin not found\"","text":"<p>Check the plugin name is spelled correctly and includes the <code>@handsonai</code> suffix:</p> <pre><code># Correct\n/plugin install business-first-ai@handsonai\n\n# Wrong \u2014 missing marketplace suffix\n/plugin install business-first-ai\n</code></pre>"},{"location":"use-the-cookbook/build/getting-started/#permission-denied-or-authentication-errors","title":"\"Permission denied\" or authentication errors","text":"<p>The marketplace is public. If you see authentication errors, check your GitHub CLI configuration (GitHub Setup guide).</p> <p>Run this in your terminal (not inside Claude Code):</p> <pre><code>gh auth status\n</code></pre>"},{"location":"use-the-cookbook/build/getting-started/#plugin-agents-not-appearing","title":"Plugin agents not appearing","text":"<p>After installing a plugin, you may need to restart your Claude Code session for the agents and skills to become available.</p>"},{"location":"use-the-cookbook/build/getting-started/#checking-installed-plugins","title":"Checking installed plugins","text":"<p>List everything you have installed:</p> <pre><code>/plugin list\n</code></pre>"},{"location":"use-the-cookbook/build/using-plugins/","title":"Using Plugins","text":"<p>You've installed a plugin \u2014 now what? This guide explains what plugins give you and how to use them across every Claude surface.</p> <p>Haven't installed a plugin yet?</p> <p>Start with the Getting Started guide \u2014 three quick steps.</p>"},{"location":"use-the-cookbook/build/using-plugins/#what-you-get-after-installing-a-plugin","title":"What You Get After Installing a Plugin","text":"<p>The plugin format supports agents, skills, commands, hooks, and MCP server connections. The Hands-on AI plugins currently provide:</p> <ul> <li>Agents \u2014 Expert personalities that Claude activates automatically based on your request. For example, ask for a LinkedIn post and Claude brings in a writing specialist.</li> <li>Skills \u2014 Step-by-step workflows (an instruction file plus optional reference material) that teach Claude how to do specific tasks. For example, a skill might teach Claude your company's naming conventions.</li> </ul> <p>As the plugins grow, they may also include commands, hooks, and connectors \u2014 but you don't need to worry about that now. Describe what you need and Claude picks the right agent or skill.</p>"},{"location":"use-the-cookbook/build/using-plugins/#agents-vs-skills","title":"Agents vs Skills","text":"Agents Skills What they are Expert personalities (writing style, domain knowledge, process) Step-by-step workflows with instructions + reference material How they activate Claude automatically picks the right one based on your request Automatically when relevant, or type <code>/plugin-name:skill-name</code> Where they work Claude Code only Claude Code, Claude.ai (upload as ZIP), and Claude Cowork Example \"Write a LinkedIn post about RAG\" activates <code>tech-executive-writer</code> \"Name a workflow for drafting email responses\" loads <code>naming-workflows</code> naming conventions"},{"location":"use-the-cookbook/build/using-plugins/#using-plugins-in-claude-code","title":"Using Plugins in Claude Code","text":""},{"location":"use-the-cookbook/build/using-plugins/#agents-just-talk-naturally","title":"Agents \u2014 just talk naturally","text":"<p>Describe what you need. Claude Code matches your request to the right agent automatically.</p> <p>Examples from the <code>business-first-ai</code> plugin:</p> <pre><code>\"Write a LinkedIn post about how RAG is transforming enterprise search\"\n\u2192 tech-executive-writer activates\n\n\"Review this article for HBR quality\"\n\u2192 hbr-editor activates\n\n\"What's new in AI today?\"\n\u2192 ai-news-researcher activates\n</code></pre> <p>Claude Code shows which agent it selected at the top of the response. You can list all available agents with <code>/agents</code>.</p>"},{"location":"use-the-cookbook/build/using-plugins/#skills-natural-language-or-slash-commands","title":"Skills \u2014 natural language or slash commands","text":"<p>Skills activate the same way \u2014 describe what you need and the relevant skill loads automatically.</p> <p>You can also invoke a skill directly with a slash command:</p> <pre><code>/ai-registry:naming-workflows\n</code></pre> <p>The format is <code>/plugin-name:skill-name</code>.</p> <p>Examples:</p> Plugin Slash command What it does <code>ai-registry</code> <code>/ai-registry:naming-workflows</code> Generates consistent workflow names and creates Notion entries <code>ai-registry</code> <code>/ai-registry:writing-workflow-sops</code> Writes Standard Operating Procedure docs for workflows <code>business-first-ai</code> <code>/business-first-ai:editing-hbr-articles</code> Loads HBR editorial criteria for article editing <p>Note</p> <p>Skills from the <code>ai-registry</code> plugin require the Notion MCP connector to be configured. Without it, Claude can follow the naming conventions and draft the output, but cannot read from or write to Notion.</p>"},{"location":"use-the-cookbook/build/using-plugins/#checking-whats-installed","title":"Checking what's installed","text":"<pre><code>/plugin list\n</code></pre> <p>This shows all installed plugins with their agents and skills. For the full plugin management commands (scopes, updates, disabling), see the official Discover and install plugins documentation.</p>"},{"location":"use-the-cookbook/build/using-plugins/#using-skills-in-claudeai-web","title":"Using Skills in Claude.ai (Web)","text":"<p>Claude.ai supports skills through a ZIP upload process. You can take any plugin skill and use it on the web \u2014 no terminal required.</p>"},{"location":"use-the-cookbook/build/using-plugins/#prerequisites","title":"Prerequisites","text":"<ul> <li>Claude Pro, Max, Team, or Enterprise plan</li> <li>Code execution enabled in Settings &gt; Capabilities (this lets Claude run skills \u2014 it does not give Claude access to your computer)</li> </ul>"},{"location":"use-the-cookbook/build/using-plugins/#upload-a-plugin-skill-to-claudeai","title":"Upload a plugin skill to Claude.ai","text":"<p>1. Find the skill on your machine</p> <p>After adding the marketplace (<code>/plugin marketplace add jamesgray-ai/handsonai</code>), all plugin skills are stored locally at:</p> <pre><code>~/.claude/plugins/marketplaces/handsonai/plugins/&lt;plugin-name&gt;/skills/&lt;skill-name&gt;/\n</code></pre> <p>Each skill is a folder containing <code>SKILL.md</code> and optional reference files.</p> <p>2. Zip the skill folder</p> Terminal command (quick)Finder (visual) <p>Open Terminal and paste this command, replacing <code>&lt;plugin-name&gt;</code> and <code>&lt;skill-name&gt;</code> with the actual names:</p> <pre><code>cd ~/.claude/plugins/marketplaces/handsonai/plugins/&lt;plugin-name&gt;/skills &amp;&amp; \\\n  zip -r ~/Desktop/&lt;skill-name&gt;.zip &lt;skill-name&gt;/\n</code></pre> <p>Concrete example for <code>editing-hbr-articles</code>:</p> <pre><code>cd ~/.claude/plugins/marketplaces/handsonai/plugins/business-first-ai/skills &amp;&amp; \\\n  zip -r ~/Desktop/editing-hbr-articles.zip editing-hbr-articles/\n</code></pre> <p>The ZIP file appears on your Desktop.</p> <ol> <li>Open Finder</li> <li>From the menu bar, click Go \u2192 Go to Folder... (or press Cmd + Shift + G)</li> <li>Paste this path and press Enter:    <pre><code>~/.claude/plugins/marketplaces/handsonai/plugins/\n</code></pre></li> <li>Open the plugin folder (e.g., <code>business-first-ai</code>), then <code>skills</code></li> <li>Right-click the skill folder (e.g., <code>editing-hbr-articles</code>) and choose Compress</li> </ol> <p>Common mistake</p> <p>Zip the folder itself, not the individual files inside it. When you open the ZIP, you should see a single folder (e.g., <code>editing-hbr-articles/</code>) \u2014 not loose files.</p> <p>3. Upload to Claude.ai</p> <p>Go to Settings &gt; Capabilities &gt; Upload skill. Select your <code>.zip</code> file.</p> <p>4. Toggle the skill on</p> <p>Find your uploaded skill in the Skills list and enable it.</p> <p>5. Start using it</p> <p>Open a new chat and describe your need. Claude automatically uses the skill when relevant.</p>"},{"location":"use-the-cookbook/build/using-plugins/#walkthrough-editing-hbr-articles-in-claudeai","title":"Walkthrough: <code>editing-hbr-articles</code> in Claude.ai","text":"<p>The <code>editing-hbr-articles</code> skill is the most portable skill in the marketplace \u2014 no external dependencies.</p> <ul> <li>Plugin: <code>business-first-ai</code></li> <li>Path: <code>~/.claude/plugins/marketplaces/handsonai/plugins/business-first-ai/skills/editing-hbr-articles/</code></li> <li>Contents: <code>SKILL.md</code> and <code>references/editorial-criteria.md</code></li> <li>Terminal zip command: <pre><code>cd ~/.claude/plugins/marketplaces/handsonai/plugins/business-first-ai/skills &amp;&amp; \\\n  zip -r ~/Desktop/editing-hbr-articles.zip editing-hbr-articles/\n</code></pre></li> <li>Test prompt in Claude.ai: \"Edit this article for HBR quality\" \u2014 then paste your draft</li> </ul> <p>Claude applies the editorial criteria from the skill's reference file automatically.</p>"},{"location":"use-the-cookbook/build/using-plugins/#what-about-agents-in-claudeai","title":"What about agents in Claude.ai?","text":"<p>In Claude Code, Claude automatically picks the right agent for your request. This automatic selection does not exist in Claude.ai.</p> <p>Agent files have a different format from skill files and cannot be uploaded as skills directly. For agent-like behavior in Claude.ai, you can:</p> <ul> <li>Create a Project and paste the agent's instructions as custom instructions</li> <li>Convert the agent into a skill (wrap its instructions in a <code>SKILL.md</code> file)</li> </ul>"},{"location":"use-the-cookbook/build/using-plugins/#skill-compatibility-across-platforms","title":"Skill compatibility across platforms","text":"<p>Most skills work fully across Claude Code, Claude.ai, Claude Desktop, and Cowork. A few skills require terminal or git access and are limited to Claude Code.</p> Skill Claude Code Claude.ai Desktop / Cowork Notes <code>editing-hbr-articles</code> Full Full Full Pure instructions + reference doc <code>naming-workflows</code> Full Full Full Reads/writes Notion across all platforms <code>writing-workflow-sops</code> Full Full Full Reads/writes Notion across all platforms <code>writing-process-guides</code> Full Full Full Reads/writes Notion across all platforms <code>registering-building-blocks</code> Full Full Full Reads/writes Notion across all platforms <code>syncing-skills-to-github</code> Full No No Requires terminal + git access"},{"location":"use-the-cookbook/build/using-plugins/#using-plugins-in-claude-cowork","title":"Using Plugins in Claude Cowork","text":"<p>Cowork is a visual workspace inside the Claude Desktop app (macOS) designed for non-technical work \u2014 writing, research, analysis, and project coordination. You set the goal and Claude delivers finished, professional work. It's available on Claude Pro, Max, Team, and Enterprise plans.</p> <p>Cowork has its own built-in plugin directory, so you don't need Claude Code or a terminal to use plugins. The directory includes plugins across productivity, marketing, legal, finance, data analysis, and more \u2014 browse the full catalog at claude.com/plugins-for/cowork.</p>"},{"location":"use-the-cookbook/build/using-plugins/#install-a-plugin-in-cowork","title":"Install a plugin in Cowork","text":"<ol> <li>Open Claude Desktop and click Cowork in the sidebar</li> <li>Click the + button at the bottom of the screen (next to \"Work in a folder\")</li> <li>Select Add plugins... from the menu</li> <li>Browse the plugin directory or upload a custom plugin file</li> </ol> <p>You can also click the Customize with plugins card on the Cowork home screen to go directly to plugin setup.</p> <p></p>"},{"location":"use-the-cookbook/build/using-plugins/#what-cowork-offers-with-plugins","title":"What Cowork offers with plugins","text":"<ul> <li>Plugins bundle skills, connectors, slash commands, and sub-agents</li> <li>Cowork coordinates parallel workstreams and delivers professional outputs (Excel, PowerPoint, formatted docs)</li> <li>Pairs with Claude in Chrome for browser-based tasks</li> <li>Pairs with MCP connectors for external tool access (e.g., Notion)</li> <li>Plugins are saved locally to your machine</li> </ul>"},{"location":"use-the-cookbook/build/using-plugins/#cowork-vs-claude-code","title":"Cowork vs Claude Code","text":"Cowork Claude Code Interface Visual \u2014 no terminal needed Terminal-based Plugin discovery + button &gt; Add plugins... or plugin directory <code>/plugin install</code> command Agent activation Via plugin commands Auto-routing based on request Best for Knowledge workers, non-technical users Developers, coding tasks Plugin format Same plugin files Same plugin files <p>Both support the same plugin format and skill files. If you're not comfortable with the terminal, Cowork is the recommended path.</p>"},{"location":"use-the-cookbook/build/using-plugins/#using-skills-via-the-claude-api","title":"Using Skills via the Claude API","text":"For developers <p>Skills can be used programmatically through the Claude API in two ways.</p>"},{"location":"use-the-cookbook/build/using-plugins/#skills-api","title":"Skills API","text":"<p>Upload custom skills via the <code>/v1/skills</code> endpoints, then reference them by <code>skill_id</code> in conversations:</p> <pre><code>import anthropic\n\nclient = anthropic.Anthropic()\n\n# Reference an uploaded skill by ID\nresponse = client.messages.create(\n    model=\"claude-sonnet-4-20250514\",\n    max_tokens=4096,\n    skill_ids=[\"sk_editing-hbr-articles\"],\n    messages=[\n        {\"role\": \"user\", \"content\": \"Edit this article for HBR quality:\\n\\n[article text]\"}\n    ]\n)\n</code></pre>"},{"location":"use-the-cookbook/build/using-plugins/#system-prompt-approach","title":"System prompt approach","text":"<p>Alternatively, embed the content of <code>SKILL.md</code> (and any reference files) directly in the <code>system</code> parameter:</p> <pre><code>import anthropic\n\nclient = anthropic.Anthropic()\n\n# Read SKILL.md content\nwith open(\"editing-hbr-articles/SKILL.md\") as f:\n    skill_content = f.read()\n\nwith open(\"editing-hbr-articles/references/editorial-criteria.md\") as f:\n    criteria = f.read()\n\nresponse = client.messages.create(\n    model=\"claude-sonnet-4-20250514\",\n    max_tokens=4096,\n    system=f\"{skill_content}\\n\\n## Reference: Editorial Criteria\\n\\n{criteria}\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Edit this article for HBR quality:\\n\\n[article text]\"}\n    ]\n)\n</code></pre> <p>Note</p> <p>MCP-dependent skills (like <code>registering-building-blocks</code> or <code>syncing-skills-to-github</code>) won't work via the raw API since they require tool integrations that the API alone doesn't provide.</p>"},{"location":"use-the-cookbook/build/using-plugins/#platform-summary","title":"Platform Summary","text":"Capability Claude Code Claude.ai Cowork API Plugin install <code>/plugin install</code> Upload skills as ZIP + button &gt; Add plugins... Skills API Agent auto-routing Yes No No No Skills (auto-trigger) Yes Yes (after upload) Yes (via plugin) Yes (Skills API) Skills (slash command) <code>/plugin-name:skill-name</code> No <code>/</code> commands No MCP / Connectors Yes Some skills (via MCP) Yes (connectors) No Browser automation No No Yes (Chrome) No Reference file loading Automatic Included in ZIP Automatic (via plugin) Manual Best for Developers Quick skill use, any device Knowledge work, non-technical users Programmatic access"},{"location":"use-the-cookbook/build/using-plugins/#troubleshooting","title":"Troubleshooting","text":""},{"location":"use-the-cookbook/build/using-plugins/#i-installed-a-plugin-but-nothing-happens","title":"\"I installed a plugin but nothing happens\"","text":"<p>Restart your Claude Code session. Then verify the plugin is installed:</p> <pre><code>/plugin list\n</code></pre> <p>If the plugin appears but agents don't activate, try being more explicit in your prompt \u2014 for example, \"Write a LinkedIn post about AI\" rather than just \"write something.\"</p>"},{"location":"use-the-cookbook/build/using-plugins/#skill-not-working-in-claudeai","title":"\"Skill not working in Claude.ai\"","text":"<ol> <li>Check that code execution is enabled in Settings &gt; Capabilities</li> <li>Check the compatibility table \u2014 some skills require MCP connectors that Claude.ai doesn't support</li> <li>Make sure the skill is toggled on in your Skills list</li> </ol>"},{"location":"use-the-cookbook/build/using-plugins/#zip-upload-failed","title":"\"ZIP upload failed\"","text":"<ul> <li>The ZIP must contain a folder with <code>SKILL.md</code> inside it \u2014 not loose files at the root</li> <li>The <code>name</code> field in <code>SKILL.md</code> frontmatter must use only lowercase letters, numbers, and hyphens</li> <li>The ZIP file should not exceed the upload size limit</li> </ul>"},{"location":"use-the-cookbook/build/using-plugins/#cant-find-skill-files","title":"\"Can't find skill files\"","text":"<p>If you've added the marketplace, skill files are on your machine at:</p> <pre><code>~/.claude/plugins/marketplaces/handsonai/plugins/&lt;plugin-name&gt;/skills/&lt;skill-name&gt;/\n</code></pre> <p>Not sure which plugin a skill belongs to?</p> <p>Run <code>/plugin list</code> in Claude Code to see all installed plugins with their skills listed.</p> <p>You can also browse skill source files on GitHub. The Plugin Marketplace links each skill name directly to its source folder, or use this URL pattern:</p> <pre><code>https://github.com/jamesgray-ai/handsonai/tree/main/plugins/&lt;plugin-name&gt;/skills/&lt;skill-name&gt;/\n</code></pre>"},{"location":"use-the-cookbook/build/using-plugins/#next-steps","title":"Next Steps","text":"<ul> <li>Getting Started \u2014 install your first plugin (if you haven't already)</li> <li>Plugin Marketplace \u2014 browse available plugins and see what each one does</li> <li>Notion Registry setup \u2014 required for <code>ai-registry</code> skills that save to Notion</li> </ul>"},{"location":"blog/archive/2026/","title":"2026","text":""},{"location":"blog/category/announcements/","title":"Announcements","text":""}]}